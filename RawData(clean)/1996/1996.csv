"1996 Index IEEE Transactions on Parallel and Distributed Systems vol. 7,"""",,""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""12"",""1"",""11"",""This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index."",""1558-2183"","""",""10.1109/TPDS.1996.553313"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=553313"","""","""","""","""","""","""",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;
"A broadcast algorithm for all-port wormhole-routed torus networks,""Yih-Jia Tsai";" P. K. McKinley"",""Department of Computer Science, Michigan State University, East Lansing, MI, USA";" Department of Computer Science, Michigan State University, East Lansing, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""8"",""876"",""885"",""A new approach to broadcast in wormhole-routed two- and three-dimensional torus networks is proposed. The underlying network is assumed to support only deterministic, dimension-ordered unicast routing. The approach extends the graph theoretical concept of dominating nodes by accounting for the relative distance-insensitivity of the wormhole routing switching strategy. The proposed algorithm also takes advantage of an all-port communication architecture, which allows each node to simultaneously transmit messages on different outgoing channels. The resulting broadcast operation is based on a tree structure that uses multiple levels of extended dominating nodes(EDNs). Performance results are presented that confirm the advantage of this method over other approaches."",""1558-2183"","""",""10.1109/71.532118"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=532118"","""",""Broadcasting";Unicast;Routing;Concurrent computing;Network topology;Communication switching;Tree data structures;Computer networks;Distributed computing;"Message passing"","""",""31"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A concurrent architecture for serializable production systems,""J. N. Amaral";" J. Ghosh"",""Electrical Engineering Department, Pntificia Univesidade Católica do Rio Grande do Sul (PUCRS), Porto Alegre, Rio Grande do Sul, Brazil";" Department of Electrical and Computer Engineering, University of Texas, Austin, Austin, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""12"",""1265"",""1280"",""This paper presents a new production system architecture that takes advantage of modern associative memory devices to allow parallel production firing, concurrent matching, and overlap among matching, selection, and firing of productions. We prove that the results produced by the architecture are correct according to the serializability criterion. A comprehensive event driven simulator is used to evaluate the scaling properties of the new architecture and to compare it with a parallel architecture that does global synchronization before every production firing. We also present measures for the improvement in speed due to the use of associative memories and an estimate for the amount of associative memory needed. Architectural evaluation is facilitated by a new benchmark program that allows for changes in the number of productions, the size of the database, the variance between the sizes of local data clusters, and the ratio between local and global data. Our results indicate that substantial improvements in speed can be achieved with a very modest increase in hardware cost."",""1558-2183"","""",""10.1109/71.553276"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=553276"","""",""Production systems";Associative memory;Parallel architectures;Costs;Discrete event simulation;Velocity measurement;Databases;Hardware;Commutation;"Engines"","""",""4"","""",""45"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A dynamic coherence protocol for distributed shared memory enforcing high data availability at low costs,""O. E. Theel";" B. D. Fleisch"",""IRISA/INRIA de Rennes, Rennes, France";" Department of Computer Science, University of California, Riverside, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""9"",""915"",""930"",""DSM coherence protocols should scale well for large networks. Fault-tolerance in terms of highly available data access and uninterrupted DSM service is needed in large-scale environments that have a greater number of potentially malfunctioning components. We present a new class of dynamic coherence protocols for DSM systems in error-prone networks whose instances offer highly available access to DSM data at low operation costs. The approach is based on the highly scalable Boundary-Restricted (BR) coherence protocol class. The new protocol class, called the Dynamic Boundary-Restricted (DBR) coherence protocol class, maintains read/write frequencies of DSM requests at run-time. This information is used to dynamically adjust the minimum number of cached copies of a single DSM page in order to guarantee a given degree of data availability. The description of the new protocol class is accompanied by an analysis covering a large variety of workloads. This analysis presents the overall savings achieved by using a DBR coherence protocol in comparison to a static BR protocol."",""1558-2183"","""",""10.1109/71.536936"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=536936"","""",""Availability";Access protocols;Costs;Coherence;Large-scale systems;Distributed Bragg reflectors;Monitoring;Power system reliability;Scalability;"Fault tolerance"","""",""16"","""",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A family of interconnection networks for nonuniform traffic,""D. M. Koppelman"",""Electrical and Computer Engineering Depavtment, Louisiana State University, Baton Rouge, LA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""5"",""486"",""492"",""New networks, called GLO networks, are constructed by adding bus-like links to omega networks, providing additional capacity between cells on momentarily busy paths. Equivalent pin-count GLO and omega networks offered uniform and nonuniform traffic were simulated. GLO networks exhibited lower latency for nonuniform traffic and light to moderate uniform traffic."",""1558-2183"","""",""10.1109/71.503773"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=503773"","""",""Multiprocessor interconnection networks";Telecommunication traffic;Traffic control;Delay;Throughput;Computer networks;Switches;Pins;Concurrent computing;"Analytical models"","""","""","""",""13"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A fast, efficient parallel-acting method of generating functions defined by power series, including logarithm, exponential, and sine, cosine,""D. M. Mandelbaum";" S. G. Mandelbaum"",""168 Hollingston Pl., East Windsor, NJ, USA";" 168 Hollingston Pl., East Windsor, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""1"",""33"",""45"",""A fundamental parallel procedure of implementing certain algorithms is by means of trees and arrays. A method of generating any function defined by a power series in a fast, efficient parallel-acting manner using trees and arrays is described. The power series considered can be written as f(Y)=a/sub 0/+a/sub 1/Y+a/sub 2/Y/sup 2/+...where Y=v/sub 1/x+V/sub 2/x/sup 2/+...+v/sub k/x/sup k/,v/sub i/=(0, 1), is a binary fraction when x=1/2. The power series must be expanded into individual terms cx/sup 1/. These terms are then transformed into weighted binary terms. Two methods are given to obtain all the individual terms (including coefficients) associated with each power of x. The hardware required for implementation is a tree similar to a Wallace or Dadda tree used for parallel multiplication of two binary numbers. Despite the multiplicity of terms required, Boolean logic methods reduce the tree dimensions in many cases so that the total tree required is smaller than an existing multiplier tree. In that case, Schwarz and Flynn (1993), have shown that the required tree can be superimposed on the existing multiplier tree in a multiplexed manner with relatively little increase in hardware. The generation of the logarithmic function is described in detail. Comparisons with other methods are made for the case of 11 bit accuracy of the logarithm. Using a figure of merit of latency times area (number of transistors), estimates show that the superposition scheme gives the best (smallest) figure of merit. For 11 bit accuracy, the superposition scheme requires only about 480 additional gates to be superimposed upon a 41 bit or larger multiplier, and the speed of operation is that of the multiplier."",""1558-2183"","""",""10.1109/71.481596"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=481596"","""",""Power generation";Hardware;Boolean functions;Delay;Partitioning algorithms;Concurrent computing;"Power generation economics"","""",""12"","""",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"A flexible bit-pattern associative router for interconnection networks,""D. H. Summerville"; J. G. Delgado-Frias;" S. Vassiliadis"",""Electrical Engineering Department, State University of New York, Binghamton, NY, USA"; Electrical Engineering Department, State University of New York, Binghamton, NY, USA;" Electrical Engineering Department, Delft University of Technnology, Delft, Netherlands"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""5"",""477"",""485"",""A programmable associative approach to execute implicit routing algorithms is presented. Algorithms are mapped onto a set of bit-patterns that are matched in parallel. We have studied and mapped a large number of routing algorithms for a wide range of interconnection network topologies. Here we report three cases that illustrate the capabilities of the router scheme. For the studied topologies, the number of required bit-patterns is of the same order as the topology degree. The proposed approach is one of the fastest routers and requires a very small amount of hardware."",""1558-2183"","""",""10.1109/71.503772"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=503772"","""",""Multiprocessor interconnection networks";Routing;Network topology;Decoding;Senior members;Hardware;Delay;Table lookup;Associative memory;"Throughput"","""",""20"","""",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"A framework for designing deadlock-free wormhole routing algorithms,""R. V. Boppana";" S. Chalasani"",""Division of Computer Science, University of Technology, San Antonio, TX, USA";" Department of Electrical and Computer Engineering, University of Wisconsin-Madison, Madison, WI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""2"",""169"",""183"",""This paper presents a framework to design fully-adaptive, deadlock-free wormhole algorithms for a variety of network topologies. The main theoretical contributions are: (a) design of new wormhole algorithms using store-and-forward algorithms, (b) a sufficient condition for deadlock free routing by the wormhole algorithms so designed, and (c) a sufficient condition for deadlock free routing by these wormhole algorithms with centralized flit buffers shared among multiple channels. To illustrate the theory, several wormhole algorithms based on store-and-forward hop schemes are designed. The hop-based wormhole algorithms can be applied to a variety of networks including torus, mesh, de Brujin, and a class of Cayley networks, with the best known bounds on virtual channels for minimal routing on the last two classes of networks. An analysis of the resource requirements and performances of a proposed algorithm, called negative-hop algorithm, with some of the previously proposed algorithms for torus and mesh networks is presented."",""1558-2183"","""",""10.1109/71.485506"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485506"","""",""Algorithm design and analysis";System recovery;Routing;Communication switching;Communication channels;Sufficient conditions;Mesh networks;Network topology;Buffer storage;"Performance analysis"","""",""42"",""3"",""43"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A framework for resource-constrained rate-optimal software pipelining,""R. Govindarajan"; E. R. Altman;" G. R. Gao"",""Supercomputer Education and Research Cen-ter Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India"; IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA;" School of Computer Science, McGill University, Montreal, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""11"",""1133"",""1149"",""The rapid advances in high-performance computer architecture and compilation techniques provide both challenges and opportunities to exploit the rich solution space of software pipelined loop schedules. In this paper, we develop a framework to construct a software pipelined loop schedule which runs on the given architecture (with a fixed number of processor resources) at the maximum possible iteration rate (a la rate-optimal) while minimizing the number of buffers-a close approximation to minimizing the number of registers. The main contributions of this paper are: First, we demonstrate that such problem can be described by a simple mathematical formulation with precise optimization objectives under a periodic linear scheduling framework. The mathematical formulation provides a clear picture which permits one to visualize the overall solution space (for rate-optimal schedules) under different sets of constraints. Secondly, we show that a precise mathematical formulation and its solution does make a significant performance difference. We evaluated the performance of our method against three leading contemporary heuristic methods. Experimental results show that the method described in this paper performed significantly better than these methods. The techniques proposed in this paper are useful in two different ways: 1) As a compiler option which can be used in generating faster schedules for performance-critical loops (if the interested users are willing to trade the cost of longer compile time with faster runtime). 2) As a framework for compiler writers to evaluate and improve other heuristics-based approaches by providing quantitative information as to where and how much their heuristic methods could be further improved."",""1558-2183"","""",""10.1109/71.544355"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=544355"","""",""Pipeline processing";Processor scheduling;Computer architecture;Space technology;Optimized production technology;Registers;Computer science;Computer Society;Senior members;"Visualization"","""",""40"",""1"",""40"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"A modular systolic linearization of the Warshall-Floyd algorithm,""J. F. Myoupo";" A. C. Fabret"",""LaRlA, Faculté de Mathématique et dE28099lnformatique, Université de Picardie Jules Verne, Amiens, France";" Université Paris Sud, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""5"",""449"",""455"",""In this paper, we use a variant of the geometric method to derive efficient modular linear systolic algorithms for the transitive closure and shortest path problems. Furthermore, we show that partially-pipelined modular linear systolic algorithms with an output operation, for matrix multiplication, can be as fast as the fully-pipelined existing ones and, moreover, they need less cells."",""1558-2183"","""",""10.1109/71.503769"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=503769"","""",""Partitioning algorithms";Systolic arrays;Algorithm design and analysis;Computer Society;Shortest path problem;Computer networks;Computer architecture;Hardware;Clocks;"Very large scale integration"","""",""9"","""",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A necessary and sufficient condition for deadlock-free routing in cut-through and store-and-forward networks,""J. Duato"",""Departamento de Ingenievia de Sistemas, Compufadoresy Automatica, Univevsidad Politecnica de Valencia, Valencia, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""8"",""841"",""854"",""This paper develops the theoretical background for the design of deadlock-free adaptive routing algorithms for virtual cut-through and store-and-forward switching. This theory is valid for networks using either central buffers or edge buffers. Some basic definitions and three theorems are proposed, developing conditions to verify that an adaptive algorithm is deadlock-free, even when there are cyclic dependencies between routing resources. Moreover, we propose a necessary and sufficient condition for deadlock-free routing. Also, a design methodology is proposed. It supplies fully adaptive, minimal and non-minimal routing algorithms, guaranteeing that they are deadlock-free. The theory proposed in this paper extends the necessary and sufficient condition for wormhole switching previously proposed by us. The resulting routing algorithms are more flexible than the ones for wormhole switching. Also, the design methodology is much easier to apply because it automatically supplies deadlock-free routing algorithms."",""1558-2183"","""",""10.1109/71.532115"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=532115"","""",""Sufficient conditions";System recovery;Routing;Delay;Design methodology;Buffer storage;Pipeline processing;Hardware;Clocks;"Frequency"","""",""105"",""1"",""38"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A new family of Cayley graph interconnection networks of constant degree four,""P. Vadapalli";" P. K. Srimani"",""Tartan Labs., Pittsburgh, PA, USA";" Department of Computer Science, Colorado State University, Collins, CO, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""1"",""26"",""32"",""We propose a new family of interconnection networks that are Cayley graphs with constant node degree 4. These graphs are regular, have logarithmic diameter, and are maximally fault tolerant. We investigate different algebraic properties of these networks (including fault tolerance) and propose optimal routing algorithms. As far as we know, this is the first family of Cayley graphs of constant degree 4."",""1558-2183"","""",""10.1109/71.481595"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=481595"","""",""Multiprocessor interconnection networks";Fault tolerance;Routing;Network topology;Hypercubes;Senior members;Parallel processing;Bibliographies;Very large scale integration;"Laboratories"","""",""37"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A new HAD algorithm for optimal routing of hierarchically structured data networks,""G. M. Huang";" Shan Zhu"",""Department of Electrical Engineering, Texas A and M University, College Station, TX, USA";" Northern Telecom, Inc., Richardson, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""9"",""939"",""953"",""In this paper, a new algorithm based on hierarchical aggregation/disaggregation and decomposition/composition (HAD) scheme is proposed to solve the optimal routing problems (ORP) for hierarchically structured networks of multi-layer backbones. Our algorithm has two major differences with the existing HAD algorithms for hierarchically clustered networks: (1) our algorithm works with more general networks than the networks with the clustered structure"; (2) our algorithm parallelizes the computations for different commodities (message flows defined by a pair of origin node and destination node) so that it speeds up with a parallel time complexity of O(mlog/sup 2/(n)), which is much less than O(Mlog/sup 2/(n)) needed for the existing HAD algorithms. Here, n is the number of nodes in the network;" M is the number of commodities and m is a positive number usually much smaller than M and is a function of the patterns of all the commodities including the locations of all origin nodes and destination nodes, and the flow demand of each commodity. Furthermore, our algorithm can make a trade-off between the run time and the optimality, i.e., by allowing the solution to be sub-optimal, our algorithm can save great amount of computation time. The implementation of the algorithm for a 200-node network is simulated using OPNET simulation package (OPNET or Optimized Network Engineering Tools is developed by MIL3, Inc.), and the test results are consistent with our analysis."",""1558-2183"","""",""10.1109/71.536938"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=536938"","""",""Routing";Clustering algorithms;Computational modeling;Analytical models;Spine;Computer networks;Concurrent computing;Packaging;Testing;"Algorithm design and analysis"","""",""3"","""",""35"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"A note on consensus on dual failure modes,""Hin-Sing Siu"; Yeh-Hao Chin;" Wei-Pang Yang"",""Institute of Computer and lnformation, National Chiao Tung University, Taiwan"; Institute of Computer and lnformation, National Tsing Hua University, Taiwan;" Institute of Computer and lnformation, National Chiao Tung University, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""3"",""225"",""230"",""F.J. Meyer and D.K. Pradhan (1991) proposed the MS (for """"mixed-sum"""") algorithm to solve the Byzantine Agreement (BA) problem with dual failure modes: arbitrary faults (Byzantine faults) and dormant faults (essentially omission faults and timing faults). Our study indicates that this algorithm uses an inappropriate method to eliminate the effects of dormant faults and that the bound on the number of allowable faulty processors is overestimated. This paper corrects the algorithm and gives a new bound for the allowable faulty processors."",""1558-2183"","""",""10.1109/71.491575"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=491575"","""",""Senior members";Voting;Timing;Fault tolerant systems;Computer crashes;Fault detection;Computer science;Electronic mail;"Transmitters"","""",""37"","""",""5"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"A parallel distributive join algorithm for cube-connected multiprocessors,""S. M. Chung";" Jaerheen Yang"",""Department of Computer Science and Engineering, Wright State University, Dayton, OH, USA";" Water Resource Research Institute, Korea Water Resources Corporation, Taejon, South Korea"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""2"",""127"",""137"",""This paper presents a parallel distributive join algorithm for cube-connected multiprocessors. The performance analysis shows that the proposed algorithm has an almost linear speedup over the sequential distributive join algorithm as the number of processors increases, and its performance is comparable to that of the parallel hybrid-hash join algorithm. A big advantage of the proposed algorithm over hash-based join algorithms is that it does not have the bucket overflow problem caused by nonuniform hashing of the smaller operand relation. Moreover, the proposed algorithm can easily support the nonequijoin operation, which is very hard to implement by using hash-based join algorithms."",""1558-2183"","""",""10.1109/71.485502"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485502"","""",""Relational databases";Partitioning algorithms;Performance analysis;Parallel processing;Merging;Water resources;Sorting;Hardware;Costs;"Computer science"","""",""12"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A subsystem-oriented performance analysis methodology for shared-bus multiprocessors,""Chiung-San Lee";" Tai-Ming Parng"",""Department of Electronic Engineering at Hwa-Hsia, Junior College of Technology, Taipei, Taiwan";" Department of Electrical Engineering at National, Taiwan University, Taipei, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""7"",""755"",""767"",""A methodology, called Subsystem Access Time (SAT) modeling, is proposed for the performance modeling and analysis of shared-bus multiprocessors. The methodology is subsystem-oriented because it is based on a Subsystem Access Time Per Instruction (SATPI) concept, in which we treat major components other than processors (e.g., off-chip cache, bus, memory, I/O) as subsystems and model for each of them the mean access time per instruction from each processor. The SAT modeling methodology is derived from the Customized Mean Value Analysis (CMVA) technique, which is request-oriented in the sense that it models the weighted total mean delay for each type of request processed in the subsystems. The subsystem-oriented view of the proposed methodology facilitates divide-and-conquer modeling and bottleneck analysis, which is rarely addressed previously. These distinguishing features lead to a simple, general, and systematic approach to the analytical modeling and analysis of complex multiprocessor systems. To illustrate the key ideas and features that are different from CMVA, an example performance model of a particular shared-bus multiprocessor architecture is presented. The model is used to conduct performance evaluation for throughput prediction. Thereby, the SATPIs of the subsystems are directly utilized to identify the bottleneck subsystem and find the requests or subsystem components that cause the bottleneck. Furthermore, the SATPIs of the subsystems are employed to explore the impact of several performance influencing factors, including memory latency, number of processors, data bus width, as well as DMA transfer."",""1558-2183"","""",""10.1109/71.508254"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=508254"","""",""Performance analysis";Interference;Multiprocessing systems;Analytical models;Predictive models;Throughput;Process control;"Delay effects"","""",""1"","""",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A time- and cost-optimal algorithm for interlocking sets-with applications,""S. Olariu";" A. Y. Zomaya"",""Department of Computer Science, Old Dominion University, Norfolk, VA, USA";" Parallel Computing Research Lab, Department ofElectrical and ElectronicEngineering, University of Western Australia, Perth, WA, Australia"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""10"",""1009"",""1025"",""Given a family I of intervals, two intervals in I interlock if they overlap but neither of them strictly contains the other. A set of intervals in which every two are related in the reflexive transitive closure of the interlock relation is referred to as an interlocking set. The task is determining the maximal interlocking sets of I arises in numerous applications, including traffic control, robot arm manipulation, segmentation of range images, routing, automated surveillance systems, recognizing polygonal configurations, and code generation for parallel machines. Our first contribution is to show that any sequential algorithm that computes the maximal interlocking sets of a family of n intervals must take /spl Omega/(n log n) time in the algebraic tree model. Next, we show that any parallel algorithm for this problem must take /spl Omega/(log n) time in the CREW model even if an infinite number of processors and memory cells are available. We then go on to show that both the sequential and the parallel lower bounds are tight by providing matching algorithms running, respectively, in /spl Theta/(n log n) sequential time and in /spl Theta/(log n) time using n processors in the CREW model. At the same time, if the endpoints of the intervals are specified in sorted order, our sequential algorithm runs in O(n) time, improving the best previously known result. It is interesting to note that even if the endpoints are sorted, /spl Omega/(log n) is a time lower bound for solving the problem in the CREW model, regardless of the amount of resources available. As an application of our algorithm for interlocking sets, we obtain a time- and cost-optimal solution to a restricted version of the single row routing problem. The best previously known result for routing a set of n nets without street crossovers runs in O(log n loglog n) time using n processors in the CRCW model. By contrast, our algorithm runs in /spl Theta/(log n) time using n/log n processors in the CREW model, being both time- and cost-optimal."",""1558-2183"","""",""10.1109/71.539733"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=539733"","""",""Routing";Traffic control;Parallel robots;Robotics and automation;Surveillance;Parallel algorithms;Application software;Image segmentation;Image recognition;"Parallel machines"","""",""7"","""",""29"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A trip-based multicasting model in wormhole-routed networks with virtual channels,""Yu-Chee Tseng"; D. K. Panda;" Ten-Hwang Lai"",""Department of Computer Science, Chung Hua Polytechnic Institute, Hsinchu, Taiwan"; Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA;" Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""2"",""138"",""150"",""This paper focuses on efficient multicasting in wormhole-routed networks. A trip-based model is proposed to support adaptive, distributed, and deadlock-free multiple multicast on any network with arbitrary topology using at most two virtual channels per physical channel. This model significantly generalizes the path-based model proposed earlier which works only for Hamiltonian networks and cannot be applicable to networks with arbitrary topology resulted due to system faults. Fundamentals of the trip-based model, including the necessary and sufficient condition to be deadlock-free, and the use of appropriate number of virtual channels to avoid deadlock are investigated. The potential of this model is illustrated by applying it to hypercubes with faulty nodes. Simulation results indicate that the proposed model can implement multiple multicast on faulty hypercubes with negligible performance degradation."",""1558-2183"","""",""10.1109/71.485503"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485503"","""",""Intelligent networks";Hypercubes;Routing;Computer Society;System recovery;Network topology;Circuit faults;Broadcasting;Packet switching;"Multicast algorithms"","""",""49"","""",""31"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"A unified framework for optimizing communication in data-parallel programs,""M. Gupta"; E. Schonberg;" H. Srinivasan"",""IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"; IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA;" IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""7"",""689"",""704"",""This paper presents a framework, based on global array data-flow analysis, to reduce communication costs in a program being compiled for a distributed memory machine. We introduce available section descriptor, a novel representation of communication involving array sections. This representation allows us to apply techniques for partial redundancy elimination to obtain powerful communication optimizations. With a single framework, we are able to capture optimizations like (1) vectorizing communication, (2) eliminating communication that is redundant on any control flow path, (3) reducing the amount of data being communicated, (4) reducing the number of processors to which data must be communicated, and (5) moving communication earlier to hide latency, and to subsume previous communication. We show that the bidirectional problem of eliminating partial redundancies can be decomposed into simpler unidirectional problems even in the context of an array section representation, which makes the analysis procedure more efficient. We present results from a preliminary implementation of this framework, which are extremely encouraging, and demonstrate the effectiveness of this analysis in improving the performance of programs."",""1558-2183"","""",""10.1109/71.508249"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=508249"","""",""Data analysis";Performance analysis;Cost function;Communication system control;Delay;Context;Optimization methods;Availability;Memory architecture;"Buildings"","""",""45"",""5"",""33"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Achieving full parallelism using multidimensional retiming,""N. L. Passos";" E. H. . -M. Sha"",""Department of Computer Science, Midwestern State University, Wichita Falls, TX, USA";" Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""11"",""1150"",""1163"",""Most scientific and digital signal processing (DSP) applications are recursive or iterative. Transformation techniques are usually applied to get optimal execution rates in parallel and/or pipeline systems. The retiming technique is a common and valuable transformation tool in one-dimensional problems, when loops are represented by data flow graphs (DFGs). In this paper, uniform nested loops are modeled as multidimensional data flow graphs (MDFGs). Full parallelism of the loop body, i.e., all nodes in the MDFG executed in parallel, substantially decreases the overall computation time. It is well known that, for one-dimensional DFGs, retiming can not always achieve full parallelism. Other existing optimization techniques for nested loops also can not always achieve full parallelism. This paper shows an important and counter-intuitive result, which proves that we can always obtain full-parallelism for MDFGs with more than one dimension. This result is obtained by transforming the MDFG into a new structure. The restructuring process is based on a multidimensional retiming technique. The theory and two algorithms to obtain full parallelism are presented in this paper. Examples of optimization of nested loops and digital signal processing designs are shown to demonstrate the effectiveness of the algorithms."",""1558-2183"","""",""10.1109/71.544356"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=544356"","""",""Multidimensional systems";Parallel processing;Digital signal processing;Flow graphs;Signal processing algorithms;Pipelines;Concurrent computing;Design optimization;Process design;"Signal design"","""",""39"",""3"",""34"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Algorithms for search trees on message passing architectures,""A. Colbrook"; E. A. Brewer; C. N. Dellarocas;" W. E. Weihl"",""Smith System Engineering"; Department of Computer Science, University of California Berkeley, Berkeley, USA; Department of Electrical Engirneering and Computer Science, Center for Coordination, MZTS;" Systems Research Center, Digital Equipment Corporation, Palo Alto, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""2"",""97"",""108"",""In this paper we describe a new algorithm for maintaining a balanced search tree on a message-passing MIMD architecture";" the algorithm is particularly well suited for implementation on a small number of processors. We introduce a (2/sup B-2/, 2/sup B/) search tree that uses a bidirectional ring of O(log n) processors to store n entries. Update operations use a bottom-up node-splitting scheme, which performs significantly better than top-down search tree algorithms. The bottom-up algorithm requires many fewer messages and results in less blocking due to synchronization than top-down algorithms. Additionally, for a given cost ratio of computation to communication the value of B may be varied to maximize performance. Implementations on a parallel-architecture simulator are described."",""1558-2183"","""",""10.1109/71.485500"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485500"","""",""Dictionaries";Delay;Throughput;Computer architecture;Parallel algorithms;Computer science;Computational efficiency;Computational modeling;Algorithm design and analysis;"Systems engineering and theory"","""",""2"",""3"",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";
"All nearest smaller values on the hypercube,""D. Kravets";" C. G. Plaxton"",""Department of Computer Science, New Jersey Institute of Technology, Newark, NJ";" Deaartment of Comanter Science, University of Texas, Austin, TX"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""5"",""456"",""462"",""Given a sequence of n elements, the All Nearest Smaller Values (ANSV) problem is to find, for each element in the sequence, the nearest element to the left (right) that is smaller, or to report that no such element exists. Time and work optimal algorithms for this problem are known on all the PRAM models but the running time of the best previous hypercube algorithm is optimal only when the number of processors p satisfies 1/spl les/p/spl les/n/((lg/sup 3/ n)(lg lg n)/sup 2/). In this paper, we prove that any normal hypercube algorithm requires /spl Omega/(M) processors to solve the ANSV problem in O(lg n) time, and we present the first normal hypercube ANSV algorithm that is optimal for all values of n and p. We use our ANSV algorithm to give the first O(lg n)-time n-processor normal hypercube algorithms for triangulating a monotone polygon and for constructing a Cartesian tree."",""1558-2183"","""",""10.1109/71.503770"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=503770"","""",""Hypercubes";"Routing"","""",""5"","""",""11"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;
"All-to-all personalized communication in a wormhole-routed torus,""Yu-Chee Tseng";" S. K. S. Gupta"",""Department of Computer Science, Chung Hua Polytechnic Institute, Hsinchu, Taiwan";" School of Electrical Engineering and Computer Science, Ohio University, Athens, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""5"",""498"",""505"",""All-to-all personalized communication, or complete exchange, is at the heart of numerous applications in parallel computing. It is one of the most dense communication patterns. In this paper, we consider this problem in a torus of any dimension with the wormhole-routing capability. We propose complete exchange algorithms that use optimal numbers of phases (if each side of the tori is a multiple of eight) or asymptotically optimal numbers of phases (otherwise). Interestingly, in order to achieve this, we only make weak assumptions-that a node is capable of sending and receiving at most one message at a time, and the network is capable of supporting the dimension-ordered (or e-cube) minimum routing."",""1558-2183"","""",""10.1109/71.503775"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=503775"","""",""Routing";Delay;Intelligent networks;Load management;Unicast;Broadcasting;Heart;Fast Fourier transforms;Table lookup;"Concurrent computing"","""",""47"",""4"",""14"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"An analysis of the average message overhead in replica control protocols,""D. Saha"; S. Rangarajan;" S. K. Tripathi"",""IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA;" Department oJComputer Science, University of Maryland College Park, College Park, MD, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""10"",""1026"",""1034"",""Management of replicated data has received considerable attention in the last few years. Several replica control schemes have been proposed which work in the presence of both node and communication link failures. However, this resiliency to failure inflicts a performance penalty in terms of the communication overhead incurred. Though the issue of performance of these schemes from the standpoint of availability of the system has been well addressed, the issue of message overhead has been limited to the analysis of worst case and best case message bounds. In this paper we derive expressions for computing the average message overhead of several well known replica control protocols and provide a comparative study of the different protocols with respect to both average message overhead and system availabilities."",""1558-2183"","""",""10.1109/71.539734"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=539734"","""",""Protocols";Voting;Permission;Control systems;Availability;Communication system control;"Binary trees"","""",""15"","""",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"An application of Petri net reduction for Ada tasking deadlock analysis,""S. M. Shatz"; Shengru Tu; T. Murata;" S. Duri"",""Concurrent Software Systems Laboratory, Department of Electrical Engineering and Computer Science, M/C 154, University of Illinois, Chicago, Chicago, IL, USA"; Computer Science Department, University of New Orleans, USA; Concurrent Software Systems Laboratory, Department of Electrical Engineering and Computer Science, M/C 154, University of Illinois, Chicago, Chicago, IL, USA;" IBM Thomas J. Watson Research Center, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""12"",""1307"",""1322"",""As part of our continuing research on using Petri nets to support automated analysis of Ada tasking behavior, we have investigated the application of Petri net reduction for deadlock analysis. Although reachability analysis is an important method to detect deadlocks, it is in general inefficient or even intractable. Net reduction can aid the analysis by reducing the size of the net while preserving relevant properties. We introduce a number of reduction rules and show how they can be applied to Ada nets, which are automatically generated Petri net models of Ada tasking. We define a reduction process and a method by which a useful description of a detected deadlock state can be obtained from the reduced net's information. A reduction tool and experimental results from applying the reduction process are discussed."",""1558-2183"","""",""10.1109/71.553301"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=553301"","""",""System recovery";Concurrent computing;Information analysis;History;Application software;Communication channels;Automata;FETs;Computer displays;"Software systems"","""",""50"",""1"",""34"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"An approximate analysis of the join the shortest queue (JSQ) policy,""Hwa-Chun Lin";" C. S. Raghavendra"",""Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan";" School of Electvical Engineering and Computer Science, Washington State University, Pullman, WA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""3"",""301"",""307"",""This paper presents an accurate analytical model for evaluating the performance of the join the shortest queue (JSQ) policy. The system considered consists of N identical queues each of which may have single or multiple servers. A birth-death Markov process is used to model the evolution of the number of jobs in the system. Our results show that this method provides very accurate estimates of the average job response times."",""1558-2183"","""",""10.1109/71.491583"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=491583"","""",""Queueing analysis";Analytical models;Performance analysis;Markov processes;Delay;Load management;Multiprocessing systems;Concurrent computing;Distributed computing;"Routing"","""",""23"","""",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"An efficient dictionary machine using hexagonal processor arrays,""Hee Yong Youn";" Jae Young Lee"",""Department of Computer Science and Engineering, University of Texas, Arlington, Arlington, TX, USA";" Department of Computer Science and Engineering, University of Texas, Arlington, Arlington, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""3"",""266"",""273"",""Dictionary machine is an important VLSI system performing high speed data archival operations. In this paper, we present a design which can efficiently implement dictionary machines in VLSI processor arrays. In order to effectively process the operations of dictionary machine, hexagonal mesh is selected as the host topology in which two different networks for update and query operation are embedded. The proposed design is simple to implement as well as allows high throughput."",""1558-2183"","""",""10.1109/71.491580"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=491580"","""",""Dictionaries";Very large scale integration;Network topology;Societies;Throughput;Computer architecture;Delay effects;Computer science;Design methodology;"Hypercubes"","""",""3"","""",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"An efficient memory system for the SIMD construction of a Gaussian pyramid,""Jong Won Park";" D. T. Harper"",""Department of Information Communications Engineering, Chungnam National University, Seoul, South Korea";" Department of Electrical Engineering, University of Texas, Dallas, Richardson, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""8"",""855"",""860"",""In this paper, a memory system is introduced for the efficient construction of a Gaussian pyramid. The memory system consists of an address calculating circuit, an address routing circuit, a memory module selection circuit, and 2/sup n/+1 memory modules. The memory system provides parallel access to 2/sup n/ image points whose patterns are a block, a row or a column, where the interval of the column and the block is 1 and the interval of the row is 2/sup l/,l/spl ges/0. The performance of a generic SIMD (single-instruction multiple-data) processor using the proposed memory system is compared with one using an interleaved memory system for the construction of a Gaussian pyramid. The ratio of the time of the construction of level 2 and level 10 from the original image (level 0) of an SIMD processor with an interleaved memory system to that of the proposed memory system is 1.485 and 1.633, respectively."",""1558-2183"","""",""10.1109/71.532116"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=532116"","""",""Circuits";Routing;Low pass filters;Computer Society;Image storage;Memory architecture;Image processing;Motion analysis;Image motion analysis;"Image texture analysis"","""",""9"",""3"",""13"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"An efficient optimal reconfiguration algorithm for FDDI-based networks,""S. Kamat";" Wei Zhao"",""IBM Thomas J. Watson Research Center, Hawthorne, NY, USA";" College Station, Texas A and M University, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""4"",""411"",""424"",""We study a new network architecture based on standard FDDI networks. This network, called FDDI-based reconfigurable network (FBRN), is constructed using multiple FDDI token rings and has the ability to reconfigure itself in the event of extensive damage to the network. Thus, an FBRN has the potential to provide high available bandwidth even in the presence of numerous faults. Realization of this potential depends crucially on a reconfiguration algorithm that guides the reconfiguration process. We design and analyze a reconfiguration algorithm for FBRNs. Our algorithm is optimal in the sense that it always produces a configuration that results in the maximum available bandwidth for a given fault pattern. This algorithm has a polynomial time complexity. We also show that the available bandwidth of an FBRN is dramatically improved with our reconfiguration algorithm."",""1558-2183"","""",""10.1109/71.494635"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=494635"","""",""FDDI";Bandwidth;Algorithm design and analysis;Token networks;Mission critical systems;Fault tolerance;Process design;Polynomials;Fault tolerant systems;"Computer architecture"","""",""3"","""",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"An efficient parallel recognition algorithm for bipartite-permutation graphs,""Chang-Wu Yu";" Gen-Huey Chen"",""Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan";" Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""1"",""3"",""10"",""We present a parallel recognition algorithm for bipartite-permutation graphs. The algorithm can be executed in O(log n) time on the CRCW PRAM if O(n/sup 3//log n) processors are used, or O(log/sup 2/ n) time on the CREW PRAM if O(n/sup 3//log/sup 2/n) processors are used. Chen and Yesha (1993) have presented another CRCW PRAM algorithm that takes O(log/sup 2/n) time if O(n/sup 3/) processors are used. Compared with Chen and Yesha's algorithm, our algorithm requires either less time and fewer processors on the same machine model, or fewer processors on a weaker machine model. Our algorithm can also be applied to determine if two bipartite-permutation graphs are isomorphic."",""1558-2183"","""",""10.1109/71.481592"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=481592"","""",""Phase change random access memory";Parallel algorithms;Genetic mutations;Optimal scheduling;Testing;Computer science;Dynamic programming;"Bipartite graph"","""",""4"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"An implementation framework for HPF distributed arrays on message-passing parallel computer systems,""K. van Reeuwijk"; W. Denissen; H. J. Sips;" E. M. R. M. Paalvast"",""Advanced School of Computing and Imaging, Delft University of Technnology, Delft, Netherlands"; TNO TPD, Delft, Netherlands; Advanced School of Computing and Imaging, Delft University of Technnology, Delft, Netherlands;" TNO TPD, Delft, Netherlands"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""9"",""897"",""914"",""Data parallel languages, like High Performance Fortran (HPF), support the notion of distributed arrays. However, the implementation of such distributed array structures and their access on message passing computers is not straightforward. This holds especially for distributed arrays that are aligned to each other and given a block-cyclic distribution. In this paper, an implementation framework is presented for HPF distributed arrays on message passing computers. Methods are presented for efficient (in space and time) local index enumeration, local storage, and communication. Techniques for local set enumeration provide the basis for constructing local iteration sets and communication sets. It is shown that both local set enumeration and local storage schemes can be derived from the same equation. Local set enumeration and local storage schemes are shown to be orthogonal, i.e., they can be freely combined. Moreover, for linear access sequences generated by our enumeration methods, the local address calculations can be moved out of the enumeration loop, yielding efficient local memory address generation. The local set enumeration methods are implemented by using a relatively simple general transformation rule for absorbing ownership tests. This transformation rule can be repeatedly applied to absorb multiple ownership tests. Performance figures are presented for local iteration overhead, a simple communication pattern, and storage efficiency."",""1558-2183"","""",""10.1109/71.536935"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=536935"","""",""Concurrent computing";Distributed computing;Message passing;Testing;Parallel languages;Equations;High performance computing;Multidimensional systems;"Optimizing compilers"","""",""26"","""",""34"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;
"Analytical modeling of multistage, multipath networks,""P. G. Sobalvarro"",""Systems Research Center, Digital Equipment Corporation, Palo Alto, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""10"",""1059"",""1064"",""Because of their ability to tolerate faults, multipath, multistage networks provide useful interconnection schemes for large-scale parallel computers. However, the analytical models that have been used to analyze the performance of Banyan networks cannot be used to evaluate the performance of multipath networks. We present here what we believe to be the first analytical model that allows calculation of the bandwidth of the general class of unbuffered, packet-switched, multipath, multistage networks. The equations yielded by the model can be solved either exactly or by Monte Carlo approximation. The model agrees well with the results of a more complex simulation and provides a first step towards solution of the open problem of modeling of buffered, packet-switched, multipath, multistage networks."",""1558-2183"","""",""10.1109/71.539737"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=539737"","""",""Analytical models";Equations;Telephony;Switching systems;Throughput;Switches;Circuits;Approximation methods;Large-scale systems;"Computer networks"","""",""7"",""2"",""14"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Asynchronous analysis of parallel dynamic programming algorithms,""G. Lewandowski"; A. Condon;" E. Bach"",""Xavier University, Cincinnati, OH, USA"; University of Wisconsin, Madison, WI, USA;" University of Wisconsin, Madison, WI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""4"",""425"",""438"",""We examine a very simple asynchronous model of parallel computation that assumes the time to compute a task is random, following some probability distribution. The goal of this model is to capture the effects of unpredictable delays on processors, due to communication delays or cache misses, for example. Using techniques from queueing theory and occupancy problems, we use this model to analyze two parallel dynamic programming algorithms. We show that this model is simple to analyze and correctly predicts which algorithm will perform better in practice. The algorithms we consider are a pipeline algorithm, where each processor i computes in order the entries of rows i, i+p, and so on, where p is the number of processors";" and a diagonal algorithm, where entries along each diagonal extending from the left to the top of the table are computed in turn. It is likely that the techniques used here can be useful in the analysis of other algorithms that use barriers or pipelining techniques."",""1558-2183"","""",""10.1109/71.494636"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=494636"","""",""Algorithm design and analysis";Dynamic programming;Heuristic algorithms;Concurrent computing;Distributed computing;Delay effects;Pipeline processing;Computational modeling;Probability distribution;"Queueing analysis"","""",""9"","""",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;
"Automatic data structure selection and transformation for sparse matrix computations,""A. J. C. Bik";" H. A. G. Wijshoff"",""High Peiformance Computing Division Department of Computer Science, Leiden University, Netherlands";" High Peiformance Computing Division Department of Computer Science, Leiden University, Netherlands"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""2"",""109"",""126"",""The problem of compiler optimization of sparse codes is well known and no satisfactory solutions have been found yet. One of the major obstacles is formed by the fact that sparse programs explicitly deal with particular data structures selected for storing sparse matrices. This explicit data structure handling obscures the functionality of a code to such a degree that optimization of the code is prohibited, for instance, by the introduction of indirect addressing. The method presented in this paper delays data structure selection until the compile phase, thereby allowing the compiler to combine code optimization with explicit data structure selection. This method enables the compiler to generate efficient code for sparse computations. Moreover, the task of the programmer is greatly reduced in complexity."",""1558-2183"","""",""10.1109/71.485501"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485501"","""",""Data structures";Sparse matrices;Optimizing compilers;Program processors;Delay;Programming profession;Bandwidth;Computer science;"Runtime"","""",""43"",""2"",""43"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Balanced spanning trees in complete and incomplete star graphs,""Tzung-Shi Chen"; Yu-Chee Tseng;" Jang-Ping Sheu"",""Department of Information Management, Chang Jung University, Tainan, Taiwan"; Department of Computer Science, Chung Hua Polytechnic Institute, Hsinchu, Taiwan;" Department of Computer Science and Information Engineering, National Central University, Chungli, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""7"",""717"",""723"",""Efficiently solving the personalized broadcast problem in an interconnection network typically relies on finding an appropriate spanning tree in the network. In this paper, we show how to construct in a complete star graph an asymptotically balanced spanning tree, and in an incomplete star graph a near-balanced spanning tree. In both cases, the tree is shown to have the minimum height. In the literature, this problem has only been considered for the complete star graph, and the constructed tree is about 4/3 times taller than the one proposed in this paper."",""1558-2183"","""",""10.1109/71.508251"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=508251"","""",""Tree graphs";Broadcasting;Computer Society;Multiprocessor interconnection networks;Hypercubes;Computer science;Intelligent networks;Parallel architectures;Parallel processing;"Information management"","""",""18"","""",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Benchmark evaluation of the IBM SP2 for parallel signal processing,""Kai Hwang"; Zhiwei Xu;" M. Arakawa"",""Department of Computer Science, University of Hong Kong, Hong Kong, China"; National Center for Intelligent Conzputing Systems, Chinese Academy and Sciences, Beijing, China;" MIT Lincoln Laboratories, Lexington, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""5"",""522"",""536"",""This paper evaluates the IBM SP2 architecture, the AIX parallel programming environment, and the IBM message-passing library (MPL) through STAP (Space-Time Adaptive Processing) benchmark experiments. Only coarse-grain parallelism was exploited on the SP2 due to its high communication overhead. A new parallelization scheme is developed for programming message passing multicomputers. Parallel STAP benchmark structures are illustrated with domain decomposition, efficient mapping of partitioned programs, and optimization of collective communication operations. We measure the SP2 performance in terms of execution time, Gflop/s rate, speedup over a single SP2 node, and overall system utilization. With 256 nodes, the Maul SP2 demonstrated the best performance of 23 Gflop/s in executing the High-Order Post-Doppler program, corresponding to a 34% system utilization. We have conducted a scalability analysis to reveal the performance growth rate as a function of machine size and STAP problem size. Important lessons learned from these parallel processing benchmark experiments are discussed in the context of real-time, adaptive, radar signal processing on massively parallel processors (MPP)."",""1558-2183"","""",""10.1109/71.503777"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=503777"","""",""Signal processing";Parallel programming;Adaptive signal processing;Libraries;Message passing;Velocity measurement;Time measurement;Scalability;Performance analysis;"Parallel processing"","""",""31"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"CGIN: a fault tolerant modified Gamma interconnection network,""Po-Jen Chuang"",""Department of Electrical Engineering, Tamkang University, Taipei, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""12"",""1301"",""1306"",""To improve the terminal reliability of the Gamma interconnection network (GIN), we consider altering its connecting patterns between stages to attain multiple disjoint paths between any source and destination pair. The new modified GIN, referred to as a CGIN with connecting patterns between stages exhibiting a cyclic feature, is able to tolerate any arbitrary single fault and to lift up terminal reliability accordingly. If several rows of switching elements are fabricated in one chip using the VLSI technology, a CGIN could lead to reduced cost because the pin count per chip decreases and the layout area taken by connections shrinks. To make routing and rerouting in the CGIN more efficient and simpler to implement, destination tag routing and rerouting is also provided."",""1558-2183"","""",""10.1109/71.553298"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=553298"","""",""Fault tolerance";Multiprocessor interconnection networks;Switches;Routing;Hardware;Joining processes;Costs;"Very large scale integration"","""",""30"","""",""8"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;
"Characterizing the memory behavior of compiler-parallelized applications,""E. Torrie"; M. Martonosi; Chau-Wen Tseng;" M. W. Hall"",""Computer Systems Laboratory, University of Stanford, Stanford, CA, USA"; Department of Electrical Engineering, Princeton University, Princeton, NJ, USA; Department of Computer Science, University of Maryland, College Park, MD, USA;" University of Southern California, Information Sciences Institute, Marina del Rey, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""12"",""1224"",""1237"",""Compiler-parallelized applications are increasing in importance as moderate-scale multiprocessors become common. This paper evaluates how features of advanced memory systems (e.g., longer cache lines) impact memory system behavior for applications amenable to compiler parallelization. Using full-sized input data sets and applications taken from standard benchmark suites, we measure statistics such as speedups, synchronization and load imbalance, causes of cache misses, cache line utilization, data traffic, and memory costs. This exploration allows us to draw several conclusions. First, we find that larger granularity parallelism often correlates with good memory system behavior, good overall performance, and high speedup in these applications. Second, we show that when long (512 byte) cache lines are used, many of these applications suffer from false sharing and low cache line utilization. Third, we identify some of the common artifacts in compiler-parallelized codes that can lead to false sharing or other types of poor memory system performance, and we suggest methods for improving them. Overall, this study offers both an important snapshot of the behavior of applications compiled by state-of-the-art compilers, as well as an increased understanding of the interplay between cache line size, program granularity, and memory performance in moderate-scale multiprocessors."",""1558-2183"","""",""10.1109/71.553272"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=553272"","""",""Concurrent computing";Application software;Parallel architectures;Program processors;Parallel programming;Supercomputers;Propulsion;Parallel processing;Computer science;"Delay"","""",""14"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Circuit-switched broadcasting in torus and mesh networks,""J. . -Y. L. Park";" Hyeong-Ah Choi"",""Department of Electrical Engineering and Computer Science, George Washington University, Washington D.C., DC, USA";" Department of Electrical Engineering and Computer Science, George Washington University, Washington D.C., DC, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""2"",""184"",""190"",""We consider the problem of broadcasting on torus and mesh networks using circuit-switched, half-duplex, and link-bound communication. In this paper, we obtain an optimal broadcasting algorithm that uses pd time steps for a d-dimensional torus with (2d+1)/sup p/ nodes in each side of the torus. Using this algorithm, we show that a broadcasting on a d-dimensional mesh with the same size can be done in pd+p+d-1 time steps."",""1558-2183"","""",""10.1109/71.485507"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485507"","""",""Circuits";Broadcasting;Intelligent networks;Mesh networks;Routing;Casting;Writing;Computer science;"Approximation algorithms"","""",""21"","""",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Circuit-switched broadcasting in torus networks,""J. G. Peters";" M. Syska"",""School of Computing Science, Simon Fraser University, Burnaby, BC, Canada";" Universite'de Nice-Sophia Antipolis, Laboratoire 13S-CNRS-UXA 1376, Sophia-Antipolis, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""3"",""246"",""255"",""In this paper we present three broadcast algorithms and lower bounds on the three main components of the broadcast time for 2-dimensional torus networks (wrap-around meshes) that use synchronous circuit-switched routing. The first algorithm is based on a recursive tiling of a torus and is optimal in terms of both phases and intermediate switch settings when the start-up time to initiate message transmissions is the dominant cost. It is the first broadcast algorithm to match the lower bound of log/sub 5/ N on number of phases (where N is the number of nodes). The second and third algorithms are hybrids which combine circuit-switching with the pipelining and arc-disjoint spanning trees techniques that are commonly used to speed up store-and-forward routing. When the propagation time of messages through the network is significant, our hybrid algorithms achieve close to optimal performance in terms of phases, intermediate switch settings, and total transmission time. They are the first algorithms to achieve this performance in terms of all three parameters simultaneously."",""1558-2183"","""",""10.1109/71.491578"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=491578"","""",""Broadcasting";Intelligent networks;Routing;Switches;Multiprocessor interconnection networks;Pipeline processing;Network topology;Switching circuits;Cost function;"Circuit topology"","""",""44"","""",""34"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Computing on anonymous networks. I. Characterizing the solvable cases,""M. Yamashita";" T. Kameda"",""Department ofElectrical Engineering, Hiroshima University, Higashihiroshima, Japan";" School of Computing Science, Simon Fraser University, Burnaby, BC, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""1"",""69"",""89"",""In anonymous networks, the processors do not have identity numbers. We investigate the following representative problems on anonymous networks: (a) the leader election problem, (b) the edge election problem, (c) the spanning tree construction problem, and (d) the topology recognition problem. On a given network, the above problems may or may not be solvable, depending on the amount of information about the attributes of the network made available to the processors. Some possibilities are: (1) no network attribute information at all is available, (2) an upper bound on the number of processors in the network is available, (3) the exact number of processors in the network is available, and (4) the topology of the network is available. In terms of a new graph property called """"symmetricity"""", in each of the four cases (1)-(4) above, we characterize the class of networks on which each of the four problems (a)(d) is solvable. We then relate the symmetricity of a network to its 1- and 2-factors."",""1558-2183"","""",""10.1109/71.481599"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=481599"","""",""Computer networks";Computer aided software engineering;Nominations and elections;Network topology;Distributed algorithms;Probes;Upper bound;Distributed computing;"Joining processes"","""",""204"",""1"",""37"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Computing on anonymous networks. II. Decision and membership problems,""M. Yamashita";" T. Kameda"",""Department of Electrical Engineering, Hiroshima University, Higashihiroshima, Japan";" School of Computing Science, Simon Fraser University, Burnaby, BC, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""1"",""90"",""96"",""For pt I see ibid. In anonymous networks, the processors do not have identity numbers. In Part I of this paper, we characterized the classes of networks on which some representative distributed computation problems are solvable under different conditions. A new graph property called symmetricity played a central role in our analysis of anonymous networks. In Part II, we turn our attention to the computational complexity issues. We first discuss the complexity of determining the symmetricity of a given graph, and then that of testing membership in each of the 16 classes of anonymous networks defined in Part I. It turns out that, depending on the class, the complexity varies from P-time to NP-complete or co-NP-complete."",""1558-2183"","""",""10.1109/71.481600"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=481600"","""",""Computer networks";Testing;Network topology;Nominations and elections;Upper bound;Computational complexity;Marine vehicles;"Polynomials"","""",""34"","""","""",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Computing programs containing band linear recurrences on vector supercomputers,""Haigeng Wang"; A. Nicolau; S. Keung;" Kai-Yeung Siu"",""Department of Information and Computer Science, University of California, Irvine, CA, USA"; Department of Information and Computer Science, University of California, Irvine, CA, USA; Department of Electrical and Computer Engineering, University of California, Irvine, CA, USA;" Arbeloff Laboratory for Information Systems, Massachusetts Institute of Technology, Cambridge, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""8"",""769"",""782"",""Many large-scale scientific and engineering computations, e.g., some of the Grand Challenge problems, spend a major portion of execution time in their core loops computing band linear recurrences (BLRs). Conventional compiler parallelization techniques cannot generate scalable parallel code for this type of computation because they respect loop-carried dependences (LCDs) in programs, and there is a limited amount of parallelism in a BLR with respect to LCDs. For many applications, using library routines to replace the core BLR requires the separation of BLR from its dependent computation, which usually incurs significant overhead. In this paper, we present a new scalable algorithm called the Regular Schedule, for parallel evaluation of BLRs. We describe our implementation of the Regular Schedule and discuss how to obtain maximum memory throughput in implementing the schedule on vector supercomputers. We also illustrate our approach, based on our Regular Schedule, to parallelizing programs containing BLR and other kinds of code. Significant improvements in CPU performance for a range of programs containing BLR implemented using the Regular Schedule in C over the same programs implemented using highly optimized coded-in-assembly BLAS routines [11] are demonstrated on Convex C240. Our approach can be used both at the user level in parallel programming code containing BLRs, and in compiler parallelization of such programs combined with recurrence recognition techniques for vector supercomputers."",""1558-2183"","""",""10.1109/71.532109"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=532109"","""",""Vectors";Processor scheduling;Program processors;Supercomputers;Large-scale systems;Concurrent computing;Parallel processing;Libraries;Scheduling algorithm;"Throughput"","""",""3"",""1"",""36"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Constant time BSR solutions to parenthesis matching, tree decoding, and tree reconstruction from its traversals,""I. Stojmenovic"",""Computer Science Department, University of Ottawa, Ottawa, ONT, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""2"",""218"",""224"",""Recently Akl et al. introduced a new model of parallel computation, called BSR (broadcasting with selective reduction) and showed that it is more powerful than any CRCW PRAM and yet requires no more resources for implementation than even EREW PRAM. The model allows constant time solutions to sorting, parallel prefix and other problems. In this paper, we describe constant time solutions to the parenthesis matching, decoding binary trees in bitstring representation, generating next tree shape in B-order, and the reconstruction of binary trees from their traversals, using the BSR model. They are the first constant time solutions to mentioned problems on any model of computation. The number of processors used is equal to the input size, for each problem. A new algorithm for sorting integers is also presented."",""1558-2183"","""",""10.1109/71.485530"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485530"","""",""Decoding";Phase change random access memory;Broadcasting;Sorting;Computational modeling;Circuits;Concurrent computing;Binary trees;Read-write memory;"Shape"","""",""21"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Constructing Euclidean minimum spanning trees and all nearest neighbors on reconfigurable meshes,""T. H. Lai";" Ming-Jye Sheng"",""Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA";" YoungTech, Inc., Edison, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""8"",""806"",""817"",""A reconfigurable mesh, R-mesh for short, is a two-dimensional array of processors connected by a grid-shaped reconfigurable bus system. Each processor has four I/O ports that can be locally connected during execution of algorithms. This paper considers the d-dimensional Euclidean minimum spanning tree (EMST) and the all nearest neighbors (ANN) problem. Two results are reported. First, we show that a minimum spanning tree of n points in a fixed d-dimensional space can be constructed in O(1) time on a /spl radic/(n/sup 3/)/spl times//spl radic/(n/sup 3/) R-mesh. Second, all nearest neighbors of n points in a fixed d-dimensional space can be constructed in O(1) time on an n/spl times/n R-mesh. There is no previous O(1) time algorithm for the EMST problem"; ours is the first such algorithm. A previous R-mesh algorithm exists for the two-dimensional ANN problem;" we extend it to any d-dimensional space. Both of the proposed algorithms have a time complexity independent of n but growing with d. The time complexity is O(1) if d is a constant."",""1558-2183"","""",""10.1109/71.532112"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=532112"","""",""Nearest neighbor searches";Computer Society;Computational geometry;Sorting;Image processing;Digital arithmetic;Computer vision;Application software;Pattern recognition;"Very large scale integration"","""",""12"","""",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Correction to ""Optimal and Load Balanced Mapping of Parallel Priority Queues in Hypercubes"" [Erratum,""S. K. Das"; M. C. Pinotti;" F. Sarkar"",""Department of Computer Sciences, University of North Texas, Denton, TX, USA"; Istituto Elaborazione dellInformazione, CNR, Pisa, Italy;" Nortel Technologies, Inc., Richardson, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""8"",""896"","""","""",""1558-2183"","""",""10.1109/TPDS.1996.532120"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=532120"","""",""Hypercubes";"Computer Society"","""","""","""","""",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;
"Data forwarding in scalable shared-memory multiprocessors,""D. A. Koufaty"; Xiangfeng Chen; D. K. Poulsen;" J. Torrellas"",""Center for Supercomputing, Research and Development, University of Illinois, Urbana-Champaign, Urbana-Champaign, IL, USA"; Silicon Graphics, Inc., Mountain View, CA, USA; Kuck and Associates, Inc., Urbana-Champaign, IL, USA;" Center for Supercomputing, Research and Development, University of Illinois, Urbana-Champaign, Urbana-Champaign, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""12"",""1250"",""1264"",""Scalable shared-memory multiprocessors are often slowed down by long-latency memory accesses. One way to cope with this problem is to use data forwarding to overlap memory accesses with computation. With data forwarding, when a processor produces a datum, in addition to updating its cache, it sends a copy of the datum to the caches of the processors that the compiler identified as consumers of it. As a result, when the consumer processors access the datum, they find it in their caches. This paper addresses two main issues. First, it presents a framework for a compiler algorithm for forwarding. Second, using address traces, it evaluates the performance impact of different levels of support for forwarding. Our simulations of a 32-processor machine show that an optimistic support for forwarding speeds up five applications by an average of 50% for large caches and 30% for small caches. For large caches, most sharing read misses are eliminated, while for small caches, forwarding does not increase the number of conflict misses significantly. Overall, support for forwarding in shared-memory multiprocessors promises to deliver good application speedups."",""1558-2183"","""",""10.1109/71.553274"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=553274"","""",""Prefetching";Delay;Protocols;Optimizing compilers;Multithreading;Research and development;Silicon;Graphics;Runtime;"Hardware"","""",""33"",""8"",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Decomposition abstraction in parallel rule languages,""Shiow-Yang Wu"; D. P. Miranker;" J. C. Browne"",""Institute of Computer Science and Information Engzneering, National Dong Hwa University, Hualien, Taiwan"; Department of Computer Sciences, University of Texas at Austin;" Department of Computer Sciences, University of Texas at Austin"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""11"",""1164"",""1184"",""Decomposition abstraction is the process of organizing and specifying decomposition strategies for the exploitation of parallelism available in an application. In this paper we develop and evaluate declarative primitives for rule-based programs that expand opportunities for parallel execution. These primitives make explicit, implicit relations among the data and similarly among the rules. The semantics of the primitives are presented in a general object-based framework such that they may be applied to most rule-based programming languages. We show how the additional information provided by the decomposition primitives can be incorporated into a semantic-based dependency analysis technique. The resulting analysis reveals parallelism at compile time that is very difficult, if not impossible, to discover by traditional syntactic analysis techniques. Simulation results demonstrate scalable and broadly available parallelism."",""1558-2183"","""",""10.1109/71.544357"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=544357"","""",""Production systems";Parallel processing;Interference;Knowledge based systems;Intelligent systems;Large-scale systems;System performance;Computer languages;Computer science;"Concurrent computing"","""",""2"","""",""57"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Designing clustered multiprocessor systems under packaging and technological advancements,""D. Basak";" D. K. Panda"",""Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA";" Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""9"",""962"",""978"",""Clustered or hierarchical interconnections have advantages when designing large scale multiprocessor systems. Earlier studies have either focused on only flat interconnections or proposed hierarchical/clustered interconnections with limited packaging and demanded performance constraints. Large systems require several levels of packaging. Packaging technologies impose various physical constraints on bisection bandwidth and channel width of a system. Pinout technologies and the capacity of packaging modules have been ignored in earlier studies, often leading to configurations that are not design-feasible. Similarly, the impact of processor and interconnect technologies on demanded performance has not been considered. We propose a new supply-demand framework for multiprocessor system design by considering packaging, processor, and interconnect technologies in an integrated manner. The elegance of this framework lies in its parameterised representation of different technologies. For a given set of technological parameters the framework derives the best configuration while considering practical design aspects like maximum board area, maximum available pinout, fixed channel width, and scalability. In order to build a scalable parallel system with a given number of processors, the framework explores the design space of flat k-ary n-cube topologies and their clustered variations (k-ary n-cube cluster-c) to derive design-feasible configurations with best system performance."",""1558-2183"","""",""10.1109/71.536940"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=536940"","""",""Multiprocessing systems";Packaging;Bandwidth;Space technology;Space exploration;Very large scale integration;Hypercubes;Large scale integration;Scalability;"Topology"","""",""22"","""",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Detection of strong unstable predicates in distributed programs,""V. K. Garg";" B. Waldecker"",""Electrical and Computer Engineering Department, University of Technology, Austin, TX, USA";" International Business Machines Corporation, Austin, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""12"",""1323"",""1333"",""This paper discusses detection of global predicates in a distributed program. A run of a distributed program results in a set of sequential traces, one for each process. These traces may be combined to form many global sequences consistent with the single run of the program. A strong global predicate is true in a run if it is true for all global sequences consistent with the run. We present algorithms which detect if the given strong global predicate became true in a run of a distributed program. Our algorithms can be executed on line as well as off line. Moreover, our algorithms do not assume that underlying channels satisfy FIFO ordering."",""1558-2183"","""",""10.1109/71.553309"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=553309"","""",""Distributed computing";Debugging;Senior members;Computer Society;Distributed algorithms;Testing;Safety;State-space methods;"Monitoring"","""",""83"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Dynamic critical-path scheduling: an effective technique for allocating task graphs to multiprocessors,""Yu-Kwong Kwok";" I. Ahmad"",""The Department of Computer Science, Hong Kong University of Science and Technology, Hong Kong, China";" The Department of Computer Science, Hong Kong University of Science and Technology, Hong Kong, China"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""5"",""506"",""521"",""In this paper, we propose a static scheduling algorithm for allocating task graphs to fully connected multiprocessors. We discuss six recently reported scheduling algorithms and show that they possess one drawback or the other which can lead to poor performance. The proposed algorithm, which is called the Dynamic Critical-Path (DCP) scheduling algorithm, is different from the previously proposed algorithms in a number of ways. First, it determines the critical path of the task graph and selects the next node to be scheduled in a dynamic fashion. Second, it rearranges the schedule on each processor dynamically in the sense that the positions of the nodes in the partial schedules are not fixed until all nodes have been considered. Third, it selects a suitable processor for a node by looking ahead the potential start times of the remaining nodes on that processor, and schedules relatively less important nodes to the processors already in use. A global as well as a pair-wise comparison is carried out for all seven algorithms under various scheduling conditions. The DCP algorithm outperforms the previous algorithms by a considerable margin. Despite having a number of new features, the DCP algorithm has admissible time complexity, is economical in terms of the number of processors used and is suitable for a wide range of graph structures."",""1558-2183"","""",""10.1109/71.503776"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=503776"","""",""Dynamic scheduling";Processor scheduling;Scheduling algorithm;Costs;Computational efficiency;Multiprocessing systems;Algorithm design and analysis;Concurrent computing;Hardware;"Queueing analysis"","""",""565"",""22"",""37"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Dynamic partitioning of non-uniform structured workloads with spacefilling curves,""J. R. Pilkington";" S. B. Baden"",""Computer Science and Engineering Department, University of California, La Jolla, CA, USA";" Computer Science and Engineering Department, University of California, La Jolla, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""3"",""288"",""300"",""We discuss inverse spacefilling partitioning (ISP), a partitioning strategy for non-uniform scientific computations running on distributed memory MIMD parallel computers. We consider the case of a dynamic workload distributed on a uniform mesh, and compare ISP against orthogonal recursive bisection (ORE) and a median of medians variant of ORE, ORB-MM. We present two results. First, ISP and ORB-MM are superior to ORE in rendering balanced workloads-because they are more fine-grained-and incur communication overheads that are comparable to ORE. Second, ISP is more attractive than ORB-MM from a software engineering standpoint because it avoids elaborate bookkeeping. Whereas ISP partitionings can be described succinctly as logically contiguous segments of the line, ORB-MM's partitionings are inherently unstructured. We describe the general d-dimensional ISP algorithm and report empirical results with two- and three-dimensional, non-hierarchical particle methods."",""1558-2183"","""",""10.1109/71.491582"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=491582"","""",""Concurrent computing";Distributed computing;Load management;Costs;Computer Society;Software engineering;Partitioning algorithms;Application software;Adaptive mesh refinement;"Computer architecture"","""",""94"",""2"",""37"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Efficient algorithms for array redistribution,""R. Thakur"; A. Choudhary;" J. Ramanujam"",""Mathematics and Computer Science Division, Argouue ational Laboratory, Argonne, IL, USA"; Department of Electrical and Computer Engineering, Syracuse University, Nagoya, Japan;" Department of Electrical and Compufer Engineering, Louisiana State University, Baton Rouge, LA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""6"",""587"",""594"",""Dynamic redistribution of arrays is required very often in programs on distributed presents efficient algorithms for redistribution between different cyclic(k) distributions, as defined in High Performance Fortran. We first propose special optimized algorithms for a cyclic(x) to cyclic(y) redistribution when x is a multiple of y, or y is a multiple of x. We then propose two algorithms, called the GCD method and the LCM method, for the general cyclic(x) to cyclic(y) redistribution when there is no particular relation between x and y. We have implemented these algorithms on the Intel Touchstone Delta, and find that they perform well for different array sizes and number of processors."",""1558-2183"","""",""10.1109/71.506697"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506697"","""",""Concurrent computing";Distributed computing;Computer Society;High performance computing;Runtime library;Random access memory;Arithmetic;Degradation;Mathematics;"Computer science"","""",""50"",""1"",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Efficient LRU-based buffering in a LAN remote caching architecture,""A. Leff"; J. L. Wolf;" P. S. Yu"",""IBM Thomas J. Watson Research Center, Yorktown, NY, USA"; IBM Thomas J. Watson Research Center, Yorktown, NY, USA;" IBM Thomas J. Watson Research Center, Yorktown, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""2"",""191"",""206"",""The possibility of fast access to the main memory of remote sites has been advanced as a potential performance improvement in distributed systems. Even if a page is not available in local memory, sites need not do a disk access. Instead, the sites can use efficient mechanisms that support rapid request/response exchanges in order to access pages that are currently buffered at a remote site. Hardware and software support in such a remote caching architecture must also include algorithms that determine which pages should be buffered at what sites. When each site uses the classic LRU replacement algorithm, performance can be much worse than optimal in many system configurations. Because sites do not coordinate individual decisions, overall system buffering/caching decisions yield very inefficient global configurations. This paper proposes an easily implementable modification of the LRU replacement algorithm for LAN environments that reduces replication. The algorithm substantially improves hit-ratios-and thus performance-over a wide range of parameters. The relatively simple LAN topology implies that much less state information need be available for good replacement decisions compared to general network topologies. Two implications of two variations of the algorithm are explored. In an environment where the network is not a performance bottleneck, and where performance is memory-limited, performance of the proposed replacement algorithm is shown to be close to optimal."",""1558-2183"","""",""10.1109/71.485508"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485508"","""",""Local area networks";Memory management;Network topology;Database systems;Distributed computing;Workstations;Application software;Bandwidth;Senior members;"Fellows"","""",""14"",""1"",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Efficient rollback-recovery technique in distributed computing systems,""Ge-Ming Chiu";" Cheng-Ru Young"",""Department of Electrical Engineering and Technology, National Taiwan Institute of Technology, Taipei, Taiwan";" Department of Electrical Engineering and Technology, National Taiwan Institute of Technology, Taipei, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""6"",""565"",""577"",""We propose an approach for implementing rollback recovery in a distributed computing system. A concept of logical ring is introduced for the maintenance of information required for consistent recovery from a system crash. Message processing order of a process is kept by all other processes on its logical ring. Transmission of data messages are accompanied by the circulation of the associated order messages on the ring. The sizes of the order messages are small. In addition, redundant transmission of order information is avoided, thereby reducing the communication overhead incurred during failure free operation. Furthermore, updating of the order information and garbage collection task are simplified in the proposed mechanism. Our approach does not require information about message processing order be written to stable storage";" in fact, the time consuming operations of saving information in stable storage are confined to the checkpointing activities. When failures occur, a surviving process need roll back only if some preceding order information is totally lost, which is relatively unlikely considering the ever growing speed of communication networks. It is shown that a system can recover correctly as long as there exists at least one surviving process."",""1558-2183"","""",""10.1109/71.506695"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506695"","""",""Distributed computing";Checkpointing;Computer crashes;Very large scale integration;Fault tolerance;Electronic switching systems;Computer Society;Communication networks;Fault tolerant systems;"Computer networks"","""",""14"","""",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Efficient termination detection for loosely synchronous applications in multicomputers,""Chengzhong Xu";" F. C. M. Lau"",""Depavtment of Electrical and Compute Engineering, Wayne State University, Detroit, MI, USA";" Department of Compute Science, University of Hong Kong, Hong Kong, China"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""5"",""537"",""544"",""We propose a simple algorithm which is based on edge-coloring of system graphs for termination detection of loosely synchronous computations. The proposed algorithm is fully symmetric in that all processors run syntactically identical code and can detect global termination at the same time. Under the 1-port communication model, the algorithm is optimal in terms of termination delay, the difference between the time when a global termination occurs and the time it is detected, in a number of structures-chain, ring of even number of nodes, k-ary n-cube and k-ary n-mesh of low degree, where k is even";" and near-optimal for other cases. The optimality analysis is based on results from a related problem, periodic gossiping in edge-colored graphs. This algorithm has been applied to some practical cases in which the overhead due to its execution is found to be insignificant."",""1558-2183"","""",""10.1109/71.503778"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=503778"","""",""Delay effects";Peer to peer computing;Computer networks;Concurrent computing;Distributed computing;Parallel processing;Distributed algorithms;Multiprocessor interconnection networks;Computational modeling;"Detection algorithms"","""",""3"","""",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Embedding and reconfiguration of binary trees in faulty hypercubes,""Pei-Ji Yang";" C. S. Raghavendra"",""Chung Shang Institute of Science and Technology, Lungtan, Taiwan";" School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""3"",""237"",""245"",""We consider the problem of embedding and reconfiguring binary tree structures in faulty hypercubes. We assume that the number of faulty nodes is at most (n-2), where n is the number of dimensions of the hypercube";" we further assume that the location of faulty nodes are known. Our embedding techniques are based on a key concept called free dimension, which can be used to partition a cube into subcubes such that each subcube contains at most one faulty node. Using this approach, two distributed schemes are provided for embedding and reconfiguration in faulty hypercubes. We extend the free dimension concept to degree of occupancy and use this to develop a distributed scheme for reconfiguration of binary tree in faulty hypercubes with up to [3n/2] node faults."",""1558-2183"","""",""10.1109/71.491577"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=491577"","""",""Binary trees";Hypercubes;Fault tolerance;Time measurement;Multiprocessing systems;Parallel machines;Parallel algorithms;Costs;"Delay effects"","""",""9"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Embedding classical communication topologies in the scalable OPAM architecture,""A. Barak";" E. Schenfeld"",""Department of Computer Science, Hebrew University of Jerusalem, Jerusalem, Israel";" NEC Research Institute, Inc., Princeton, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""9"",""979"",""992"",""The paper presents novel embeddings of various classical topologies into the OPAM multicomputer. OPAM consists of a large number of processors that are connected by a two level, crossbar based interconnection network. The network combines a large, optical circuit-switched crossbar (reconfigurable network), with many small, packet-switching crossbars. The necessary embedding is very different than classical approaches. The goal in our case is to minimize routing decisions, so that communication requests can be satisfied by passing through two small crossbars. We show how to map parallel programs to this architecture using graph contraction notations. The family of parallel programs that we consider consists of multiple processes and communication links that are represented by connected, regular graphs such as rings, trees, two dimensional grids, cube connected cycles and hypercubes. In each case we show how to partition the vertex set of the program's graph to subsets, and how to assign each subset a cluster of processors in order to realize the topology of the given problem. In some of the cases we also prove that our partition and assignment algorithms are optimal."",""1558-2183"","""",""10.1109/71.536941"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=536941"","""",""Network topology";Circuit topology;Multiprocessor interconnection networks;Optical interconnections;Optical fiber networks;Optical packet switching;Routing;Tree graphs;Hypercubes;"Clustering algorithms"","""",""4"","""",""35"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Embedding of complete binary trees into meshes with row-column routing,""Sang-Kyu Lee";" Hyeong-Ah Choi"",""Department of Electrical Engineering and Computer Science, George Washington University, Washington D.C., DC, USA";" Department of Electrical Engineering and Computer Science, George Washington University, Washington D.C., DC, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""5"",""493"",""497"",""This paper considers the problem of embedding complete binary trees into meshes using the row-column routing and obtained the following results: a complete binary tree with 2/sup p/-1 nodes can be embedded (1) with link congestion one into a /sup 9///sub 8//spl radic/(2/sup p/)/spl times//sup 9///sub 8//spl radic/(2/sup p/) mesh when p is even and a /spl radic/(/sup 9///sub 8/2/sup p/)/spl times//spl radic/(/sup 9///sub 8/2/sup p/) mesh when p is odd, and (2) with link congestion two into a /spl radic/(2/sup p/)/spl times//spl radic/(2/sup p/) mesh when p is even, and a /spl radic/(2/sup p-1/)/spl times//spl radic/(2/sup p-1/) mesh when p is odd."",""1558-2183"","""",""10.1109/71.503774"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=503774"","""",""Binary trees";Routing;Communication switching;"Very large scale integration"","""",""19"","""",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;
"Enhancing distributed event predicate detection algorithms,""Hsien-Kuang Chiou";" W. Korfhage"",""Department of Information Management, Nan-Tai College, Tainan, Taiwan";" D. E. Shaw and Company, Cambridge, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""7"",""673"",""676"",""Recently published algorithms for matching concurrent sets of events have the problem of unbounded message queue growth if events arrive in an undesirable order. This paper presents some algorithms that mitigate this problem by examining events waiting to be processed and removing those that cannot be part of a concurrent set."",""1558-2183"","""",""10.1109/71.508247"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=508247"","""",""Detection algorithms";Event detection;Debugging;Clocks;Distributed algorithms;Vents;System recovery;Monitoring;Performance analysis;"Information management"","""",""7"","""",""8"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Evaluation of hardware-based stride and sequential prefetching in shared-memory multiprocessors,""F. Dahlgren";" P. Stenstrom"",""Department of Computer Engineering, Lund University, Lund, Sweden";" Department of Computer Engineering, Chalmers University of Technology, Gothenburg, Sweden"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""4"",""385"",""398"",""We study the efficiency of previously proposed stride and sequential prefetching-two promising hardware-based prefetching schemes to reduce read-miss penalties in shared-memory multiprocessors. Although stride accesses dominate in four out of six of the applications we study, we find that sequential prefetching does as well as and in same cases even better than stride prefetching for five applications. This is because 1) most strides are shorter than the block size (we assume 32 byte blocks), which means that sequential prefetching is as effective for these stride accesses, and 2) sequential prefetching also exploits the locality of read misses with nonstride accesses. However, since stride prefetching in general results in fewer useless prefetches, it offers the extra advantage of consuming less memory-system bandwidth."",""1558-2183"","""",""10.1109/71.494633"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=494633"","""",""Prefetching";Read-write memory;Delay;Computer Society;Application software;Coherence;Hardware;Bandwidth;Multiprocessor interconnection networks;"Counting circuits"","""",""41"",""6"",""22"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Evaluation of load sharing in HARTS with consideration of its communication activities,""K. G. Shin";" C. . -J. Hou"",""Real-Time Computing Labovatory, Department ofElectrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA";" Department of Electvical and Computer Engineering, University of Wisconsin, Madison, Madison, WI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""7"",""724"",""739"",""We rigorously analyze load sharing (LS) in a distributed real-time system, called HARTS (Hexagonal Architecture for Real-Time Systems), while considering LS-related communication activities, such as task transfers and state-change broadcasts. First, we give an overview of the general distributed real-time LS approach described previously, and then adapt it to HARTS by exploiting the topological properties of HARTS. Second, we model task arrival/completion/transfer activities in HARTS as a continuous-time Markov chain from which we derive the distribution of queue length and the rate of generating LS-related traffic-task transfer-out rate and state-region change broadcast rate. Third, we derive the distribution of packet delivery time as a function of LS-related traffic rates by characterizing the hexagonal mesh topology and the virtual cut-through capability of HARTS. Finally, we derive the distribution of task waiting time (the time a task is queued for execution plus the time it would spend if the task is to be transferred), from which the probability of a task failing to complete in time, called the probability of dynamic failure, can be computed. The results obtained from our analytic models are verified through event-driven simulations, and can be used to study the effects of varying various design parameters on the performance of LS while considering the details of LS-related communication activities."",""1558-2183"","""",""10.1109/71.508252"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=508252"","""",""Real time systems";Broadcasting;Application software;Communication switching;Distributed computing;Laboratories;Buildings;Computer architecture;Skin;"Delay"","""",""5"",""1"",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Exact bounds on running ASCEND/DESCEND and FAN-IN algorithms on synchronous multiple bus networks,""A. Ali";" R. Vaidyanathan"",""Cirrus Logic, Inc., Fremont, CA, USA";" Department of Electrical and Computer Engineering, Louisiana State University, Baton Rouge, LA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""8"",""783"",""790"",""We consider the problem of running ASCEND/DESCEND and FAN-IN algorithms on synchronous multiple bus networks with a restricted number of buses. Exact lower bounds on the time are derived. We present a method that runs FAN-IN algorithms optimally and ASCEND/DESCEND algorithms in one step beyond the lower bound."",""1558-2183"","""",""10.1109/71.532110"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=532110"","""",""Parallel processing";Scheduling algorithm;Hypercubes;Very large scale integration;Parallel algorithms;Processor scheduling;Delay;Optical fiber communication;Communications technology;"Algorithm design and analysis"","""",""5"","""",""19"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Fast parallel sorting under LogP: experience with the CM-5,""A. C. Dusseau"; D. E. Culler; K. E. Schauser;" R. P. Martin"",""Computer Science Division, University of California, Berkeley, CA, USA"; Computer Science Division, University of California, Berkeley, CA, USA; University of California, Santa Barbara, USA;" Computer Science Division, University of California, Berkeley, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""8"",""791"",""805"",""In this paper, we analyze four parallel sorting algorithms (bitonic, column, radix, and sample sort) with the LogP model. LogP characterizes the performance of modern parallel machines with a small set of parameters: the communication latency (L), overhead (o), bandwidth (g), and the number of processors (P). We develop implementations of these algorithms in Split-C, a parallel extension to C, and compare the performance predicted by LogP to actual performance on a CM-5 of 32 to 512 processors for a range of problem sizes. We evaluate the robustness of the algorithms by varying the distribution and ordering of the key values. We also briefly examine the sensitivity of the algorithms to the communication parameters. We show that the LogP model is a valuable guide in the development of parallel algorithms and a good predictor of implementation performance. The model encourages the use of data layouts which minimize communication and balanced communication schedules which avoid contention. With an empirical model of local processor performance, LogP predictions closely match observed execution times on uniformly distributed keys across a broad range of problem and machine sizes. We find that communication performance is oblivious to the distribution of the key values, whereas the local processor performance is not";" some communication phases are sensitive to the ordering of keys due to contention. Finally, our analysis shows that overhead is the most critical communication parameter in the sorting algorithms."",""1558-2183"","""",""10.1109/71.532111"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=532111"","""",""Sorting";Predictive models;Algorithm design and analysis;Parallel algorithms;Processor scheduling;Context modeling;Network topology;Parallel machines;Delay;"Bandwidth"","""",""61"",""9"",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";
"Fault-tolerant wormhole routing in meshes without virtual channels,"""",,""IEEE Transactions on Parallel and Distributed Systems"",""3 Feb 2009"",""1996"",""7"",""6"",""620"",""636"",""Previous methods of making wormhole-routed meshes fault tolerant have been based on adding virtual channels to the networks. This paper proposes an alternative method, one based on the turn model for designing wormhole routing algorithms. The turn model produces routing algorithms that are deadlock free, very adaptive, minimal or nonminimal, and livelock free for direct networks--whether or not they contain virtual channels. This paper illustrates how to modify the routing algorithms produced by the turn model to handle dynamic faults. This paper first describes how to modify the negative-first routing algorithm, which the turn model produces for n-dimensional meshes without virtual channels, to make it one-fault tolerant. Simulations of the one-fault-tolerant routing algorithm and other minimal and nonminimal routing algorithms in a two-dimensional mesh indicate that misrouting increases communication latencies significantly at high throughputs. The conclusion is that misrouting should be used only for increasing the degree of fault tolerance, never for just increasing adaptiveness. Finally , the paper describes how to modify the negative-first routing algorithm to make it (n - 1)-fault tolerant for n-dimensional meshes without virtual channels."",""1558-2183"","""",""10.1109/TPDS.1996.4772741"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4772741"",""Wormhole routing, fault-tolerant routing, adaptive routing, dynamic faults, mesh networks"",""Fault tolerance";Routing;Glass;Concurrent computing;Network topology;Switching circuits;Algorithm design and analysis;System recovery;Delay;"Throughput"","""",""66"","""",""22"",""IEEE"",""3 Feb 2009"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"File migration and file replication: a symbiotic relationship,""R. T. Hurley";" Soon Aun Yeap"",""Yeap are with the Computer Studies Program, Trent University, Peterborough, ONT, Canada";" Yeap are with the Computer Studies Program, Trent University, Peterborough, ONT, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""6"",""578"",""586"",""Much of the past research on file migration and file replication has examined these two resource management strategies in isolation or in an environment where they do not work together. We establish through simulation that these two strategies can be utilized simultaneously to potentially provide significant performance benefits over a system without file migration or replication. File replication can be viewed as a natural extension to file migration, and thus, we derive a dynamic file replication policy based on an established file migration heuristic: a file is migrated (or replicated) whenever a reduction in total mean response time of the file requests currently in the affected storage sites can be achieved. Through our performance model, we use simulation to establish the conditions under which our file migration/replication policies are beneficial in a distributed file system."",""1558-2183"","""",""10.1109/71.506696"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506696"","""",""Symbiosis";Costs;Concurrency control;Maintenance;"Degradation"","""",""28"",""11"",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;
"File-access characteristics of parallel scientific workloads,""N. Nieuwejaar"; D. Kotz; A. Purakayastha; C. Sclatter Ellis;" M. L. Best"",""Department of Computer Science 6211 Sudikoff Laboratory, Dartmouth College, Hanover, NH, USA"; Department of Computer Science 6211 Sudikoff Laboratory, Dartmouth College, Hanover, NH, USA; Department of Computer Science Lewine Science Research Center, Duke University, Durham, NC, USA; Department of Computer Science Lewine Science Research Center, Duke University, Durham, NC, USA;" Media Labovatory, Massachusetts Institute of Technology, Cambridge, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""10"",""1075"",""1089"",""Phenomenal improvements in the computational performance of multiprocessors have not been matched by comparable gains in I/O system performance. This imbalance has resulted in I/O becoming a significant bottleneck for many scientific applications. One key to overcoming this bottleneck is improving the performance of multiprocessor file systems. The design of a high-performance multiprocessor file system requires a comprehensive understanding of the expected workload. Unfortunately, until recently, no general workload studies of multiprocessor file systems have been conducted. The goal of the CHARISMA project was to remedy this problem by characterizing the behavior of several production workloads, on different machines, at the level of individual reads and writes. The first set of results from the CHARISMA project describe the workloads observed on an Intel iPSC/860 and a Thinking Machines CM-5. This paper is intended to compare and contrast these two workloads for an understanding of their essential similarities and differences, isolating common trends and platform-dependent variances. Using this comparison, we are able to gain more insight into the general principles that should guide multiprocessor file-system design."",""1558-2183"","""",""10.1109/71.539739"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=539739"","""",""File systems";Application software;Concurrent computing;Computer Society;Performance gain;Production;Student members;System performance;Scientific computing;"Supercomputers"","""",""105"",""1"",""46"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals"""
"Folded Petersen cube networks: new competitors for the hypercubes,""S. Ohring";" S. K. Das"",""Department of Computer Sciences, University of North Texas, TX, USA";" Department of Computer Sciences, University of North Texas, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""2"",""151"",""168"",""We introduce and analyze a new interconnection topology, called the k-dimensional folded Petersen (FP/sub k/) network, which is constructed by iteratively applying the Cartesian product operation on the well-known Petersen graph. Since the number of nodes in FP/sub k/ is restricted to a power of ten, for better scalability we propose a generalization, the folded Petersen cube network FPQ/sub n,k/=Q/sub n//spl times/FP/sub k/, which is a product of the n-dimensional binary hypercube (Q/sub n/) and FP/sub k/. The FPQ/sub n,k/ topology provides regularity, node- and edge-symmetry, optimal connectivity (and therefore maximal fault-tolerance), logarithmic diameter, modularity, and permits simple self-routing and broadcasting algorithms. With the same node-degree and connectivity, FPQ/sub n,k/ has smaller diameter and accommodates more nodes than Q/sub n+3k/, and its packing density is higher compared to several other product networks. This paper also emphasizes the versatility of the folded Petersen cube networks as a multicomputer interconnection topology by providing embeddings of many computationally important structures such as rings, multi-dimensional meshes, hypercubes, complete binary trees, tree machines, meshes of trees, and pyramids. The dilation and edge-congestion of all such embeddings are at most two."",""1558-2183"","""",""10.1109/71.485505"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485505"","""",""Hypercubes";Network topology;Tree graphs;Binary trees;Fault tolerance;Broadcasting;Multiprocessor interconnection networks;Routing;Scalability;"Positron emission tomography"","""",""50"","""",""30"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Generalized multiprocessor scheduling and applications to matrix computations,""G. N. S. Prasanna";" B. R. Musicus"",""AT and T Bell Laboratories, Inc., Murray Hill, NJ, USA";" BBN Laboratories, Inc., Cambridge, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""6"",""650"",""664"",""The paper considerably extends the multiprocessor scheduling techniques of G.N.S. Prasanna and B.R. Musicus (1995"; 1991) and applies it to matrix arithmetic compilation. Using optimal control theory in the special case where the speedup function of each task is p/sup /spl alpha// (where p is the amount of processing power applied to the task), closed form solution for task graphs formed from parallel and series connections was derived by G.N.S. Prasanna and B.R. Musicus (1995;" 1991). The paper extends these results for arbitrary DAGS. The optimality conditions impose nonlinear constraints on the flow of processing power from predecessors to successors, and on the finishing times of siblings. The paper presents a fast algorithm for determining and solving these nonlinear equations. The algorithm utilizes the structure of the finishing time equations to efficiently run a conjugate gradient minimization, leading to the optimal solution. The algorithm has been tested on a variety of DAGs commonly encountered in matrix arithmetic. The results show that if the p/sup /spl alpha// speedup assumption holds, the schedules produced are superior to heuristic approaches. The algorithm has been applied to compiling matrix arithmetic (K.P. Belkhale and P. Banerjee, 1993), for the MIT Alewife machine, a distributed shared memory multiprocessor. While matrix arithmetic tasks do not exactly satisfy the p/sup /spl alpha// speedup assumptions, the algorithm can be applied as a good heuristic. The results show that the schedules produced by our algorithm are faster than alternative heuristic techniques."",""1558-2183"","""",""10.1109/71.506703"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506703"","""",""Processor scheduling";Computer applications;Arithmetic;Finishing;Nonlinear equations;Optimal control;Closed-form solution;Minimization methods;Testing;"Scheduling algorithm"","""",""19"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Globally consistent event ordering in one-directional distributed environments,""P. Ammann"; S. Jajodia;" P. G. Frankl"",""Center for Secure Information Depavtment of Information and Softsoare Systems Engineering, George Mason University, Fairfax, VA, USA"; Center for Secure Information Depavtment of Information and Softsoare Systems Engineering, George Mason University, Fairfax, VA, USA;" Computer Science Department, Polytechnic University, Brooklyn, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""6"",""665"",""670"",""We consider communication structures for event ordering algorithms in distributed environments where information flows only in one direction. Example applications are multilevel security and hierarchically decomposed databases. Although the most general one directional communication structure is a partial order, partial orders do not enjoy the property of being consistently ordered, a formalization of the notion that local ordering decisions are ensured to be globally consistent. Our main result is that the crown free property is necessary and sufficient for a communication structure to be consistently ordered. We discuss the computational complexity of detecting crowns and sketch typical applications."",""1558-2183"","""",""10.1109/71.506704"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506704"","""",""Distributed databases";Clocks;Computer Society;Application software;Multilevel systems;Computational complexity;Data security;Computer networks;Distributed computing;"Counting circuits"","""",""7"","""",""14"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Graph isomorphism and identification matrices: parallel algorithms,""Lin Chen"",""FRL, Los Angeles, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""3"",""308"",""319"",""In this paper, we explore some properties of identification matrices and exhibit some uses of identification matrices in studying the graph isomorphism problem, a famous open problem. We show that, given two graphs in the form of a certain identification matrix, isomorphism can be tested efficiently in parallel if at least one matrix satisfies the circular 1s property, and more efficiently in parallel if at least one matrix satisfies the consecutive 1s property. Graphs which have identification matrices satisfying the consecutive 1s property include, among others, proper interval graphs and doubly convex bipartite graphs. The result presented here substantially broadens the class of graphs for which there are known efficient parallel isomorphism testing algorithms."",""1558-2183"","""",""10.1109/71.491584"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=491584"","""",""Parallel algorithms";Testing;Transmission line matrix methods;Bipartite graph;Phase change random access memory;Polynomials;"Algorithm design and analysis"","""",""19"","""",""29"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;
"Impact of memory contention on dynamic scheduling on NUMA multiprocessors,""D. Durand"; T. Montaut; L. Kervella;" W. Jalby"",""Computer and lnformation Science Department, University of Pennsylvania, Philadelphia, PA, USA"; Institut de Recherches in Informa tique et Systèmes Aléatoires, Rennes, France; Institut de Recherches in Informa tique et Systèmes Aléatoires, Rennes, France;" Laboratoire MASI, Université de Versailles Saint Quentin en Yvelines, Versailles, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""11"",""1201"",""1214"",""Self-scheduling is a method for task scheduling in parallel programs, in which each processor acquires a new block of tasks for execution whenever it becomes idle. To get the best performance, the block size must be chosen to balance the scheduling overhead against the load imbalance. To determine the best block size, a better understanding of the role of load imbalance in self-scheduling performance is needed. In this paper we study the effect of memory contention on task duration distributions and, hence, load balancing in self-scheduling on a Nonuniform Memory Access (NUMA) machine. Experimental studies on a BBN TC2000 are used to reveal the strengths and weaknesses of analytical performance models to predict running time and optimal block size. The models are shown to be very accurate for small block sizes. However, the models fail when the block size is large due to a previously unrecognized source of load imbalance. We extend the analytical models to address this failure. The implications for the construction of compilers and runtime systems are discussed."",""1558-2183"","""",""10.1109/71.544359"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=544359"","""",""Dynamic scheduling";Processor scheduling;Analytical models;Load management;Performance analysis;Predictive models;Scalability;Multiprocessor interconnection networks;Programming profession;"Shape"","""",""11"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Issues in the design of high performance SIMD architectures,""J. D. Allen";" D. E. Schimmel"",""School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA";" School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""8"",""818"",""829"",""In this paper, we consider the design of high performance SIMD architectures. We examine three mechanisms by which the performance of this class of machines may be improved, and which have been largely unexplored by the SIMD community. The mechanisms are pipelined instruction broadcast, pipelining of the PE architecture, and the introduction of a novel memory hierarchy in the PE address space which we denote the direct only data cache, (dod-cache). For each of the performance improvements, we develop analytical models of the potential speedup, and apply those models to real program traces obtained on a MasPar MP-2 system. In addition, we consider the impact of all improvements taken together."",""1558-2183"","""",""10.1109/71.532113"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=532113"","""",""Broadcasting";Clocks;Pipeline processing;Delay;Analytical models;Integrated circuit packaging;Packaging machines;Integrated circuit technology;"Microprocessors"","""",""24"","""",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Leader election in the presence of link failures,""G. Singh"",""Department of Computing and Information Sciences, Kansas State University, Manhattan, KS, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""3"",""231"",""236"",""We study the problem of leader election in the presence of intermittent link failures. We assume that up to N/2-1 links incident on each node may fail during the execution of the protocol. We present a message optimal algorithm with message complexity O(N/sup 2/)."",""1558-2183"","""",""10.1109/71.491576"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=491576"","""",""Nominations and elections";Protocols;Distributed algorithms;Algorithm design and analysis;Distributed computing;"Electronic mail"","""",""53"",""3"",""7"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;
"Localizing failures in distributed synchronization,""M. Choy";" A. K. Singh"",""Department of Computer Science, Hong Kong University of Science and Technology, Hong Kong, China";" Department of Computer Science, University of California, Santa Barbara, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""7"",""705"",""716"",""The fault-tolerance of distributed algorithms is investigated in asynchronous message passing systems with undetectable process failures. Two specific synchronization problems are considered, the dining philosophers problem and the binary committee coordination problem. The abstraction of a bounded doorway is introduced as a general mechanism for achieving individual progress and good failure locality. Using it as a building block, optimal fault-tolerant algorithms are constructed for the two problems."",""1558-2183"","""",""10.1109/71.508250"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=508250"","""",""Distributed computing";Fault tolerant systems;Distributed algorithms;Fault tolerance;Electronic switching systems;Computer science;Message passing;Algorithm design and analysis;"Fault detection"","""",""6"","""",""22"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Loop transformations for fault detection in regular loops on massively parallel systems,""Chun Gong"; R. Melhem;" R. Gupta"",""Massachusetts Language Laboratory, Chelmsford, MA, USA"; University of Pittsburgh, Pittsburgh, PA, USA;" University of Pittsburgh, Pittsburgh, PA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""12"",""1238"",""1249"",""Distributed-memory systems can incorporate thousands of processors at a reasonable cost. However, with an increasing number of processors in a system, fault detection and fault tolerance become critical issues. By replicating the computation on more than one processor and comparing the results produced by these processors, errors can be detected. During the execution of a program, due to data dependencies, typically not all of the processors in a multiprocessor system are busy at all times. Therefore processor schedules contain idle time slots and it is the goal of this work to exploit these idle time slots to schedule duplicated computation for the purpose of fault detection. We propose a compiler-assisted approach to fault detection in regular loops on distributed-memory systems. This approach achieves fault detection by duplicating the execution of statement instances. After carefully analyzing the data dependencies of a regular loop, selected instances of loop statements are duplicated in a way that ensures the desired fault coverage. We first present duplication strategies for fault detection and show that these strategies use idle processor times for executing replicated statements, whenever possible. Next, we present loop transformations to implement these fault-detection strategies. Also, a general framework for selecting appropriate loop transformations is developed. Experimental results performed on the CRAY-T3D show that the overhead of adding the fault detection capability is usually less than 25%, and is less than 10% when communication overhead is reduced by grouping messages."",""1558-2183"","""",""10.1109/71.553273"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=553273"","""",""Fault detection";Costs;Redundancy;Multiprocessing systems;Program processors;Scalability;Fault tolerant systems;Hardware;VLIW;"Postal services"","""",""24"",""1"",""30"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Low-cost checkpointing and failure recovery in mobile computing systems,""R. Prakash";" M. Singhal"",""Department of Cornputer Science, University of Rochester, Rochester, NY, USA";" Department of Computer and lnfoumation Science, Ohio State Uinversity, Columbus, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""10"",""1035"",""1048"",""A mobile computing system consists of mobile and stationary nodes, connected to each other by a communication network. The presence of mobile nodes in the system places constraints on the permissible energy consumption and available communication bandwidth. To minimize the lost computation during recovery from node failures, periodic collection of a consistent snapshot of the system (checkpoint) is required. Locating mobile nodes contributes to the checkpointing and recovery costs. Synchronous snapshot collection algorithms, designed for static networks, either force every node in the system to take a new local snapshot, or block the underlying computation during snapshot collection. Hence, they are not suitable for mobile computing systems. If nodes take their local checkpoints independently in an uncoordinated manner, each node may have to store multiple local checkpoints in stable storage. This is not suitable for mobile nodes as they have small memory. This paper presents a synchronous snapshot collection algorithm for mobile systems that neither forces every node to take a local snapshot, nor blocks the underlying computation during snapshot collection. If a node initiates snapshot collection, local snapshots of only those nodes that have directly or transitively affected the initiator since their last snapshots need to be taken. We prove that the global snapshot collection terminates within a finite time of its invocation and the collected global snapshot is consistent. We also propose a minimal rollback/recovery algorithm in which the computation at a node is rolled back only if it depends on operations that have been undone due to the failure of node(s). Both the algorithms have low communication and storage overheads and meet the low energy consumption and low bandwidth constraints of mobile computing systems."",""1558-2183"","""",""10.1109/71.539735"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=539735"","""",""Checkpointing";Mobile computing;Computer networks;Energy consumption;Mobile communication;Bandwidth;Communication networks;Costs;Algorithm design and analysis;"Energy storage"","""",""105"",""5"",""28"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"MAD kernels: an experimental testbed to study multiprocessor memory system behavior,""A. K. Nanda";" L. M. Ni"",""Transarc Corporation, Pittsburg, PA, USA";" Department of Computer Science, Michigan State University, East Lansing, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""2"",""207"",""217"",""On large-scale multiprocessors, access to common memory is one of the key performance limiting factors. The shared-memory performance depends not only on the characteristics of the memory hierarchy itself, but also upon the characteristics of the memory address streams and the interaction between the two. We present a technique for multiprocessor workload construction and a family of artificial kernels, called MAD-kernels, to systematically investigate the behavior of the memory hierarchy. The measured performance is independent of any particular application or algorithm. The proposed methodology is demonstrated on two commercial shared-memory systems."",""1558-2183"","""",""10.1109/71.485509"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485509"","""",""Kernel";System testing;Large-scale systems;Particle measurements;Multiprocessor interconnection networks;Performance analysis;Hardware;Degradation;Bandwidth;"Memory architecture"","""","""","""",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Matrix partitioning on a virtual shared memory parallel machine,""B. Charny"",""Audre, Inc., San Diego, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""4"",""343"",""355"",""The general problem considered in the paper is partitioning of a matrix operation between processors of a parallel system in an optimum load-balanced way without potential memory contention. The considered parallel system is defined by several features the main of which is availability of a virtual shared memory divided into segments. If partitioning of a matrix operation causes parallel access to the same memory segment with writing data to the segment by at least one processor, then contention between processors arises which implies performance degradation. To eliminate such situation, a restriction is imposed on a class of possible partitionings, so that no two processors would write data to the same segment. On the resulting class of contention-free partitionings, a load-balanced optimum partitioning is defined as satisfying independent minimax criteria. The main result of the paper is an algorithm for finding the optimum partitioning by means of analytical solution of respective minimax problems. The paper also discusses implementation and performance issues related to the algorithm, on the basis of experience at Kendall Square Research Corporation, where the partitioning algorithm was used for creating high-performance parallel matrix libraries."",""1558-2183"","""",""10.1109/71.494629"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=494629"","""",""Parallel machines";Partitioning algorithms;Minimax techniques;Electronic mail;Arithmetic;Matrix decomposition;Availability;Writing;Degradation;"Algorithm design and analysis"","""",""2"","""",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Mesh-connected trees: a bridge between grids and meshes of trees,""K. Efe";" A. Fernandez"",""Center for Advanced Computer Studies, University of Southwestern Louisiana, Lafayette, LA, USA";" Departmento de Arquitectura y Tecnología de Computadores, Universidad Politécnica de Madrid, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""12"",""1281"",""1291"",""The grid and the mesh of trees (or MOT) are among the best-known parallel architectures in the literature. Both of them enjoy efficient VLSI layouts, simplicity of topology, and a large number of parallel algorithms that can efficiently execute on them. One drawback of these architectures is that algorithms that perform best on one of them do not perform very well on the other. Thus there is a gap between the algorithmic capabilities of these two architectures. We propose a new class of parallel architectures, called the mesh-connected trees (or MCT) that can execute grid algorithms as efficiently as the grid, and MOT algorithms as efficiently as the MOT, up to a constant amount of slowdown. In particular, the MCT topology contains the MOT as a subgraph and emulates the grid via embedding with dilation 3 and congestion two. This significant amount of computational versatility offered by the MCT comes at no additional VLSI area cost over these earlier networks. Many topological, routing, and embedding properties analyzed here suggest that the MCT architecture is also a serious competitor for the hypercube. In fact, while the MCT is much simpler and cheaper than the hypercube, for all the algorithms we developed, the running time complexity on the MCT matches those of well known hypercube algorithms. We also present an interesting variant of the MCT architecture that admits both the MOT and the torus as its subgraphs. While most of the discussion in this paper is focused on the MCT architecture itself, these analyses can be easily extended to the variant of the MCT presented here."",""1558-2183"","""",""10.1109/71.553283"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=553283"","""",""Bridges";Hypercubes;Parallel architectures;Very large scale integration;Parallel algorithms;Network topology;Computer networks;Costs;Routing;"Computer architecture"","""",""18"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Multiskewing-a novel technique for optimal parallel memory access,""A. Deb"",""Department of Computer Science, Memorial University of Newfoundland, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""6"",""595"",""604"",""The disparity between the processing speed and the data access rates presents a serious bottleneck in pipelined/vector processors. The memory bank conflict in interleaved system can be alleviated by skewing, for scientific computations performing functions on varieties of submatrices. So far uniskewing involving periodic and linear functions have been studied. Several difficulties encountered in such schemes are that they require a prime number of memory modules, may create wasted memory space, or addressing functions and the alignment network become complex. We present a new technique, termed multiskewing, which applies multiple functions on different sections of the array. Each of these functions may be as simple as a linear shift. We show that some of the advantages are that it does not require a prime number of memory, memory utilization factor is 100%, maintains the logical structure of the array, and allows optimal memory access of a large class of submatrices."",""1558-2183"","""",""10.1109/71.506698"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506698"","""",""Logic arrays";Bandwidth;Computer architecture;Concurrent computing;Computer science;Vectors;Arithmetic;Decoding;Hardware;"Standards organizations"","""",""16"","""",""13"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Multiway merging in parallel,""Zhaofang Wen"",""Hewlwtt-Packard Convex Technology Center, Richardson, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""1"",""11"",""17"",""The problem of merging k (k/spl ges/2) sorted lists is considered. We give an optimal parallel algorithm which takes O((n log k/p)+log n) time using p processors on a parallel random access machine that allows concurrent reads and exclusive writes, where n is the total size of the input lists. This algorithm achieves O(log n) time using p=n log k/log n processors. Most of the previous log n research for this problem has been focused on the case when k=2. Very recently, parallel solutions for the case when k=2 have been reported. Our solution is the first logarithmic time optimal parallel algorithm for the problem when k/spl ges/2. It can also be seen as a unified optimal parallel algorithm for sorting and merging. In order to support the algorithm, a new processor assignment strategy is also presented."",""1558-2183"","""",""10.1109/71.481593"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=481593"","""",""Merging";Parallel algorithms;Sorting;Information retrieval;Computer Society;Concurrent computing;Database systems;"Hardware"","""",""5"","""",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;
"Network-based multicomputers: a practical supercomputer architecture,""P. Steenkiste"",""Sckool of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""8"",""861"",""875"",""Multicomputers built around a general network are an attractive architecture for a wide class of applications. The architecture provides many benefits compared with special-purpose approaches, including heterogeneity, reuse of application and system code, and sharing of resources. The architecture also poses new challenges to both computer system implementers and users. First, traditional local-area networks do not have enough bandwidth and create a communication bottleneck, thus seriously limiting the set of applications that can be run effectively. Second, programmers have to deal with large bodies of code distributed over a variety of architectures, and work in an environment where both the network and nodes are shared with other users. Our experience in the Nectar project shows that it is possible to overcome these problems. We show how networks based on high-speed crossbar switches and efficient protocol implementations can support high bandwidth and low latency communication while still enjoying the flexibility of general networks, and we use three applications to demonstrate that network-based multicomputers are a practical architecture. We also show how the network traffic generated by this new class of applications poses severe requirements for networks."",""1558-2183"","""",""10.1109/71.532117"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=532117"","""",""Supercomputers";Computer architecture;Application software;Bandwidth;Local area networks;Programming profession;Switches;Communication switching;Protocols;"Delay"","""",""6"","""",""67"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"New encoding/decoding methods for designing fault-tolerant matrix operations,""D. L. Tao"; C. R. P. Hartmann;" Y. S. Han"",""Department of Electrical Engineering, State University of New York, Stony Brook, Stony Brook, NY, USA"; School of Computer and Information Science, Syracuse University, Syracuse, NY, USA;" Department of Electronics Engineering, HuaFan College of Humanities and Technology, Taipei, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""9"",""931"",""938"",""Algorithm-based fault tolerance (ABFT) can provide a low-cost error protection for array processors and multiprocessor systems. Several ABFT techniques (weighted check-sum) have been proposed to design fault-tolerant matrix operations. In these schemes, encoding/decoding uses either multiplications or divisions so that overhead is high. In this paper, new encoding/decoding methods are proposed for designing fault-tolerant matrix operations. The unique feature of these new methods is that only additions and subtractions are used in encoding/decoding. In this paper, new algorithms are proposed to construct error detecting/correcting codes with the minimum Hamming distance 3 and 4. We will show that the overhead introduced due to the incorporation of fault tolerance is drastically reduced by using these new coding schemes."",""1558-2183"","""",""10.1109/71.536937"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=536937"","""",""Encoding";Decoding;Design methodology;Fault tolerance;Fault tolerant systems;Matrix decomposition;Multiprocessing systems;Error correction codes;Fault detection;"Protection"","""",""6"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"On effective execution of nonuniform DOACROSS loops,""Ding-Kai Chen";" Pen-Chung Yew"",""Silicon Graphics Computer Systems, Mountain View, CA, USA";" Department of Computer Science, University of Minnesota, Saint Paul, MN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""5"",""463"",""476"",""It is extremely difficult to parallelize DOACROSS loops with nonuniform loop-carried dependences. In this paper, we present a static scheduling scheme with an accompanying synchronization strategy that can execute such DOACROSS loops effectively and efficiently. Our approach uses one of the parallelization techniques called Dependence Uniformization, which finds a small set of uniform dependence vectors to cover all possible nonuniform dependences in a DOACROSS loop. It differs from the previous schemes in that we demonstrate a better way to select the uniform dependence vectors. When used with the Static Strip Scheduling scheme, the proposed uniform dependence vector set allows us to enforce dependences with more locality, which reduces the requirement of explicit synchronization considerably while retaining most of the parallelism. This paper describes the uniform dependence vectors selection strategy and the static strip scheduling scheme. The performance analysis and examples are also presented."",""1558-2183"","""",""10.1109/71.503771"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=503771"","""",""Strips";Parallel processing;Senior members;Performance analysis;Optimizing compilers;Runtime;Silicon;Computer graphics;Computer science;"Electronic mail"","""",""18"","""",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"On general results for all-to-all broadcast,""Ming-Syan Chen"; Jeng-Chun Chen;" P. S. Yu"",""IBM Thomas J. Watson Research Center, Yorktown, NY, USA"; IBM Thomas J. Watson Research Center, Yorktown, NY, USA;" IBM Thomas J. Watson Research Center, Yorktown, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""4"",""363"",""370"",""All-to-all broadcast refers to the process by which every node broadcasts its certain piece of information to all other nodes in the system. In this paper, we develop all-to-all broadcast schemes by dealing with two classes of schemes. A prior scheme based on generation of minimal complete sets is first described, and then a new scheme based on propagation of experts is developed. The former always completes the broadcasting in the minimal number of steps and the latter is designed to minimize the number of messages. Performance of these two classes of schemes is comparatively analyzed. The all-to-all broadcast scheme desired can be derived by combining the advantages of these two classes of schemes."",""1558-2183"","""",""10.1109/71.494631"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=494631"","""",""Broadcasting";Distributed computing;Computer Society;Protocols;Electronic mail;Senior members;Performance analysis;Message passing;Clocks;"Synchronization"","""",""8"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"On parallel algorithms for single-fault diagnosis in fault propagation graph systems,""N. S. V. Rao"",""Center for Engineering Systems Advanced Research, Oak Ridge National Laboratory, Oak Ridge, TN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""12"",""1217"",""1223"",""Systems modeled as directed graphs where nodes represent components and edges represent fault propagation between components, are studied from a parallel computation viewpoint. Some of the components are equipped with alarms that ring in response to an abnormal condition. The single fault diagnosis problem is to compute the set of all potential failure sources, P/sub S/, that correspond to a set of ringing alarms A/sub R/. There is a lower bound for any sequential algorithm for this problem (under a decision tree model)."",""1558-2183"","""",""10.1109/71.553268"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=553268"","""",""Parallel algorithms";Fault diagnosis;Phase change random access memory;Hypercubes;Aircraft;Physics computing;System testing;Concurrent computing;Decision trees;"Chemical industry"","""",""17"","""",""33"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"On the design and implementation of broadcast and global combine operations using the postal model,""J. Bruck"; L. De Coster; N. Dewulf; Ching-Tien Ho;" R. Lauwereins"",""California Institute of Technology, Pasadena, CA, USA"; K.U.Leuven-ESAT, Heverlee, Belgium; K.U.Leuven-ESAT, Heverlee, Belgium; IBM Almaden Research Center, San Jose, CA, USA;" K.U.Leuven-ESAT, Heverlee, Belgium"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""3"",""256"",""265"",""There are a number of models that were proposed in recent years for message passing parallel systems. Examples are the postal model and its generalization the LogP model. In the postal model a parameter /spl lambda/ is used to model the communication latency of the message-passing system. Each node during each round can send a fixed-size message and, simultaneously, receive a message of the same size. Furthermore, a message sent out during round r will incur a latency of /spl lambda/ and will arrive at the receiving node at round r+/spl lambda/-1. Our goal in this paper is to bridge the gap between the theoretical modeling and the practical implementation. In particular, we investigate a number of practical issues related to the design and implementation of two collective communication operations, namely, the broadcast operation and the global combine operation. Those practical issues include, for example, (1) techniques for measurement of the value of /spl lambda/ on a given machine, (2) creating efficient broadcast algorithms that get the latency h and the number of nodes n as parameters and (3) creating efficient global combine algorithms for parallel machines with /spl lambda/ which is not an integer. We propose solutions that address those practical issues and present results of an experimental study of the new algorithms on the Inter Delta machine. Our main conclusion is that the postal model can help in performance prediction and tuning, for example, a properly tuned broadcast improves the known implementation by more than 20%."",""1558-2183"","""",""10.1109/71.491579"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=491579"","""",""Broadcasting";Delay;Message passing;Senior members;Computer Society;Bridges;Parallel machines;Predictive models;Postal services;"User interfaces"","""",""24"","""",""29"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals"""
"Optimal and load balanced mapping of parallel priority queues in hypercubes,""S. K. Das"; M. C. Pinotti;" F. Sarkar"",""Department of Computer Sciences, University of North Texas, Denton, TX, USA"; Instituto Elaborazione dell'lnformazione, CNR, Pisa, Italy;" Novtel Technologies, Richardson, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""6"",""555"",""564"",""We efficiently map a priority queue on the hypercube architecture in a load balanced manner, with no additional communication overhead, and present optimal parallel algorithms for performing insert and deletemin operations. Two implementations for such operations are proposed on the single port hypercube model. In a b-bandwidth, n-item priority queue in which every node contains b items in sorted order, the first implementation achieves optimal speed up of O(min{log n, b log n/log b+log log n}) for inserting b presorted items or deleting b smallest items, where b=O(n/sup 1/c/) with c>1. In particular, single insertion and deletion operations are cost optimal and require O(log n/p+log p) time using O(log n/log log n) processors. The second implementation is more scalable since it uses a larger number of processors, and attains a """"nearly"""" optimal speedup on the single hypercube. Namely, the insertion of log n presorted items or the deletion of the log n smallest items is accomplished in O(log log n/sup 2/) time using O(log/sup 2/ n/log log n) processors. Finally, on the slightly more powerful pipelined hypercube model, the second implementation performs log n operations in O(log log n) time using O(log/sup 2/ n/log log n) processors, thus achieving an optimal speed up. To the best of our knowledge, our algorithms are the first implementations of b-bandwidth distributed priority queues, which are load balanced and yet guarantee optimal speed ups."",""1558-2183"","""",""10.1109/71.506694"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506694"","""",""Hypercubes";Sorting;Computer Society;Data structures;Computer architecture;Parallel algorithms;Discrete event simulation;Scheduling algorithm;"Operating systems"","""",""24"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Optimal information dissemination in star and pancake networks,""P. Berthome"; A. Ferreira;" S. Perennes"",""École Normale Supérieure de Lyon, Unité de Recherche Associé au CNRS No. 1398, CNRS-Laboratoire de l'Informatique du Parallélisme, Lyon, France"; École Normale Supérieure de Lyon, Unité de Recherche Associé au CNRS No. 1398, CNRS-Laboratoire de l'Informatique du Parallélisme, Lyon, France;" I3S, CNRS, La Valbonne, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""12"",""1292"",""1300"",""This paper presents a new decomposition technique for hierarchical Cayley graphs. This technique yields a very easy implementation of the divide and conquer paradigm for some problems on very complex architectures as the star graph or the pancake. As applications, we introduce algorithms for broadcasting and prefix-like operations that improve the best known bounds for these problems. We also give the first nontrivial optimal gossiping algorithms for these networks. In star-graphs and pancakes with N=n! processors, our algorithms take less than [log N]+1.5n steps."",""1558-2183"","""",""10.1109/71.553290"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=553290"","""",""Intelligent networks";Broadcasting;Hypercubes;Algorithm design and analysis;Concurrent computing;Network topology;Multiprocessor interconnection networks;Computer networks;"Parallel programming"","""",""42"","""",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Optimal layouts of midimew networks,""F. C. M. Lau";" Guihai Chen"",""Department of Computer Science, University of Hong Kong, Hong Kong, China";" Department of Computer Science, University of Hong Kong, Hong Kong, China"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""9"",""954"",""961"",""Midimew networks are mesh-connected networks derived from a subset of degree-4 circulant graphs. They have minimum diameter and average distance among all degree-4 circulant graphs, and are better than some of the most common topologies for parallel computers in terms of various cost measures. Among the many midimew networks, the rectangular ones appear to be most suitable for practical implementation. Unfortunately, with the normal way of laying out these networks on a 2D plane, long cross wires that grow with the size of the network exist. In this paper, we propose ways to lay out rectangular midimew networks in a 2D grid so that the length of the longest wire is at most a small constant. We prove that these constants are optimal under the assumption that rows and columns are moved as a whole during the layout process."",""1558-2183"","""",""10.1109/71.536939"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=536939"","""",""Wire";Concurrent computing;Multiprocessor interconnection networks;Computer networks;Very large scale integration;Network topology;Costs;Embedded computing;High performance computing;"Parallel processing"","""",""13"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Optimal simulation of linear multiprocessor architectures on multiply-twisted cube using generalized Gray Codes,""S. Q. Zheng";" S. Latifi"",""Department of Computer Science, Louisiana State University, Baton Rouge, LA, USA";" Department of Electrical and Computer Engineering, University of Nevada, Las Vegas, NV, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""6"",""612"",""619"",""We consider the problem of simulating linear arrays and rings on the multiply twisted cube. We introduce a new concept, the reflected link label sequence, and use it to define a generalized Gray Code (GGC). We show that GGCs can be easily used to identify Hamiltonian paths and cycles in the multiply twisted cube. We also give a method for embedding a ring of arbitrary number of nodes into the multiply twisted cube."",""1558-2183"","""",""10.1109/71.506700"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506700"","""",""Computational modeling";Hypercubes;Tree graphs;Multiprocessor interconnection networks;Computer architecture;Data communication;Sorting;Switches;Computer science;"Fault tolerance"","""",""28"","""",""13"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Optimal synthesis of algorithm-specific lower-dimensional processor arrays,""K. N. Ganapathy";" B. W. Wah"",""Telecommunications Division, Rockwell International, Newport Beach, CA, USA";" Department of Electrical and Computer Engineering and the Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, Urbana-Champaign, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""3"",""274"",""287"",""Processor arrays are frequently used to deliver high performance in many applications with computationally intensive operations. This paper presents the general parameter method (GPM), a systematic parameter-based approach for synthesizing such algorithm-specific architectures. GPM can synthesize processor arrays of any lower dimension from a uniform-recurrence description of the algorithm. The design objective is a general nonlinear and nonmonotonic user-specified function, and depends on attributes such as computation time of the recurrence on the processor array, completion time, load time, and drain time. In addition, bounds on some or all of these attributes can be specified. GPM performs an efficient search of polynomial complexity to find the optimal design satisfying the user-specified design constraints. As an illustration, we show how GPM can be used to find optimal linear processor arrays for computing transitive closures. We consider design objectives that minimize computation time, or processor count, or completion time (including load and drain times), and user-specified constraints on number of processing elements and/or computation/completion times. We show that GPM can be used to obtain optimal designs that trade between number of processing elements and completion time, thereby allowing the designer to choose a design that best meets the specified design objectives. We also show the equivalence between the model assumed in GPM and that in the popular dependence-based methods. Consequently, GPM can be used to find optimal designs for both models."",""1558-2183"","""",""10.1109/71.491581"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=491581"","""",""Computer applications";Computer architecture;Polynomials;High performance computing;Time factors;Process design;Systolic arrays;"Very large scale integration"","""",""14"","""",""19"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Packet synchronization for synchronous optical deflection-routed interconnection networks,""J. R. Feehrer";" L. H. Ramfelt"",""Hewlett Packard Company, Fort Collins, CO, USA";" Department of Teleinformatics, Royal Institute of Technology in Sweden, KTHITeIeinformatik, Electrum, Kista, Sweden"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""6"",""605"",""611"",""Deflection routing resolves output port contention in packet switched multiprocessor interconnection networks by granting the preferred port to the highest priority packet and directing contending packets out other ports. When combined with optical links and switches, deflection routing yields simple bufferless nodes, high bit rates, scalable throughput, and low latency. We discuss the problem of packet synchronization in synchronous optical deflection networks with nodes distributed across boards, racks, and cabinets. Synchronous operation is feasible due to very predictable optical propagation delays. A routing control processor at each node examines arriving packets and assigns them to output ports. Packets arriving on different input ports must be bit wise aligned";" there are no elastic buffers to correct for mismatched arrivals. """"Time of flight"""" packet synchronization is done by balancing link delays during network design. Using a directed graph network model, we formulate a constrained minimization problem for minimizing link delays subject to synchronization and packaging constraints. We demonstrate our method on a ShuffleNet graph, and show modifications to handle multiple packet sizes and latency critical paths."",""1558-2183"","""",""10.1109/71.506699"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506699"","""",""Optical buffering";Optical packet switching;Routing;Optical interconnections;Delay;Multiprocessor interconnection networks;Optical fiber communication;Optical switches;Bit rate;"Throughput"","""",""4"","""",""39"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Parallel asynchronous team algorithms: convergence and performance analysis,""B. Baran"; E. Kaszkurewicz;" A. Bhaya"",""National Computer Center, National University of Asuncion, Paraguay"; Department of Electrical Engineering, Federal University of Rio de Janeiro, Rio de Janeiro, Brazil;" Department of Electrical Engineering, Federal University of Rio de Janeiro, Rio de Janeiro, Brazil"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""7"",""677"",""688"",""This paper formalizes a general technique to combine different methods in the solution of large systems of nonlinear equations using parallel asynchronous implementations on distributed-memory multiprocessor systems. Such combinations of methods, referred to as team algorithms, are evaluated as a way of obtaining desirable properties of different methods and a sufficient condition for their convergence is derived. The load flow problem of electrical power networks is presented as an example problem that, under certain conditions, has the characteristics to make a team algorithm an appealing choice for its solution. Experimental results of an implementation on an Intel iPSC/860 Hypercube are reported, showing that considerable speedup and robustness can be obtained using team algorithms."",""1558-2183"","""",""10.1109/71.508248"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=508248"","""",""Convergence";Performance analysis;Load flow;Iterative algorithms;Algorithm design and analysis;Sufficient conditions;Distributed computing;Nonlinear equations;Hypercubes;"Computer networks"","""",""25"","""",""22"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Parallel computing in networks of workstations with Paralex,""R. Davoli"; L. . -A. Giachini; O. Babaoglu; A. Amoroso;" L. Alvisi"",""Department of Computer Science, University of Bologna, Bologna, Italy"; Department of Computer Science, University of Bologna, Bologna, Italy; Department of Computer Science, University of Bologna, Bologna, Italy; Department of Computer Science, University of Bologna, Bologna, Italy;" Department of Computer Science, University of Texas, Austin, Austin, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""4"",""371"",""384"",""Modern distributed systems consisting of powerful workstations and high-speed interconnection networks are an economical alternative to special-purpose supercomputers. The technical issues that need to be addressed in exploiting the parallelism inherent in a distributed system include heterogeneity, high-latency communication, fault tolerance and dynamic load balancing. Current software systems for parallel programming provide little or no automatic support towards these issues and require users to be experts in fault-tolerant distributed computing. The Paralex system is aimed at exploring the extent to which the parallel application programmer can be liberated from the complexities of distributed systems. Paralex is a complete programming environment and makes extensive use of graphics to define, edit, execute, and debug parallel scientific applications. All of the necessary code for distributing the computation across a network and replicating it to achieve fault tolerance and dynamic load balancing is automatically generated by the system. In this paper we give an overview of Paralex and present our experiences with a prototype implementation."",""1558-2183"","""",""10.1109/71.494632"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=494632"","""",""Parallel processing";Workstations;Fault tolerant systems;Load management;Distributed computing;Multiprocessor interconnection networks;Power generation economics;Environmental economics;Supercomputers;"Software systems"","""",""11"",""2"",""42"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals"""
"Parallel divide and conquer on meshes,""V. Lo"; S. Rajopadhye;" J. A. Telle"",""Dept. of Comput. & Inf. Sci., Oregon Univ., Eugene, OR, USA"; NA;" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""10"",""1049"",""1058"",""We address the problem of mapping divide-and-conquer programs to mesh connected multicomputers with wormhole or store-and-forward routing. We propose the binomial tree as an efficient model of parallel divide-and-conquer and present two mappings of the binomial tree to the 2D mesh. Our mappings exploit regularity in the communication structure of the divide-and-conquer computation and are also sensitive to the underlying flow control scheme of the target architecture. We evaluate these mappings using new metrics which are extensions of the classical notions of dilation and contention. We introduce the notion of communication slowdown as a measure of the total communication overhead incurred by a parallel computation. We conclude that significant performance gains can be realized when the mapping is sensitive to the flow control scheme of the target architecture."",""1558-2183"","""",""10.1109/71.539736"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=539736"","""",""Routing";Computer Society;Communication system control;Computer architecture;Tree graphs;Concurrent computing;Performance gain;Problem-solving;Embedded computing;"Large-scale systems"","""",""9"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Parallelized direct execution simulation of message-passing parallel programs,""P. M. Dickens"; P. Heidelberger;" D. M. Nicol"",""NASA Langley Research Center, ICASE, Hampton, VA, USA"; IBM Thomas J. Watson Research Center, Yorktown, NY, USA;" Department of Computer Science, College of William and Mary, Williamsburg, VA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""10"",""1090"",""1105"",""As massively parallel computers proliferate, there is growing interest in finding ways by which performance of massively parallel codes can be efficiently predicted. This problem arises in diverse contexts such as parallelizing compilers, parallel performance monitoring, and parallel algorithm development. In this paper, we describe one solution where one directly executes the application code, but uses a discrete-event simulator to model details of the presumed parallel machine, such as operating system and communication network behavior. Because this approach is computationally expensive, we are interested in its own parallelization, specifically the parallelization of the discrete-event simulator. We describe methods suitable for parallelized direct execution simulation of message-passing parallel programs, and report on the performance of such a system, LAPSE (Large Application Parallel Simulation Environment), we have built on the Intel Paragon. On all codes measured to date, LAPSE predicts performance well, typically within 10% relative error. Depending on the nature of the application code, we have observed low slowdowns (relative to natively executing code) and high relative speedups using up to 64 processors."",""1558-2183"","""",""10.1109/71.539740"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=539740"","""",""Virtual machining";Computational modeling;Concurrent computing;High performance computing;Instruments;Performance analysis;Performance evaluation;Communication networks;NASA;"Space technology"","""",""36"","""",""39"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Performance analysis of finite-buffered asynchronous multistage interconnection networks,""P. Mohapatra";" C. R. Das"",""Departmmt of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA";" Department of Computer Science and Engineering, Pennsylvania State University, University Park, PA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""1"",""18"",""25"",""We present a queueing model for performance analysis of finite-buffered multistage interconnection networks. The proposed model captures network behaviour in an asynchronous communication mode and is based on realistic assumptions. A uniform traffic model is developed first and then extended to capture nonuniform traffic in the presence of a hot-spot. Throughput and delay are computed using the proposed model and the results are validated via simulation. The analysis is extended to predict performance of MIN-based multiprocessors. The effects of buffer length, switch size, and the maximum allowable outstanding requests on the system performance are discussed. Various design decisions using this model are drawn with respect to delay, throughput, and system power."",""1558-2183"","""",""10.1109/71.481594"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=481594"","""",""Performance analysis";Telecommunication traffic;Traffic control;Throughput;Switches;Queueing analysis;Multiprocessor interconnection networks;Asynchronous communication;Delay;"Computational modeling"","""",""8"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Randomized routing with shorter paths,""E. Upfal"; S. Felperin;" M. Snir"",""Weizmann Institute of Science, Rehovot, Israel"; IBM System Architecture Group, Argentina;" IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""4"",""356"",""362"",""Studies the use of randomized routing in multistage networks. While log N additional randomizing stages are needed to break """"spatial locality"""", within each permutation, only log log N additional randomizing stages are needed to break """"temporal locality"""" among successive permutations. Thus, log N bits of initial randomization per input, followed by log log N bits of randomization per packet are sufficient to ensure that t permutations are delivered in time t+log N. We present simulation results that validate this analysis."",""1558-2183"","""",""10.1109/71.494630"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=494630"","""",""Routing";Delay;Switches;Analytical models;Circuit simulation;Context;Switching circuits;Communication switching;Intelligent networks;"Packet switching"","""",""5"","""",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Resource allocation in cube network systems based on the covering radius,""Nian-Feng Tzeng";" Gui-Liang Feng"",""Centev for Advanced Computer Studies, University of Southwestern Louisiana, Lafayette, LA, USA";" Centev for Advanced Computer Studies, University of Southwestern Louisiana, Lafayette, LA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""4"",""328"",""342"",""When multiple copies of a certain resource exist in a cube network system, it is desirable that every nonresource node can reach the resource in a given number of hops. In this paper, we introduce systematic approaches to resource allocation in a cube system so that each nonresource node is connected with a specified number of resource copies and that the allocation performance measure of interest is optimized. The methodology used is based on the covering radius results of known codes. These codes aid in constructing desired linear codes whose codewords address nodes where resource copies are placed. The resource allocation problem is translated to an integer nonlinear program whose best possible solution can be identified quickly by taking advantage of basic properties derived from the known codes, yielding an optimal or near-optimal allocation result. Those basic properties lead to drastic time complexity reduction (up to several orders of magnitude smaller), in particular for large system sizes. Our approaches are applicable to any cube size, often arriving at more efficient allocation outcomes than what are attainable using prior schemes."",""1558-2183"","""",""10.1109/71.494628"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=494628"","""",""Resource management";Intelligent networks;Hypercubes;Senior members;Size measurement;Time measurement;Optimization methods;Linear code;Lead time reduction;"Block codes"","""",""24"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Routing schemes for multiple random broadcasts in arbitrary network topologies,""E. A. Varvarigos";" A. Banerjee"",""Department of EIectricaI and Computer Engineering, University of California,슠Santa Barbara, Santa Barbara, CA, USA";" Department of EIectricaI and Computer Engineering, University of California,슠Santa Barbara, Santa Barbara, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""8"",""886"",""895"",""We consider the problem where packets are generated at each node of a network according to a Poisson process with rate /spl lambda/, and each of them has to be broadcast to all the other nodes. The network topology is assumed to be an arbitrary bidirectional graph. We derive upper bounds on the maximum achievable broadcast throughput, and lower bounds on the average time required to complete a broadcast. These bounds apply to any network topology, independently of the scheme used to perform the broadcasts. We also propose two dynamic broadcasting schemes, called the indirect and the direct broadcasting scheme, that can be used in a general topology, and we evaluate analytically their throughput and average delay. The throughput achieved by the proposed schemes is equal to the maximum possible, if a half-duplex link model is assumed, and is at least equal to one half of the maximum possible, if a full-duplex model is assumed. The average delay of both schemes is of the order of the diameter of the trees used to perform the broadcasts. The analytical results obtained do not use any approximating assumptions."",""1558-2183"","""",""10.1109/71.532119"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=532119"","""",""Routing";Broadcasting;Intelligent networks;Network topology;Throughput;Hypercubes;Upper bound;Delay;Tree graphs;"Performance evaluation"","""",""9"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Runtime incremental parallel scheduling (RIPS) on distributed memory computers,""Wei Shu";" Min-You Wu"",""Department of Computer Science, State University of New York, University at Buffalo, Buffalo, NY, USA";" Department of Computer Science, State University of New York, University at Buffalo, Buffalo, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""6"",""637"",""649"",""Runtime Incremental Parallel Scheduling (RIPS) is an alternative strategy to the commonly used dynamic scheduling. In this scheduling strategy, the system scheduling activity alternates with the underlying computation work. RIPS utilizes the advanced parallel scheduling technique to produce a low overhead, high quality load balancing, as well as adapting to irregular applications. The paper presents methods for scheduling a single job on a dedicated parallel machine."",""1558-2183"","""",""10.1109/71.506702"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506702"","""",""Runtime";Processor scheduling;Concurrent computing;Distributed computing;Dynamic scheduling;Load management;Application software;Parallel machines;Dynamic programming;"Senior members"","""",""20"","""",""40"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Scheduling in and out forests in the presence of communication delays,""T. A. Varvarigou"; V. P. Roychowdhury; T. Kallath;" E. Lawler"",""Department of Electronic and Computer Engineering, Technical University of Crete, China"; Department of Electrical Engineering, University of California, Los Angeles, Los Angeles, CA, USA; NA;" Department of Electrical Engineering and Computer Science, University of California, Berkeley, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""10"",""1065"",""1074"",""We consider the problem of scheduling tasks on multiprocessor architectures in the presence of communication delays. Given a set of dependent tasks, the scheduling problem is to allocate the tasks to processors such that the pre-specified precedence constraints among the tasks are obeyed and certain cost-measures (such as the computation time) are minimized. Several cases of the scheduling problem have been proven to be NP-complete. Nevertheless, there are polynomial time algorithms for interesting special cases of the general scheduling problem. Most of these results, however, do not take into consideration the delays due to message passing among processors. In this paper we study the increase in time complexity of scheduling problems due to the introduction of communication delays. In particular, we address the open problem of scheduling Out-forests (In-forests) in a multiprocessor system of m identical processors when communication delays are considered. The corresponding problem of scheduling Out-forests (In-forests) without communication delays admits an elegant polynomial time solution as presented first by Hu in 1961";" however, the problem in the presence of communication delays has remained unsolved. We present here first known polynomial time algorithms for the computation of the optimal schedule when the number of available processors is given and bounded and both computation and communication delays are assumed to take one unit of time. Furthermore, we present a linear-time algorithm for computing a near-optimal schedule for unit-delay out-forests. The schedule's length exceeds the optimum by no more than (m-2) time units, where m is the number of processors. Hence for two processors the computed schedule is strictly optimum."",""1558-2183"","""",""10.1109/71.539738"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=539738"","""",""Processor scheduling";Optimal scheduling;Polynomials;Scheduling algorithm;Delay effects;Computer architecture;Message passing;"Multiprocessing systems"","""",""30"","""",""19"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;
"Scheduling soft real-time jobs over dual non-real-time servers,""B. Kao";" H. Garcia-Molina"",""Department of Computer Science, Princeton University, USA";" Department of Computer Science, University of Stanford, Stanford, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""1"",""56"",""68"",""In this paper, we consider soft real-time systems with redundant off-the-shelf processing components (e.g., CPU, disk, network), and show how applications can exploit the redundancy to improve the system's ability of meeting response time goals (soft deadlines). We consider two scheduling policies, one that evenly distributes load (Balance), and one that partitions load according to job slackness (Chop). We evaluate the effectiveness of these policies through analysis and simulation. Our results show that by intelligently distributing jobs by their slackness amount the servers, Chop can significantly improve real-time performance."",""1558-2183"","""",""10.1109/71.481598"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=481598"","""",""Hardware";Real time systems;Network servers;Computer science;Scheduling algorithm;Delay;Timing;Redundancy;Analytical models;"Time factors"","""",""24"",""1"",""36"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"SPIFFI-a scalable parallel file system for the Intel Paragon,""C. S. Freedman"; J. Burger;" D. J. DeWitt"",""Informix Software, Inc., Portugal"; Computer Sciences Department, University of Wisconsin, Madison, Madison, WI, USA;" Computer Sciences Department, University of Wisconsin, Madison, Madison, WI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""11"",""1185"",""1200"",""This paper presents the design and performance of SPIFFI, a scalable high-performance parallel file system intended for use by extremely I/O intensive applications including """"Grand Challenge"""" scientific applications and multimedia systems. This paper contains experimental results from a SPIFFI prototype on a 64 node/64 disk Intel Paragon. The results show that SPIFFI provides high performance and linear scaleup on real hardware. The paper also explains how shared file pointers (i.e., file pointers that are shared by multiple processes) can simplify the design of a parallel application. By sequentializing I/O accesses and by providing dynamic I/O load balancing, a shared file pointer may even improve an application's performance. This paper also presents the predictions of a SPIFFI simulator that we validated using the prototype. The simulator results show that SPIFFI continues to provide high performance even when it is scaled to configurations with as many as 128 disks or 256 compute nodes."",""1558-2183"","""",""10.1109/71.544358"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=544358"","""",""File systems";Hardware;Computational modeling;Prototypes;Supercomputers;Bandwidth;Multimedia systems;High performance computing;Predictive models;"Microprocessors"","""",""16"",""1"",""54"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Square meshes are not optimal for convex hull computation,""D. Bhagavathi"; H. Gurla; S. Olariu; J. L. Schwing;" Jingyuan Zhang"",""Department of Computer Science, Southem Illinois University, Edwardsville, IL, USA"; The Department of Computer Science, Old Dominion University, Norfolk, VA, USA; The Department of Computer Science, Old Dominion University, Norfolk, VA, USA; The Department of Computer Science, Old Dominion University, Norfolk, VA, USA;" Department of Mathematics and Computer Science, Elizabeth City State University, Elizabeth, NC, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""6"",""545"",""554"",""Recently it has been noticed that for semigroup computations and for selection, rectangular meshes with multiple broadcasting yield faster algorithms than their square counterparts. The contribution of the paper is to provide yet another example of a fundamental problem for which this phenomenon occurs. Specifically, we show that the problem of computing the convex hull of a set of n sorted points in the plane can be solved in O(n/sup 1/8/ log /sup 3/4/) time on a rectangular mesh with multiple broadcasting of size n/sup 3/8/ log/sup 1/4/ n/spl times/n/sup 5/8//log/sup 1/4/n. The fastest previously known algorithms on a square mesh of size /spl radic/n/spl times//spl radic/n run in O(n/sup 1/6/) time in case the n points are pixels in a binary image, and in O(n/sup 1/6/log/sup 3/2/ n) time for sorted points in the plane."",""1558-2183"","""",""10.1109/71.506693"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506693"","""",""Broadcasting";Pattern recognition;Image processing;Computational geometry;Path planning;Parallel architectures;Computer science;Cities and towns;Very large scale integration;"Computer architecture"","""",""9"","""",""42"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals"""
"Static and dynamic evaluation of data dependence analysis techniques,""P. M. Petersen";" D. A. Padua"",""Kuck and Associates, Inc., Champaign, IL, USA";" Center for Supercomputing Research and Development, Coordinatrd Science Laboratory, University of Illinois, Urbana-Champaign, Urbana-Champaign, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""11"",""1121"",""1132"",""Data dependence analysis techniques are the main component of today's trategies for automatic detection of parallelism. Parallelism detection strategies are being incorporated in commercial compilers with increasing frequency because of the widespread use of processors capable of exploiting instruction-level parallelism and the growing importance of multiprocessors. An assessment of the accuracy of data dependence tests is therefore of great importance for compiler writers and researchers. The tests evaluated in this study include the generalized greatest common divisor test, three variants of Banerjee's test, and the Omega test. Their effectiveness was measured with respect to the Perfect Benchmarks and the linear algebra libraries, EISPACK and LAPACK. Two methods were applied, one using only compile-time information for the analysis, and the second using information gathered during program execution. The results indicate that Banerjee's test is for all practical purposes as accurate as the more complex Omega test in detecting parallelism. However, the Omega test is quite effective in proving the existence of dependences, in contrast with Banerjee's test, which can only disprove, or break dependences. The capability of the Omega test of proving dependences could have a significant impact on several compiler algorithms not considered in this study."",""1558-2183"","""",""10.1109/71.544354"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=544354"","""",""Data analysis";Information analysis;Runtime;Program processors;Linear programming;Senior members;Frequency;Benchmark testing;Linear algebra;"Libraries"","""",""31"",""1"",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Successive superposition: a technique for the exact modeling of deterministic packet queuing networks,""D. Picker";" R. D. Fellman"",""Nokia Mobile Phones Limited, San Diego, CA, USA";" Department of Electrical and Computer Engineering, University of California, La Jolla, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""10"",""1106"",""1120"",""This paper provides a methodology to decompose a complex network, containing primarily deterministic traffic, into isolated /spl Sigma/D/sub i//D/1 queuing models. We then present a new technique, Successive Superposition, to analyze the resulting models. In a /spl Sigma/D/sub i//D/1 queuing system, multiple streams of different bit rate, but constant length packets, arrive at a single high-speed multiplexer. Because of its application to Asynchronous Transfer Mode (ATM) switching nodes, previous /spl Sigma/D/sub i//D/1 analyses have assumed that stream arrivals are randomly staggered, and packets are served on a first-come-first-served basis. This work was, however, inspired primarily by the need for the accurate assessment of interprocessor communication costs in compile-time multiprocessor scheduling applications. For these applications, streams typically have known arrival times and must often be prioritized. This paper applies primarily to the class of digital signal processing and other application which can be represented by directed, acyclic precedence graphs. The analysis presented in this paper provides an exact characterization of the traffic, including service start times, queue sizes, and system departure times. We confirm the validity of our approach against simulation results. Finally, we demonstrate the utility of this work in a compile-time multiprocessor scheduling application."",""1558-2183"","""",""10.1109/71.539741"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=539741"","""",""Traffic control";Asynchronous transfer mode;Processor scheduling;Complex networks;Telecommunication traffic;Bit rate;Multiplexing;Packet switching;Communication switching;"Costs"","""",""2"","""",""15"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Synchronous and asynchronous parallel simulated annealing with multiple Markov chains,""Soo-Young Lee";" Kyung Geun Lee"",""Department of Electrical Engineering, Aubum University, Auburn, AL, USA";" Network Reseavch Group, Samsung Electronics Company Limited, Seoul, South Korea"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""10"",""993"",""1008"",""Simulated annealing is a general-purpose optimization technique capable of finding an optimal or near-optimal solution in various applications. However, the long execution time required for a good quality solution has been a major drawback in practice. Extensive studies have been carried out to develop parallel algorithms for simulated annealing. Most of them were not very successful, mainly because multiple processing elements (PEs) were required to follow a single Markov chain and, therefore, only a limited parallelism was exploited. In this paper, we propose new parallel simulated annealing algorithms which allow multiple Markov chains to be traced simultaneously by PEs which may communicate with each other. We have considered both synchronous and asynchronous implementations of the algorithms. Their performance has been analyzed in detail and also verified by extensive experimental results. It has been shown that for graph partitioning the proposed parallel simulated annealing schemes can find a solution of equivalent (or even better) quality up to an order of magnitude faster than the conventional parallel schemes. Among the proposed schemes, the one where PEs exchange information dynamically (not with a fixed period) performs best."",""1558-2183"","""",""10.1109/71.539732"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=539732"","""",""Simulated annealing";Partitioning algorithms;Parallel algorithms;Very large scale integration;Processor scheduling;Sliding mode control;Performance analysis;Iterative algorithms;Monte Carlo methods;"Design optimization"","""",""62"",""2"",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Task clustering and scheduling for distributed memory parallel architectures,""M. A. Palis"; Jing-Chiou Liou;" D. S. L. Wei"",""Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA"; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA;" School of Computer Science and Engineering, University of Aizu, Fukushima, Japan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""1"",""46"",""55"",""This paper addresses the problem of scheduling parallel programs represented as directed acyclic task graphs for execution on distributed memory parallel architectures. Because of the high communication overhead in existing parallel machines, a crucial step in scheduling is task clustering, the process of coalescing fine grain tasks into single coarser ones so that the overall execution time is minimized. The task clustering problem is NP-hard, even when the number of processors is unbounded and task duplication is allowed. A simple greedy algorithm is presented for this problem which, for a task graph with arbitrary granularity, produces a schedule whose makespan is at most twice optimal. Indeed, the quality of the schedule improves as the granularity of the task graph becomes larger. For example, if the granularity is at least 1/2, the makespan of the schedule is at most 5/3 times optimal. For a task graph with n tasks and e inter-task communication constraints, the algorithm runs in O(n(n lg n+e)) time, which is n times faster than the currently best known algorithm for this problem. Similar algorithms are developed that produce: (1) optimal schedules for coarse grain graphs"; (2) 2-optimal schedules for trees with no task duplication;" and (3) optimal schedules for coarse grain trees with no task duplication."",""1558-2183"","""",""10.1109/71.481597"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=481597"","""",""Parallel architectures";Optimal scheduling;Processor scheduling;Parallel machines;Scheduling algorithm;Tree graphs;Memory architecture;Degradation;Read-write memory;"Senior members"","""",""130"",""3"",""19"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"The block distributed memory model,""J. F. Jaja";" Kwan Woo Ryu"",""Institute Advanced Computer Studies and the Electrical Enginrering Department, University of Maryland, College Park, MD, USA";" Department of Computer Engineering, Kyungpook National University, Daegu, South Korea"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""8"",""830"",""840"",""We introduce a computation model for developing and analyzing parallel algorithms on distributed memory machines. The model allows the design of algorithms using a single address space and does not assume any particular interconnection topology. We capture performance by incorporating a cost measure for interprocessor communication induced by remote memory accesses. The cost measure includes parameters reflecting memory latency, communication bandwidth, and spatial locality. Our model allows the initial placement of the input data and pipelined prefetching. We use our model to develop parallel algorithms for various data rearrangement problems, load balancing, sorting, FFT, and matrix multiplication. We show that most of these algorithms achieve optimal or near optimal communication complexity while simultaneously guaranteeing an optimal speed-up in computational complexity. Ongoing experimental work in testing and evaluating these algorithms has thus far shown very promising results."",""1558-2183"","""",""10.1109/71.532114"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=532114"","""",""Algorithm design and analysis";Parallel algorithms;Costs;Concurrent computing;Distributed computing;Computational modeling;Topology;Delay;Bandwidth;"Prefetching"","""",""7"","""",""30"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Traffic analysis and simulation performance of incomplete hypercubes,""N. . -F. Tzeng";" H. Kumar"",""Centerfor Advanced Computer Studies, University of Southwestern Louisiana, Lafayette, LA, USA";" Intel Corporation, Beaverton, OR, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""7"",""740"",""754"",""The incomplete hypercube with arbitrary nodes provides far better incremental flexibility than the complete hypercube, whose size is restricted to exactly a power of 2. After faults arise in a complete hypercube system, it is desirable to reconfigure the system so as to retain as many healthy nodes as possible, often leading to an incomplete hypercube of arbitrary size. In this paper, the highest traffic density over links in an incomplete hypercube under uniform message distribution is shown to be bounded by 2 (messages per link per cycle), independent of its size and despite its structural nonhomogeneity. As a result, it is easily achievable to construct an incomplete hypercube with sufficient link communication capability where any potential points of congestion are avoided, ensuring high performance. Simulation results for the incomplete hypercube reveal that mean latency for delivering messages is roughly the same in an incomplete hypercube as in a compatible complete hypercube under both packet-switching and wormhole routing. The incomplete hypercube thus appears to be an attractive and practical architecture, since it shares every advantage of complete hypercubes while eliminating the restriction on the system size."",""1558-2183"","""",""10.1109/71.508253"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=508253"","""",""Traffic control";Performance analysis;Analytical models;Hypercubes;Delay;Topology;Routing;Nearest neighbor searches;Neck;"Degradation"","""",""7"","""",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Two ranking schemes for efficient computation on the star interconnection network,""D. K. Saikia";" R. K. Sen"",""Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur, India";" Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur, India"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""4"",""321"",""327"",""A node ranking scheme provides the necessary structural view for developing algorithms on a network. We present two ranking schemes for the star interconnection network both of which allow constant time order preserving communication. The first scheme is based on a hierarchical view of the star network. It enables one to efficiently implement order preserving ASCEND/DESCEND class of algorithms. This class includes several important algorithms such as the Fast Fourier Transform (FFT) and matrix multiplication. The other ranking scheme gives a flexible pipelined view of the star interconnection network and provides a suitable framework for implementation of pipelined algorithms."",""1558-2183"","""",""10.1109/71.494627"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=494627"","""",""Computer networks";Multiprocessor interconnection networks;Fast Fourier transforms;Parallel processing;Computer science;Senior members;Computer architecture;Parallel algorithms;Concurrent computing;"Context"","""",""19"","""",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Using finite state automata to produce self-optimization and self-control,""B. Tung";" L. Kleinrock"",""Computer Science Department, University of California, Los Angeles, Los Angeles, CA, USA";" Information Sciences Institute, University of Southern California, Los Angeles, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""4"",""439"",""448"",""A simple game provides a framework within which agents can spontaneously self-organize. In this paper, we present this game, and develop basic theory underlying a robust method for distributed coordination based on this game. This method makes use of finite state automata-one associated with each agent-which guide the agents. We give a new, general method of analysis of these systems, which previously had been studied only in limited cases. We also provide a physical example, which should hint at the type of problems resolvable using this method."",""1558-2183"","""",""10.1109/71.494637"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=494637"","""",""Automata";Voting;Game theory;Robustness;Legged locomotion;Robot kinematics;Robotics and automation;Centralized control;Automatic control;"Control systems"","""",""38"",""4"",""9"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Valid transformations: a new class of loop transformations for high-level synthesis and pipelined scheduling applications,""Minjoong Rim";" R. Jain"",""Samsung, South Korea";" Hewlett Packard Company, Westlake Village, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1996"",""7"",""4"",""399"",""410"",""In this paper we present a new class of loop optimizing transformations called valid transformations, which are suitable for fine-grain parallelization applications such as high-level synthesis of VLSI designs or compilers for super-scalar or VLIW machines. This class of transformations are different from existing ones in that valid transformations can be illegal. Nevertheless, if a transformation is valid, the transformed loop has a feasible pipeline schedule. We present an example valid transformation called loop expansion which can help produce cost-performance efficient designs and explore a larger design space for a satisfactory design. Several examples are used to demonstrate the efficacy of the proposed technique."",""1558-2183"","""",""10.1109/71.494634"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=494634"","""",""High level synthesis";Pipeline processing;Very large scale integration;Job shop scheduling;Design optimization;Algorithm design and analysis;Signal processing algorithms;Parallel processing;Optimizing compilers;"VLIW"","""",""2"",""1"",""53"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;