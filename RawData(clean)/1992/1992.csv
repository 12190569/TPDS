"A dynamic information-structure mutual exclusion algorithm for distributed systems,""M. Singhal"",""Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""1"",""121"",""125"",""A dynamic information-structure mutual exclusion algorithm is presented for distributed systems whose information-structure evolves with time as sites learn about the state of the system through messages. An interesting feature of the algorithm is that it adapts itself to heterogeneous or fluctuating traffic conditions to optimize the performance (the number of messages exchanged). The performance of the algorithm is studied by simulation technique and compared to the performance of a well-known mutual exclusion algorithm. The impact message loss and site failures on the algorithm is discussed and methods to tolerate these failures are proposed.<>"",""1558-2183"","""",""10.1109/71.113087"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=113087"","""",""Communication networks";Algorithm design and analysis;Traffic control;Performance loss;Message passing;Propagation delay;Telecommunication network reliability;Computer crashes;Fault tolerance;"Permission"","""",""55"","""",""19"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A hybrid scheme for processing data structures in a dataflow environment,""B. Lee"; A. R. Hurson;" B. Shirazi"",""Department of Electrical and Computer Engineering, Oregon State University, Corvallis, OR, USA"; Department of Electrical and Computer Engineering, Pennsylvania State University, University Park, PA, USA;" Department of Computer Science, University of Texas, Arlington, Arlington, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""1"",""83"",""96"",""The asynchronous nature of the dataflow model of computation allows the exploitation of maximum inherent parallelism in many application programs. However, before the dataflow model of computation can become a viable alternative to the control flow model of computation, one has to find practical solutions to some problems such as efficient handling of data structures. The paper introduces a new model for handling data structures in a dataflow environment. The proposed model combines constant time access capabilities of vectors as well as the flexibility inherent in the concept of pointers. This allows a careful balance between copying and sharing to optimize the storage and processing overhead incurred during the operations on data structures. The mode) is compared by simulation to other data structure models proposed in the literature, and the results are good.<>"",""1558-2183"","""",""10.1109/71.113084"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=113084"","""",""Data structures";Computational modeling;Data flow computing;Analytical models;Concurrent computing;Parallel processing;Counting circuits;Distributed computing;Distributed control;"Computer science"","""",""10"","""",""38"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"A multiprocessor bus design model validated by system measurement,""T. . -F. Tsuei";" M. K. Vernon"",""Advanced Technology Group, Apple Computer, Inc., Cupertino, CA, USA";" Computer Sciences Department, University of Wisconsin, Madison, Madison, WI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""6"",""712"",""727"",""An accurate and efficient model of a commercial multiprocessor bus is developed. Four important characteristics of the bus design are modeled: asynchronous memory write operations"; in-order delivery of responses to processor read requests; priority scheduling of memory responses;" and upper bounds on the number of outstanding processor requests. A two-level hierarchical model employing both Markov chain and mean value analysis techniques for analyzing queueing networks is used. The model is shown to accurately predict measured system performance for two parallel program workloads that have different memory access characteristics. The results provide evidence that analytic queueing models can be extremely accurate in spite of simplifying assumptions required for model tractability. Model estimates are compared against detailed simulation of the bus to investigate in more detail the likely source of small model inaccuracies. The use of the analytical model for assessing system design tradeoffs is illustrated.<>"",""1558-2183"","""",""10.1109/71.180626"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=180626"","""",""Processor scheduling";Interference;Analytical models;Read-write memory;Queueing analysis;Bandwidth;Protocols;Upper bound;Predictive models;"System performance"","""",""9"",""2"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";
"A parallel execution method for minimizing distributed query response time,""C. Wang"; A. L. P. Chen;" S. . -C. Shyu"",""Department of Computer Science, University of California, Riverside, CA, USA"; Department of Computer Science, National Tsing Hua University, Taiwan;" IBM Santa Teresa Laboratory, San Jose, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""3"",""325"",""333"",""Performance studies show that traditional semi-join processing methods are sometimes inefficient because of the storage and processing overhead. To remedy this problem, a new semi-join processing method, called one-shot semi-join execution is proposed. This method allows parallel generation of all the semi-join projections, parallel transmission of all the semi-join projections, and parallel execution of all the semi-joins. The authors apply this method to optimize the response time for processing distributed queries. A response time model is established, which considers both data transmission time and local processing time. Based on this model, an efficient query processing algorithm is developed and analyzed.<>"",""1558-2183"","""",""10.1109/71.139206"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=139206"","""",""Delay";Costs;Query processing;Computer science;Optimization methods;Relational databases;Data communication;Database systems;Marine vehicles;"Councils"","""",""14"",""1"",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"A processor-time-minimal systolic array for cubical mesh algorithms,""P. Cappello"",""Department of Computer Science, University of California, Santa Barbara, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""1"",""4"",""13"",""Using a directed acyclic graph (DAG) model of algorithms, the paper focuses on time-minimal multiprocessor schedules that use as few processors as possible. Such a processor-time-minimal scheduling of an algorithm's DAG first is illustrated using a triangular shaped 2-D directed mesh (representing, for example, an algorithm for solving a triangular system of linear equations). Then, algorithms represented by an n*n*n directed mesh are investigated. This cubical directed mesh is fundamental";" it represents the standard algorithm for computing matrix product as well as many other algorithms. Completion of the cubical mesh required 3n-2 steps. It is shown that the number of processing elements needed to achieve this time bound is at least (3n/sup 2/4/). A systolic array for the cubical directed mesh is then presented. It completes the mesh using the minimum number of steps and exactly (3n/sup 2/4/) processing elements it is processor-time-minimal. The systolic array's topology is that of a hexagonally shaped, cylindrically connected, 2-D directed mesh.<>"",""1558-2183"","""",""10.1109/71.113078"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=113078"","""",""Systolic arrays";Processor scheduling;Concurrent computing;Difference equations;Scheduling algorithm;Physics computing;Topology;Very large scale integration;Digital arithmetic;"Databases"","""",""26"",""1"",""50"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"A processor-time-minimal systolic array for transitive closure,""C. J. Scheiman";" P. R. Cappello"",""Department of Computer Science, University of California, Santa Barbara, CA, USA";" Department of Computer Science, University of California, Santa Barbara, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""3"",""257"",""269"",""Using a directed acyclic graph (DAG) model of algorithms, the authors focus on processor-time-minimal multiprocessor schedules: time-minimal multiprocessor schedules that use as few processors as possible. The Kung, Lo, and Lewis (KLL) algorithm for computing the transitive closure of a relation over a set of n elements requires at least 5n-4 parallel steps. As originally reported. their systolic array comprises n/sup 2/ processing elements. It is shown that any time-minimal multiprocessor schedule of the KLL algorithm's dag needs at least n/sup 2//3 processing elements. Then a processor-time-minimal systolic array realizing the KLL dag is constructed. Its processing elements are organized as a cylindrically connected 2-D mesh, when n=0 mod 3. When n not=0 mod 3, the 2-D mesh is connected as a torus.<>"",""1558-2183"","""",""10.1109/71.139200"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=139200"","""",""Systolic arrays";Processor scheduling;Difference equations;Differential equations;Computational modeling;Algorithm design and analysis;Concurrent computing;Linearity;Constraint optimization;"Computer science"","""",""21"","""",""34"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"A unified task-based dependability model for hypercube computers,""C. R. Das";" J. Kim"",""Dept. of Electr. & Comput. Eng., Pennsylvania State Univ., University Park, PA, USA";" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""3"",""312"",""324"",""A unified analytical model for computing the task-based dependability (TDB) of hypercube architectures is presented. A hypercube is deemed operational as long as a task can be executed on the system. The technique can compute both reliability and availability for two types of task requirements-I-connected model and subcube model. The I-connected TBD assumes that a connected group of at least I working nodes is required for task execution. The subcube TBD needs at least an m-cube in an n-cube, m<or=n, for task execution. The dependability is computed by multiplying the probability that x nodes (x>or=I or x>or=2/sup m/) are working in an n-cube at time t by the conditional probability that the hypercube can satisfy any one of the two task requirements from x working nodes. Recursive models are proposed for the two types of task requirements to find the connection probability. The subcube requirement is extended to find multiple subcubes for analyzing multitask dependability. The analytical results are validated through extensive simulation.<<ETX>>"",""1558-2183"","""",""10.1109/71.139205"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=139205"","""",""Hypercubes";Availability;Computer architecture;Power system modeling;Analytical models;Power system reliability;Government;Power engineering and energy;"Performance analysis"","""",""31"","""",""22"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"A VLSI constant geometry architecture for the fast Hartley and Fourier transforms,""E. L. Zapata";" F. Arguello"",""Dept. of Electron.. Univ. Santiago de Compostela, Spain";" Dept. of Electron.. Univ. Santiago de Compostela, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""1"",""58"",""70"",""An application-specific architecture for the parallel calculation of the decimation in time and radix 2 fast Hartley (FHT) and Fourier (FFT) transforms is presented. A real sequence with N=2/sup n/ data items is considered as input. The system calculates the FHT and the FFT in n and n+1 stages. respectively. The modular and regular parallel architecture is based on a constant geometry algorithm using butterflies of four data items and the perfect unshuffle permutation. With this permutation, the mapping of the algorithm in VLSI technology is simplified and the communications among processors are minimized. Organization of the processor memory based on first-in, first-out (FIFO) queues facilitates a systolic data flow and permits the implementation in a direct way of the complex data movements and address sequences of the transforms. This is accomplished by means of simple multiplexing operations, using hardwired control. The total calculation time is (Nlog/sub 2/N)/4Q cycles for the FHT and N(1+log/sub 2/N)/4Q cycles for the FFT, where Q is the number of processors (Q= 2/sup q/, Q<or=N/4).<<ETX>>"",""1558-2183"","""",""10.1109/71.113082"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=113082"","""",""Very large scale integration";Geometry;Fourier transforms;Discrete transforms;Fast Fourier transforms;Parallel architectures;Hardware;Costs;"Energy consumption"","""",""22"",""4"",""46"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Accuracy of memory reference traces of parallel computations in trace-drive simulation,""M. A. Holliday";" C. S. Ellis"",""Department of Computer Science, Duke University, Durham, NC, USA";" Department of Computer Science, Duke University, Durham, NC, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""1"",""97"",""109"",""For given input the global trace generated by a parallel program in a shared memory multiprocessing environment may change as the memory architecture, and management policies change. A method is proposed for ensuring that a correct global trace is generated in the new environment. This method involves a new characterization of a parallel program that identifies its address change points and address affecting points. An extension of traditional process traces, called the intrinsic trace of each process, is developed. The intrinsic traces maximize the decoupling of program execution from simulation by describing the address flow graph and path expressions of each process program. At each point where an address is issued, the trace-driven simulator uses the intrinsic traces and the sequence of loads and stores before the current cycle, to determine the next address. The mapping between load and store sequences and next addresses to issue, sometimes, requires partial program reexecution. Programs that do not require partial program reexecution are called graph-traceable.<>"",""1558-2183"","""",""10.1109/71.113085"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=113085"","""",""Concurrent computing";Computational modeling;Buildings;Memory management;Memory architecture;Environmental management;Computer science;Computer architecture;"Interleaved codes"","""",""12"","""",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"An analysis of cache performance for a hypercube multicomputer,""C. B. Stunkel";" W. K. Fuchs"",""IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA";" Coordinated Science Laboratory, University of Illinois, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""4"",""421"",""432"",""Multicomputer cache simulation results derived from address traces collected from an Intel iPSC/2 hypercube multicomponent are presented. The primary emphasis is on examining how increasing the number of processor nodes executing a parallel application affects the overall multicomputer cache performance. The effects on multicomputer direct-mapped cache performance of application-specific data partitioning, data access patterns, communication distribution, and communication frequency are illustrated. The effects of system accesses on total cache performance are explored, as well as the reasons for application-specific differences in cache behavior for system and user accesses. Comparing user code results with full user and system code analysis reveals the significant effect of system accesses, and this effect increases with multicomputer size. The time distribution of an application's message-passing operations is found to more strongly affect cache performance than the total amount of time spent in message-passing code.<>"",""1558-2183"","""",""10.1109/71.149961"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=149961"","""",""Performance analysis";Hypercubes;Computational modeling;Analytical models;Cache memory;Frequency;Parallel processing;Computer networks;Distributed computing;"Multiprocessor interconnection networks"","""",""1"","""",""19"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"An example of modeling and evaluation of a concurrent program using colored stochastic Petri nets: Lamport's fast mutual exclusion algorithm,""G. Balbo"; G. Chiola; S. C. Bruell;" P. . -Z. Chen"",""Dipartimento di Informatica, Università degli Studi di Torino, Torino, Italy"; Dipartimento di Informatica, Università degli Studi di Torino, Torino, Italy; Department of Computer Science, University of Iowa, Iowa, IA, USA;" Department of Computer Science, University of Iowa, Iowa, IA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""2"",""221"",""240"",""A colored generalized stochastic Petri net (CGSPN) model was used to study the correctness and performance of the Lamport concurrent algorithm to solve the mutual exclusion problem on machines lacking an atomic test and set instruction. In particular, a parametric formal proof of liveness is developed based on the structure and initial state of the model. The performance evaluation is based on a Markovian analysis that exploits the symmetries of the model to reduce the cost of the numerical solution. Both kinds of analysis are supported by efficient algorithms. The potential of the GSPN modeling technique is illustrated on an academic but nontrivial example of an application from distributed systems.<>"",""1558-2183"","""",""10.1109/71.127262"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=127262"","""",""Stochastic processes";Petri nets;Algorithm design and analysis;Performance analysis;Partitioning algorithms;Costs;Concurrent computing;Monitoring;Computer science;"Cities and towns"","""",""37"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals"""
"Automatic extraction of functional parallelism from ordinary programs,""M. Girkar";" C. D. Polychronopoulos"",""Center for Supercomputing Research and Development, University of Illinois, Urbana-Champaign, Urbana, IL, USA";" Center for Supercomputing Research and Development, University of Illinois, Urbana-Champaign, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""2"",""166"",""178"",""Presents the hierarchical task graph (HTG) as an intermediate parallel program representation which encapsulates minimal data and control dependences, and which can be used for the extraction and exploitation of functional, or task-level parallelism. The hierarchical nature of the HTG facilitates efficient task-granularity control during code generation, and thus applicability to a variety of parallel architectures. The construction of the HTG at a given hierarchy level, the derivation of the execution conditions of tasks which maximizes task-level parallelism, and the optimization of these conditions which results in reducing synchronization overhead imposed by data and control dependences are emphasized. Algorithms for the formation of tasks and their execution conditions based on data and control dependence constraints are presented. The issue of optimization of such conditions is discussed, and optimization algorithms are proposed. The HTG is used as the intermediate representation of parallel Fortran and C programs for generating parallel source as well as parallel machine code.<>"",""1558-2183"","""",""10.1109/71.127258"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=127258"","""",""Parallel processing";Program processors;Concurrent computing;Parallel architectures;Computational modeling;Data mining;Parallel machines;Parallel languages;"Parallel programming"","""",""126"",""18"",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Bused hypercubes and other pin-optimal networks,""C. M. Fiduccia"",""Supercomputing Research Center, Bowie, MD, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""1"",""14"",""24"",""Pin minimization is an important issue for massively parallel architectures because the number of processing elements that can be placed on a chip, board, or chassis is often pin limited. A d-dimensional bused hypercube interconnection network is presented that allows nodes to simultaneously (in one clock tick) exchange data across any dimension using only d+1 ports per node rather than 2d. Despite this near two-to-one reduction, the network also allows nodes that are two dimensions apart to simultaneously exchange data";" as a result, certain routings can be performed in nearly half the time. The network is shown to be a special case of a general construction in which any set of d permutations can be performed, in one clock tick, using only d+1 ports per node. A lower-bound technique is also presented and used to establish the optimality of the network, as well as that of several other new bused networks.<>"",""1558-2183"","""",""10.1109/71.113079"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=113079"","""",""Hypercubes";Clocks;Multiprocessor interconnection networks;Parallel architectures;Routing;Labeling;Parallel algorithms;"Geometry"","""",""21"","""",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Checkpointing for distributed databases: starting from the basics,""S. Pilarski";" T. Kameda"",""School of Computing Science, Simon Fraser University, Burnaby, BC, Canada";" School of Computing Science, Simon Fraser University, Burnaby, BC, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""5"",""602"",""610"",""Checkpointing in a distributed database system is analyzed by establishing a correspondence between consistent snapshots in a general distributed system and transaction-consistent checkpoints in a distributed database system. The analysis culminates in a useful condition for transaction-consistent checkpoints. Based on this condition, a general checkpointing scheme, which records a transaction-consistent set of values of all or some selected data items is presented. These rules are implemented in some representative concurrency control protocols, i.e., those based on two-phase locking and timestamping. These implementations cause little interference with other activities in the database system.<>"",""1558-2183"","""",""10.1109/71.159043"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=159043"","""",""Checkpointing";Distributed databases;Transaction databases;Database systems;Concurrency control;Abortion;Protocols;Interference;Indexes;"Computational modeling"","""",""9"",""17"",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Chitra: visual analysis of parallel and distributed programs in the time, event, and frequency domains,""M. Abrams"; N. Doraswamy;" A. Mathur"",""Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA"; Digital Equipment Corporation, Cambridge, MA, USA;" Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""6"",""672"",""685"",""Chitra analyzes a program execution sequence (PES) collected during execution of a program and produces a homogeneous, semi-Markov chain model fitting the PES. The PES represents the evolution of a program state vector in time. Therefore Chitra analyzes the time-dependent behavior of a program. The authors describe a set of transforms that map a PES to a simplified PES. Because the transforms are program-independent. Chitra can be used with any program. Chitra provides a visualization of PESs and transforms, to allow a user to visually guide transform selection in an effort to generate a simple yet accurate semi-Markov chain model. The resultant chain can predict performance at program parameters different than those used in the input PES, and the chain structure can diagnose performance problems.<>"",""1558-2183"","""",""10.1109/71.180623"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=180623"","""",""Frequency domain analysis";Visualization;Software performance;Operating systems;Instruments;Performance analysis;TCPIP;Protocols;"Time domain analysis"","""",""20"",""2"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;
"Conservative parallel simulation of priority class queuing networks,""D. Nicol"",""Department of Computer Science, College of William and Mary, Williamsburg, VA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""3"",""294"",""303"",""A conservative synchronization protocol for the parallel simulation of queuing networks having C job priority classes, where a job's class is fixed, is described. This problem has long vexed designers of conservative synchronization protocols because of its seemingly poor ability to compute lookahead: the time of the next departure. For, a job in service having low priority can be preempted at any time by an arrival having higher priority and an arbitrarily small service time. The solution is to slow the event generation activity so that events for higher priority jobs are generated farther ahead in simulated time than lower priority jobs. Thus. when a lower priority job enters service for the first time, all the higher priority jobs that may preempt it are already known and the job's departure time can be exactly predicted. The author analyzes the protocol and demonstrates that good performance can be expected on the simulation of large queuing networks.<>"",""1558-2183"","""",""10.1109/71.139203"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=139203"","""",""Computational modeling";Discrete event simulation;Protocols;Queueing analysis;Performance analysis;Analytical models;NASA;Context modeling;Stochastic processes;"Computer networks"","""",""14"",""2"",""14"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Coterie join algorithm,""M. L. Neilsen";" M. Mizuno"",""Department of Computing and Information Sciences, Kansas State University, Manhattan, KS, USA";" Department of Computing and Information Sciences, Kansas State University, Manhattan, KS, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""5"",""582"",""590"",""Given a set of nodes in a distributed system, a coterie is a collection of subsets of the set of nodes such that any two subsets have a nonempty intersection and are not properly contained in one another. A subset of nodes in a coterie is called a quorum. An algorithm, called the join algorithm, which takes nonempty coteries as input, and returns a new, larger coterie called a composite coterie is introduced. It is proved that a composite coterie is nondominated if and only if the input coteries are nondominated. Using the algorithm, dominated or nondominated coteries may be easily constructed for a large number of nodes. An efficient method for determining whether a given set of nodes contains a quorum of a composite coterie is presented. As an example, tree coteries are generalized using the join algorithm, and it is proved that tree coteries are nondominated. It is shown that the join algorithm may be used to generate read and write quorums which may be used by a replica control protocol.<>"",""1558-2183"","""",""10.1109/71.159041"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=159041"","""",""Protocols";Testing;Concurrent computing;Distributed computing;Fault tolerance;Permission;Availability;Voting;"Binary trees"","""",""35"","""",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Demonstration of automatic data partitioning techniques for parallelizing compilers on multicomputers,""M. Gupta";" P. Banerjee"",""Center for Reliable and High-Performance Computing, Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, Urbana, IL, USA";" Center for Reliable and High-Performance Computing, Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""2"",""179"",""193"",""An approach to the problem of automatic data partitioning is introduced. The notion of constraints on data distribution is presented, and it is shown how, based on performance considerations, a compiler identifies constraints to be imposed on the distribution of various data structures. These constraints are then combined by the compiler to obtain a complete and consistent picture of the data distribution scheme, one that offers good performance in terms of the overall execution time. Results of a study performed on Fortran programs taken from the Linpack and Eispack libraries and the Perfect Benchmarks to determine the applicability of the approach to real programs are presented. The results are very encouraging, and demonstrate the feasibility of automatic data partitioning for programs with regular computations that may be statically analyzed, which covers an extremely significant class of scientific application programs.<>"",""1558-2183"","""",""10.1109/71.127259"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=127259"","""",""Program processors";Programming profession;Data structures;Libraries;Costs;Scalability;NASA;Parallel languages;"Context"","""",""152"",""8"",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Design and analysis of a scalable cache coherence scheme based on clocks and timestamps,""S. L. Min";" J. . -L. Baer"",""Department of Computer Engineering, Pusan National University, busan, South Korea";" Department of Computer Science and Engineering, University of Washington, Seattle, WA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""1"",""25"",""44"",""A timestamp-based software-assisted cache coherence scheme that does not require any global communication to enforce the coherence of multiple private caches is proposed. It is intended for shared memory multiprocessors. The scheme is based on a compile-time marking of references and a hardware-based local incoherence detection scheme. The possible incoherence of a cache entry is detected and the associated entry is implicitly invalidated by comparing a clock (related to program flow) and a timestamp (related to the time of update in the cache). Results of a performance comparison, which is based on a trace-driven simulation using actual traces. between the proposed timestamp-based scheme and other software-assisted schemes indicate that the proposed scheme performs significantly better than previous software-assisted schemes, especially when the processors are carefully scheduled so as to maximize the reuse of cache contents. This scheme requires neither a shared resource nor global communication and is, therefore, scalable up to a large number of processors.<>"",""1558-2183"","""",""10.1109/71.113080"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=113080"","""",""Clocks";Multiprocessor interconnection networks;Broadcasting;Computer architecture;Memory management;Global communication;Processor scheduling;Scholarships;Computer science;"Runtime"","""",""53"",""10"",""41"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Design considerations for shared memory multiprocessor message systems,""N. Islam";" R. H. Campbell"",""Department of Computer Science, University of Illinois, Urbana-Champaign, Urbana, IL, USA";" Department of Computer Science, University of Illinois, Urbana-Champaign, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""6"",""702"",""711"",""The comparative performance is studied of different message passing system designs experimentally on a shared memory Encore Multimax multiprocessor. The systems are measured both by benchmarks and by running example parallel applications. To act as a control, the shared memory machine results are compared with the performance of the benchmarks and applications on the Intel iPSC/2 running the NX/2 operating system. The design alternatives considered are buffering, buffer organization, reference and value semantics, synchronization, coordination strategy and the location of the system in user or kernel space. The results include measurements of the effects of the design alternatives, memory caching, message sizes and copying.<>"",""1558-2183"","""",""10.1109/71.180625"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=180625"","""",""Message systems";Message passing;Operating systems;Costs;Delay;Application software;Control systems;Kernel;Scalability;"Size measurement"","""",""7"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Design of an adaptive cache coherence protocol for large scale multiprocessors,""Q. Yang"; G. Thangadurai;" L. N. Bhuyan"",""Department of Electrical Engineering, University of Rhode Island, Kingston, RI, USA"; EPG-Arch., Intel Corporation, CA, USA;" Department of Computer Science, Texas A and M University, College Station, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""3"",""281"",""293"",""A large scale, cache-based multiprocessor that is interconnected by a hierarchical network such as hierarchical buses or a multistage interconnection network (MIN) is considered. An adaptive cache coherence scheme for the system is proposed based on a hardware approach that handles multiple shared reads efficiently. The new protocol allows multiple copies of a shared data block in the hierarchical network, but minimizes the cache coherence overhead by dynamically partitioning the network into sharing and nonsharing regions based on program behavior. The new cache coherence scheme effectively utilizes the bandwidth of the hierarchical networks and exploits the locality properties of parallel algorithms. Simulation experiments have been carried out to analyze the performance of the new protocol. The simulation results show that the new protocol gives 15% to 30% performance improvement over some existing cache coherence schemes on similar systems for a wide range of workload parameters.<>"",""1558-2183"","""",""10.1109/71.139202"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=139202"","""",""Protocols";Large-scale systems;Multiprocessor interconnection networks;Hardware;Bandwidth;Multiprocessing systems;Parallel algorithms;Analytical models;Performance analysis;"Computer architecture"","""",""28"",""4"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Efficient processor assignment algorithms and loop transformations for executing nested parallel loops on multiprocessors,""Chien-Min Wang";" Sheng-De Wang"",""Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan";" Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""1"",""71"",""82"",""An important issue for the efficient use of multiprocessor systems is the assignment of parallel processors to nested parallel loops. It is desirable for a processor assignment algorithm to be fast and always generate an optimal processor assignment. The paper proposes two efficient algorithms to decide the optimal number of processors assigned to each individual loop. Efficient parallel counterparts of these two algorithms are also presented. These algorithms not only always generate an optimal processor assignment, but also are much faster than the exiting optimal algorithm in the literature. The paper discusses improving the performance of parallel execution by transforming a nested parallel loop into a semantically equivalent one. Three loop transformations are investigated. It is observed that, in most cases, the parallel execution time is improved after applying these transformations.<>"",""1558-2183"","""",""10.1109/71.113083"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=113083"","""",""Parallel processing";Multiprocessing systems;Dynamic scheduling;Runtime;Logic;Concurrent computing;Processor scheduling;Councils;Memory management;"Scheduling algorithm"","""",""12"","""",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Efficient task migration algorithm for distributed systems,""T. T. Y. Suen";" J. S. K. Wong"",""Department of Computer Science, Iowa State University, Ames, IA, USA";" Department of Computer Science, Iowa State University, Ames, IA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""4"",""488"",""499"",""The objective of the study was to achieve balanced load among processors, reduce the communication overhead of the load balancing algorithm, and improve respource utilization, which results in better average resonse time. A communication protocol and a fully distributed algorithm for dynamic load balancing through task migration in a connected N-processor network are presented. Each processor communicates its load directly with only a subset (of the size square root N) of processors, reducing communication traffic and average response time. It is proved that the given algorithm will perform task migration even if there is only one light load processor and one heavy load processor in the system. Simulation results show that the proposed scheme can save up to 60% of the protocol messages used by the broadcast algorithms and can reduce the average response time.<>"",""1558-2183"","""",""10.1109/71.149966"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=149966"","""",""Load management";Protocols;Delay;Distributed algorithms;Distributed control;Distributed computing;Resource management;Broadcasting;Computer networks;"Processor scheduling"","""",""42"",""1"",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Evaluation of NUMA memory management through modeling and measurements,""R. P. LaRowe"; C. S. Ellis;" M. A. Holliday"",""Center for High Performance Computing, Worcester Polytechnic Institute, Marlborough, MA, USA"; Department of Computer Science, Duke University, Durham, NC, USA;" Department of Computer Science, Duke University, Durham, NC, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""6"",""686"",""701"",""Dynamic page placement policies for NUMA (nonuniform memory access time) shared-memory architectures are explored using two approaches that complement each other in important ways. The authors measure the performance of parallel programs running on the experimental DUnX operating system kernel for the BBN GP1000, which supports a highly parameterized dynamic page placement policy. They also develop and apply an analytic model of memory system performance of a local/remote NUMA architecture based on approximate mean-value analysis techniques. The model is validated against experimental data obtained with DUnX while running a synthetic workload. The results of this validation show that, in general, model predictions are quite good. Experiments investigating the effectiveness of dynamic page-placement and, in particular, dynamic multiple-copy page placement the cost of replication/coherency fault errors, and the cost of errors in deciding whether a page should move or be remotely referenced are described.<>"",""1558-2183"","""",""10.1109/71.180624"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=180624"","""",""Memory management";Operating systems;Kernel;Time measurement;Performance analysis;Predictive models;Costs;Random access memory;Memory architecture;"System performance"","""",""23"",""3"",""29"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Evaluation of two traffic distribution strategies for a dual-network multiprocessor system,""S. Chalasani";" A. Varma"",""Department of Electrical and Computer Engineering, University of Wisconsin, Madison, WI, USA";" Department of Computer Engineering, University of California, Santa Cruz, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""3"",""375"",""384"",""The effect of nonuniform traffic patterns is studied based on simulation and analysis when two multistage networks are used in parallel to interconnect processors and memory modules in a shared-memory system. The networks considered are identical copies of buffered multi stage networks. The authors consider the following two strategies to distribute the total traffic between the two networks: distribute the traffic randomly among the networks, and route the nonuniform component of the traffic to one network and the uniform component to the other. To facilitate the implementation of these strategies in a system, a technique to detect nonuniformities in the network traffic at run-time and change the routing strategy dynamically is discussed. The authors compare this technique to an ideal scheme by means of analysis and simulation. The results show that the run-time detection scheme performs very close to the ideal case. The effectiveness of dual networks in tolerating short bursts of nonuniform traffic is also demonstrated.<>"",""1558-2183"","""",""10.1109/71.139210"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=139210"","""",""Multiprocessing systems";Telecommunication traffic;Traffic control;Degradation;Multiprocessor interconnection networks;Analytical models;Runtime;Switches;Pattern analysis;"Routing"","""",""4"","""",""11"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Extended hypercube: a hierarchical interconnection network of hypercubes,""J. M. Kumar";" L. M. Patnaik"",""Microprocessor Applications Laboratory, Indian Institute of Science, Bangalore, India";" Microprocessor Applications Laboratory, Supercomputer Education and Research Center and the Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""1"",""45"",""57"",""A new interconnection topology-the extended hypercube-consisting of an interconnection network of k-cubes is discussed. The extended hypercube is a hierarchical, expansive, recursive structure with a constant predefined building block. The extended hypercube retains the positive features of the k-cube at different levels of hierarchy and at the same time has some additional advantages like reduced diameter and constant degree of a node. The paper presents an introduction to the topology of the extended hypercube and analyzes its architectural potential in terms of message routing and executing a class of highly parallel algorithms. Topological properties and performance studies of the extended hypercube are presented.<>"",""1558-2183"","""",""10.1109/71.113081"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=113081"","""",""Hypercubes";Multiprocessor interconnection networks;Network topology;Routing;Integrated circuit interconnections;Parallel algorithms;Bandwidth;Costs;Hardware;"Microprocessors"","""",""94"",""15"",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Heterogeneous distributed shared memory,""S. Zhou"; M. Stumm; K. Li;" D. Wortman"",""Computer Systems Research Institute, University of Toronto, Toronto, ONT, Canada"; Computer Systems Research Institute, University of Toronto, Toronto, ONT, Canada; Department of Computer Science, Princeton University, Princeton, NJ, USA;" Computer Systems Research Institute, University of Toronto, Toronto, ONT, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""5"",""540"",""554"",""The design, implementation, and performance of heterogeneous distributed shared memory (HDSM) are studied. A prototype HDSM system that integrates very different types of hosts has been developed, and a number of applications of this system are reported. Experience shows that despite a number of difficulties in data conversion, HDSM is implementable with minimal loss in functional and performance transparency when compared to homogeneous DSM systems.<>"",""1558-2183"","""",""10.1109/71.159038"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=159038"","""",""Distributed computing";Concurrent computing;Message passing;Programming profession;Application software;Vehicles;Prototypes;Data conversion;Performance loss;"Access protocols"","""",""61"",""8"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals"""
"Implementation of production systems on message-passing computers,""A. Acharya"; M. Tambe;" A. Gupta"",""School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA"; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA;" Computer Systems Laboratory, University of Stanford, Stanford, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""4"",""477"",""487"",""The authors examine the suitability of message-passing computers for parallel implementations of production systems. Two mappings for production systems on these computers, one targeted toward fine-grained message-passing machines and the other targeted toward medium-grained machines, are presented. Simulation results for the medium-grained mapping are presented, and it is shown that it is possible to exploit the available parallelism and to obtain reasonable speedups. The authors perform a detailed analysis of the results and suggest solutions for some of the problems.<>"",""1558-2183"","""",""10.1109/71.149965"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=149965"","""",""Production systems";Concurrent computing;Delay;Parallel processing;Computer architecture;Process design;Computer networks;Computational modeling;Artificial intelligence;"Laboratories"","""",""18"","""",""38"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Implementation of the conversation scheme in message-based distributed computer systems,""S. . -M. Yang";" K. H. Kim"",""Computer Science Engineering Department, University of Texas, Arlington, Arlington, TX, USA";" Department of Electrical and Computer Engineering, University of California, Irvine, Irvine, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""5"",""555"",""572"",""Several different approaches for implementing conversations in message-based distributed computer systems (DCSs) are discussed. Two different exit control strategies (synchronous and asynchronous) and three different approaches to execution of the conversation acceptance test (centralized, decentralized, and semicentralized) are examined and compared in terms of system performance and implementation cost. An efficient approach to run-time management of recovery information based on an extension of the recovery cache scheme is also discussed. The two major types of conversation structures, name-linked recovery block and abstract data type conversations, are examined to analyze which execution approaches are the most efficient for each conversation structure. As a case study, an unmanned vehicle system is used to illustrate how the approaches can be used in a realistic real-time application.<>"",""1558-2183"","""",""10.1109/71.159039"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=159039"","""",""Distributed computing";Centralized control;Control systems;System testing;System performance;Costs;Runtime;Information management;Vehicles;"Real time systems"","""",""10"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Interleaving a join sequence with semijoins in distributed query processing,""M. . -S. Chen";" P. S. Yu"",""IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA";" IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""5"",""611"",""621"",""The problem of combining join and semijoin reducers for distributed query processing is studied. An approach based on interleaving a join sequence with beneficial semijoins is proposed. A join sequence is mapped into a join sequence tree first. The join sequence tree provides an efficient way to identify for each semijoin its correlated semijoins as well as its reducible relations under the join sequence. In light of these properties, an algorithm for determining an effective sequence of join and semijoin reducers is developed. Examples are given to illustrate the results. They show the advantage of using a combination of joins and semijoins as reducers for distributed query processing.<>"",""1558-2183"","""",""10.1109/71.159044"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=159044"","""",""Interleaved codes";Query processing;Data communication;Tree graphs;Marine vehicles;Relational databases;Computer networks;Context;"Cost function"","""",""30"",""1"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"JEWEL: design and implementation of a distributed measurement system,""F. Lange"; R. Kroeger;" M. Gergeleit"",""German National Research Center for Computer Science (GMD), Saint Augustine, USA"; German National Research Center for Computer Science (GMD), Saint Augustine, USA;" German National Research Center for Computer Science (GMD), Saint Augustine, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""6"",""657"",""671"",""The distributed measurement system JEWEL, developed within project RelaX, is described. JEWEL consists of a flexible toolkit for low-interference online performance measurement integrated with a powerful adaptable graphical presentation facility and a generic interactive experiment control system. JEWEL supports a large set of different system models as well as a wide variety of interfaces to the observed system. Two examples are presented in order to demonstrate its flexibility.<>"",""1558-2183"","""",""10.1109/71.180622"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=180622"","""",""Computerized monitoring";Control systems;Distributed computing;Centralized control;Measurement;Interference;Power system modeling;Visualization;Concurrent computing;"Resource management"","""",""58"",""1"",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Lock-free garbage collection for multiprocessors,""M. P. Herlihy";" J. E. B. Moss"",""Cambridge Research Laboratory, Digital Equipment Corporation, Cambridge, MA, USA";" Department of Computer Science, University of Massachusetts, Amherst, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""3"",""304"",""311"",""Garbage collection algorithms for shared-memory multiprocessors typically rely on some form of global synchronization to preserve consistency. Such global synchronization may lead to problems on asynchronous architectures: if one process is halted or delayed, other, nonfaulty processes will be unable to progress. By contrast, a storage management algorithm is lock-free if (in the absence of resource exhaustion) a process that is allocating or collecting memory can be delayed at any point without forcing other processes to block. The authors present the first algorithm for lock-free garbage collection in a realistic model. The algorithm assumes that processes synchronize by applying read, write, and compare&swap operations to shared memory. This algorithm uses no locks, busy-waiting, or barrier synchronization, it does not assume that processes can observe or modify one another's local variables or registers, and it does not use inter-process interrupts.<>"",""1558-2183"","""",""10.1109/71.139204"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=139204"","""",""Delay";Resource management;Memory management;Laboratories;Real time systems;Read-write memory;Registers;Timing;Uncertainty;"Operating systems"","""",""27"",""16"",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Methodical analysis of adaptive load sharing algorithms,""O. Kremien";" J. Kramer"",""Department of Computing, Imperial College of Science, Technology and Medicine, London, UK";" Department of Computing, Imperial College of Science, Technology and Medicine, London, UK"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""6"",""747"",""760"",""A method for qualitative and quantitative analysis of load sharing algorithms is presented, using a number of well known examples as illustration. Algorithm design choice are considered with respect to the main activities of information dissemination and allocation decision making. It is argued that nodes must be capable of making local decisions, and for this efficient state, dissemination techniques are necessary. Activities related to remote execution should be bounded and restricted to a small proportion of the activity of the system. The quantitative analysis provides both performance and efficiency measures, including consideration of the load and delay characteristics of the environment. To assess stability, which is also a precondition for scalability, the authors introduce and measure the load-sharing hit-ratio, the ratio of remote execution requests concluded successfully. Using their analysis method, they are able to suggest improvements to some published algorithms.<>"",""1558-2183"","""",""10.1109/71.180629"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=180629"","""",""Algorithm design and analysis";Stability;Scalability;Delay effects;Software algorithms;Load management;Application software;Decision making;Performance analysis;"Resource management"","""",""86"",""4"",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Models of access delays in multiprocessor memories,""I. Y. Bucher";" D. A. Calahan"",""Los Alamos National Laboratory, Computer Research Group, Los Alamos, NM, USA";" Department of Electrical Engineering and Compuler Science, University of Michigan, Ann Arbor, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""3"",""270"",""280"",""The performance of an interleaved common memory accessed uniformly by multiple processors is modeled by queuing and simulation methods. The model includes access conflicts at the bank level while assuming an ideal access network. A general scaling law is derived that indicates that memory access delays are given by the product of the bank reservation time and a function of the memory utilization, which is the average number of access requests arriving at a bank per bank reservation time. For light, uniform memory traffic. access delays are proportional to the square of the bank reservation time and to the ratio of the number of active memory access streams to the number of memory banks. With an assumption of random access patterns, an open and a closed queuing model are developed. To model pipelined access operations a new negative feedback model is introduced that includes the open and the closed models as special cases and is also well suited for modeling linked access streams. Delay dependence on bank reservation time is quadratic for light loads and linear for very heavy loads. The queuing models are validated by simulations.<>"",""1558-2183"","""",""10.1109/71.139201"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=139201"","""",""Delay effects";National electric code;Degradation;Intelligent networks;Computational modeling;Concurrent computing;Supercomputers;Vector processors;Clocks;"Telecommunication traffic"","""",""13"","""",""14"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Multiprocessor implementation of digital filtering algorithms using a parallel block processing method,""W. Sung"; S. K. Mitra;" B. Jeren"",""Inter-university Semiconductor Research Center (ISRC) and the Department of Control and Instrumentation, Seoul National University, Seoul, South Korea"; Center for Information Processing Research, Department of Electrical and Computer Engineering, University of California, Santa Barbara, CA, USA;" Faculty of Electrical Engineering, University of Zagreb, Zagreb, Croatia"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""1"",""110"",""120"",""An efficient real-time implementation of digital filtering algorithms using a multiprocessor system in a ring network is investigated. This method is based on a parallel block processing approach, where a continuously supplied input data is divided into blocks, and the blocks are processed concurrently by being assigned to each processor in the system. This approach requires only a simple interconnection network and reduces significantly the number of communications among the processors, making the system easily expandable and highly efficient. In addition, various digital signal processing algorithms can be implemented on the same multiprocessor system. The data dependency of the blocks to be processed concurrently brings on dependency problems between the processors. A systematic scheduling method has been developed by using a precedence graph for the analysis of the dependency relation. Methods for solving the dependency problems between the processors are also investigated. Implementation procedures and results for FIR, recursive, and adaptive filtering algorithms are illustrated.<>"",""1558-2183"","""",""10.1109/71.113086"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=113086"","""",""Filtering algorithms";Signal processing algorithms;Signal processing;Real time systems;Digital filters;Finite impulse response filter;Multiprocessing systems;Digital signal processing;Processor scheduling;"Parallel processing"","""",""19"",""1"",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"On the parallel computation of the algebraic path problem,""Gen-Huey Chen"; Biing-Feng Wang;" Chi-Jen Lu"",""Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan"; Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan;" Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""2"",""251"",""256"",""The algebraic path problem is a general description of a class of problems, including some important graph problems such as transitive closure, all pairs shortest paths, minimum spanning tree, etc. In this work, the algebraic path problem is solved on a processor array with a reconfigurable bus system. The proposed algorithms are based on repeated matrix multiplications. The multiplication of two n*n matrices takes O(log n) time in the worst case, but, for some special cases, O(1) time is possible. It is shown that three instances of the algebraic path problem, transitive closure, all pairs shortest paths, and minimum spanning tree, can be solved in O(log n) time, which is as fast as on the CRCW PRAM.<>"",""1558-2183"","""",""10.1109/71.127265"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=127265"","""",""Concurrent computing";Tree graphs;Parallel algorithms;Computer science;Computational modeling;Phase change random access memory;Gaussian processes;Systolic arrays;Terrorism;"Heart"","""",""11"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"On time mapping of uniform dependence algorithms into lower dimensional processor arrays,""W. Shang";" J. A. B. Fortes"",""Center for Adv. Comput. Studies, Southwestern Louisiana Univ., Lafayette, LA, USA";" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""3"",""350"",""363"",""Most existing methods of mapping algorithms into processor arrays are restricted to the case where n-dimensional algorithms, or algorithms with n nested loops, are mapped into (n-1)-dimensional arrays. However, in practice, it is interesting to map n-dimensional algorithms into (k-1)-dimensional arrays where k<n. A computational conflict occurs if two or more computations of an algorithm are mapped into the same execution time. Based on the Hermite normal form of the mapping matrix, necessary and sufficient conditions are derived to identify mapping without computational conflicts. These conditions are used to find time mappings of n-dimensional algorithms into (k-1)-dimensional arrays, k<n, without computational conflicts. For some applications, the mapping is time-optimal.<<ETX>>"",""1558-2183"","""",""10.1109/71.139208"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=139208"","""",""Matrix decomposition";Convolution;Member and Geographic Activities Board committees;Sufficient conditions;Educational technology;Contracts;Signal processing;Image processing;Scientific computing;"Digital audio players"","""",""59"","""",""37"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Optimal broadcasting on the star graph,""V. E. Mendia";" D. Sarkar"",""AT and T Bell Laboratories, Inc., Columbus, OH, USA";" Department of Mathematics and Computer Science, University of Miami, Coral Gables, FL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""4"",""389"",""396"",""The star graph has been show to be an attractive alternative to the widely used n-cube. Like the n-cube, the star graph possesses rich structure and symmetry as well as fault tolerant capabilities, but has a smaller diameter and degree. However, very few algorithms exists to show its potential as a multiprocessor interconnection network. Many fast and efficient parallel algorithms require broadcasting as a basic step. An optimal algorithm for one-to-all broadcasting in the star graph is proposed. The algorithm can broadcast a message to N processors in O(log/sub 2/ N) time. The algorithm exploits the rich structure of the star graph and works by recursively partitioning the original star graph into smaller star graphs. In addition, an optimal all-to-all broadcasting algorithm is developed.<>"",""1558-2183"","""",""10.1109/71.149958"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=149958"","""",""Broadcasting";Multiprocessor interconnection networks;Partitioning algorithms;Parallel algorithms;Topology;Fault tolerance;Throughput;Concurrent computing;Message passing;"Mathematics"","""",""108"","""",""8"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Optimal parallel algorithms for problems modeled by a family of intervals,""S. Olariu"; J. L. Schwing;" J. Zhang"",""Department of Computer Science, Old Dominion University, Norfolk, VA, USA"; Department of Computer Science, Old Dominion University, Norfolk, VA, USA;" Department of Computer Science, Old Dominion University, Norfolk, VA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""3"",""364"",""374"",""A family of intervals on the real line provides a natural model for a vast number of scheduling and VLSI problems. Recently, a number of parallel algorithms to solve a variety of practical problems on such a family of intervals have been proposed in the literature. The authors develop computational tools and show how they can be used for the purpose of devising cost-optimal parallel algorithms for a number of interval-related problems, including finding a largest subset of pairwise nonoverlapping intervals, a minimum dominating subset of intervals, along with algorithms to compute the shortest path between a pair of intervals and, based on the shortest path, a parallel algorithm to find the center of the family of intervals. More precisely, with an arbitrary family of n intervals as input, all the algorithms run in O(log n) time using O(n) processors in the EREW-PRAM model of computation.<>"",""1558-2183"","""",""10.1109/71.139209"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=139209"","""",""Parallel algorithms";Processor scheduling;Very large scale integration;Concurrent computing;Biological system modeling;Context modeling;Lapping;Computational modeling;Scheduling algorithm;"Printed circuits"","""",""37"","""",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Parallel evaluation of attribute grammars,""A. Klaiber";" M. Gokhale"",""Department of Computer Science and Engineering, University of Washington, Seattle, WA, USA";" Supercomputing Research Center, Bowie, MD, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""2"",""206"",""220"",""Examines the generation of parallel evaluators for attribute grammars, targeted to shared-memory MIMD computers. Evaluation-time overhead due to process scheduling and synchronization is reduced by detecting coarse-grain parallelism (as opposed to the naive one-process-per-node approach). As a means to more clearly expose inherent parallelism, it is shown how to automatically transform productions of the form X to Y X into list-productions of the form X to Y/sup +/. This transformation allows for many simplifications to be applied to the semantic rules, which can expose a significant degree of inherent parallelism, and thus further increase the evaluator's performance. Effectively, this constitutes an extension of the concept of attribute grammars to the level of abstract syntax.<>"",""1558-2183"","""",""10.1109/71.127261"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=127261"","""",""Parallel processing";Production;Program processors;Packaging;Concurrent computing;Processor scheduling;Optimizing compilers;Functional programming;Computer science;"Tree graphs"","""",""6"",""1"",""30"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Partitioning and labeling of loops by unimodular transformations,""E. H. D'Hollander"",""Department of Electrical Engineering, State University of Ghent, Ghent, Belgium"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""4"",""465"",""476"",""A general method for the identification of the independent subsets in loops with constant dependence vectors is presented. It is shown that the dependence relation remains invariant under a unimodular transformation. Then a unimodular transformation is used to bring the dependence matrix into a form where the independent subsets are obtained by a direct and inexpensive partitioning algorithm. This leads to a procedure for the automatic conversion of a serial loop into a nest of parallel DO-ALL loops. Another unimodular transformation results in an algorithm to label the dependent iterations of an n-fold nested loop in O(n/sup 2/) time. This provides a multithreaded dynamic scheduling scheme requiring only one fork and one join primitive.<>"",""1558-2183"","""",""10.1109/71.149964"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=149964"","""",""Labeling";Partitioning algorithms;Dynamic scheduling;Parallel processing;Data mining;Quantization;Scheduling algorithm;Polynomials;Programming profession;"Inspection"","""",""37"",""1"",""38"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Performance analysis of a generalized class of m-level hierarchical multiprocessor systems,""I. O. Mahgoub";" A. K. Elmagarmid"",""Department of Computer Science and Engineering, Florida Atlantic University, Boca Raton, FL, USA";" Department of Computer Sciences, Purdue University, West Lafayette, IN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""2"",""129"",""138"",""The performance of the m-level hierarchical multiprocessor system is analyzed in terms of the system bandwidth for both hierarchically nonuniform reference and uniform reference models. The results show that for a higher rate of local requests (requests to memory modules within the same cluster) the m-level system performs fairly close to the crossbar system and outperforms a typical multiple-bus system (with the number of buses equal to half the number of processors). The bandwidth of the m-level system is evaluated for different numbers of levels, and the results are compared with those of a crossbar system (m=1).<>"",""1558-2183"","""",""10.1109/71.127255"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=127255"","""",""Performance analysis";Multiprocessing systems;Bandwidth;Very large scale integration;Intelligent networks;Costs;Hierarchical systems;Multiprocessor interconnection networks;Large-scale systems;"Computer science"","""",""16"",""13"",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Performance analysis of synchronized iterative algorithms on multiprocessor systems,""V. D. Agrawal";" S. T. Chakradhar"",""AT and T Bell Laboratories, Inc., Murray Hill, NJ, USA";" Department of Computer Science, Rutgers University, New Brunswick, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""6"",""739"",""746"",""A statistical model of parallel processing and a performance evaluation technique are introduced. A task is characterized by the number of atoms and by activity. An atom is the smallest part of computation that cannot be distributed to multiple processors and all atoms of a task are assumed to be equal in computational effort. Furthermore, atoms of the task became active with a fixed probability a called the activity. The task is equally divided among processors and the computation is synchronized at periodic instances when the results can be shared. The amount of computational activity of a processor within the period between synchronizations is assumed to be a binomial random variable. The performance of the multiprocessor system is derived from the maximum order-statistic of these random variables. The theoretical performance predicted by the analysis agrees well with the reported experimental performance of logic simulation of production VLSI chips, and several observed phenomena are explainable.<>"",""1558-2183"","""",""10.1109/71.180628"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=180628"","""",""Performance analysis";Iterative algorithms;Distributed computing;Random variables;Parallel processing;Multiprocessing systems;Logic;Computational modeling;Analytical models;"Predictive models"","""",""27"","""",""15"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Performance analysis of the communication architecture of the Connection Machine,""A. K. Ahluwalia";" M. Singhal"",""Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA";" Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""6"",""728"",""738"",""The performance of the interprocessor communication architecture of the CM-2 is analyzed. A discrete-time Markov chain model of its network architecture is developed to compute the message delay introduced by the network architecture. Due to the synchronous time-division multiplexing nature of the network operation, it is amenable to a discrete-time Markov chain modeling. The analysis yields formulas for response time and several other related performance measures, showing how the performance of the network degrades with the message arrival rate and other parameters. Since the communication delays affect interprocess communication, knowledge of the sensitivity of the delays to the parameters can be a useful aid in designing a high performance parallel system. To keep the analysis tractable, an approximate Markov model is used that requires the use of fixed-point iteration for its solution. Validation of the results against a simulation study reveals that the analysis predicts the performance of the network with high accuracy.<>"",""1558-2183"","""",""10.1109/71.180627"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=180627"","""",""Performance analysis";Computer architecture;Parallel processing;Parallel machines;Delay;Computer networks;Communication networks;Computational modeling;Analytical models;"Parallel algorithms"","""",""3"","""",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Performance analysis pf parallelizing compilers on the Perfect Benchmarks programs,""W. Blume";" R. Eigenmann"",""Center for Supercomputing Research and Development, University of Illinois, Urbana-Champaign, Urbana, IL, USA";" Center for Supercomputing Research and Development, University of Illinois, Urbana-Champaign, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""6"",""643"",""656"",""The speedups of the Perfect Benchmarks codes that result from automatic parallelization are reported. The performance gains caused by individual restructuring techniques have also been measured. Specific reasons for the successes and failures of the transformations are discussed, and potential improvements that result in measurably better program performance are analyzed. The most important findings are that available restructurers often cause insignificant performance gains in real programs and that only few restructuring techniques contribute to this gain. However, it can be shown that there is potential for advancing compiler technology so that many of the most important loops in these programs can be parallelized.<>"",""1558-2183"","""",""10.1109/71.180621"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=180621"","""",""Performance analysis";Program processors;Performance gain;Failure analysis;Parallel architectures;Automatic testing;US Department of Energy;Costs;Performance loss;"Velocity measurement"","""",""79"",""1"",""33"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Performance evaluation of circuit switched multistage interconnection networks using a hold strategy,""S. . -H. Hsiao";" C. Y. R. Chen"",""School of Computer and Information Science, Syracuse University, Syracuse, NY, USA";" Department of Electrical and Computer Engineering, Syracuse University, Syracuse, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""5"",""632"",""640"",""The performance evaluation of processor-memory communications for multiprocessor systems using circuit switched interconnection networks with a hold strategy is performed. Message size and processor processing time are considered and shown to have a significant effect on the overall system performance. A closed queuing network model is proposed such that only (n+2) states are required by the proposed model, in contrast to (n/sup 2/+3n+4)/2 states needed in previous studies, where n is the number of stages of the multistage interconnection network. Since a closed-form solution is obtained, the behavior of a complete cycle of memory access through multistage interconnection networks can be accurately analyzed and various performance bounds can be obtained.<>"",""1558-2183"","""",""10.1109/71.159047"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=159047"","""",""Switching circuits";Multiprocessor interconnection networks;Multiprocessing systems;Performance analysis;System performance;Queueing analysis;Synchronous generators;Performance evaluation;Closed-form solution;"Signal resolution"","""",""10"","""",""7"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Performance measurement and trace driven simulation of parallel CAD and numeric applications on a hypercube multicomputer,""J. . -M. Hsu";" P. Banerjee"",""IBM Research Division, Yorktown Heights, NY, USA";" Center for Reliable and High-Performance, Computing Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""4"",""451"",""464"",""The performance evaluation, workload characterization, and trace-driven simulation of a hypercube multicomputer running realistic workloads are presented. Eleven representative parallel applications were selected as benchmarks. Software monitoring techniques were then used to collect execution traces. Based on the measurement results, both the computation and communication behavior of these parallel programs were investigated. The various time interval distributions were modeled by statistical functions which were verified by a nonlinear regression technique using the empirical data. The temporal and spatial localities of message destinations were also studied. A model for the temporal locality of message length was introduced and used to analyze the communication traces. A trace-drive simulation environment, which uses the communication patterns of the parallel programs as inputs, was developed to study the behavior of the communication hardware under real workload. Simulation results on DMA and link utilizations are reported.<>"",""1558-2183"","""",""10.1109/71.149963"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=149963"","""",""Hypercubes";Concurrent computing;Application software;Computational modeling;Monitoring;Length measurement;Distributed computing;Statistical distributions;Joining processes;"Message passing"","""",""20"",""1"",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Performance measurement intrusion and perturbation analysis,""A. D. Malony"; D. A. Reed;" H. A. G. Wijshoff"",""Department of Computer and Information Science, University of Oregon, Eugene, OR, USA"; Department of Computer Science, University of Illinois, Urbana, IL, USA;" Department of Computer Science, Leiden University, Leiden, Netherlands"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""4"",""433"",""450"",""The authors study the instrumentation perturbations of software event tracing on the Alliant FX/80 vector multiprocessor in sequential, vector, concurrent, and vector-concurrent modes. Based on experimental data, they derive a perturbation model that can approximate true performance from instrumented execution. They analyze the effects of instrumentation coverage, (i.e., the ratio of instrumented to executed statements), source level instrumentation, and hardware interactions. The results show that perturbations in execution times for complete trace instrumentations can exceed three orders of magnitude. With appropriate models of performance perturbation, these perturbations in execution time can be reduced to less than 20% while retaining the additional information from detailed traces. In general, it is concluded that it is possible to characterize perturbations through simple models. This permits more detailed, accurate instrumentation than traditionally believed possible.<>"",""1558-2183"","""",""10.1109/71.149962"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=149962"","""",""Performance analysis";Instruments;Hardware;Testing;Computer science;Physics;Optimizing compilers;Time measurement;Registers;"Military computing"","""",""61"",""4"",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Performance tradeoffs in multithreaded processors,""A. Agarwal"",""Laboratory for Computer Science, Massachusetts Institute of Technology, Cambridge, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""5"",""525"",""539"",""An analytical performance model for multithreaded processors that includes cache interference, network contention, context-switching overhead, and data-sharing effects is presented. The model is validated through the author's simulations and by comparison with previously published simulation results. The results indicate that processors can substantially benefit from multithreading, even in systems with small caches, provided sufficient network bandwidth exists. Caches that are much larger than the working-set sizes of individual processes yield close to full processor utilization with as few as two to four contexts. Smaller caches require more contexts to keep the processor busy, while caches that are comparable in size to the working-sets of individual processes cannot achieve a high utilization regardless of the number of contexts. Increased network contention due to multithreading has a major effect on performance. The available network bandwidth and the context-switching overhead limits the best possible utilization.<>"",""1558-2183"","""",""10.1109/71.159037"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=159037"","""",""Multithreading";Delay;Switches;Performance analysis;Bandwidth;Parallel processing;Synchronization;Process design;"Pipelines"","""",""98"",""4"",""43"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Reduction operations on a distributed memory machine with a reconfigurable interconnection network,""S. Miguet";" Y. Robert"",""Ecole Normale Supérieure de Lyon, Lyon, France";" Ecole Normale Supérieure de Lyon, Lyon, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""4"",""500"",""505"",""Performing reduction operations with distributed memory machines whose interconnection networks are reconfigurable is considered. The focus is on machines whose interconnection graph can be configured as any graph of maximum degree d. The best way of interconnecting the p processors as a function of p,d and some problem- and machine-dependent parameters that characterize the ratio communication/arithmetic for the reduction operation are discussed. Experiments on transputer-based networks are in good accordance with the theoretical results.<>"",""1558-2183"","""",""10.1109/71.149967"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=149967"","""",""Multiprocessor interconnection networks";Scattering;Broadcasting;Arithmetic;Concurrent computing;Pipelines;Kernel;Parallel architectures;Parallel algorithms;"Binary trees"","""",""1"",""1"",""9"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Reliability analysis of distributed systems based on a fast reliability algorithm,""Deng-Jyi Chen";" Tien-Hsiang Huang"",""Computer Science and Information Engineering Department, National Chiao Tung University, Hsinchu, Taiwan";" Computer Science and Information Engineering Department, National Chiao Tung University, Hsinchu, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""2"",""139"",""154"",""The reliability of a distributed processing system (DPS) can be expressed by the analysis of distributed program reliability (DPR) and distributed system reliability (DSR). One of the good approaches to formulate these reliability performance indexes is to generate all disjoint file spanning trees (FSTs) in the DPS graph such that the DPR and DSR can be expressed by the probability that at least one of these FSTs is working. In the paper, a unified algorithm to efficiently generate disjoint FSTs by cutting different links is presented, and the DPR and DSR are computed based on a simple and consistent union operation on the probability space of the FSTs. The DPS reliability related problems are also discussed. For speeding up the reliability evaluation, nodes merged, series, and parallel reduction concepts are incorporated in the algorithm. Based on the comparison of number of subgraphs (or FSTs) generated by the proposed algorithm and by existing evaluation algorithms, it is concluded that the proposed algorithm is much more economic in terms of time and space than the existing algorithms.<>"",""1558-2183"","""",""10.1109/71.127256"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=127256"","""",""Algorithm design and analysis";Computer network reliability;Tree graphs;Reliability theory;Distributed processing;Performance analysis;Graph theory;Resource management;Throughput;"Fault tolerant systems"","""",""40"","""",""19"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Reliability of a class of multistage interconnection networks,""X. Cheng";" O. C. Ibe"",""Aeronomics, Inc., Fayetteville, GA, USA";" GTE Laboratories, Inc., Waltham, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""2"",""241"",""246"",""The reliability of extra-stage interconnection networks is discussed. Three types of reliability are analyzed: terminal reliability, which is the probability that at least one fault-free path exists between a given input-output pair: network reliability, which is the probability that at least one fault-free path exists between every input-output pair";" and broadcast reliability, which is the probability that at least one fault-free path exists between a given input and all outputs. A recursive expression for the broadcast reliability is obtained. Tight bounds are derived for the network reliability. The numerical results indicate that for practical networks (i.e. when network reliability is at least 0.5) the difference between the upper bound and the lower bound is no more than 2% of the lower bound.<>"",""1558-2183"","""",""10.1109/71.127263"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=127263"","""",""Multiprocessor interconnection networks";Broadcasting;Identity-based encryption;Packet switching;Computer networks;Upper bound;Communication switching;Fabrics;Communication networks;"Fault tolerance"","""",""19"","""",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;
"Reliable distributed sorting through the application-oriented fault tolerance paradigm,""B. M. McMillin";" L. M. Ni"",""Department Computer Science, University of Missouri, Rolla, Rolla, MO, USA";" Department of Computer Science, Michigan State University, East Lansing, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""4"",""411"",""420"",""A fault-tolerant parallel sorting algorithm developed using the application-oriented fault tolerance paradigm is presented. The algorithm is tolerant of one processor/link failure in an n-cube. The addition of reliability to the sorting algorithm results in a performance penalty. Asymptotically, the fault-tolerant algorithm is less costly than host sorting. Experimentally it is shown that fault-tolerant sorting quickly becomes more efficient that host sorting when the bitonic sort/merge is considered. The main contribution is the demonstration that the application-oriented fault tolerance paradigm is applicable to problems of a noniterative-convergent nature.<>"",""1558-2183"","""",""10.1109/71.149960"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=149960"","""",""Sorting";Fault tolerance;Testing;Peer to peer computing;Application software;Performance evaluation;Algorithm design and analysis;Hardware;Fault detection;"Parallel algorithms"","""",""14"",""1"",""9"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Requirements for optimal execution of loops with tests,""A. K. Uht"",""Department of Computer Science and Engineering, University of California, San Diego, La Jolla, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""5"",""573"",""581"",""Both the efficient execution of branch intensive code and knowing the bounds on the same are important issues in computing in general and supercomputing in particular. In prior work, it has been suggested that the hardware needed to execute code with branches optimally is exponentially dependent on the total number of dynamic branches executed, this number of branches being proportional at least to the number of iterations of the loop. For classes of code taking at least one cycle per iteration to execute, this is not the case. For loops containing one test (normally in the form of a Boolean recurrence of order one), it is shown that the hardware necessary varies from exponential to polynomial in the length of the dependence cycle L, while execution time varies from one time cycle per iteration to less than L time cycles per iteration";" the variation depends on specific code dependences. These results bring the eager evaluation of imperative code closer to fruition.<>"",""1558-2183"","""",""10.1109/71.159040"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=159040"","""",""Testing";Hardware;Optimal control;Supercomputers;Concurrent computing;Parallel machines;Application software;Computer science;Timing;"Pipelines"","""",""8"","""",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Rollback recovery in distributed systems using loosely synchronized clocks,""Z. Tong"; R. Y. Kain;" W. T. Tsai"",""Bit 3 Computer Corporation, Minneapolis, MN, USA"; Department of Electrical Engineering, University of Minnesota, Minneapolis, MN, USA;" Department of Computer Science, University of Minnesota, Minneapolis, MN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""2"",""246"",""251"",""A rollback recovery scheme for distributed systems is proposed. The state-save synchronization among processes is implemented by bounding clock drifts such that no state-save synchronization messages are required. Since the clocks are only loosely synchronized, the synchronization overhead can be negligible in many applications. An interprocess communication protocol which encodes state-save progress information within message frames is introduced to checkpoint consistent system states. A rollback recovery algorithm that will force a minimum number of nodes to roll back after failures is developed.<>"",""1558-2183"","""",""10.1109/71.127264"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=127264"","""",""Synchronization";Clocks;Protocols;Fault detection;Fault tolerant systems;Concrete;Delay;Computer science;"Checkpointing"","""",""26"","""",""13"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;
"Rotator graphs: an efficient topology for point-to-point multiprocessor networks,""P. F. Corbett"",""T. J. Watson Research Center, IBM, Yorktown Heights, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""5"",""622"",""626"",""Rotator graphs, a set of directed permutation graphs, are proposed as an alternative to star and pancake graphs. Rotator graphs are defined in a way similar to the recently proposed Faber-Moore graphs. They have smaller diameter, n-1 in a graph with n factorial vertices, than either the star or pancake graphs or the k-ary n-cubes. A simple optimal routing algorithm is presented for rotator graphs. The n-rotator graphs are defined as a subset of all rotator graphs. The distribution of distances of vertices in the n-rotator graphs is presented, and the average distance between vertices is found. The n-rotator graphs are shown to be optimally fault tolerant and maximally one-step fault diagnosable. The n-rotator graphs are shown to be Hamiltonian, and an algorithm for finding a Hamiltonian circuit in the graphs is given.<>"",""1558-2183"","""",""10.1109/71.159045"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=159045"","""",""Network topology";Routing;Fault tolerance;Multicast algorithms;Circuit faults;Computer networks;Distributed computing;Hypercubes;Sorting;"Broadcasting"","""",""83"","""",""9"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"SNAP: a market-propagation architecture for knowledge processing,""D. Moldovan"; W. Lee;" C. Lin"",""Department of Electrical Engineering-Systems, University of Southern California, Los Angeles, CA, USA"; Department of Electrical Engineering-Systems, University of Southern California, Los Angeles, CA, USA;" Department of Electrical Engineering-Systems, University of Southern California, Los Angeles, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""4"",""397"",""410"",""The semantic network array processor (SNAP), a highly parallel architecture targeted to artificial intelligence applications, and in particular natural language understanding, is presented. The knowledge is represented in a form of the semantic network. The knowledge base is distributed among the elements of the SNAP array, and the processing is performed locally where the knowledge is stored. A set of powerful instructions specific to knowledge processing is implemented directly in hardware. SNAP is packaged into 256 custom-designed chips assembled on four printed circuit boards and can store a 16 K node semantic network. SNAP is a marker propagation architecture in which the movement of markers between cells is controlled by propagation rules. Various reasoning mechanisms are implemented with these marker propagation rules.<>"",""1558-2183"","""",""10.1109/71.149959"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=149959"","""",""Artificial intelligence";Computer architecture;Humans;Natural languages;Mechanical factors;Parallel architectures;Hardware;Packaging;Assembly;"Printed circuits"","""",""9"",""1"",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Sorting in mesh connected multiprocessors,""P. F. Corbett";" I. D. Scherson"",""IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA";" Department of Information and Computer Science, University of California, Irvine, Irvine, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""5"",""626"",""632"",""A sorting algorithm, dubbed MeshSort, for multidimensional mesh-connected multiprocessors is introduced. Bitonic Sort and ShearSort are shown to be special cases of MeshSort. MeshSort thus provides some insight into the operation of parallel sorting. It requires operations only along orthogonal vectors of processors, simplifying the control of the multiprocessor. This allows MeshSort to be used on any reduced architecture where a multidimensional memory structure is interconnected with a lower dimensional structure of processors. A modified version of MeshSort, called FastMeshSort, is presented. This algorithm applies the same basic principle as MeshSort, and is almost as simple to implement, but achieves much better performance. The modified algorithm is shown to be very efficient for reasonably sized meshes. FastMeshSort is presented as a practical sorting and routing algorithm for real multidimensional mesh-connected multiprocessors. The algorithms can easily be extended to other multiprocessor structures.<>"",""1558-2183"","""",""10.1109/71.159046"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=159046"","""",""Sorting";Routing;Circuit faults;Fault tolerance;Integrated circuit interconnections;Fault diagnosis;Multidimensional systems;Network topology;Circuit topology;"Hypercubes"","""",""14"","""",""22"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Synchronization and communication costs of loop partitioning on shared-memory multiprocessor systems,""R. Gupta"",""Department of Computer Science, University of Pittsburgh, Pittsburgh, PA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""4"",""505"",""512"",""The author presents strategies for static loop decomposition and scheduling as well as computer-assisted run-time scheduling that take into account, in addition to the cost of performing operations, the overhead costs associated with a decomposition and schedule. An algorithm for static decomposition of multidimensional loops based on the operation execution costs, communication costs, and synchronization costs is discussed. Synchronization instructions are introduced to ensure correct program execution following program decomposition. An algorithm for determining the explicit synchronization instruction that should be introduced to ensure correct execution of a program with arbitrarily nested loops is presented. Techniques for reducing run-time scheduling and communication and synchronization costs due to self-scheduling of multidimensional loops are also presented. Experiments performed on the Encore multiprocessor system demonstrate that the techniques developed can reduce overhead costs.<>"",""1558-2183"","""",""10.1109/71.149968"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=149968"","""",""Costs";Multiprocessing systems;Processor scheduling;Runtime;Multiprocessor interconnection networks;Hypercubes;Multidimensional systems;Concurrent computing;Network topology;"Arithmetic"","""",""7"","""",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Systems with low distributed simulation overhead,""D. Kumar"",""Department of Computer Engineering and Science, Case Western Reserve University, Cleveland, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""2"",""155"",""165"",""Distributed simulation often involves a large number of overhead messages. This may lead to severe performance degradation of the simulator as pointed out in several previous works. In this work special classes of systems which can be simulated with low overhead-in most systems identified here the total number of overhead messages on any given communication line is at most one, irrespective of the time up to which the physical system is to be simulated-are presented. This includes acyclic systems, some closed queuing networks, some open cyclic queuing networks, and other special types of cyclic networks. Distributed simulation algorithms specially tailored to these systems are given. By isolating these classes of systems and designing distributed simulation algorithms specifically geared for them, a large number of overhead messages can be avoided. By contrast, other distributed simulation algorithms are usually designed for more general systems and they usually require too many overhead messages, even in simulating these special classes of systems.<>"",""1558-2183"","""",""10.1109/71.127257"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=127257"","""",""System recovery";Discrete event simulation;Degradation;Algorithm design and analysis;Event detection;Petri nets;Clocks;Synchronization;Military computing;"Discrete event systems"","""",""8"",""1"",""56"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"The adaptive-hash join algorithm for a hypercube multicomputer,""E. Omiecinski";" E. T. Lin"",""College of Computing, Georgia Institute of Technology, Atlanta, GA, USA";" IBM, Corporation, San Jose, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""3"",""334"",""349"",""The cube adaptive-hash join algorithm, which combines the merits of nested-loop and hybrid-hash, is presented. The performance of these algorithms is compared through analytical cost modeling. The nonuniform data value distribution of the inner relation is shown to have a greater impact than that of the outer relation. The cube adaptive-hash algorithm outperforms the cube hybrid-hash algorithm when bucket overflow occurs. In the worst case, this algorithm converges to the cube nested-loop-hash algorithm. When there is no hash table overflow, the cube adaptive-hash algorithm converges to the cube hybrid-hash algorithm. Since the cube adaptive-hash algorithm adapts itself depending on the characteristics of the relations, it is relatively immune to the data distribution.<>"",""1558-2183"","""",""10.1109/71.139207"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=139207"","""",""Hypercubes";Algorithm design and analysis;Relational databases;Clustering algorithms;Costs;Distributed databases;Transaction databases;Performance analysis;Analytical models;"Multiprocessing systems"","""",""12"",""1"",""31"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"The crossed cube architecture for parallel computation,""K. Efe"",""The Center for Advanced Computer Studies, University of Southwestern Louisiana, Lafayette, LA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""5"",""513"",""524"",""The construction of a crossed cube which has many of the properties of the hypercube, but has diameter only about half as large, is discussed. This network is self-routing, in the sense that there is a simple distributed routing algorithm which guarantees optimal paths between any pair of vertices. This fact, together with other properties such as regularity, symmetry, high connectivity, and a simple recursive structure, suggests that the crossed cube may be an attractive alternative to the ordinary hypercube for massively parallel architectures, SIMD algorithms, which utilize the architecture are developed, and it is shown that the CQ/sub n/ architecture can profitably emulate the ordinary hypercube. It is also shown that addition of simple switches can improve the capabilities of the system significantly. For instance, the dynamic reconfiguration capability allows hypercube algorithms to be executed on the proposed architecture. The use of these switches also improves the embedding properties of the system.<>"",""1558-2183"","""",""10.1109/71.159036"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=159036"","""",""Computer architecture";Concurrent computing;Hypercubes;Switches;Communication switching;Network topology;Routing;Sorting;Parallel architectures;"Computational modeling"","""",""317"","""",""11"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"The power test for data dependence,""M. Wolfe";" C. . -W. Tseng"",""Department of Computer Science and Engineering, Oregon Graduate Institute, Beaverton, OR, USA";" Department of Computer Science, Rice University, Houston, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""5"",""591"",""601"",""A data dependence decision algorithm called the power test is introduced. The power test is a combination of the extended GCD algorithm and the Fourier-Motzkin method to eliminate variables in a system of inequalities. This is the first test that can generate the information needed for some advanced transformations, and that can handle complex simultaneous loop limits. Previous work in data dependence decision algorithms is reviewed. Some examples which motivated the development of this test are examined, including those which demonstrate the additional power of the power test. Although it may be too expensive for use as a general-purpose dependence test in a compiler, the power test has proved useful in an interactive program restructuring environment.<>"",""1558-2183"","""",""10.1109/71.159042"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=159042"","""",""System testing";Program processors;Computer science;Optimizing compilers;Supercomputers;Parallel processing;Cache memory;Law;Legal factors;"Equations"","""",""85"","""",""40"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Virtual-channel flow control,""W. J. Dally"",""Artificial Intelligence Laboratory and Laboratory for Computer Science, Massachusetts Institute of Technology, Cambridge, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1992"",""3"",""2"",""194"",""205"",""Network throughput can be increased by dividing the buffer storage associated with each network channel into several virtual channels. Each physical channel is associated with several small queues, virtual channels, rather than a single deep queue. The virtual channels associated with one physical channel are allocated independently but compete with each other for physical bandwidth. Virtual channels decouple buffer resources from transmission resources. This decoupling allows active messages to pass blocked messages using network bandwidth that would otherwise be left idle. The paper studies the performance of networks using virtual channels using both analysis and simulation. These studies show that virtual channels increase network throughput, by a factor of four for 10-stage networks, and reduce the dependence of throughput on the depth of the network.<>"",""1558-2183"","""",""10.1109/71.127260"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=127260"","""",""Multiprocessor interconnection networks";Routing;Throughput;Bandwidth;Computer networks;Concurrent computing;Network topology;Resource management;Buffer storage;"Coupling circuits"","""",""1020"",""75"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;