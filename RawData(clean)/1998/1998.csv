"1998 Index IEEE Transactions on Parallel And Distributed Systems - Author Index,"""",,""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""12"",""1269"",""1273"",""This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index."",""1558-2183"","""",""10.1109/TPDS.1998.737701"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=737701"","""","""","""","""","""","""",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;
"A basic-cycle calculation technique for efficient dynamic data redistribution,""Yeh-Ching Chung"; Ching-Hsien Hsu;" Sheng-Wen Bai"",""Department of Information Engineering, Feng Chia University FCU, Taichung, Taiwan"; Department of Information Engineering, Feng Chia University FCU, Taichung, Taiwan;" Department of Information Engineering, Feng Chia University FCU, Taichung, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""4"",""359"",""377"",""Array redistribution is usually required to enhance algorithm performance in many parallel programs on distributed memory multicomputers. Since it is performed at run-time, there is a performance trade-off between the efficiency of the new data decomposition for a subsequent phase of an algorithm and the cost of redistributing data among processors. In this paper, we present a basic-cycle calculation technique to efficiently perform BLOCK-CYCLIC(S) to BLOCK-CYCLIC(t) redistribution. The main idea of the basic-cycle calculation technique is, first, to develop closed forms for computing source/destination processors of some specific array elements in a basic-cycle, which is defined as icm(s,t)/gcd(s,t). These closed forms are then used to efficiently determine the communication sets of a basic-cycle. From the source/destination processor/data sets of a basic-cycle, we can efficiently perform a BLOCK-CYCLIC(s) to BLOCK-CYCLIC(t) redistribution. To evaluate the performance of the basic-cycle calculation technique, we have implemented this technique on an IBM SP2 parallel machine, along with the PITFALLS method and the multiphase method. The cost models for these three methods are also presented. The experimental results show that the basic-cycle calculation technique outperforms the PITFALLS method and the multiphase method for most test samples."",""1558-2183"","""",""10.1109/71.667897"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=667897"","""",""Phased arrays";Runtime;Parallel programming;Costs;Parallel machines;Testing;Program processors;Programming profession;"Algorithm design and analysis"","""",""20"","""",""33"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"A comment on ""A circular list-based mutual exclusion scheme for large shared-memory multiprocessor"",""Ting-Lu Huang";" Chien-Hua Shann"",""Department of Computer Science and Information Engineering, National Chiao Tung University, Hsinchu, Taiwan";" Department of Computer Science and Information Engineering, National Chiao Tung University, Hsinchu, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""4"",""414"",""415"",""The circular list-based mutual exclusion algorithm proposed by Fu and Tzeng (1997) is subject to a race condition that leads to a deadlock under subtle situations. An execution sequence evidences the race, and a modified version is provided. The performance of the original algorithm remains unchanged."",""1558-2183"","""",""10.1109/71.667901"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=667901"","""",""Hypercubes";System recovery;Multiprocessor interconnection networks;Electronic switching systems;Application software;Computer architecture;Concurrent computing;Parallel processing;"Spinning"","""",""4"","""",""1"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"A compiler optimization algorithm for shared-memory multiprocessors,""K. S. McKinley"",""Department of Computer Science, University of Massachusetts, Amherst, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""8"",""769"",""787"",""This paper presents a new compiler optimization algorithm that parallelizes applications for symmetric, shared-memory multiprocessors. The algorithm considers data locality, parallelism, and the granularity of parallelism. It uses dependence analysis and a simple cache model to drive its optimizations. It also optimizes across procedures by using interprocedural analysis and transformations. We validate the algorithm by hand-applying it to sequential versions of parallel, Fortran programs operating over dense matrices. The programs initially were hand-coded to target a variety of parallel machines using loop parallelism. We ignore the user's parallel loop directives, and use known and implemented dependence and interprocedural analysis to find parallelism. We then apply our new optimization algorithm to the resulting program. We compare the original parallel program to the hand-optimized program, and show that our algorithm improves three programs, matches four programs, and degrades one program in our test suite on a shared-memory, bus-based parallel machine with local caches. This experiment suggests existing dependence and interprocedural array analysis can automatically detect user parallelism, and demonstrates that user parallelized codes often benefit from our compiler optimizations, providing evidence that we need both parallel algorithms and compiler optimizations to effectively utilize parallel machines."",""1558-2183"","""",""10.1109/71.706049"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=706049"","""",""Optimizing compilers";Algorithm design and analysis;Parallel processing;Parallel machines;Program processors;Parallel algorithms;Hardware;Parallel programming;Costs;"Degradation"","""",""20"",""4"",""51"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;
"A cost and speed model for k-ary n-cube wormhole routers,""A. A. Chein"",""Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""2"",""150"",""162"",""The evaluation of advanced routing features must be based on both of costs and benefits. To date, adaptive routers have generally been evaluated on the basis of the achieved network throughput (channel utilization), ignoring the effects of implementation complexity. In this paper, we describe a parameterized cost model for router performance, characterized by two numbers: router delay and flow control time. Grounding the cost model in a 0.8 micron gate array technology, we use it to compare a number of proposed routing algorithms. From these design studies, several insights into the implementation complexity of adaptive routers are clear. First, header update and selection is expensive in adaptive routers, suggesting that absolute addressing should be reconsidered. Second, virtual channels are expensive in terms of latency and cycle time, so decisions to include them to support adaptivity or even virtual lanes should not be taken lightly. Third, requirements of larger crossbars and more complex arbitration cause some increase in the complexity of adaptive routers, but the rate of increase is small. Last, the complexity of adaptive routers significantly increases their setup delay and flow control cycle times, implying that claims of performance advantages in channel utilization and low load latency must be carefully balanced against losses in achievable implementation speed."",""1558-2183"","""",""10.1109/71.663877"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663877"","""",""Costs";Routing;Clocks;Network topology;Delay effects;System recovery;Parallel machines;Concrete;Throughput;"Grounding"","""",""177"","""",""36"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;
"A distributed graph algorithm for the detection of local cycles and knots,""A. Boukerche";" C. Tropper"",""Department of Computer Science, University of North Texas, Denton, TX, USA";" School of Computer Science, McGill University, Montreal, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""8"",""748"",""757"",""In this paper, a distributed cycle/knot detection algorithm for general graphs is presented. The algorithm distinguishes between cycles and knots and is the first algorithm to our knowledge which does so. It is especially relevant to an application such as parallel simulation in which 1) cycles and knots can arise frequently 2) the size of the graph is very large, and 3) it is necessary to know if a given node is in a cycle or a knot. It requires less communication than previous algorithms-2m vs. (at least) (4m) for the Chandy and Misra algorithm, where m is the number of links in the graph. It requires O (nlog (n)) bits of memory, where n is the number of nodes. The algorithm differs from the classical diffusing computation methods through its use of incomplete search messages to speed up the computation. We introduce a marking scheme in order to identify strongly connected subcomponents of the graph which cannot reach the initiator of the algorithm. This allows us to distinguish between the case in which the initiator is in a cycle (only) or is in a knot."",""1558-2183"","""",""10.1109/71.706047"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=706047"","""",""System recovery";Detection algorithms;Clustering algorithms;Signal detection;Distributed computing;Computational modeling;Database systems;Signal generators;"Detectors"","""",""30"",""1"",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"A fault-tolerant dynamic scheduling algorithm for multiprocessor real-time systems and its analysis,""G. Manimaran";" C. S. R. Murthy"",""Department of Computer Science and Engineering, Indian Institute of Technology, Chennai, India";" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""11"",""1137"",""1152"",""Many time-critical applications require dynamic scheduling with predictable performance. Tasks corresponding to these applications have deadlines to be met despite the presence of faults. In this paper, we propose an algorithm to dynamically schedule arriving real-time tasks with resource and fault-tolerant requirements on to multiprocessor systems. The tasks are assumed to be nonpreemptable and each task has two copies (versions) which are mutually excluded in space, as well as in time in the schedule, to handle permanent processor failures and to obtain better performance, respectively. Our algorithm can tolerate more than one fault at a time, and employs performance improving techniques such as 1) distance concept which decides the relative position of the two copies of a task in the task queue, 2) flexible backup overloading, which introduces a trade-off between degree of fault tolerance and performance, and 3) resource reclaiming, which reclaims resources both from deallocated backups and early completing tasks. We quantify, through simulation studies, the effectiveness of each of these techniques in improving the guarantee ratio, which is defined as the percentage of total tasks, arrived in the system, whose deadlines are met. Also, we compare through simulation studies the performance our algorithm with a best known algorithm for the problem, and show analytically the importance of distance parameter in fault-tolerant dynamic scheduling in multiprocessor real-time systems."",""1558-2183"","""",""10.1109/71.735960"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=735960"","""",""Fault tolerance";Dynamic scheduling;Heuristic algorithms;Scheduling algorithm;Processor scheduling;Real time systems;Fault tolerant systems;Time factors;Multiprocessing systems;"Analytical models"","""",""112"",""2"",""33"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A framework for reinforcement-based scheduling in parallel processor systems,""A. Y. Zomaya"; M. Clements;" S. Olariu"",""Parallel Computing Research Laboratory, Department of Electrical and Electronic Engineering, University of Western Australia, Perth, WA, Australia"; Digital Equipment Corporation, Turner, ACT, Australia;" Department of Computer Science, Old Dominion University, Norfolk, VA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""3"",""249"",""260"",""Task scheduling is important for the proper functioning of parallel processor systems. The static scheduling of tasks onto networks of parallel processors is well-defined and documented in the literature. However, in many practical situations a priori information about the tasks that need to be scheduled is not available. In such situations, tasks usually arrive dynamically and the scheduling should be performed on-line or """"on the fly"""". In this paper, we present a framework based on stochastic reinforcement learning, which is usually used to solve optimization problems in a simple and efficient way. The use of reinforcement learning reduces the dynamic scheduling problem to that of learning a stochastic approximation of an unknown average error surface. The main advantage of the proposed approach is that no prior information is required about the parallel processor system under consideration. The learning system develops an association between the best action (schedule) and the current state of the environment (parallel system). The performance of reinforcement learning is demonstrated by solving several dynamic scheduling problems. The conditions under which reinforcement learning can used to efficiently solve the dynamic scheduling problem are highlighted."",""1558-2183"","""",""10.1109/71.674317"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=674317"","""",""Processor scheduling";Optimal scheduling;Job shop scheduling;Dynamic scheduling;Parallel processing;Stochastic processes;Intelligent networks;Learning systems;"Application software"","""",""27"",""3"",""33"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"A fully adaptive routing algorithm for dynamically injured hypercubes, meshes, and tori,""Ming-Jer Tsai";" Sheng-De Wang"",""Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan";" Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""2"",""163"",""174"",""Unicast V is a progressive, misrouting algorithm for packet or virtual cut-through networks. A progressive protocol forwards a message at an intermediate node if a nonfaulty profitable link is available and waits, deroutes, or aborts otherwise. A misrouting protocol uses both profitable and nonprofitable links at each node";" thus, a message can move farther away from its destination at some steps. Unicast V is simple for hardware implementation, requires a very small message overhead, and makes routing decisions by local failure information only. However, it is claimed to be partially adaptive and to be able to tolerate static faults in hypercubes only. In this paper, we uncover some new features of Unicast V: (1) it is fully-adaptive, (2) it also applies to meshes and tori, and (3) it can tolerate dynamic faults by careful implementation. In addition, we also provide bounds on the performance of the algorithm."",""1558-2183"","""",""10.1109/71.663879"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663879"","""",""Heuristic algorithms";Hypercubes;Packet switching;Routing protocols;Delay;History;Computer Society;Hardware;Programmable control;"Adaptive control"","""",""4"","""",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"A general theory for deadlock avoidance in wormhole-routed networks,""E. Fleury";" P. Fraigniaud"",""LORIA, Villers-Les-Nancy, France";" LRI, Universite Paris-Sud, Orsay, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""7"",""626"",""638"",""Most machines of the last generation of distributed memory parallel computers possess specific routers which are used to exchange messages between nonneighboring nodes in the network. Among the several technologies, wormhole routing is usually preferred because it allows low channel-setup time and reduces the dependency between latency and internode distance. However, wormhole routing is very susceptible to deadlock because messages are allowed to hold many resources while requesting others. Therefore, designing deadlock-free routing algorithms using few hardware facilities is a major problem for wormhole-routed networks. In this paper, we describe a general theoretical framework for the study of deadlock-free routing functions. We give a general definition of what can be a routing function. This definition captures many specific definitions of the literature (e.g., vertex dependent, input-dependent, source-dependent, path-dependent etc.). Using our definition, we give a necessary and sufficient condition which characterizes deadlock-free routing functions. Our theory embraces, at a high level, most of the theories related to deadlock avoidance in wormhole-routed networks previously derived in the literature. In particular, it applies not only to one-to-one routing, but also to one-to-many routing. The latter paradigm is used to solve the multicast problem with the path-based or tree-based facility."",""1558-2183"","""",""10.1109/71.707539"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=707539"","""",""System recovery";Intelligent networks;Routing;Sufficient conditions;Delay;Algorithm design and analysis;Hardware;Computer Society;Computer networks;"Concurrent computing"","""",""52"",""7"",""76"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A new algorithm based on Givens rotations for solving linear equations on fault-tolerant mesh-connected processors,""K. N. B. Murthy"; K. Bhuvaneswari;" C. S. Ram Murthy"",""The Department of Electrical and Electronics Engineering, Malnad College of Engineering, Hassan, India"; India Development Center, Oracle Software India Limited, Bangalore, India;" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""8"",""825"",""832"",""In this paper, we propose a new I/O overhead free Givens rotations based parallel algorithm for solving a system of linear equations. The algorithm uses a new technique called two-sided elimination and requires an N/spl times/(N+1) mesh-connected processor array to solve N linear equations in (5N-log N-4) time steps. The array is well suited for VLSI implementation as identical processors with simple and regular interconnection pattern are required. We also describe a fault-tolerant scheme based on an algorithm based fault tolerance (ABFT) approach. This scheme has small hardware and time overhead and can tolerate up to N processor failures."",""1558-2183"","""",""10.1109/71.706053"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=706053"","""",""Fault tolerance";Equations;Linear systems;Parallel algorithms;Fault tolerant systems;Phased arrays;Systolic arrays;Neural networks;Very large scale integration;"Hardware"","""",""4"","""",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A new parallel and distributed shortest path algorithm for hierarchically clustered data networks,""S. Zhu";" G. M. Huang"",""Nortel, Inc., Richardson, TX, USA";" Department of Electrical Engineering, Texas A and M University, College Station, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""9"",""841"",""855"",""This paper presents new efficient shortest path algorithms to solve single origin shortest path problems (SOSP problems) and multiple origins shortest path problems (MOSP problems) for hierarchically clustered data networks. To solve an SOSP problem for a network with n nodes, the distributed version of our algorithm reaches the time complexity of O(log(n)), which is less than the time complexity of O(log/sup 2/ (n)) achieved by the best existing algorithm. To solve an MOSP problem, our algorithm minimizes the needed computation resources, including computation processors and communication links for the computation of each shortest path so that we can achieve massive parallelization. The time complexity of our algorithm for an MOSP problem is O(m log(n)), which is much less than the time complexity of O(M log/sup 2/ (0)) of the best previous algorithm. Here, M is the number of the shortest paths to be computed and m is a positive number related to the network topology and the distribution of the nodes incurring communications, m is usually much smaller than M. Our experiment shows that m is almost a constant when the network size increases. Accordingly, our algorithm is significantly faster than the best previous algorithms to solve MOSP problems for large data networks."",""1558-2183"","""",""10.1109/71.722218"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722218"","""",""Clustering algorithms";Network topology;Concurrent computing;Shortest path problem;Distributed computing;Algorithm design and analysis;Computer networks;Distributed algorithms;Broadcasting;"Parallel processing"","""",""20"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A note on total ordering multicast using propagation trees,""Ge-Ming Chiu";" Chih-Ming Hsiao"",""Department of Electrical Engineering and Technology, National Taiwan University of Science and Technology, Taipei, Taiwan";" Department of Electrical Engineering and Technology, National Taiwan University of Science and Technology, Taipei, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""2"",""217"",""223"",""Jia (1995) proposed a multicast scheme, using propagation trees, to ensure the total ordering (including causal ordering) delivery of messages for group communication. Our study indicates that causal relation between some messages may not actually be presented in this protocol. We then present a revised approach for closed group communication."",""1558-2183"","""",""10.1109/71.663947"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663947"","""",""Computer Society";Multicast communication;Multicast protocols;Organizing;"Broadcasting"","""",""4"","""",""8"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;
"A parallel system for text inference using marker propagations,""S. M. Harabagiu";" D. I. Moldovan"",""Department of Computer Science and Engineering, Southern Methodist University, Dallas, TX, USA";" Department of Computer Science and Engineering, Southern Methodist University, Dallas, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""8"",""729"",""747"",""This paper presents a possible solution for the text inference problem-extracting information unstated in a text, but implied. Text inference is central to natural language applications such as information extraction and dissemination, text understanding, summarization, and translation. Our solution takes advantage of a semantic English dictionary available in electronic form that provides the basis for the development of a large linguistic knowledge base. The inference algorithm consists of a set of highly parallel search methods that, when applied to the knowledge base, find contexts in which sentences are interpreted. These contexts reveal information relevant to the text. Implementation, results, and parallelism analysis are discussed."",""1558-2183"","""",""10.1109/71.706046"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=706046"","""",""Natural languages";Inference algorithms;Parallel processing;Humans;Data mining;Information retrieval;Text recognition;Natural language processing;Computer science;"Computer Society"","""",""5"","""",""30"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A practical approach to dynamic load balancing,""J. Watts";" S. Taylor"",""Scalable Concurrent Programming Laboratory, Syracuse University, Syracuse, NY, USA";" Scalable Concurrent Programming Laboratory, Syracuse University, Syracuse, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""3"",""235"",""248"",""This paper presents a cohesive, practical load balancing framework that improves upon existing strategies. These techniques are portable to a broad range of prevalent architectures, including massively parallel machines, such as the Cray T3D/E and Intel Paragon, shared memory systems, such as the Silicon Graphics PowerChallenge, and networks of workstations. As part of the work, an adaptive heat diffusion scheme is presented, as well as a task selection mechanism that can preserve or improve communication locality. Unlike many previous efforts in this arena, the techniques have been applied to two large-scale industrial applications on a variety of multicomputers. In the process, this work exposes a serious deficiency in current load balancing strategies, motivating further work in this area."",""1558-2183"","""",""10.1109/71.674316"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=674316"","""",""Load management";Concurrent computing;Application software;Large-scale systems;Parallel machines;Silicon;Graphics;Workstations;Parallel processing;"Plasma simulation"","""",""110"",""3"",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A priority-driven flow control mechanism for real-time traffic in multiprocessor networks,""S. Balakrishnan";" F. Ozguner"",""Department of Computing and Software Systems, University of Washington, Bothell, WA, USA";" Department of Electrical Engineering, Ohio State Uinversity, Columbus, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""7"",""664"",""678"",""Real-time applications when mapped to distributed memory multiprocessors produce periodic messages with an associated deadline and priority. Real-time messages may be hard or soft deadline. Real-time extensions to wormhole routing (WR) with multiple virtual channels (VCs) and priority-based physical link arbitration and VC allocation have been proposed in the literature. With a fixed number of VCs/link, a message can face an unbounded priority inversion, rendering the global priority ineffective. In this paper, we propose a new flow control mechanism called Preemptive Pipelined Circuit Switching for Real-Time messages (PPCS-RT) to reduce the priority inversion problem. For the proposed model, with some architectural support, we present an off-line approach to compute delivery guarantees of hard deadline real-time messages. We also perform a comparison of real-time WR and PPCS-RT in terms of performance with soft deadline traffic. The overall miss ratio percentage is over 30 percent higher for WR than PPCS-RT with one VC/link at high traffic loads. Finally, we compare the architectural complexity of a PPCS-RT router and other real-time routers."",""1558-2183"","""",""10.1109/71.707545"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=707545"","""",""Communication system traffic control";Intelligent networks;Virtual colonoscopy;Real time systems;Routing;Multiprocessing systems;Switching circuits;Spread spectrum communication;Computer networks;"Bandwidth"","""",""25"","""",""31"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A self-stabilizing ring orientation algorithm with a smaller number of processor states,""N. Umemoto"; H. Kakugawa;" M. Yamashita"",""Hi-Elecom-Kowa Company Limited, Hiroshima, Japan"; Research Institute for Information Science and Education, Hiroshima University, Higashihiroshima, Hiroshima, Japan;" Department of Electrical Engineering, Hiroshima University, Higashihiroshima, Hiroshima, Japan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""6"",""579"",""584"",""A distributed system is said to be self-stabilizing if it will eventually reach a legitimate system state regardless of its initial state. Because of this property, a self-stabilizing system is extremely robust against failures";" it tolerates any finite number of transient failures. The ring orientation problem for a ring is the problem of all the processors agreeing on a common ring direction. This paper focuses on the problem of designing a deterministic self-stabilizing ring orientation system with a small number of processor states under the distributed daemon. Because of the impossibility of symmetry breaking, under the distributed daemon, no such systems exist when the number n of processors is even. Provided that n is odd, the best known upper bound on the number of states is 256 in the link-register model, and eight in the state-reading model. We improve the bound down to 6/sup 3/=216 in the link-register model."",""1558-2183"","""",""10.1109/71.689445"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=689445"","""",""Registers";Computer Society;Robustness;Upper bound;Fault tolerant systems;Algorithm design and analysis;"Computational modeling"","""",""3"","""",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A software approach to avoiding spatial cache collisions in parallel processor systems,""D. C. Wong"; E. W. Davis;" J. O. Young"",""North Carolina State University, Raleigh, NC, USA"; North Carolina State University, Raleigh, NC, USA;" Atmospheric Sciences Modeling Division, Air Resources Laboratory, National Oceanic and Atmospheric Administration, NC, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""6"",""601"",""608"",""In parallel processor systems, the performance of individual processors is a key factor in overall performance. Processor performance is strongly affected by the behavior of cache memory in that high hit rates are essential for high performance. Hit rates are lowered when collisions on placing lines in the cache force a cache line to be replaced before it has been used to best effect. Spatial cache collisions occur if data structures and data access patterns are misaligned. We describe a mathematical scheme to improve alignment and enhance performance in applications which have moderate-to-large numbers of arrays, where various dimensionalities are involved in localized computation and array access patterns are sequential. These properties are common in many computational modeling applications. Furthermore, the scheme provides a single solution when an application is targeted to run on various numbers of processors in power-of-two sizes. The applicability of the proposed scheme is demonstrated on testbed code for an air quality modeling problem."",""1558-2183"","""",""10.1109/71.689447"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=689447"","""",""Cache memory";Data structures;Computational modeling;Testing;Power system modeling;Bridges;Hardware;Arithmetic;Software performance;"Kernel"","""",""1"",""1"",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A spanning multichannel linked hypercube: a gradually scalable optical interconnection network for massively parallel computing,""A. Louri"; B. Weech;" C. Neocleous"",""Department of Electrical and Computer Engineering and Computer Science (ECE/CS), University of Arizona Tucson, Tucson, AZ, USA"; Department of Electrical and Computer Engineering and Computer Science (ECE/CS), University of Arizona Tucson, Tucson, AZ, USA;" Department of Electrical and Computer Engineering and Computer Science (ECE/CS), University of Arizona Tucson, Tucson, AZ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""5"",""497"",""512"",""A new, scalable interconnection topology called the Spanning Multichannel Linked Hypercube (SMLH) is proposed. This proposed network is very suitable to massively parallel systems and is highly amenable to optical implementation. The SMLH uses the hypercube topology as a basic building block and connects such building blocks using two-dimensional multichannel links (similar to spanning buses). In doing so, the SMLH combines positive features of both the hypercube (small diameter, high connectivity, symmetry, simple routing, and fault tolerance) and the spanning bus hypercube (SBH) (constant node degree, scalability, and ease of physical implementation), while at the same time circumventing their disadvantages. The SMLH topology supports many communication patterns found in different classes of computation, such as bus-based, mesh-based, and tree-based problems, as well as hypercube-based problems. A very attractive feature of the SMLH network is its ability to support a large number of processors with the possibility of maintaining a constant degree and a constant diameter. Other positive features include symmetry, incremental scalability, and fault tolerance. It is shown that the SMLH network provides better average message distance, average traffic density, and queuing delay than many similar networks, including the binary hypercube, the SBH, etc. Additionally, the SMLH has comparable performance to other high-performance hypercubic networks, including the Generalized Hypercube and the Hypermesh. An optical implementation methodology is proposed for SMLH. The implementation methodology combines both the advantages of free space optics with those of wavelength division multiplexing techniques. A detailed analysis of the feasibility of the proposed network is also presented."",""1558-2183"","""",""10.1109/71.679219"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=679219"","""",""Hypercubes";Network topology;Fault tolerance;Scalability;Optical interconnections;Optical fiber networks;Routing;Telecommunication traffic;Traffic control;"Wavelength division multiplexing"","""",""23"","""",""51"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A stochastic model for heterogeneous computing and its application in data relocation scheme development,""Min Tan";" H. J. Siegel"",""Segue Software, Inc., Los Gatos, CA, USA";" Parallel Processing Laboratory, School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""11"",""1088"",""1101"",""In a dedicated, mixed-machine, heterogeneous computing (HC) system, an application program may be decomposed into subtasks, then each subtask assigned to the machine where it is best suited for execution. Data relocation is defined as selecting the sources for needed data items. It is assumed that multiple independent subtasks of an application program can be executed concurrently on different machines whenever possible. A theoretical stochastic model for HC Is proposed, in which the computation times of subtasks and communication times for intermachine data transfers can be random variables. The optimization problem for finding the optimal matching, scheduling, and data relocation schemes to minimize the total execution time of an application program is defined based on this stochastic HC model. The global optimization criterion and search space for the above optimization problem are described. It is validated that a greedy algorithm-based approach can establish a local optimization criterion for developing data relocation heuristics. The validation is provided by a theoretical proof based on a set of common assumptions about the underlying HC system and application program. The local optimization criterion established by the greedy approach, coupled with the search space defined for choosing valid data relocation schemes, can help developers of future practical data relocation heuristics."",""1558-2183"","""",""10.1109/71.735956"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=735956"","""",""Stochastic processes";Computer applications;Processor scheduling;Application software;Random variables;Optimal matching;Computer networks;Greedy algorithms;Hardware;"High-speed networks"","""",""6"",""1"",""28"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A theory for total exchange in multidimensional interconnection networks,""V. V. Dimakopoulos";" N. J. Dimopoulos"",""Department of Computer Science, University of Ioannina (UoI), Ioannina, Greece";" Department of Electrical and Computer Engineering, University of Victoria, Victoria, BC, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""7"",""639"",""649"",""Total exchange (or multiscattering) is one of the important collective communication problems in multiprocessor interconnection networks. It involves the dissemination of distinct messages from every node to every other node. We present a novel theory for solving the problem in any multidimensional (cartesian product) network. These networks have been adopted as cost-effective interconnection structures for distributed-memory multiprocessors. We construct a general algorithm for single-port networks and provide conditions under which it behaves optimally. It is seen that many of the popular topologies, including hypercubes, k-ary n-cubes, and general tori satisfy these conditions. The algorithm is also extended to homogeneous networks with 2/sup k/ dimensions and with multiport capabilities. Optimality conditions are also given for this model. In the course of our analysis, we also derive a formula for the average distance of nodes in multidimensional networks";" it can be used to obtain almost closed-form results for many interesting networks."",""1558-2183"","""",""10.1109/71.707541"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=707541"","""",""Intelligent networks";Multidimensional systems;Multiprocessor interconnection networks;Hypercubes;Broadcasting;Network topology;Tree graphs;Message passing;Communication standards;"Scattering"","""",""12"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Abstractions for portable, scalable parallel programming,""G. A. Alverson"; W. G. Griswold; C. Lin; D. Notkin;" L. Snyder"",""Tera Computer Company, Seattle, WA, USA"; Department of Computer Science and Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Computer Sciences, University of Technology, Austin, TX, USA; Department of Computer Science and Engineering, University of Washington, Seattle, WA, USA;" Department of Computer Science and Engineering, University of Washington, Seattle, WA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""1"",""71"",""86"",""In parallel programming, the need to manage communication, load imbalance, and irregularities in the computation puts substantial demands on the programmer. Key properties of the architecture, such as the number of processors and the cost of communication, must be exploited to achieve good performance, but coding these properties directly into a program compromises the portability and flexibility of the code because significant changes are then needed to port or enhance the program. We describe a parallel programming model that supports the concise, independent description of key aspects of a parallel program-including data distribution, communication, and boundary conditions-without reference to machine idiosyncrasies. The independence of such components improves portability by allowing the components of a program to be tuned independently, and encourages reuse by supporting the composition of existing components. The isolation of architecture-sensitive aspects of a computation simplifies the task of porting programs to new platforms. Moreover, the model is effective in exploiting both data parallelism and functional parallelism. This paper provides programming examples, compares this work to related languages, and presents performance results."",""1558-2183"","""",""10.1109/71.655246"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=655246"","""",""Parallel programming";Parallel processing;Programming profession;Computer architecture;Concurrent computing;Costs;Aggregates;Computer science;"Load management"","""",""7"","""",""49"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;
"Access control and signatures via quorum secret sharing,""M. Naor";" A. Wool"",""Department of Applied Mathematics and Computer Science, Weizmann Institute of Science, Rehovot, Israel";" Bell Laboratories, Lucent Technologies, Inc., Murray Hill, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""9"",""909"",""922"",""We suggest a method of controlling the access to a secure database via quorum systems. A quorum system is a collection of sets (quorums) every two of which have a nonempty intersection. Quorum systems have been used for a number of applications in the area of distributed systems. We propose a separation between access servers, which are protected and trustworthy, but may be outdated, and the data servers, which may all be compromised. The main paradigm is that only the servers in a complete quorum can collectively grant (or revoke) access permission. The method we suggest ensures that, after authorization is revoked, a cheating user Alice will not be able to access the data even if many access servers still consider her authorized and even if the complete raw database is available to her. The method has a low overhead in terms of communication and computation. It can also be converted into a distributed system for issuing secure signatures. An important building block in our method is the use of secret sharing schemes that realize the access structures of quorum systems. We provide several efficient constructions of such schemes which may be of interest in their own right."",""1558-2183"","""",""10.1109/71.722223"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722223"","""",""Access control";Cryptography;Databases;Licenses;Access protocols;Protection;Availability;Wool;Computer Society;"Control systems"","""",""43"",""4"",""49"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Adaptive fault-tolerant routing in cube-based multicomputers using safety vectors,""Jie Wu"",""Department of Computer Science and Engineering, Florida, Atlanta University, Boca Raton, FL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""4"",""321"",""334"",""Reliable communication in cube-based multicomputers using the safety vector concept is studied in this paper. In our approach, each node in a cube-based multicomputer of dimension n is associated with a safety vector of n bits, which is an approximated measure of the number and distribution of faults in the neighborhood. The safety vector of each node can be easily calculated through n-1 rounds of information exchange among neighboring nodes. Optimal unicasting between two nodes is guaranteed if the kth bit of the safety vector of the source node is one, where k is the Hamming distance between the source and destination nodes. The concept of dynamic adaptivity is introduced, representing the ability of a routing algorithm to dynamically adjust its routing adaptivity based on fault distribution in the neighborhood. The feasibility of the proposed unicasting can be easily determined at the source node by comparing its safety vector with the Hamming distance between the source and destination nodes. The proposed unicasting can also be used in disconnected hypercubes, where nodes in a hypercube are disjointed (into two or more parts). We then extend the safety vector concept to general cube-based multicomputers."",""1558-2183"","""",""10.1109/71.667894"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=667894"","""",""Fault tolerance";Routing;Safety;Hypercubes;Unicast;Hamming distance;Topology;Heuristic algorithms;Telecommunication network reliability;"Message passing"","""",""43"","""",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;
"All to-all communication with minimum start-up costs in 2D/3D tori and meshes,""Young-Joo Suh";" S. Valamanchili"",""Real-Time Computing Laboratory, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA";" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""5"",""442"",""458"",""All-to-all communication patterns occur in many important parallel algorithms. This paper presents new algorithms for all-to-all communication patterns (all-to-all broadcast and all-to-all personalized exchange) for wormhole switched 2D/3D torus- and mesh-connected multiprocessors. The algorithms use message combining to minimize message start-ups at the expense of larger message sizes. The unique feature of these algorithms is that they are the first algorithms that we know of that operate in a bottom-up fashion rather than a recursive, top-down manner. For a 2/sup d//spl times/2/sup d/ torus or mesh, the algorithms for all-to-all personalized exchange have time complexity of O(2/sup 3d/). An important property of the algorithms is the O(d) time due to message start-ups, compared with O(2/sup d/) for current algorithms. This is particularly important for modern parallel architectures where the start-up cost of message transmissions still dominates, except for very large block sizes. Finally, the 2D algorithms for all-to-all personalized exchange are extended to O(2/sup 4d/) algorithms in a 2/sup d//spl times/2/sup d//spl times/2/sup d/3D torus or mesh. These algorithms also retain the important property of O(d) time due to message start-ups."",""1558-2183"","""",""10.1109/71.679215"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=679215"","""",""Costs";Broadcasting;Parallel algorithms;Scattering;Concurrent computing;Computer architecture;Message passing;Communication switching;Parallel architectures;"Multiprocessor interconnection networks"","""",""41"",""3"",""19"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"All-to-all broadcast and matrix multiplication in faulty SIMD hypercubes,""A. Sengupta";" C. S. Raghavendra"",""Oracle Corporation, Redwood Shores, CA, USA";" Aerospace Corporation, Los Angeles, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""6"",""550"",""560"",""In this paper, we develop algorithms in order of efficiency for all-to-all broadcast problem in an N=2/sup n/-node n-dimensional faulty SIMD hypercube, Q/sub n/, with up to n-1 node faults. The algorithms use a property of a certain ordering of dimensions. Our analysis includes startup time (/spl alpha/) and transfer time (/spl beta/). We have established the lower bound for such an algorithm to be n/spl alpha/+(2N-3)L/spl beta/ in a faulty hypercube with at most n-1 faults (each node has a value of L bytes). Our best algorithm requires 2n/spl alpha/+2NL/spl beta/ and is near-optimal. We develop an optimal algorithm for matrix multiplication in a faulty hypercube using all-to-all broadcast and compare the efficiency of all-to-all broadcast approach with broadcast approach and global sum approach for matrix multiplication. The algorithms are congestion-free and applicable in the context of available hypercube machines."",""1558-2183"","""",""10.1109/71.689442"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=689442"","""",""Broadcasting";Hypercubes;Fault tolerance;Routing;Parallel algorithms;Linear algebra;Matrices;Computer networks;Concurrent computing;"Image processing"","""",""1"","""",""31"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Alleviating consumption channel bottleneck in wormhole routed k-ary n-cube systems,""D. Basak";" D. K. Panda"",""FORE Systems, Inc., Warrendale, PA, USA";" Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""5"",""481"",""496"",""This paper identifies performance degradation in wormhole routed k-ary n-cube networks due to limited number of router-to-processor consumption channels at each node. Many recent research in wormhole routing have advocated the advantages of adaptive routing and virtual channel flow control schemes to deliver better network performance. This paper indicates that the advantages associated with these schemes cannot be realized with limited consumption capacity. To alleviate such performance bottlenecks, a new network interface design using multiple consumption channels is proposed. To match virtual multiplexing on network channels, we also propose each consumption channel to support multiple virtual consumption channels. The impact of message arrival rate at a node on the required number of consumption channels is studied analytically. It is shown that wormhole networks with higher routing adaptivity, dimensionality, degree of hot-spot traffic, and number of virtual lanes have to take advantage of multiple consumption channels to deliver better performance. The interplay between system topology, routing algorithm, number of virtual lanes, messaging overheads, and communication traffic is studied through simulation to derive the effective number of consumption channels required in a system. Using the ongoing technological trend, it is shown that wormhole-routed systems can use up to two-four consumption channels per node to deliver better system performance."",""1558-2183"","""",""10.1109/71.679218"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=679218"","""",""Routing";Telecommunication traffic;Degradation;Programmable control;Adaptive control;Traffic control;Computer worms;Intelligent networks;Network interfaces;"Network topology"","""",""9"","""",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"An algorithm for scheduling jobs in hypercube systems,""Oh-Heum Kwon";" Kyung-Yong Chwa"",""Department of Computer Engineering, Pukyong National University, busan, South Korea";" Department of Computer Science, KAIST, Taejon, South Korea"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""9"",""856"",""860"",""In this paper, we consider the problem of nonpreemptively scheduling independent jobs so as to minimize overall finish time on an m-dimensional hypercube system. This problem is NP-hard. We propose a polynomial time approximation algorithm and prove that the absolute performance ratio of the algorithm does not exceed 1.875. This is the first algorithm achieving an absolute performance ratio less than two by a constant."",""1558-2183"","""",""10.1109/71.722219"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722219"","""",""Scheduling algorithm";Hypercubes;Approximation algorithms;Polynomials;Processor scheduling;Optimized production technology;Virtual manufacturing;Computer networks;"Communication channels"","""",""8"","""",""3"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"An analytical model for hybrid checkpointing in time warp distributed simulation,""H. M. Soliman";" A. S. Elmaghraby"",""College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia";" Multimedia Research Laboratory, Speed Scientific School, University of Louisville, Louisville, KY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""10"",""947"",""951"",""The Time Warp distributed simulation algorithm uses checkpointing to save process states after certain event executions for later recovery at the time of a rollback. Two main techniques have been used for checkpointing: periodic state saving and incremental state saving. The former technique introduces large overheads in reconstructing a desired state by coasting forward from an earlier checkpointed state if the computational granularity is large. The latter technique also has large overheads in applications with large rollback distances. A hybrid checkpointing technique is proposed which uses both periodic and incremental state saving simultaneously in such a way that it reduces checkpointing time overheads. A detailed analytical model is developed for the hybrid technique, and comparisons are made using similar analytical models with periodic and incremental state saving techniques. Results show that when the system parameters are chosen to represent large and complex simulated systems, the hybrid approach has less checkpointing time overhead than the other two techniques."",""1558-2183"","""",""10.1109/71.730524"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=730524"","""",""Analytical models";Checkpointing;Time warp simulation;Discrete event simulation;Clocks;Synchronization;System recovery;Safety;Event detection;"Topology"","""",""28"","""",""14"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"An efficient algorithm for row minima computations on basic reconfigurable meshes,""K. Nakano";" S. Olariu"",""Dept. of Electr. Eng. & Comput. Sci., Nagoya Inst. of Technol., Japan";" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""6"",""561"",""569"",""A matrix A of size m/spl times/n containing items from a totally ordered universe is termed monotone if, for every i, j, 1/spl les/i<j/spl les/m, the minimum value in row j lies below or to the right of the minimum in row i monotone matrices, and variations thereof, are known to have many important applications. In particular, the problem of computing the row minima of a monotone matrix is of import in image processing, pattern recognition, text editing, facility location, optimization, and VLSI. Our first main contribution is to exhibit a number of nontrivial lower bounds for matrix search problems. These lower bound results hold for arbitrary, infinite, two-dimensional reconfigurable meshes as long as the input is pretiled onto a contiguous n/spl times/n submesh thereof. Specifically in this context, we show that every algorithm that solves the problem of computing the minimum of an n/spl times/n matrix must take /spl Omega/(log log n) time. The same lower bound is shown to hold for the problem of computing the minimum in each row of an arbitrary n/spl times/n matrix. As a by product, we obtain an /spl Omega/(log log n) time lower bound for the problem of selecting the kth smallest item in a monotone matrix, thus extending the best previously known lower bound for selection on the reconfigurable mesh. Finally, we show an /spl Omega/(/spl radic/loglogn) time lower bound for the task of computing the row minima of a monotone n/spl times/n matrix. Our second main contribution is to provide a nearly optimal algorithm for the row-minima problem: With a monotone matrix of size m/spl times/n with m/spl les/n pretiled, one item per processor, onto a basic reconfigurable mesh of the same size, our row-minima algorithm runs in O(log n) time if 1/spl les/m/spl les/2 and in O(logn/logm loglog m) time if m>2. In case m=n/sup /spl epsiv// for some constant /spl epsiv/, (0</spl epsiv//spl les/1), our algorithm runs in O(log log n) time."",""1558-2183"","""",""10.1109/71.689443"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=689443"","""",""Power system modeling";Very large scale integration;Search problems;Computer architecture;Broadcasting;Image processing;Pattern recognition;Automata;Phase change random access memory;"Parallel processing"","""",""7"","""",""31"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"An efficient dynamic scheduling algorithm for multiprocessor real-time systems,""G. Manimaran";" C. S. R. Murthy"",""Department of Computer Science and Engineering, Indian Institute of Technology, Chennai, India";" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""3"",""312"",""319"",""Many time-critical applications require predictable performance and tasks in these applications have deadlines to be met. In this paper, we propose an efficient algorithm for nonpreemptive scheduling of dynamically arriving real-time tasks (aperiodic tasks) in multiprocessor systems. A real-time task is characterized by its deadline, resource requirements, and worst case computation time on p processors, where p is the degree of parallelization of the task. We use this parallelism in tasks to meet their deadlines and, thus, obtain better schedulability compared to nonparallelizable task scheduling algorithms. To study the effectiveness of the proposed scheduling algorithm, we have conducted extensive simulation studies and compared its performance with the myopic scheduling algorithm. The simulation studies show that the schedulability of the proposed algorithm is always higher than that of the myopic algorithm for a wide variety of task parameters."",""1558-2183"","""",""10.1109/71.674322"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=674322"","""",""Dynamic scheduling";Heuristic algorithms;Scheduling algorithm;Processor scheduling;Time factors;Real time systems;Multiprocessing systems;Concurrent computing;Parallel processing;"Computational modeling"","""",""116"",""1"",""14"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"An efficient method for approximating submesh reliability of two dimensional-meshes,""Chung-Yen Chang";" P. Mohapatra"",""Amdahl Corporation, Sunnyvale, CA, USA";" Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""11"",""1115"",""1124"",""An analytical model for submesh reliability of mesh-connected systems is proposed in this paper. A mesh is considered operational as long as a functional submesh of the required size is available. We use the principle of inclusion and exclusion to find the exact probability of having a functional submesh within a partition of the mesh. The partitions are taken along either dimension of the mesh. The partitions along the rows are called row partitions (RPs) and along the columns are called column partitions (CPs). The reliability of a partition is then used to approximate the submesh reliability of the system and, thus, this model is called partitioned mesh (PM) model. Instead of using a computationally intensive recursive algorithm as done in the previous work, a closed form approximation of the submesh reliability is derived in this paper. The PM model is validated through simulation and compared with the earlier proposed approximation techniques. It is shown that the PM model provides better approximations for submesh reliability with constant computational complexity."",""1558-2183"","""",""10.1109/71.735958"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=735958"","""",""Computer Society";Analytical models;Approximation algorithms;Partitioning algorithms;Computational modeling;Computational complexity;Computer architecture;Parallel processing;"Very large scale integration"","""",""9"","""",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"An O((log log n)/sup 2/) time algorithm to compute the convex hull of sorted points on reconfigurable meshes,""T. Hayashi"; K. Nakano;" S. Olarlu"",""Department of Electrical and Computer Engineering, Nagoya Institute of Technology, Nagoya, Japan"; Department of Electrical and Computer Engineering, Nagoya Institute of Technology, Nagoya, Japan;" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""12"",""1167"",""1179"",""The problem of computing the convex hull of a set of n sorted points in the plane is one of the fundamental tasks in image processing, pattern recognition, cellular network design, and robotics, among many others. Somewhat surprisingly, in spite of a great deal of effort, the best previously known algorithm to solve this problem on a reconfigurable mesh of size /spl radic/n/spl times//spl radic/n was running in O(log2 n) time. It was open for more than ten years to obtain an algorithm for this important problem running in sublogarithmic time. Our main contribution is to provide the first breakthrough: we propose an almost optimal convex hull algorithm running in O((log log n)/sup 2/) time on a reconfigurable mesh of size /spl radic/n/spl times//spl radic/n. With slight modifications, this algorithm can be implemented to run in O((log log n)/sup 2/) time on a reconfigurable mesh of size /spl radic/n/loglogn/spl times//spl radic/n/loglogn. Clearly, the latter algorithm is work-optimal. We also show that any algorithm that computes the convex hull of a set of n sorted points on an n-processor reconfigurable mesh must take /spl Omega/(log log n) time. Our result opens the door to an entire slew of efficient convex-hull-based algorithms on reconfigurable meshes."",""1558-2183"","""",""10.1109/71.737694"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=737694"","""",""Power system modeling";Image processing;Pattern recognition;Computer networks;Morphology;Mobile computing;Computer architecture;Computer Society;Land mobile radio cellular systems;"Algorithm design and analysis"","""",""9"","""",""30"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Analysis of task assignment policies in scalable distributed web-server systems,""M. Colajanni"; P. S. Yu;" D. M. Dias"",""Dipartimento di Informatica, Sistemi e Produzi-One, Tor Vergata, Universita di Roma, Rome, Italy"; IBM Thomas J. Watson Research Center, Hawthorne, NY, USA;" IBM Thomas J. Watson Research Center, Hawthorne, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""6"",""585"",""600"",""A distributed multiserver Web site can provide the scalability necessary to keep up with growing client demand at popular sites. Load balancing of these distributed Web-server systems, consisting of multiple, homogeneous Web servers for document retrieval and a Domain Name Server (DNS) for address resolution, opens interesting new problems. In this paper, we investigate the effects of using a more active DNS which, as an atypical centralized scheduler, applies some scheduling strategy in routing the requests to the most suitable Web server. Unlike traditional parallel/distributed systems in which a centralized scheduler has full control of the system, the DNS controls only a very small fraction of the requests reaching the multiserver Web site. This peculiarity, especially in the presence of highly skewed load, makes it very difficult to achieve acceptable load balancing and avoid overloading some Web servers. This paper adapts traditional scheduling algorithms to the DNS, proposes new policies, and examines their impact under different scenarios. Extensive simulation results show the advantage of strategies that make scheduling decisions on the basis of the domain that originates the client requests and limited server state information (e.g., whether a server is overloaded or not). An initially unexpected result is that using detailed server information, especially based on history, does not seem useful in predicting the future load and can often lead to degraded performance."",""1558-2183"","""",""10.1109/71.689446"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=689446"","""",""Web server";Load management;Control systems;Centralized control;Scheduling algorithm;Degradation;Web sites;Network servers;Uniform resource locators;"Computer Society"","""",""79"",""35"",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Arachne: a portable threads system supporting migrant threads on heterogeneous network farms,""B. Dimitrov";" V. Rego"",""Department of Computer Sciences, Purdue University, West Lafayette, IN, USA";" Department of Computer Sciences, Purdue University, West Lafayette, IN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""5"",""459"",""469"",""We present the design and implementation of Arachne, a threads system that can be interfaced with a communications library for multithreaded distributed computations. In particular, Arachne supports thread migration between heterogeneous platforms, dynamic stack size management, and recursive thread functions. Arachne is efficient, flexible, and portable-it is based entirely on C and C++. To facilitate heterogeneous thread operations, we have added three keywords to the C++ language. The Arachne preprocessor takes as input code written in that language and outputs C++ code suitable for compilation with a conventional C++ compiler. The Arachne runtime system manages all threads during program execution. We present some performance measurements on the costs of basic thread operations and thread migration in Arachne and compare these to costs in other threads systems."",""1558-2183"","""",""10.1109/71.679216"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=679216"","""",""Concurrent computing";Distributed computing;Costs;Counting circuits;Libraries;Computer interfaces;Computer networks;Data preprocessing;"Measurement"","""",""27"",""1"",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"Basic operations on the OTIS-Mesh optoelectronic computer,""Chih-Fang Wang";" S. Sahni"",""Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA";" Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""12"",""1226"",""1236"",""In this paper, we develop algorithms for some basic operations-broadcast, window broadcast, prefix sum, data sum, rank, shift, data accumulation, consecutive sum, adjacent sum, concentrate, distribute, generalize, sorting, random access read and write-on the OTIS-Mesh model. These operations are useful in the development of efficient algorithms for numerous applications."",""1558-2183"","""",""10.1109/71.737698"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=737698"","""",""Optical interconnections";Broadcasting;Sorting;Power system interconnection;Concurrent computing;Hypercubes;Multiprocessor interconnection networks;Neural networks;Computational modeling;"Distributed computing"","""",""66"","""",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Bound performance models of heterogeneous parallel processing systems,""S. Balsamo"; L. Donatiello;" N. M. Van Dijk"",""Dipartimento di Matematica e Informatica, University of Udine, Udine, Italy"; Dipartimento di Scienze dell'Informazione, University of Bologna, Bologna, Italy;" Department of Economterics, University of Amsterdam, Amsterdam, Netherlands"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""10"",""1041"",""1056"",""Systems of heterogeneous parallel processing are studied such as arising in parallel programs executed on distributed systems. A lower and an upper bound model are suggested to obtain secure lower and upper bounds on the performance of these systems. The bounding models are solved by using a matrix-geometric algorithmic approach. Formal proofs of the bounds are provided along with error bounds on the accuracy of the bounds. These error bounds in turn are reduced to simple computational expressions. Numerical results are included. The results are of interest for application to arbitrary fork-join models with parallel heterogeneous processors and synchronization."",""1558-2183"","""",""10.1109/71.730531"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=730531"","""",""Parallel processing";Upper bound;Process design;Queueing analysis;System performance;Resource management;Database systems;Delay effects;"Throughput"","""",""47"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Byzantine agreement in the presence of mixed faults on processors and links,""Hin-Sing Siu"; Yeh-Hao Chin;" Wei-Pang Yang"",""Department of Industrial Engineering and Management, MingChi Institute of Technology, Taipei, Taiwan"; Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan;" Department of Computer and Information Science, National Chiao Tung University, Hsinchu, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""4"",""335"",""345"",""In early stage, the Byzantine agreement (BA) problem was studied with single faults on processors in either a fully connected network or a nonfully connected network. Subsequently, the single fault assumption was extended to mixed faults (also referred to as hybrid fault model) on processors. For the case of both processor and link failures, the problem has been examined in a fully connected network with a single faulty type, namely an arbitrary fault. To release the limitations of a fully connected network and a single faulty type, the problem is reconsidered in a general network. The processors and links in such a network can both be subjected to different types of fault simultaneously. The proposed protocol uses the minimum number of message exchanges and can tolerate the maximum number of allowable faulty components to make each fault-free processor reach an agreement."",""1558-2183"","""",""10.1109/71.667895"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=667895"","""",""Protocols";Computer Society;Fault tolerant systems;Synchronization;Fault detection;Data processing;Database systems;Clocks;Network topology;"Delay"","""",""36"",""1"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Characterizing distributed shared memory performance: a case study of the Convex SPP1000,""G. A. Abandah";" E. S. Davidson"",""Advanced Computer Architecture Laboratory, Electrical Engineering and Computer Science Department, University of Michigan, Ann Arbor, MI, USA";" Advanced Computer Architecture Laboratory, Electrical Engineering and Computer Science Department, University of Michigan, Ann Arbor, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""2"",""206"",""216"",""In a distributed shared memory (DSM) multiprocessor, the processors cooperate in solving a parallel application by accessing the shared memory. The latency of a memory access depends on several factors, including the distance to the nearest valid data copy, data sharing conditions, and traffic of other processors. To provide a better understanding of DSM performance and to support application tuning and compiler development for DSM systems, this paper extends microbenchmarking techniques to characterize the important aspects of a DSM system. We present an experiment-based methodology for characterizing the memory, communication, scheduling, and synchronization performance, and apply it to the Convex SPP1000. We present carefully designed microbenchmarks to characterize the performance of the local and remote memory, producer-consumer communication involving two or more processors, and the effects on performance when multiple processors contend for utilization of the distributed memory and the interconnection network."",""1558-2183"","""",""10.1109/71.663946"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663946"","""",""Computer aided software engineering";Processor scheduling;Multiprocessor interconnection networks;Application software;Delay;Coherence;Power system modeling;Access protocols;Hardware;"Software performance"","""",""14"","""",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Circuit retiming applied to decomposed software pipelining,""P. . -Y. Calland"; A. Darte;" Y. Robert"",""Laboratoire LIP, URA CNRS 1398, Ecole Normale Supérieure de Lyon, Lyon, France"; Laboratoire LIP, URA CNRS 1398, Ecole Normale Supérieure de Lyon, Lyon, France;" Laboratoire LIP, URA CNRS 1398, Ecole Normale Supérieure de Lyon, Lyon, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""1"",""24"",""35"",""This paper elaborates on a new view on software pipelining, called decomposed software pipelining. The approach is to decouple the problem into resource constraints and dependence constraints. Resource constraints management amounts to scheduling an acyclic graph subject to resource constraints for which an efficiency bound is known, resulting in a bound for loop scheduling. The acyclic graph is obtained by cutting some particular edges of the (cyclic) dependence graph. In this paper, we cut edges in a different way, using circuit retiming algorithms, so as to minimize both the longest dependence path in the acyclic graph, and the number of edges in the acyclic graph. With this technique, we improve the efficiency bound given for Gasperoni and Schwlegelshohn algorithm, and we reduce the constraints that remain for the acyclic problem. We believe this framework to be of interest because it brings a new insight into the software problem by establishing its deep link with the circuit retiming problem."",""1558-2183"","""",""10.1109/71.655240"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=655240"","""",""Circuits";Pipeline processing;Processor scheduling;Computer Society;VLIW;Software tools;Software algorithms;Resource management;Computer architecture;"Kernel"","""",""26"",""3"",""13"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Coding for high availability of a distributed-parallel storage system,""Q. M. Malluhi";" W. E. Johnston"",""Computer Science Department, Jackson State University, Jackson, MS, USA";" Information and Computer Sciences Division, Ernest Orlando Lawrence Berkeley National Laboratory, Berkeley, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""12"",""1237"",""1252"",""We have developed a distributed parallel storage system that employs the aggregate bandwidth of multiple data servers connected by a high-speed wide-area network to achieve scalability and high data throughput. This paper studies different schemes to enhance the reliability and availability of such network-based distributed storage systems. The general approach of this paper employs """"erasure"""" error-correcting codes that can be used to reconstruct missing information caused by hardware, software, or human faults. The paper describes the approach and develops optimized algorithms for the encoding and decoding operations. Moreover, the paper presents techniques for reducing the communication and computation overhead incurred while reconstructing missing data from the redundant information. These techniques include clustering, multidimensional coding, and the full two-dimensional parity schemes. The paper considers trade-offs between redundancy, fault tolerance, and complexity of error recovery."",""1558-2183"","""",""10.1109/71.737699"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=737699"","""",""Availability";Aggregates;Bandwidth;Network servers;Scalability;Throughput;Error correction codes;Hardware;Humans;"Clustering algorithms"","""",""17"",""5"",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Collection-aware optimum sequencing of operations and closed-form solutions for the distribution of a divisible load on arbitrary processor trees,""G. D. Barlas"",""Department of Electrical and Computing Engineering, National and Technical University of Athens, Athens, Greece"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""5"",""429"",""441"",""The problem of optimally distributing a divisible load to the nodes of an arbitrary processor tree is tackled in this paper. The rigorous mathematical foundation presented allows the derivation of the sequence of operations that is necessary to obtain the minimum processing time, along with closed-form expressions that yield the solution in time O(NP), where P is the number of tree nodes and N their maximum degree. The main contributions of this work are: (1) both load distribution and result collection overheads are considered, thus providing better resource utilization, and (2) arbitrary processor trees are examined in contrast with previous approaches that examined either complete homogeneous trees, or single level trees. Additionally, approximate algorithms for solving the problem of specifying the optimum subset of active processors for a given load, are presented and evaluated."",""1558-2183"","""",""10.1109/71.679214"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=679214"","""",""Distributed computing";Closed-form solution;Resource management;Parallel processing;Pattern matching;Vector quantization;Image databases;Image processing;"Message passing"","""",""71"","""",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;
"Comments on ""Hierarchical cubic networks"",""Sang Kyun Yun";" Kyu Ho Park"",""Department of Computer Science, Seowon University, Chongju, Chungbuk, South Korea";" Department of Electrical Engineering, Korea Advanced Institute of Science and Technology, Taejon, South Korea"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""4"",""410"",""414"",""Ghose and Desai (1995) introduced a new interconnection for large-scale distributed memory multiprocessors called the Hierarchical Cubic Network (HCN). The HCN is topologically superior to a comparable hypercube. They also proposed optimal routing algorithms for the HCN and obtained its diameter, which is about three-fourths the diameter of a comparable hypercube. However, their routing algorithm is not distance-optimal. In this paper, we propose an optimal routing algorithm for the HCN and show that HCN has about two-thirds the diameter of a comparable hypercube."",""1558-2183"","""",""10.1109/71.667900"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=667900"","""",""Hypercubes";Routing;Clustering algorithms;Multiprocessor interconnection networks;Optimized production technology;Large-scale systems;Computer networks;"Concurrent computing"","""",""29"","""",""11"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;
"Competitive analysis of caching in distributed databases,""O. Wolfson";" Yixiu Huang"",""Electrical Engineering and Computer Science Department, University of Illinois, Chicago, IL, USA";" Electrical Engineering and Computer Science Department, University of Illinois, Chicago, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""4"",""391"",""409"",""This paper makes two contributions. First, we introduce a model for evaluating the performance of data allocation and replication algorithms in distributed databases. The model is comprehensive in the sense that it accounts for I/O cost, for communication cost, and, because of reliability considerations, for limits on the minimum number of copies of the object. The model captures existing replica-management algorithms, such as read-one-write-all, quorum-consensus, etc. These algorithms are static in the sense that, in the absence of failures, the copies of each object are allocated to a fixed set of processors. In modern distributed databases, particularly in mobile computing environments, processors will dynamically store objects in their local database and will relinquish them. Therefore, as a second contribution of this paper, we introduce an algorithm for automatic dynamic allocation of replicas to processors. Then, using the new model, we compare the performance of the traditional read-one-write-all static allocation algorithm to the performance of the dynamic allocation algorithm. As a result, we obtain the relationship between the communication cost and I/O cost for which static allocation is superior to dynamic allocation, and the relationships for which dynamic allocation is superior."",""1558-2183"","""",""10.1109/71.667899"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=667899"","""",""Distributed databases";Costs;Electrical capacitance tomography;Heuristic algorithms;Mobile computing;Distributed computing;Computer Society;Mobile communication;Wireless communication;"Availability"","""",""12"","""",""34"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Computing performance bounds of fork-join parallel programs under a multiprocessing environment,""J. C. S. Lui"; R. R. Muntz;" D. Towsley"",""Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong, China"; Computer Science Department, University of California, Los Angeles, Los Angeles, CA, USA;" Department of Computer Science, University of Massachusetts, Amherst, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""3"",""295"",""311"",""We study a multiprocessing computer system which accepts parallel programs that have a fork-join computational paradigm. The multiprocessing computer system under study is modeled as K homogeneous servers, each with an infinite capacity queue. Parallel programs arrive at the multiprocessing system according to a series-parallel phase type interarrival process with mean arrival rate of h. Upon the program arrival, it forks into K-independent tasks and each task is assigned to an unique server. Each task's service time has a k-stage Erlang distribution with mean service time of /spl lambda/. A parallel program is completed upon the completion of its last task. This kind of queuing model has no known closed form solution in the general (K/spl ges/2) case. In this paper, we show that by carefully modifying the arrival and service distributions at some imbedded points in time, we can obtain tight performance bounds. We also provide a computational efficient algorithm for obtaining upper and lower bounds on the expected response time. The methodology is flexible and allows one to trade-off the tightness of the bounds and computational cost."",""1558-2183"","""",""10.1109/71.674321"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=674321"","""",""Concurrent computing";Multiprocessing systems;Closed-form solution;Computational efficiency;Parallel programming;Computer vision;Ray tracing;Rendering (computer graphics);State-space methods;"Queueing analysis"","""",""34"","""",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Constant-time algorithms for constrained triangulations on reconfigurable meshes,""V. V. Bokka"; H. Gurla; S. Olariu;" J. L. Schwing"",""AT and T Research Laboratories, USA"; ADC Telecom, Sunnyvale, CA, USA; Department of Computer Science, Old Dominion University, VA, USA;" Central Washington University, Ellensburg, WA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""11"",""1057"",""1072"",""A number of applications in computer-aided manufacturing, CAD, and computer-aided geometric design ask for triangulating pieces of material with defects. These tasks are known collectively as constrained triangulations. Recently, a powerful architecture called the reconfigurable mesh has been proposed: In essence, a reconfigurable mesh consists of a mesh-connected architecture augmented by a dynamically reconfigurable bus system. The main contribution of this paper is to show that the flexibility of the reconfigurable mesh can be exploited for the purpose of obtaining constant-time algorithms for a number of constrained triangulation problems. These include triangulating a convex planar region containing any constant number of convex holes, triangulating a convex planar region in the presence of a collection of rectangular holes, and triangulating a set of ordered line segments. Specifically with a collection of O(n) such objects as input, our algorithms run in O(1) time on a reconfigurable mesh of size n/spl times/n. To the best of our knowledge, this is the first time constant time solutions to constrained triangulations are reported on this architecture."",""1558-2183"","""",""10.1109/71.735954"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=735954"","""",""Computer aided manufacturing";Robots;Design automation;Very large scale integration;Pattern recognition;Application software;Algorithm design and analysis;Automobile manufacture;Computational geometry;"Computer vision"","""",""1"",""2"",""55"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Critical path profiling of message passing and shared-memory programs,""J. K. Hollingsworth"",""Computer Science Department, University of Maryland, College Park, MD, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""10"",""1029"",""1040"",""We introduce a runtime, nontrace-based algorithm to compute the critical path profile of the execution of message passing and shared-memory parallel programs. Our algorithm permits starting or stopping the critical path computation during program execution and reporting intermediate values. We also present an online algorithm to compute a variant of critical path, called critical path zeroing, that measures the reduction in application execution time that improving a selected procedure will have. Finally, we present a brief case study to quantify the runtime overhead of our algorithm and to show that online critical path profiling can be used to find program bottlenecks."",""1558-2183"","""",""10.1109/71.730530"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=730530"","""",""Message passing";Runtime;Time measurement;Instruments;Computer Society;Concurrent computing;Distributed processing;"Monitoring"","""",""39"",""22"",""28"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;
"Cyclic-cubes: a new family of interconnection networks of even fixed-degrees,""Ada Wai-Chee Fu";" Siu-Cheung Chau"",""Department of Computer Science and Engineering, Chinese University of Hong Kong, Sha Tin, Hong Kong, China";" Department of Mathematics and Computer Science, University of Lethbridge, Lethbridge, AB, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""12"",""1253"",""1268"",""We introduce a new family of interconnection networks that are Cayley graphs with fixed degrees of any even number greater than or equal to four. We call the proposed graphs cyclic-cubes because contracting some cycles in such a graph results in a generalized hypercube. These Cayley graphs have optimal fault tolerance and logarithmic diameters. For comparable number of nodes, a cyclic-cube can have a diameter smaller than previously known fixed-degree networks. The proposed graphs can adopt an optimum routing algorithm known for one of its subfamilies of Cayley graphs. We also show that a graph in the new family has a Hamiltonian cycle and, hence, there is an embedding of a ring. Embedding of meshes and hypercubes are also discussed."",""1558-2183"","""",""10.1109/71.737700"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=737700"","""",""Multiprocessor interconnection networks";Hypercubes;Fault tolerance;"Routing"","""",""15"",""3"",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;
"Designing tree-based barrier synchronization on 2D mesh networks,""Jenq-Shyan Yang";" Chung-Ta King"",""Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan";" Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""6"",""526"",""534"",""In this paper, we consider a tree-based routing scheme for supporting barrier synchronization on scalable parallel computers with a 2D mesh network. Based on the characteristics of a standard programming interface, the scheme builds a collective synchronization (CS) tree among the participating nodes using a distributed algorithm. When the routers are set up properly with the CS tree information, barrier synchronization can be accomplished very efficiently by passing simple messages. Performance evaluations show that our proposed method performs better than previous path-based approaches and is less sensitive to variations in group size and startup delay. However, our scheme has the extra overhead of building the CS tree. Thus, it is more suitable for parallel iterative computations in which the same barrier is invoked repetitively."",""1558-2183"","""",""10.1109/71.689440"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=689440"","""",""Mesh networks";Routing;Concurrent computing;Hardware;System recovery;Multiprocessor interconnection networks;Message passing;Computer networks;Distributed algorithms;"Performance evaluation"","""",""16"","""",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Deterministic voting in distributed systems using error-correcting codes,""L. Xu";" J. Bruck"",""Electrical Engineering Department, California Institute of Technology, Pasadena, CA, USA";" Electrical Engineering Department, California Institute of Technology, Pasadena, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""8"",""813"",""824"",""Distributed voting is an important problem in reliable computing. In an N Modular Redundant (NMR) system, the N computational modules execute identical tasks and they need to periodically vote on their current states. In this paper, we propose a deterministic majority voting algorithm for NMR systems. Our voting algorithm uses error-correcting codes to drastically reduce the average case communication complexity. In particular, we show that the efficiency of our voting algorithm can be improved by choosing the parameters of the error-correcting code to match the probability of the computational faults. For example, consider an NMR system with 31 modules, each with a state of m bits, where each module has an independent computational error probability of 10/sup -3/. 1, this NMR system, our algorithm can reduce the average case communication complexity to approximately 1.0825 m compared with the communication complexity of 31 m of the naive algorithm in which every module broadcasts its local result to all other modules. We have also implemented the voting algorithm over a network of workstations. The experimental performance results match well the theoretical predictions."",""1558-2183"","""",""10.1109/71.706052"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=706052"","""",""Voting";Error correction codes;Complexity theory;Nuclear magnetic resonance;Broadcasting;Error probability;Workstations;Fault tolerant systems;Distributed computing;"Checkpointing"","""",""5"",""1"",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Diagnosability of the Mobius cubes,""Jianxi Fan"",""Department of Computer Science, Qingdao University of China, Qingdao, China"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""9"",""923"",""928"",""The recently introduced interconnection networks, the Mobius cubes, are hypercube variants that have some better properties than hypercubes. The n-dimensional Mobius cube M/sub n/ is a regular graph with 2/sup n/ nodes and n2/sup n-1/ edges. The diameter of M/sub n/ is about one half that of the n-dimensional hypercube Q/sub n/ and the average number of steps between nodes for M/sub n/ is about two-thirds of the average for Q/sub n/, and 1-M/sub n/ has dynamic performance superior to that of Q/sub n/. Of course, the symmetry of M/sub n/ is not superior to that of Q/sub n/, i.e., Q/sub n/ is both node symmetric and edge symmetric , whereas M/sub n/ is, in general, neither node symmetric (n/spl ges/4) nor edge symmetric (n/spl ges/3). In this paper, we study the diagnosability of M/sub n/. We use two diagnosis strategies, both based on the so-called PMC diagnostic model-the precise (one-step) diagnosis strategy proposed by Preparata et al. (1967) and the pessimistic diagnosis strategy proposed by Friedman (1975). We show that the diagnosability of M/sub n/ is the same as that of Q/sub n/, i.e., M/sub n/ is n-diagnosable under the precise diagnosis strategy and (2n-2)/(2n-2)-diagnosable under the pessimistic diagnosis strategy."",""1558-2183"","""",""10.1109/71.722224"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722224"","""",""Hypercubes";Multiprocessing systems;Automatic testing;System testing;Fault diagnosis;"Multiprocessor interconnection networks"","""",""109"","""",""14"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;
"Diskless checkpointing,""J. S. Plank"; Kai Li;" M. A. Puening"",""Department of Computer Science, University of Tennessee, Knoxville, USA"; Department of Computer Science, Princeton University, Princeton, NJ, USA;" Cardinal Solutions Group, Inc., Cincinnati, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""10"",""972"",""986"",""Diskless Checkpointing is a technique for checkpointing the state of a long-running computation on a distributed system without relying on stable storage. As such, it eliminates the performance bottleneck of traditional checkpointing on distributed systems. In this paper, we motivate diskless checkpointing and present the basic diskless checkpointing scheme along with several variants for improved performance. The performance of the basic scheme and its variants is evaluated on a high-performance network of workstations and compared to traditional disk-based checkpointing. We conclude that diskless checkpointing is a desirable alternative to disk-based checkpointing that can improve the performance of distributed applications in the face of failures."",""1558-2183"","""",""10.1109/71.730527"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=730527"","""",""Checkpointing";Computer Society;Workstations;Redundancy;Fault tolerance;Distributed computing;Error correction codes;Fault tolerant systems;Hardware;"Programming environments"","""",""221"",""4"",""39"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Efficient broadcast and multicast on multistage interconnection networks using multiport encoding,""R. Sivaram"; D. K. Panda;" C. B. Stunkel"",""IBM Power Parallel Systems, Poughkeepsie, NY, USA"; Department of Computer and Information Science, Dreese Laboratories, Ohio State Uinversity, Columbus, OH, USA;" IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""10"",""1004"",""1028"",""This paper proposes anew approach for implementing fast multicast and broadcast in unidirectional and bidirectional multistage interconnection networks (MINs) with multiport encoded multidestination worms. For a MIN with n stages, such worms use n header flits each. One flit is used for each stage of the network and it indicates the output ports to which a multicast message needs to be replicated. A multiport encoded worm with (d/sub 1/, d/sub 2/..., d/sub n/, 1/spl les/d/sub i//spl les/k) degrees of replication for the respective stages is capable of covering (d/sub 1//spl times/d/sub x//spl times/.../spl times/d/sub n/) destinations with a single communication start-up. In this paper, a switch architecture is proposed for implementing multidestination worms without deadlock. Three grouping algorithms of varying complexity are presented to derive the associated multiport encoded worms for a multicast to an arbitrary set of destinations. Using these worms, a multinomial tree-based scheme is proposed to implement the multicast. This scheme significantly reduces broadcast/multicast latency compared to schemes using unicast messages. Simulation studies for both unidirectional and bidirectional MIN systems indicate that improvement in broadcast/multicast latency up to a factor of four is feasible using the new approach. Interestingly, this approach is able to implement multicast with reduced latency as the number of destinations increases beyond a certain number. Compared to implementing unicast messages, this approach requires little additional logic at the switches. Thus, the scheme demonstrates significant potential for implementing efficient collective communication operations on current and future MIN-based systems."",""1558-2183"","""",""10.1109/71.730529"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=730529"","""",""Broadcasting";Multiprocessor interconnection networks;Encoding;Computer worms;Delay;Unicast;Communication switching;Switches;Hardware;"Message passing"","""",""27"",""1"",""37"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Efficient fault-tolerant multicast scheme for hypercube multicomputers,""Ge-Ming Chiu";" Kai-Shung Chen"",""The Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan";" Vanguard International Semiconductor Corporation, Hsinchu, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""10"",""952"",""962"",""This paper presents a fault-tolerant multicast scheme for hypercube multicomputers. The method is based on the routing capability information that is stored in each node. In comparison with the previous schemes, this information is able to capture the fault status more precisely. Two multicast algorithms are presented in the paper. These algorithms multicast messages in an attempt to minimize derouting so that time optimality can be achieved. Moreover, the routing capability information is used to guide derouting in an efficient manner when such needs arise. The amount of traffic incurred is addressed in the paper. The hardware design for the algorithms is also discussed. Extensive simulation has been conducted to evaluate the performance of the scheme. The results show the effectiveness of the proposed algorithms."",""1558-2183"","""",""10.1109/71.730525"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=730525"","""",""Fault tolerance";Hypercubes;Multicast algorithms;Routing;Algorithm design and analysis;Multicast communication;Communication switching;Computer Society;Traffic control;"Hardware"","""",""8"","""",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Efficient sparse LU factorization with partial pivoting on distributed memory architectures,""Cong Fu"; Xiangmin Jiao;" Tao Yang"",""Siemens Pyramid Information Systems, San Jose, CA, USA"; Department of Computer Science, University of Illinois, Urbana-Champaign, Urbana, IL, USA;" Department of Computer Science, University of California, Santa Barbara, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""2"",""109"",""125"",""A sparse LU factorization based on Gaussian elimination with partial pivoting (GEPP) is important to many scientific applications, but it is still an open problem to develop a high performance GEPP code on distributed memory machines. The main difficulty is that partial pivoting operations dynamically change computation and nonzero fill-in structures during the elimination process. This paper presents an approach called S* for parallelizing this problem on distributed memory machines. The S* approach adopts static symbolic factorization to avoid run-time control overhead, incorporates 2D L/U supemode partitioning and amalgamation strategies to improve caching performance, and exploits irregular task parallelism embedded in sparse LU using asynchronous computation scheduling. The paper discusses and compares the algorithms using 1D and 2D data mapping schemes, and presents experimental studies on Cray-T3D and T3E. The performance results for a set of nonsymmetric benchmark matrices are very encouraging, and S* has achieved up to 6.878 GFLOPS on 128 T3E nodes. To the best of our knowledge, this is the highest performance ever achieved for this challenging problem and the previous record was 2.583 GFLOPS on shared memory machines."",""1558-2183"","""",""10.1109/71.663864"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663864"","""",""Memory architecture";Sparse matrices;Parallel processing;Concurrent computing;Symmetric matrices;Numerical stability;Processor scheduling;Equations;Data structures;"Runtime"","""",""14"","""",""36"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Embedding torus on the star graph,""D. K. Saikia"; R. Badrinath;" R. K. Sen"",""Department of Computer Science, Tezpur University, Tezpur, India"; Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur, India;" Department of Computer Science, Rutgers University, Camden, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""7"",""650"",""663"",""In this paper, we present a scheme for efficient embedding of torus of any dimension on a star graph. The dilation of the embedding is four. The expansion is small. Congestion depends upon the routing scheme used. With one routing scheme, the congestion is bound by a small constant (/spl ap/2) with an increase in expansion cost. For a second routing scheme, the congestion is O(n), for an n-star, with bounded expansion."",""1558-2183"","""",""10.1109/71.707542"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=707542"","""",""Peer to peer computing";Routing;Multiprocessor interconnection networks;Costs;Parallel processing;Computational modeling;Concurrent computing;Buildings;Computer networks;"Hypercubes"","""",""8"","""",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Fast and processor efficient parallel matrix multiplication algorithms on a linear array with a reconfigurable pipelined bus system,""Keqin Li"; Yi Pan;" Si Qing Zheng"",""Department of Mathematics and Computer Science, State University of New York, New Paltz, NY, USA"; Department of Computer Science, University of Dayton, Dayton, OH, USA;" Department of Computer Science, Louisiana State University, Baton Rouge, LA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""8"",""705"",""720"",""We present efficient parallel matrix multiplication algorithms for linear arrays with reconfigurable pipelined bus systems (LARPBS). Such systems are able to support a large volume of parallel communication of various patterns in constant time. An LARPBS can also be reconfigured into many independent subsystems and, thus, is able to support parallel implementations of divide-and-conquer computations like Strassen's algorithm. The main contributions of the paper are as follows. We develop five matrix multiplication algorithms with varying degrees of parallelism on the LARPBS computing model";" namely, MM/sub 1/, MM/sub 2/, MM/sub 3/, and compound algorithms C/sub 1/(/spl epsiv/)and C/sub 2/(/spl delta/). Algorithm C/sub 1/(/spl epsiv/) has adjustable time complexity in sublinear level. Algorithm C/sub 2/(/spl delta/) implies that it is feasible to achieve sublogarithmic time using /spl sigma/(N/sup 3/) processors for matrix multiplication on a realistic system. Algorithms MM/sub 3/, C/sub 1/(/spl epsiv/), and C/sub 2/(/spl delta/) all have o(/spl Nscr//sup 3/) cost and, hence, are very processor efficient. Algorithms MM/sub 1/, MM/sub 3/, and C/sub 1/(/spl epsiv/) are general-purpose matrix multiplication algorithms, where the array elements are in any ring. Algorithms MM/sub 2/ and C/sub 2/(/spl delta/) are applicable to array elements that are integers of bounded magnitude, or floating-point values of bounded precision and magnitude, or Boolean values. Extension of algorithms MM/sub 2/ and C/sub 2/(/spl delta/) to unbounded integers and reals are also discussed."",""1558-2183"","""",""10.1109/71.706044"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=706044"","""",""Costs";Concurrent computing;Optical arrays;Parallel algorithms;Parallel processing;Power engineering and energy;Eigenvalues and eigenfunctions;Polynomials;Graph theory;"Tree graphs"","""",""64"",""1"",""50"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Fast compaction in hypercubes,""Nian-Feng Tzeng";" Hsing-Lung Chen"",""Center for Advanced Computer Studies, University of Southwestern Louisiana, Lafayette, LA, USA";" Department of Electronic Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""1"",""50"",""56"",""Compaction relocates active subcubes in a fragmented hypercube so as to produce a contiguous free region and eliminate the adverse impact of fragmentation on performance. The overhead of compaction is often contributed primarily by task migration, which makes use of disjoint paths for transmitting migrated data. Since task migration usually involves transmitting a large amount of data, the time required for migration with single paths is long, making compaction an undesirably lengthy process. This paper considers fast compaction through the use of all disjoint paths in existence for migration simultaneously from a source subcube to its target subcube, effectively reducing the size of data transmitted over a path and shortening the migration time. This approach leads to considerable savings in the compaction time for hypercubes which support circuit switching or wormhole routing, when compared with that using single migration paths."",""1558-2183"","""",""10.1109/71.655243"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=655243"","""",""Compaction";Hypercubes;Costs;Switching circuits;Routing;Scattering;Delay;Timing;Real time systems;"Resumes"","""",""10"","""",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Fault diagnosis in a Benes interconnection network,""S. Das";" A. Chaudhuri"",""Department of Computer Science and Technology, Bengal Engineering College슠(Deemed University), Howrah, India";" Department of Computer Science and Engineering, Jadavpur University, Calcutta, India"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""7"",""700"",""703"",""Benes network, being a back-to-back connection of two Baseline networks, the method for fault diagnosis for the class of nonredundant networks, as elucidated in our previous work, can be directly mapped on the two nonredundant networks. The individual results from these two networks can be combined to construct a comprehensive algorithm for the Benes network to diagnose single fault."",""1558-2183"","""",""10.1109/71.707550"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=707550"","""",""Fault diagnosis";Intelligent networks;Multiprocessor interconnection networks;Fault detection;"Joining processes"","""",""1"","""",""7"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;
"Fault-tolerant real-time communication in distributed computing systems,""Qin Zheng";" K. G. Shin"",""Argon Networks, Littleton, MA, USA";" Real-Time Computing Laboratory, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""5"",""470"",""480"",""The delivery delay in a point-to-point packet switching network is difficult to control due to the contention among randomly-arriving packets at each node and multihops a packet must travel between its source and destination. Despite this difficulty, there are an increasing number of applications that require packets to be delivered reliably within prespecified delay bounds. This paper shows how this can be achieved by using real-time channels which make """"soft"""" reservation of network resources to ensure the timely delivery of real-time packets. We first present theoretical results and detailed procedures for the establishment of real-time channels and then show how the basic real-time channels can be enhanced to be fault-tolerant using the multiple disjoint paths between a pair of communicating nodes. The contribution of the former is a tighter schedulability condition which makes more efficient use of network resources than any other existing approaches, and that of the latter is a significant improvement in fault tolerance over the basic real-time channel, which is inherently susceptible to component failures."",""1558-2183"","""",""10.1109/71.679217"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=679217"","""",""Fault tolerant systems";Real time systems;Distributed computing;Circuits;Processor scheduling;Bandwidth;Fault tolerance;Packet switching;Delay;"Intelligent networks"","""",""10"","""",""13"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Finding a k-tree core and a k-tree center of a tree network in parallel,""Biing-Feng Wang"",""Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""2"",""186"",""191"",""A k-tree core of a tree network is a subtree with exactly k leaves that minimizes the total distance from vertices to the subtree. A k-tree center of a tree network is a subtree with exactly k leaves that minimizes the distance from the farthest vertex to the subtree. In this paper, two efficient parallel algorithms are proposed for finding a k-tree core and a k-tree center of a tree network, respectively. Both the proposed algorithms perform on the EREW PRAM in O(log n log n) time using O(n) work (time-processor product). Besides being efficient on the EREW PRAM, in the sequential case, our algorithm for finding a k-tree core of a tree network improves the two algorithms previously proposed."",""1558-2183"","""",""10.1109/71.663884"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663884"","""",""Intelligent networks";Phase change random access memory;Parallel algorithms;"Joining processes"","""",""14"","""",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;
"Gossiping on meshes and tori,""B. H. H. Juurlink"; J. F. Sibeyn;" P. S. Rao"",""Heinz Nixdorf Institute, Paderborn University, Paderborn, Germany"; Max Planck Institut für Informatik, Saarbruecken, Germany;" Dow Jones Markets"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""6"",""513"",""525"",""Algorithms for performing gossiping on one- and higher-dimensional meshes are presented. As a routing model, the practically important wormhole routing is assumed. We especially focus on the trade-off between the start-up time and the transmission time. For one-dimensional arrays and rings, we give a novel lower bound and an asymptotically optimal gossiping algorithm for all choices of the parameters involved. For two-dimensional meshes and tori, a simple algorithm composed of one-dimensional phases is presented. For an important range of packet and mesh sizes, it gives clear improvements upon previously developed algorithms. The algorithm is analyzed theoretically and the achieved improvements are also convincingly demonstrated by simulations, as well as an implementation on the Paragon. On the Paragon, our algorithm even outperforms the gossiping routine provided in the NX message-passing library. For higher-dimensional meshes, we give algorithms which are based on an interesting generalization of the notion of a diagonal. These algorithms are analyzed theoretically, as well as by simulation."",""1558-2183"","""",""10.1109/71.689439"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=689439"","""",""Routing";Algorithm design and analysis;Analytical models;Concurrent computing;Costs;Computer Society;Libraries;Computational modeling;Global communication;"Mesh networks"","""",""18"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Hyper-systolic parallel computing,""T. Lippert"; A. Seyfried; A. Bode;" K. Schilling"",""HLRZ, Julich, Germany"; Department of Physics, University of Wuppertal, Wuppertal, Germany; Department of Physics, Humboldt University of Berlin, Berlin, Germany;" HLRZ, Julich, Germany"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""2"",""97"",""108"",""We introduce a new class of parallel algorithms for the exact computation of systems with pairwise mutual interactions of n elements, so called n/sup 2/-problems. Hitherto, practical conventional parallelization strategies could achieve a complexity of O(np) with respect to the inter-processor communication, p being the number of processors. Our new approach can reduce the inter-processor communication complexity to a number O(np). In the framework of Additive Number Theory, the determination of the optimal communication pattern can be formulated as h-range minimization problem that can be solved numerically. Based on a complexity model, the scaling behavior of the new algorithm is numerically tested on the connection machine CM5. As a real life example, we have implemented a fast code for globular cluster n-body simulations, a generic n/sup 2/-problem, on the CRAY T3D, with striking success. Our parallel method promises to be useful in various scientific and engineering fields like polymer chain computations, protein folding, signal processing, and, in particular, for parallel level-3 BLAS."",""1558-2183"","""",""10.1109/71.663861"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663861"","""",""Parallel processing";Concurrent computing;Parallel algorithms;Complexity theory;Clustering algorithms;Signal processing algorithms;Testing;Computational modeling;Polymers;"Protein engineering"","""",""9"","""",""29"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Improved compressions of cube-connected cycles networks,""R. Klasing"",""Department of Computer Science, University of Warwick, Coventry, UK"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""8"",""803"",""812"",""We present a new technique for the embedding of large cube-connected cycles networks (CCC) into smaller ones, a problem that arises when algorithms designed for an architecture of an ideal size are to be executed on an existing architecture of a fixed size. Using the new embedding strategy, we show that the CCC of dimension I can be embedded into the CCC of dimension k with dilation 1 and optimum load for any k, l/spl isin/ N, k/spl ges/8, such 5/3+c/sub k/<1/k/spl les/2, c/sub k/=3.2(2/3k)/4k+3, thus improving known results. Our embedding technique also leads to improved dilation-1 embeddings in the case 3/2<1/k/spl les/5/3+C/sub k/."",""1558-2183"","""",""10.1109/71.706051"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=706051"","""",""Algorithm design and analysis";Parallel architectures;Multiprocessor interconnection networks;Computational modeling;Parallel algorithms;Hypercubes;Computer networks;Concurrent computing;Embedded computing;"Computer simulation"","""",""4"","""",""30"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;
"Interprocedural partial redundancy elimination with application to distributed memory compilation,""G. Agrawal"",""Department of Computer and Information Sciences, University of Delaware, Newark, DE, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""7"",""609"",""625"",""Partial Redundancy Elimination (PRE) is a general scheme for suppressing partial redundancies which encompasses traditional optimizations like loop invariant code motion and redundant code elimination. In this paper, we address the problem of performing this optimization interprocedurally. We present an Interprocedural Partial Redundancy Elimination (IPRE) scheme based upon a new, concise, full program representation. Our method is applicable to arbitrary recursive programs. We use interprocedural partial redundancy elimination for placement of communication and communication preprocessing statements while compiling for distributed memory parallel machines. We have implemented our scheme as an extension to the Fortran D compilation system. We present experimental results from two codes compiled using our system to demonstrate the useful of IPRE in distributed memory compilation."",""1558-2183"","""",""10.1109/71.707537"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=707537"","""",""Runtime";Optimizing compilers;Data analysis;Parallel machines;Flow graphs;Performance analysis;Communication system control;Pattern recognition;"Safety"","""",""4"",""2"",""39"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;
"Job scheduling in mesh multicomputers,""D. Das Sharma";" D. K. Pradhan"",""Systems Technology Division, Hewlett Packard Company, Cupertino, CA, USA";" Department of Computer Science, Texas A and M University, College Station, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""1"",""57"",""70"",""A new approach for dynamic job scheduling in mesh-connected multiprocessor systems, which supports a multiuser environment, is proposed in this paper. Our approach combines a submesh reservation policy with a priority-based scheduling policy to obtain high performance in terms of high throughput, high utilization, and low turn-around times for jobs. This high performance is achieved at the expense of scheduling jobs in a strictly fair, FCFS fashion";" in fact, the algorithm is parameterized to allow trade-offs between performance and (short-term) POPS fairness. The proposed scheduler can be used with any submesh allocation policy. A fast and efficient implementation of the proposed scheduler has also been presented. The performance of the proposed scheme has been compared with the FCFS policy, the only existing scheduling strategy for meshes, to demonstrate the effectiveness of the proposed approach. Simulation results indicate that our scheduling strategy outperforms the FCFS policy significantly. Specifically, our strategy significantly reduces the average waiting delay of jobs over the FCFS policy. The fast implementation of the proposed scheduler results in low allocation and deallocation time overhead, as well as low space overhead."",""1558-2183"","""",""10.1109/71.655244"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=655244"","""",""Processor scheduling";Delay;Dynamic scheduling;Multiprocessing systems;Throughput;Scheduling algorithm;Operating systems;Resource management;Fault tolerance;"Scalability"","""",""19"",""2"",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Low expansion packings and embeddings of hypercubes into star graphs: a performance-oriented approach,""M. Moraes de Azevedo"; N. Bagherzadeh;" S. Latifi"",""NonStop System Software Division, Parallele Systems Group, Tandem Computers, Inc.orporated, Cupertino, CA, USA"; Department of Electrical and Computer Engineering, University of California, Irvine, CA, USA;" Department of Electrical and Computer Engineering, University of Nevada, Las Vegas, NV, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""3"",""261"",""274"",""We discuss the problem of packing hypercubes into an n-dimensional star graph S(n), which consists of embedding a disjoint union of hypercubes U into S(n) with load one. Hypercubes in U have from [n/2] to (n+1)/spl middot/[log/sub 2/ n]-2([lod/sub 2/n]+1)+2 dimensions, i.e., they can be as large as any hypercube which can be embedded with dilation at most four into S(n). We show that U can be embedded into S(n) with optimal expansion, which contrasts with the growing expansion ratios of previously known techniques. We employ several performance metrics to show that, with our techniques, a star graph can efficiently execute heterogeneous workloads containing hypercube, mesh, and star graph algorithms. The characterization of our packings includes some important metrics which have not been addressed by previous research (namely, average dilation, average congestion, and congestion). Our packings consistently produce small average congestion and average dilation, which indicates that the induced communication slowdown is also small. We consider several combinations of node mapping functions and routing algorithms in S(n), and obtain their corresponding performance metrics using either mathematical analysis or computer simulation."",""1558-2183"","""",""10.1109/71.674318"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=674318"","""",""Hypercubes";Concurrent computing;Multiprocessor interconnection networks;Computer networks;Embedded computing;Measurement;Routing;Application software;Pervasive computing;"Distributed computing"","""",""6"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Macro-star networks: efficient low-degree alternatives to star graphs,""Chi-Hsiang Yeh";" E. A. Varvarigos"",""Department of Electrical and Computer Engineering, University of California, Santa Barbara, CA, USA";" Department of Electrical and Computer Engineering, University of California, Santa Barbara, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""10"",""987"",""1003"",""We propose a new class of interconnection networks, called macro-star networks, which belong to the class of Cayley graphs and use the star graph as a basic building module. A macro-star network can have node degree that is considerably smaller than that of a star graph of the same size, and diameter that is sublogarithmic and asymptotically within a factor of 1.25 from a universal lower bound (given its node degree). We show that algorithms developed for star graphs can be emulated on suitably constructed macro-stars with asymptotically optimal slowdown. This enables us to obtain through emulation a variety of efficient algorithms for the macro-star network, thus proving its versatility. Basic communication tasks, such as the multimode broadcast and the total exchange, can be executed in macro-star networks in asymptotically optimal time under both the single-port and the all-port communication models. Moreover, no interconnection network with similar node degree can perform these communication tasks in time that is better by more than a constant factor than that required in a macro-star network. We show that macro-star networks can embed trees, meshes, hypercubes, as well as star, bubble-sort, and complete transposition graphs with constant dilation. We introduce several variants of the macro-star network that provide more flexibility in scaling up the number of nodes. We also discuss implementation issues and compare the new topology with the star graph and other popular topologies."",""1558-2183"","""",""10.1109/71.730528"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=730528"","""",""Hypercubes";Network topology;Emulation;Multiprocessor interconnection networks;Broadcasting;Tree graphs;Parallel architectures;Routing;Algorithm design and analysis;"Parallel processing"","""",""27"","""",""53"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Managing statistical behavior of large data sets in shared-nothing architectures,""I. Rigoutsos";" A. Delis"",""Bioinformatics and Pattern Discovery Group, T.J. Watson Research Center, IBM, Yorktown Heights, NY, USA";" Department of Computer and Information Science, Polytechnic University, Brooklyn, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""11"",""1073"",""1087"",""Increasingly larger data sets are being stored in networked architectures. Many of the available data structures are not easily amenable to parallel realizations. Hashing schemes show promise in that respect for the simple reason that the underlying data structure can be decomposed and spread among the set of cooperating nodes with minimal communication and maintenance requirements. In all cases, storage utilization and load balancing are issues that need to be addressed. One can identify two basic approaches to tackle the problem. One way is to address it as part of the design of the data structure that is used to store and retrieve the data. The other is to maintain the data structure intact but address the problem separately. The method that we present here falls in the latter category and is applicable whenever a hash table is the preferred data structure. Intrinsically attached to the used hash table is a hashing function that allows one to partition a possibly unbounded set of data items into a finite set of groups";" the hashing function provides the partitioning by assigning each data item to one of the groups. In general, the hashing function cannot guarantee that the various groups will have the same cardinality on average, for all possible data item distributions. In this paper, we propose a two-stage methodology that uses the knowledge of the hashing function to reorganize the group assignments so that the resulting groups have similar expected cardinalities. The method is generally applicable and independent of the used hashing function. We show the power of the methodology using both synthetic and real-world databases. The derived quasi-uniform storage occupancy and associated load-balancing gains are significant."",""1558-2183"","""",""10.1109/71.735955"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=735955"","""",""Data structures";Load management;Databases;Intelligent networks;Information retrieval;Workstations;Educational institutions;"Quantization"","""",""1"",""1"",""49"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"Minimization of communication cost through caching in mobile environments,""A. Prasad Sistla"; O. Wolfson;" Yixiu Huang"",""Electrical Engineering and Computer Science Department, University of Illinois, Chicago, IL, USA"; Electrical Engineering and Computer Science Department, University of Illinois, Chicago, IL, USA;" Electrical Engineering and Computer Science Department, University of Illinois, Chicago, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""4"",""378"",""390"",""Users of mobile computers will soon have online access to a large number of databases via wireless networks. Because of limited bandwidth, wireless communication is more expensive than wire communication. In this paper, we present and analyze various static and dynamic data allocation methods. The objective is to optimize the communication cost between a mobile computer and the stationary computer that stores the online database. Analysis is performed in two cost models. One is connection (or time) based, as in cellular telephones, where the user is charged per minute of connection. The other is message based, as in packet radio networks, where the user is charged per message. Our analysis addresses both the average case and the worst case for determining the best allocation method."",""1558-2183"","""",""10.1109/71.667898"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=667898"","""",""Mobile communication";Mobile computing;Databases;Computer networks;Wireless networks;Bandwidth;Wireless communication;Wire;Cost function;"Data analysis"","""",""25"",""1"",""38"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Modeled and measured instruction fetching performance for superscalar microprocessors,""S. Wallace";" N. Bagherzadeh"",""Department of Electrical and Computer Engineering, University of California, Irvine, Irvine, CA, USA";" Department of Electrical and Computer Engineering, University of California, Irvine, Irvine, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""6"",""570"",""578"",""Instruction fetching is critical to the performance of a superscalar microprocessor. We develop a mathematical model for three different cache techniques and evaluate its performance both in theory and in simulation using the SPEC95 suite of benchmarks. In all the techniques, the fetching performance is dramatically lower than ideal expectations. To help remedy the situation, we also evaluate its performance using prefetching. Nevertheless, fetching performance is fundamentally limited by control transfers. To solve this problem, we introduce a new fetching mechanism called a dual branch target buffer. The dual branch target buffer enables fetching performance to leap beyond the limitation imposed by conventional methods and achieve a high instruction fetching rate."",""1558-2183"","""",""10.1109/71.689444"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=689444"","""",""Microprocessors";Hardware;Prefetching;Decoding;Software performance;Mathematical model;Performance analysis;Concurrent computing;"Pipelines"","""",""20"",""6"",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"Multistep interactive convergence: an efficient approach to the fault-tolerant clock synchronization of large multicomputers,""M. M. de Azevedo";" D. M. Blough"",""Tandem Division, Compaq Computer Corporation, Cupertino, CA, USA";" Department of Electrical and Computer Engineering, University of California, Irvine, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""12"",""1195"",""1212"",""We present a new approach for fault-tolerant internal clock synchronization in multicomputer systems employing not completely connected networks (NCCNs). The approach is referred to as multistep interactive convergence and is locally implemented in each multicomputer node by a time server process (TSP). We describe a specific algorithm that uses multistep interactive convergence and bases its operation on a logical mapping of the system's TSPs into an m-dimensional array. A TSP executes m steps per round of synchronization, with each step including a call to an interactive convergence procedure. For any TSP, clock readings in step i are gathered only from TSPs with which it shares a row along dimension i of the array. Hence, a TSP reads clocks only from a small subset of the TSPs in the system, which reduces the number of messages by orders of magnitude over a conventional interactive convergence algorithm in which reliable all-to-all broadcast of clock values is done. The algorithm can be used in systems of arbitrary topology and provides the added benefit of increased locality of communication in regular NCCNs such as hypercubes and tori. These advantages can be combined with a variety of message staggering mechanisms to maintain network contention at a minimum. We present expressions for the maximum clock skew, maximum clock drift, maximum clock discontinuity, and number of messages produced by the algorithm, and show that it tolerates arbitrary faults. A comparison with other algorithms that elucidates the advantages of multistep interactive convergence is also provided."",""1558-2183"","""",""10.1109/71.737696"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=737696"","""",""Convergence";Clocks;Synchronization;Fault tolerant systems;Network servers;Logic arrays;Telecommunication network reliability;Broadcasting;Network topology;"Hypercubes"","""",""12"","""",""43"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Nonlinear and symbolic data dependence testing,""W. Blume";" R. Eigenmann"",""Hewlett Packard Company, Cupertino, CA, USA";" School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""12"",""1180"",""1194"",""One of the most crucial qualities of an optimizing compiler is its ability to detect when different data references access the same storage location. Such references are said to be data-dependent and they impose constraints on the amount of program modifications the compiler can apply for improving the program's performance. For parallelizing compilers, the most important program constructs to investigate are loops and the array references they contain. In previous work, we have found a serious limitation of current data dependence tests to be that they cannot handle loop bounds or array subscripts that are symbolic, nonlinear expressions. In this paper, we describe a dependence test, called the range test, that can handle such expressions. Briefly, the range test proves independence by determining whether certain symbolic inequalities hold for a permutation of the loop nest. Powerful symbolic analyses and constraint propagation techniques were developed to prove such inequalities. The range test has been implemented in Polaris, a parallelizing compiler developed at the University of Illinois. We present measurements of the range test's performance and compare it with state-of-the-art tests."",""1558-2183"","""",""10.1109/71.737695"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=737695"","""",""Testing";Optimizing compilers;Program processors;Sequential analysis;Performance evaluation;Computer Society;Polarization;Parallel machines;Data analysis;"Performance analysis"","""",""38"",""3"",""33"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"On coordinated checkpointing in distributed systems,""Guohong Cao";" M. Singhal"",""Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA";" Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""12"",""1213"",""1225"",""Coordinated checkpointing simplifies failure recovery and eliminates domino effects in case of failures by preserving a consistent global checkpoint on stable storage. However, the approach suffers from high overhead associated with the checkpointing process. Two approaches are used to reduce the overhead: first is to minimize the number of synchronization messages and the number of checkpoints, the other is to make the checkpointing process nonblocking. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm combined them. In other words, the Prakash-Singhal algorithm forces only a minimum number of processes to take checkpoints and it does not block the underlying computation. However, we found two problems in this algorithm. In this paper, we identify these problems and prove a more general result: there does not exist a nonblocking algorithm that forces only a minimum number of processes to take their checkpoints. Based on this general result, we propose an efficient algorithm that neither forces all processes to take checkpoints nor blocks the underlying computation during checkpointing. Also, we point out future research directions in designing coordinated checkpointing algorithms for distributed computing systems."",""1558-2183"","""",""10.1109/71.737697"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=737697"","""",""Checkpointing";Algorithm design and analysis;Distributed computing;Fault tolerant systems;Programming profession;Degradation;System performance;"Process control"","""",""75"","""",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;
"On exploiting task duplication in parallel program scheduling,""Ishfaq Ahmad";" Yu-Kwong Kwok"",""Department of Computer Science, Hong Kong University of Science and Technology, Hong Kong, China";" Department of Electrical and Electronic Engineering, University of Hong Kong, Hong Kong, China"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""9"",""872"",""892"",""One of the main obstacles in obtaining high performance from message-passing multicomputer systems is the inevitable communication overhead which is incurred when tasks executing on different processors exchange data. Given a task graph, duplication-based scheduling can mitigate this overhead by allocating some of the tasks redundantly on more than one processor. In this paper, we focus on the problem of using duplication in static scheduling of task graphs on parallel and distributed systems. We discuss five previously proposed algorithms and examine their merits and demerits. We describe some of the essential principles for exploiting duplication in a more useful manner and, based on these principles, propose an algorithm which outperforms the previous algorithms. The proposed algorithm generates optimal solutions for a number of task graphs. The algorithm assumes an unbounded number of processors. For scheduling on a bounded number of processors, we propose a second algorithm which controls the degree of duplication according to the number of available processors. The proposed algorithms are analytically and experimentally evaluated and are also compared with the previous algorithms."",""1558-2183"","""",""10.1109/71.722221"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722221"","""",""Processor scheduling";Costs;Scheduling algorithm;Computational efficiency;Algorithm design and analysis;Workstations;Delay;Bandwidth;Timing;"Concurrent computing"","""",""215"","""",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"On submesh allocation for mesh multicomputers: a best-fit allocation and a virtual submesh allocation for faulty meshes,""Geunmo Kim";" Hyunsoo Yoon"",""Department of Computer Science, Korea Advanced, Institute of Science and Technology, Taejon, South Korea";" Department of Computer Science, Korea Advanced, Institute of Science and Technology, Taejon, South Korea"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""2"",""175"",""185"",""The submesh allocation problem is to recognize and locate a free submesh that can accommodate a request for a submesh of a specified size. In this paper, we propose a new best-fit submesh allocation strategy for mesh-connected multiprocessor systems. The proposed strategy maintains and uses a free submesh list for an efficient allocation. For an allocation request, the strategy selects the best-fit submesh which causes the least amount of potential processor fragmentation. As many large free submeshes as possible are preserved for later allocations. For this purpose, we introduce a novel function quantifying the degree of potential fragmentation of submeshes. The proposed strategy has the capability of recognizing a complete submesh. We also propose an allocation strategy for faulty meshes which can maintain and allocate virtual submeshes derived from faulty submeshes. Extensive simulation is carried out to compare the proposed strategy with previous strategies. The proposed strategy has the best performance: a 6-50 percent improvement over the previous best strategy."",""1558-2183"","""",""10.1109/71.663881"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663881"","""",""Multitasking";Computer Society;Topology;Multiprocessing systems;Computer architecture;Concurrent computing;Prototypes;Character recognition;"Computer science"","""",""32"",""20"",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"On supernode transformation with minimized total running time,""E. Hodzic";" Weijia Shang"",""AT and T Laboratories, San jose, CA, USA";" Department of Computer Engineering, Santa Clara University, Santa Clara, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""5"",""417"",""428"",""With the objective of minimizing the total execution time of a parallel program on a distributed memory parallel computer, this paper discusses how to find an optimal supernode size and optimal supernode relative side lengths of a supernode transformation (also known as tiling). We identify three parameters of supernode transformation: supernode size, relative side lengths, and cutting hyperplane directions. For algorithms with perfectly nested loops and uniform dependencies, for sufficiently large supernodes and number of processors, and for the case where multiple supernodes are mapped to a single processor, we give an order n polynomial whose real positive roots include the optimal supernode size. For two special cases, 1) two-dimensional algorithm problems and 2) n-dimensional algorithm problems, where the communication cost is dominated by the startup penalty and, therefore, can be approximated by a constant, we give a closed form expression for the optimal supernode size, which is independent of the supernode relative side lengths and cutting hyperplanes. For the case where the algorithm iteration index space and the supernodes are hyperrectangular, we give closed form expressions for the optimal supernode relative side lengths. Our experiment shows a good match of the closed form expressions with experimental data."",""1558-2183"","""",""10.1109/71.679213"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=679213"","""",""Concurrent computing";Distributed computing;Polynomials;Cost function;Partitioning algorithms;"Delay effects"","""",""30"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;
"On the automatic parallelization of the Perfect Benchmarks(R),""R. Eigenmann"; J. Hoeflinger;" D. Padua"",""School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA"; Department of Computer Science, University of Illinois, Urbana, IL, USA;" Department of Computer Science, University of Illinois, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""1"",""5"",""23"",""This paper presents the results of the Cedar Hand-Parallelization Experiment conducted from 1989 through 1992, within the Center for Supercomputing Research and Development (CSRD) at the University of Illinois. In this experiment, we manually transformed the Perfect Benchmarks(R) into parallel program versions. In doing so, we used techniques that may be automated in an optimizing compiler. We then ran these programs on the Cedar multiprocessor (built at CSRD during the 1980s) and measured the speed improvement due to each technique. The results presented here extend the findings previously reported. The techniques credited most for the performance gains include array privatization, parallelization of reduction operations, and the substitution of generalized induction variables. All these techniques can be considered extensions of transformations that were available in vectorizers and commercial restructuring compilers of the late 1980s. We applied these transformations by hand to the given programs, in a mechanical manner, similar to that of a parallelizing compiler. Because of our success with these transformations, we believed that it would be possible to implement many of these techniques in a new parallelizing compiler. Such a compiler has been completed in the meantime and we show preliminary results."",""1558-2183"","""",""10.1109/71.655238"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=655238"","""",""Optimizing compilers";Program processors;Programming profession;Research and development;Velocity measurement;Polarization;Parallel machines;Radio access networks;Performance gain;"Privatization"","""",""56"",""2"",""37"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Optimal parallel algorithms for finding proximate points, with applications,""T. Hayashi"; K. Nakano;" S. Olariu"",""Department of Electrical and Computer Engineering, Nagoya Institute of Technology, Nagoya, Japan"; Department of Electrical and Computer Engineering, Nagoya Institute of Technology, Nagoya, Japan;" Department of Computer Science, Old Dominion University, Norfolk, VA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""12"",""1153"",""1166"",""Consider a set P of points in the plane sorted by the x-coordinate. A point p in P is said to be a proximate point if there exists a point q on the x-axis such that p is the closest point to q over all points in P. The proximate point problem is to determine all the proximate points in P. Our main contribution is to propose optimal parallel algorithms for solving instances of size n of the proximate points problem. We begin by developing a work-time optimal algorithm running in O(log log n) time and using n/loglogn Common-CRCW processors. We then go on to show that this algorithm can be implemented to run in O(log n) time using n/logn EREW processors. In addition to being work-time optimal, our EREW algorithm turns out to also be time-optimal. Our second main contribution is to show that the proximate points problem finds interesting, and quite unexpected, applications to digital geometry and image processing. As a first application, we present a work-time optimal parallel algorithm for finding the convex hull of a set of n points in the plane sorted by x-coordinate";" this algorithm runs in O(log log n) time using n/logn Common-CRCW processors. We then show that this algorithm can be implemented to run in O(log n) time using n/logn EREW processors. Next, we show that the proximate points algorithms afford us work-time optimal (resp, time-optimal) parallel algorithms for various fundamental digital geometry and image processing problems."",""1558-2183"","""",""10.1109/71.737693"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=737693"","""",""Parallel algorithms";Geometry;Application software;Image processing;Phase change random access memory;Computer Society;Euclidean distance;Image analysis;Pattern recognition;"Performance evaluation"","""",""20"","""",""31"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Optimal scheduling algorithm for distributed-memory machines,""S. Darbha";" D. P. Agrawal"",""Department of Electrical and Computer Engineering, Rutgers University, Piscataway, NJ, USA";" Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""1"",""87"",""95"",""Task Scheduling is one of the key elements in any distributed-memory machine (DMM), and an efficient algorithm can help reduce the interprocessor communication time. As optimal scheduling of tasks to DMMs is a strong NP-hard problem, many heuristic algorithms have been introduced in the literature. This paper presents a Task Duplication based Scheduling (TDS) algorithm which can schedule directed acyclic graphs (DAGs) with a complexity of O(|V|/sup 2/), where |V| is the number of tasks in the DAG. This algorithm generates an optimal schedule for a class of DAGs which satisfy a simple cost relationship. The performance of the algorithm has been observed by its application to some practical DAGs, and by comparing it with other existing scheduling schemes in terms of the schedule length and algorithm complexity."",""1558-2183"","""",""10.1109/71.655248"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=655248"","""",""Optimal scheduling";Scheduling algorithm;Processor scheduling;Polynomials;Computational efficiency;NP-hard problem;Heuristic algorithms;Cost function;Very large scale integration;"Communications technology"","""",""142"","""",""19"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Optimized broadcasting and multicasting protocols in cut-through routed networks,""J. Cohen"; P. Fraigniaud; J. Konig;" A. Raspaud"",""Laboratoire de Recherches en Informatique, Université Paris Sud, Orsay, France"; Laboratoire de Recherches en Informatique, Université Paris Sud, Orsay, France; Département d'Informatique, Université d'Evry, Evry, France;" Laboratoire Bordelais de Recherche en Informatique, Université de Bordeaux 1, Talence, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""8"",""788"",""802"",""This paper addresses the one-to-all broadcasting problem and the one-to-many broadcasting problem, usually simply called broadcasting and multicasting, respectively. Broadcasting is the information dissemination problem in which a node of a network sends the same piece of information to all the other nodes. Multicasting is a partial broadcasting in the sense that only a subset of nodes forms the destination set. Both operations have many applications in parallel and distributed computing. In this paper, we study these problems in both line model, and cut-through model. The former assumes long distance calls between nonneighboring processors. The latter strengthens the line model by taking into account the use of a routing function. Long distance calls are possible in circuit-switched and wormhole-routed networks, and also in many networks supporting optical facilities. In the line model, it is well known that one can compute in polynomial time a [log/sub 2/n]-round broadcast or multicast protocol for any arbitrary network. Unfortunately such a protocol is often inefficient from a practical point of view because it does not use the resources of the network in a balanced way. In this paper, we present a new algorithm to compute broadcast or multicast protocols. This algorithm applies under both line and cut-through models. Moreover, it returns protocols that efficiently use the bandwidth of the network. From a complexity point of view, we also show that most of the optimization problems relative to the maximization of the efficiency of broadcast or multicast protocols in terms of switching time or vertex load are NP-complete. We have, however, derived polynomial efficient solutions for tree-networks."",""1558-2183"","""",""10.1109/71.706050"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=706050"","""",""Broadcasting";Multicast protocols;Polynomials;Multicast algorithms;Distributed computing;Routing;Circuits;Optical fiber networks;Optical sensors;"Computer networks"","""",""9"","""",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Optimizing computing costs using divisible load analysis,""Jeeho Sohn"; T. G. Robertazzi;" S. Luryi"",""AT and T, Middletown, NJ, USA"; Department of Electrical Engineering, State University of New York, Stony Brook, Stony Brook, NY, USA;" Department of Electrical Engineering, State University of New York, Stony Brook, Stony Brook, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""3"",""225"",""234"",""A bus oriented network where there is a charge for the amount of divisible load processed on each processor is investigated. A cost optimal processor sequencing result is found which involves assigning load to processors in nondecreasing order of the cost per load characteristic of each processor. More generally, one can trade cost against solution time. Algorithms are presented to minimize computing cost with an upper bound on solution time and to minimize solution time with an upper bound on cost. As an example of the use of this type of analysis, the effect of replacing one fast but expensive processor with a number of cheap but slow processors is also discussed. The type of questions investigated here are important for future computer utilities that perform distributed computation for some charge."",""1558-2183"","""",""10.1109/71.674315"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=674315"","""",""Cost function";Distributed computing;Computer networks;Telecommunication computing;Upper bound;Processor scheduling;Concurrent computing;Pricing;"Disaster management"","""",""69"","""",""45"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Parallel algorithms for relational coarsest partition problems,""S. Rajasekaran";" I. Lee"",""Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA";" Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""7"",""687"",""699"",""Relational Coarsest Partition Problems (RCPPs) play a vital role in verifying concurrent systems. It is known that RCPPs are P-complete and hence it may not be possible to design polylog time parallel algorithms for these problems. In this paper, we present two efficient parallel algorithms for RCPP in which its associated label transition system is assumed to have m transitions and n states. The first algorithm runs in O(n/sup 1+/spl epsiv//) time using m/n/sup /spl epsiv// CREW PRAM processors, for any fixed /spl epsiv/<1. This algorithm is analogous to and optimal with respect to the sequential algorithm of P.C. Kanellakis and S.A. Smolka (1990). The second algorithm runs in O(n log n) time using m/n CREW PRAM processors. This algorithm is analogous to and nearly optimal with respect to the sequential algorithm of R. Paige and R.E. Tarjan (1987)."",""1558-2183"","""",""10.1109/71.707548"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=707548"","""",""Parallel algorithms";Partitioning algorithms;Algorithm design and analysis;Algebra;Phase change random access memory;Logic functions;Concurrent computing;Polynomials;Computer Society;"Hardware"","""",""14"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Parallel computation in biological sequence analysis,""T. K. Yap"; O. Frieder;" R. L. Martino"",""Division of Computer Research and Technology, National Institutes of Health DHHS, Bethesda, MD, USA"; Division of Electrical and Computer Science and Engineering, Florida Institute of Technology, Melbourne, FL, USA;" Division of Computer Research and Technology, National Institutes of Health DHHS, Bethesda, MD, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""3"",""283"",""294"",""A massive volume of biological sequence data is available in over 36 different databases worldwide, including the sequence data generated by the Human Genome project. These databases, which also contain biological and bibliographical information, are growing at an exponential rate. Consequently, the computational demands needed to explore and analyze the data contained in these databases is quickly becoming a great concern. To meet these demands, we must use high performance computing systems, such as parallel computers and distributed networks of workstations. We present two parallel computational methods for analyzing these biological sequences. The first method is used to retrieve sequences that are homologous to a query sequence. The biological information associated with the homologous sequences found in the database may provide important clues to the structure and function of the query sequence. The second method, which helps in the prediction of the function, structure, and evolutionary history of biological sequences, is used to align a number of homologous sequences with each other. These two parallel computational methods were implemented and evaluated on an Intel IPSC/860 parallel computer. The resulting performance demonstrates that parallel computational methods can significantly reduce the computational time needed to analyze the sequences contained in large databases."",""1558-2183"","""",""10.1109/71.674320"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=674320"","""",""Biology computing";Concurrent computing;Databases;High performance computing;Humans;Genomics;Bioinformatics;Data analysis;Computer networks;"Distributed computing"","""",""43"",""6"",""54"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Parallel genetic simulated annealing: a massively parallel SIMD algorithm,""H. Chen"; N. S. Flann;" D. W. Watson"",""SingleTrac Entertainment, Inc."; Department of Computer Science, Utah State University, Logan, UT, USA;" Department of Computer Science, Utah State University, Logan, UT, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""2"",""126"",""136"",""Many significant engineering and scientific problems involve optimization of some criteria over a combinatorial configuration space. The two methods most often used to solve these problems effectively-simulated annealing (SA) and genetic algorithms (GA)-do not easily lend themselves to massive parallel implementations. Simulated annealing is a naturally serial algorithm, while GA involves a selection process that requires global coordination. This paper introduces a new hybrid algorithm that inherits those aspects of GA that lend themselves to parallelization, and avoids serial bottle-necks of GA approaches by incorporating elements of SA to provide a completely parallel, easily scalable hybrid GA/SA method. This new method, called Genetic Simulated Annealing, does not require parallelization of any problem specific portions of a serial implementation-existing serial implementations can be incorporated as is. Results of a study on two difficult combinatorial optimization problems, a 100 city traveling salesperson problem and a 24 word, 12 bit error correcting code design problem, performed on a 16 K PE MasPar MP-1, indicate advantages over previous parallel GA and SA approaches. One of the key results is that the performance of the algorithm scales up linearly with the increase of processing elements, a feature not demonstrated by any previous parallel GA or SA approaches, which enables the new algorithm to utilize massive parallel architecture with maximum effectiveness. Additionally, the algorithm does not require careful choice of control parameters, a significant advantage over SA and GA."",""1558-2183"","""",""10.1109/71.663870"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663870"","""",""Simulated annealing";Optimization methods;Error correction codes;Computational modeling;Computer Society;Genetic algorithms;Design optimization;Temperature;Cities and towns;"Parallel architectures"","""",""90"","""",""28"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Parallelization model for successive approximations to the Rayleigh-Ritz linear variational problem,""J. C. Greer"",""National Microelectronic Research Centre, University College Cork, National University of Ireland, Cork, Ireland"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""10"",""938"",""946"",""Many of the differential equations arising in science and engineering can be recast in the form of a matrix eigenvalue problem. Solution of this equation within the context of the Rayleigh-Ritz variational method may be viewed as one of the fundamental tasks of numerical analysis. Successive approximation approaches to the Rayleigh-Ritz problem seek to improve eigenvectors and eigenfunctions by sequentially refining a trial function. Parallelization of successive approximation approaches has been demonstrated numerous times in the literature";" these studies addressed either the successive approximations or the matrix diagonalization levels of the algorithm. It is shown in this paper that these two strategies may be applied independently of one another, and the advantages of applying both parallelization levels simultaneously to the problem are discussed. Performance estimates for a two-tiered parallelization strategy are obtained by extrapolating from existing published performance data for which the two levels of parallelization were applied separately."",""1558-2183"","""",""10.1109/71.730523"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=730523"","""",""Eigenvalues and eigenfunctions";Differential equations;Numerical analysis;Approximation algorithms;Finite element methods;Laplace equations;Poisson equations;Finite difference methods;Kinetic theory;"Magnetic separation"","""",""2"","""",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"Performance estimation for real-time distributed embedded systems,""Ti-Yen Yen";" W. Wolf"",""Quickturn Design Systems, San Jose, CA, USA";" Department of Electrical Engineering, Princeton University, Princeton, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""11"",""1125"",""1136"",""Many embedded computing systems are distributed systems: communicating processes executing on several CPUs/ASICs. This paper describes a performance analysis algorithm for a set of tasks executing on a heterogeneous distributed system. Tight bounds are essential to the synthesis and verification of application-specific distributed systems, such as embedded computing systems. Our bounding algorithms are valid for a general problem model: The system can contain several tasks with hard real-time deadlines and different periods";" each task is partitioned into a set of processes related by data dependencies. The periods of tasks and the computation times of processes are not necessarily constant and can be specified by a lower bound and an upper bound. Such a model requires a more sophisticated algorithm, but leads to more accurate results than previous work. Our algorithm both provides tighter bounds and is faster than previous methods."",""1558-2183"","""",""10.1109/71.735959"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=735959"","""",""Real time systems";Embedded system;Performance analysis;Signal processing algorithms;Embedded computing;Processor scheduling;Delay estimation;Hardware;Scheduling algorithm;"Embedded software"","""",""46"","""",""35"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Randomized routing, selection, and sorting on the OTIS-mesh,""S. Rajasekaran";" S. Sahni"",""Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA";" Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""9"",""833"",""840"",""The Optical Transpose Interconnection System (OTIS) is a recently proposed model of computing that exploits the special features of both electronic and optical technologies. In this paper we present efficient algorithms for packet routing, sorting, and selection on the OTIS-Mesh. The diameter of an N/sup 2/-processor OTIS-Mesh is 4/spl radic/N-3. We present an algorithm for routing any partial permutation in 4/spl radic/N+o(/spl radic/N) time. Our selection algorithm runs in time 6/spl radic/N+o(/spl radic/N) and our sorting algorithm runs in 8/spl radic/N+o(/spl radic/N) time. All these algorithms are randomized and the stated time bounds hold with high probability. Also, the queue size needed for these algorithms is O(1) with high probability."",""1558-2183"","""",""10.1109/71.722217"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722217"","""",""Routing";Sorting;Concurrent computing;Optical interconnections;Partitioning algorithms;Optical fiber communication;Hypercubes;Computer Society;Optical computing;"Parallel algorithms"","""",""47"","""",""13"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Recognizing nondominated coteries and wr-coteries by availability,""Yu-Chen Kuo";" Shing-Tsaan Huang"",""Department of Computer and Information Science, Soochow University, Taipei, Taiwan";" Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""8"",""721"",""728"",""Coterie is a widely accepted concept for solving the mutual exclusion problem. Nondominated coteries are an important class of coteries which have better performance than dominated coteries. The performance of a coterie is usually measured by availability. Higher availability of a coterie exhibits greater ability to tolerate node or communication link failures. In this paper, we demonstrate a way to recognize nondominated coteries using availability. By evaluating the availability of a coterie instead of using a formal proof, the coterie can be recognized as a nondominated coterie or not. Moreover, with regard to wr-coterie, a concept for solving the replica control problem, we also present a similar result for recognizing nondominated wr-coteries. Finally, we apply our results to some well-known coteries and wr-coteries."",""1558-2183"","""",""10.1109/71.706045"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=706045"","""",""Availability";Neodymium;Fault tolerance;Permission;Boolean functions;Distributed algorithms;Communication system control;Voting;Costs;"Size measurement"","""",""6"","""",""15"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Resource deadlocks and performance of wormhole multicast routing algorithms,""R. V. Boppana"; S. Chalasani;" C. S. Raghavendra"",""University of San Antonio, San Antonio, TX, USA"; University of Wisconsin, Madison, Madison, WI, USA;" Aerospace Corporation, Los Angeles, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""6"",""535"",""549"",""We show that deadlocks due to dependencies on consumption channels are a fundamental problem in wormhole multicast routing. This type of resource deadlocks has not been addressed in many previously proposed wormhole multicast algorithms. We also show that deadlocks on consumption channels can be avoided by using multiple classes of consumption channels and restricting the use of consumption channels by multicast messages. We provide upper bounds for the number of consumption channels required to avoid deadlocks. In addition, we present a new multicast routing algorithm, column-path, which is based on the well-known dimension-order routing used in many multicomputers and multiprocessors. Therefore, this algorithm could be implemented in existing multicomputers with simple changes to the hardware. Using simulations, we compare the performance of the proposed column-path algorithm with the previously proposed Hamiltonian-path-based multipath and an e-cube-based multicast routing algorithms. Our results show that for multicast traffic, the column-path routing offers higher throughputs, while the multipath algorithm offers lower message latencies. Another result of our study is that the commonly implemented simplistic scheme of sending one copy of a multicast message to each of its destinations exhibits good performance provided the number of destinations is small."",""1558-2183"","""",""10.1109/71.689441"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=689441"","""",""System recovery";Routing;Multicast algorithms;Broadcasting;Multicast communication;Unicast;Communication switching;Concurrent computing;Hypercubes;"Context"","""",""67"",""1"",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Scalable s-to-p broadcasting on message-passing MPPs,""S. E. Hambrusch";" A. A. Khokhar"",""Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA";" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""8"",""758"",""768"",""In s-to-p broadcasting, s processors in a processor machine contain a message to be broadcast to all the processors, 1/spl les/s/spl les/p. We present a number of different broadcasting algorithms that handle all ranges of s. We show how the performance of each algorithm is influenced by the distribution of the s source processors and by the relationships between the distribution and the characteristics of the interconnection network. For the Intel Paragon we show that for each algorithm and machine dimension there exist ideal distributions and distributions on which the performance degrades. For the Cray T3D we also demonstrate dependencies between distributions and machine sizes. To reduce the dependence of the performance on the distribution of sources, we propose a repositioning approach. In this approach, the initial distribution is turned into an ideal distribution of the target broadcasting algorithm. We report experimental results for the Intel Paragon and Cray T3D and discuss scalability and performance."",""1558-2183"","""",""10.1109/71.706048"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=706048"","""",""Broadcasting";Scalability;Iterative algorithms;Multiprocessor interconnection networks;Degradation;Libraries;Load management;Data structures;"Algorithm design and analysis"","""",""4"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"Scaling simulation of the fusing-restricted reconfigurable mesh,""J. A. Fernandez-Zepeda"; R. Vaidyanathan;" J. L. Trahan"",""Department of Electrical and Computer Engineering, Louisiana State University, Baton Rouge, LA, USA"; Department of Electrical and Computer Engineering, Louisiana State University, Baton Rouge, LA, USA;" Department of Electrical and Computer Engineering, Louisiana State University, Baton Rouge, LA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""9"",""861"",""871"",""This paper deals with the ability of a model to adapt algorithm instances of different sizes to run on a given model size without significant loss of efficiency. The overhead in simulating a step of a large instance of the model on a smaller instance can quantify this ability. A reconfigurable mesh (R-Mesh) can use its bus structure as a computational resource, presenting an obstacle to efficiently scaling down algorithms to run on a smaller R-Mesh. We construct a scaling simulation of a Fusing-Restricted Reconfigurable Mesh (FR-Mesh), a version of the R-Mesh. The overhead of this simulation depends only on the simulating machine size and not on the simulated machine size. Previously, the R-Mesh was not known to admit such a simulation overhead without significantly reducing its computational power. The small overhead holds importance for flexibility in algorithm design and for running algorithms with various input sizes on an available model of given size. The results of this paper extend to a variety of concurrent write rules and also translate to an improved scaling simulation of an unrestricted R-Mesh."",""1558-2183"","""",""10.1109/71.722220"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722220"","""",""Computational modeling";Algorithm design and analysis;Parallel algorithms;Bibliographies;Concurrent computing;"Programming profession"","""",""8"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;
"Scheduling algorithms for parallel Gaussian elimination with communication costs,""A. K. Amoura"; E. Bampis;" J. . -C. Konig"",""LRI, Université de Paris Sud, Orsay, France"; LAMI, Université D'Evry Val D'Essonne, Evry, France;" LAMI, Université d''Evry Val d''Essonne, Evry, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""7"",""679"",""686"",""We consider a graph theoretical model and study a parallel implementation of the well-known Gaussian elimination method on parallel distributed memory architectures, where the communication delay for the transmission of an elementary data is higher than the computation time of an elementary instruction. We propose and analyze two low-complexity algorithms for scheduling the tasks of the parallel Gaussian elimination on an unbounded number of completely connected processors. We compare these two algorithms with a higher-complexity general-purpose scheduling algorithm, the DSC heuristic, proposed by A. Gerasoulis and T. Yang (1993)."",""1558-2183"","""",""10.1109/71.707547"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=707547"","""",""Scheduling algorithm";Costs;Processor scheduling;Algorithm design and analysis;Computer aided instruction;Partitioning algorithms;Computational modeling;Memory architecture;Delay effects;"Concurrent computing"","""",""28"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Scheduling block-cyclic array redistribution,""F. Desprez"; J. Dongarra; A. Petitet; C. Randriamaro;" Y. Robert"",""Ecole Normale Supérieure de Lyon, L.I.P, Lyon, France"; Department of Computer Science, University of Tennessee, Knoxville, TN, USA; Department of Computer Science, University of Tennessee, Knoxville, TN, USA; Ecole Normale Supérieure de Lyon, L.I.P, Lyon, France;" Department of Computer Science, University of Tennessee, Knoxville, TN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""2"",""192"",""205"",""This article is devoted to the run-time redistribution of one-dimensional arrays that are distributed in a block-cyclic fashion over a processor grid. While previous studies have concentrated on efficiently generating the communication messages to be exchanged by the processors involved in the redistribution, we focus on the scheduling of those messages: how to organize the message exchanges into """"structured"""" communication steps that minimize contention. We build upon results of Walker and Otto, who solved a particular instance of the problem, and we derive an optimal scheduling for the most general case, namely, moving from a CYCLIC(r) distribution on a P-processor grid to a CYCLIC(s) distribution on a Q-processor grid, for arbitrary values of the redistribution parameters P, Q, r, and s."",""1558-2183"","""",""10.1109/71.663945"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663945"","""",""Optimal scheduling";Processor scheduling;Phased arrays;Lifting equipment;Multidimensional systems;Kernel;Runtime environment;Heuristic algorithms;Scheduling algorithm;"Bipartite graph"","""",""46"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Strong interaction fairness via randomization,""Yuh-Jzer Joung";" S. A. Smolka"",""Department of Information Management, National Taiwan University, Taipei, Taiwan";" Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""2"",""137"",""149"",""We present MULTI, a symmetric, distributed, randomized algorithm that, with probability one, schedules multiparty interactions in a strongly fair manner. To our knowledge, MULTI is the first algorithm for strong interaction fairness to appear in the literature. Moreover, the expected time taken by MULTI to establish an interaction is a constant not depending on the total number of processes in the system. In this sense, MULTI guarantees real-time response. MULTI makes no assumptions (other than boundedness) about the time it takes processes to communicate. It, thus, offers an appealing tonic to the impossibility results of Tsay and Bagrodia, and Joung concerning strong interaction fairness in an environment, shared-memory, or message-passing, in which processes are deterministic and the communication time is nonnegligible. Because strong interaction fairness is as strong a fairness condition that one might actually want to impose in practice, our results indicate that randomization may also prove fruitful for other notions of fairness lacking deterministic realizations and requiring real-time response."",""1558-2183"","""",""10.1109/71.663873"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663873"","""",""Distributed algorithms";Computer languages;Scheduling algorithm;Delay;Concurrent computing;Taxonomy;"Real time systems"","""",""15"",""1"",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;
"Subject index,"""",,""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""12"",""1273"",""1280"",""This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the coauthors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under he primary entry in the Author Index."",""1558-2183"","""",""10.1109/TPDS.1998.737702"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=737702"","""","""","""","""","""","""",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;
"The CLAM approach to multithreaded communication on shared-memory multiprocessors: design and experiments,""J. C. Gomez"; E. Mascarenhas;" V. Rego"",""Department of Computer Sciences, Purdue University, West Lafayette, IN, USA"; Silicon Graphics Computer Systems, Mountain View, CA, USA;" Department of Computer Sciences, Purdue University, West Lafayette, IN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""1"",""36"",""49"",""We present results on the experimental design and development of a Connectionless, Lightweight, and Multiway (CLAM) communications environment. The system provides efficient and scalable multiprotocol support for distributed applications that use multimodal data. We present motivation behind design decisions for the CLAM system, and describe two simple, but effective scheduling algorithms for the simultaneous support of multiple, threads-based user-space protocols. One algorithm is readily portable to shared-memory multiprocessors, and enables two or more protocols to coexist within an OS-level process. We present experimental results on the performance of both algorithms."",""1558-2183"","""",""10.1109/71.655241"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=655241"","""",""Protocols";Libraries;Proposals;Distributed computing;Delay;Design for experiments;Algorithm design and analysis;Scheduling algorithm;"Processor scheduling"","""",""5"","""",""34"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"The Hector distributed run-time environment,""S. H. Russ"; J. Robinson; B. K. Flachs;" B. Heckel"",""Engineering Research Center, Mississippi State University, MS, USA"; Advanced Micro Electronics, Ridgeland, MS, USA; Austin Research Laboratory, IBM, Austin, TX, USA;" Computer Science Department, 2063 Engineering II, University of California, Davis, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""11"",""1102"",""1114"",""Harnessing the computational capabilities of a network of workstations promises to off-load work from overloaded supercomputers onto largely idle resources overnight. Several capabilities are needed to do this, including support for an architecture-independent parallel programming environment, task migration, automatic resource allocation, and fault tolerance. The Hector distributed run-time environment is designed to present these capabilities transparently to programmers. MPI programs can be run under this environment on homogeneous clusters with no modifications to their source code needed. The design of Hector, its internal structure, and several benchmarks and tests are presented."",""1558-2183"","""",""10.1109/71.735957"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=735957"","""",""Runtime environment";Workstations;Computer networks;Supercomputers;Parallel programming;Resource management;Fault tolerance;Programming profession;Load management;"Availability"","""",""15"",""29"",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"The offset cube: a three-dimensional multicomputer network topology using through-wafer optics,""W. S. Lacy"; J. L. Cruz-Rivera;" D. S. Wills"",""Comput. Syst. Lab., Stanford Univ., CA, USA"; Department of Electrical and Computer Engineering, University of Puerto Rico, MayagÜez, Mayaguez, Puerto Rico;" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""9"",""893"",""908"",""Three-dimensional packaging technologies are critical for enabling ultra-compact, massively parallel processors (MPPs) for embedded applications. Through-water optical interconnect has been proposed as a useful technology for building ultra-compact MPPs since it provides a simplified mechanism for interconnecting stacked multichip substrates. This paper presents the offset cube, a new network topology designed to exploit the packaging benefits of through-wafer optical interconnect in ultra-compact MPP systems. We validate the offset cube's topological efficiency by developing deadlock-free adaptive routing protocols with modest virtual channel requirements (only two virtual channels per link needed for full adaptivity). A preliminary analysis of router complexity suggests these protocols can be efficiently implemented in hardware. We also present a 3D mesh embedding for the offset cube. Network simulations show the offset cube performs comparably to a bidirectional 3D mesh of equal size under uniform, hot-spot, and trace-driven traffic loads. While the offset cube is not proposed as a general replacement for the mesh topology it leverages the benefits of through-wafer optical interconnect more effectively than a mesh by completely eliminating chip-to-chip wires for data signals. Hence, the offset cube is an effective topology for interconnecting ultra-compact MCM-level MPP systems."",""1558-2183"","""",""10.1109/71.722222"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722222"","""",""Network topology";Optical interconnections;Packaging;Buildings;Optical design;System recovery;Routing protocols;Hardware;Telecommunication traffic;"Wires"","""",""12"",""4"",""55"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Theoretical analysis for communication-induced checkpointing protocols with rollback-dependency trackability,""Jichiang Tsai"; Sy-Yen Kuo;" Yi-Min Wang"",""Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan"; Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan;" Microsoft Research, Microsoft Corporation, Redmond, WA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""10"",""963"",""971"",""Rollback-Dependency Trackability (RDT) is a property that states that all rollback dependencies between local checkpoints are on-line trackable by using a transitive dependency vector. In this paper, we address three fundamental issues in the design of communication-induced checkpointing protocols that ensure RDT. First, we prove that the following intuition commonly assumed in the literature is in fact false: If a protocol forces a checkpoint only at a stronger condition, then it must take, at most, as many forced checkpoints as a protocol based on a weaker condition. This result implies that the common approach of sharpening the checkpoint-inducing condition by piggybacking more control information on each message may not always yield a more efficient protocol. Next, we prove that there is no optimal on-line RDT protocol that takes fewer forced checkpoints than any other RDT protocol for all possible communication patterns. Finally, since comparing checkpoint-inducing conditions is not sufficient for comparing protocol performance, we present some formal techniques for comparing the performance of several existing RDT protocols."",""1558-2183"","""",""10.1109/71.730526"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=730526"","""",""Checkpointing";Protocols;Communication system control;Distributed computing;Computer networks;Communication networks;Nonvolatile memory;Process control;Force control;"Sufficient conditions"","""",""27"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Time- and VLSI-optimal sorting on enhanced meshes,""D. Bhagavathi"; H. Gurla; S. Olariu; J. L. Schwing; L. Wilson;" Jingyuan Zhang"",""Dept. of Math. & Comput. Sci., Fairleigh Dickinson Univ., Madison, NJ, USA"; NA; NA; NA; NA;" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""10"",""929"",""937"",""Sorting is a fundamental problem with applications in all areas of computer science and engineering. In this work, we address the problem of sorting on mesh connected computers enhanced by endowing each row and each column with its own dedicated high-speed bus. This architecture, commonly referred to as a mesh with multiple broadcasting, is commercially available and has been adopted by the DAP family of multiprocessors. Somewhat surprisingly, the problem of sorting m, (m/spl les/n), elements on a mesh with multiple broadcasting of size /spl radic/n/spl times//spl radic/n has been studied, thus far, only in the sparse case, where m/spl isin//spl Theta/(/spl radic/n) and in the dense case, where m/spl isin//spl Theta/O(/spl radic/n). Yet, many applications require using an existing platform of size /spl radic/n/spl times//spl radic/n for sorting m elements, with /spl radic/n<m/spl les/n. Our main contribution is to present the first known adaptive time- and VLSI-optimal sorting algorithm for meshes with multiple broadcasting. Specifically we show that, for every choice of a constant 0</spl epsiv//spl les/ 1/2 , it is possible to sort m elements, n/sup 1/2 +/spl epsiv///spl les/m/spl les/n, stored in the leftmost [m//spl radic/n] columns of a mesh with multiple broadcasting of size /spl radic/n/spl times//spl radic/n in /spl Theta/(m//spl radic/n) time."",""1558-2183"","""",""10.1109/71.730522"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=730522"","""",""Sorting";Broadcasting;Very large scale integration;Parallel machines;Application software;Computer architecture;Digital audio players;Image processing;Computer vision;"Pattern recognition"","""",""2"","""",""47"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals"""
"Using recorded values for bounding the minimum completion time in multiprocessors,""L. Lundberg";" H. Lennerstad"",""Department of Computer Science, University of Karlskrona Ronneby, Ronneby, Sweden";" Department of Mathematics, University of Karlskrona Ronneby, Karlskrona, Sweden"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""4"",""346"",""358"",""The way the processes in a parallel program are scheduled on the processors of a multiprocessor system affects the performance significantly. Finding a schedule of processes to processors which results in minimum completion time is NP-hard. Therefore, one has to resort to heuristic schedules. However, it is often difficult to determine if a specific schedule is close to the optimal case or if it is worthwhile to look for other schedules. Based on information from previous executions of the parallel program, we present a formula for an upper bound on the minimum completion time of the program. The bound is a function of a set of parameters. Some of these parameters are obtained from the previous executions of the program and the others describe the target multiprocessor architecture for which we want to bound the minimum completion time. The bound is optimal when it is based on information from one previous execution. Using these results, we are able to decide if a certain schedule is close to optimal or if it is worthwhile to look for other schedules. This is demonstrated by evaluating the completion time of a specific schedule of a particular program. The proofs used for obtaining the bound are based on program transformations and combinatorial mathematics."",""1558-2183"","""",""10.1109/71.667896"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=667896"","""",""Processor scheduling";Multiprocessing systems;Upper bound;Combinatorial mathematics;Programming environments;Parallel programming;Java;Sun;"Operating systems"","""",""4"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"Work-time optimal k-merge algorithms on the PRAM,""T. Hayashi"; K. Nakano;" S. Olariu"",""Department of Electrical and Computer Engineering, Nagoya Institute of Technology, Nagoya, Japan"; Department of Electrical and Computer Engineering, Nagoya Institute of Technology, Nagoya, Japan;" Department of Computer Science, Old Dominion University, Norfolk, VA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1998"",""9"",""3"",""275"",""282"",""For 2/spl les/k/spl les/n, the k-merge problem is to merge a collection of ksorted sequences of total length n into a new sorted sequence. The k-merge problem is fundamental as it provides a common generalization of both merging and sorting. The main contribution of this work is to give simple and intuitive work-time optimal algorithms for the k-merge problem on three PRAM models, thus settling the status of the k-merge problem. We first prove that /spl Omega/(n log k) work is required to solve the k-merge problem on the PRAM models. We then show that the EREW-PRAM and both the CREW-PRAM and the CRCW require /spl Omega/(log n) time and /spl Omega/(log log n+log k) time, respectively, provided that the amount of work is bounded by O(n log k). Our first k-merge algorithm runs in /spl Theta/(log n) time and performs /spl Theta/(n log k) work on the EREW-PRAM. Finally, we design a work-time optimal CREW-PRAM k-merge algorithm that runs in /spl Theta/(log log n+log k) time and performs /spl Theta/(n log k) work. This latter algorithm is also work-time optimal on the CREW-PRAM model. Our algorithms completely settle the status of the k-merge problem on the three main PRAM models."",""1558-2183"","""",""10.1109/71.674319"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=674319"","""",""Phase change random access memory";Merging;Sorting;Parallel algorithms;Information retrieval;Databases;Memory management;Read-write memory;Writing;"Query processing"","""",""6"","""",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;