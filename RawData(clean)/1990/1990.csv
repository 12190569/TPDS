"A distributed management scheme for partitionable parallel computers,""M. Jeng";" H. J. Siegel"",""Computer Science Department, University of Houston, Houston, TX, USA";" Parallel Processing Laboratory, School of Electrical Engineering, Purdue University, West Lafayette, IN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""1"",""120"",""126"",""A distributed scheme for dynamic partitioning is investigated. Distributed procedures to split a subsystem and to combine subsystems are presented. The correctness of each of these two procedures is shown, and the complexity is analyzed. The procedures are applicable to parallel computers that use interconnection networks, such as hypercube, omega, multistage cube, and extra-stage cube networks.<>"",""1558-2183"","""",""10.1109/71.80130"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80130"","""",""Concurrent computing";Distributed computing;Multiprocessor interconnection networks;Computer networks;Parallel processing;Application software;Hypercubes;Intelligent networks;Resource management;"Large-scale systems"","""",""12"",""1"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A fault-tolerant protocol for atomic broadcast,""S. . -W. Luan";" V. D. Gligor"",""Department of Electrical Engineering, University of Maryland, College Park, MD, USA";" Department of Electrical Engineering, University of Maryland, College Park, MD, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""3"",""271"",""285"",""A general protocol for atomic broadcast in networks is presented. The protocol tolerates loss, duplication, reordering, delay of messages, and network partitioning in an arbitrary network of fail-stop sites (i.e. no Byzantine site behavior is tolerated). The protocol is based on majority-concensus decisions to commit on unique ordering of received broadcast messages. Under normal operating conditions, the protocol requires three phases to complete and approximately 4N/V messages where N is the number of sites. This overhead is distributed among the messages of which the delivery decision is made and the heavier the broadcast message traffic, the lower the overhead per broadcast message becomes. Under abnormal operating conditions, a decentralized termination protocol (also presented) is invoked. A performance analysis of this protocol is presented, showing that this protocol commits with high probability under realistic operating conditions without invoking termination protocol if N is sufficiently large. The protocol retains its efficiency in wide-area networks where broadcast communication media are unavailable.<>"",""1558-2183"","""",""10.1109/71.80156"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80156"","""",""Fault tolerance";Protocols;Clocks;Synchronization;Ethernet networks;Satellite broadcasting;Disruption tolerant networking;Performance analysis;Voting;"Fault tolerant systems"","""",""75"","""",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A parallel algorithm for 2-D DFT computation with no interprocessor communication,""I. Gertner";" M. Rofheart"",""Center for Large Scale Computation, Graduate School and University Center, CUNY, New York, NY, USA";" Center for Large Scale Computation, Graduate School and University Center, CUNY, New York, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""3"",""377"",""382"",""A parallel algorithm is proposed for the two-dimensional discrete Fourier transform (2-D DFT) computation which eliminates interprocessor communications and uses only O(N) processors. The mapping of the algorithm onto architectures with broadcast and report capabilities is discussed. Expressions are obtained for estimating the speed performance on these machines as a function of the size N*N of the 2-D DFT, the bandwidth of the communications channel, the time for an addition, the time T(F/sub N/) for a single processing element to perform an N-point DFT, and the degree of parallelism. For single I/O channel machines that are capable of exploiting the full degree of parallelism of the algorithm, attainable execution times are as low as the time T(F/sub N/) plus the I/O time for data upload and download. An implementation on a binary tree computer is discussed.<>"",""1558-2183"","""",""10.1109/71.80164"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80164"","""",""Parallel algorithms";Concurrent computing;Discrete Fourier transforms;Parallel processing;Two dimensional displays;Computer architecture;Broadcasting;Bandwidth;Communication channels;"Binary trees"","""",""15"",""1"",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"A parallel algorithm for relational database normalization,""E. R. Omiecinski"",""Georgia Institute of Technology, School of Information and Computer Science, Atlanta, GA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""4"",""415"",""423"",""The problem of database normalization in a parallel environment is examined. Generating relation schemes in third normal form is straightforward when given a set of functional dependencies that is a reduced cover. It is shown that a reduced cover for a set of functional dependencies can be produced in parallel. The correctness of the algorithm is based on two important theorems. it is demonstrated that the companion third normal form algorithm can be easily translated into a parallel version. The performance of the two algorithms is compared to the performance of their serial counterparts. The standard serial algorithms for computing minimal covers and synthesizing third normal form relations are presented. The parallel algorithms and their rationale are discussed.<>"",""1558-2183"","""",""10.1109/71.80171"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80171"","""",""Parallel algorithms";Relational databases;Concurrent computing;Performance analysis;Pathology;Standards development;Computer science;Parallel processing;"Query processing"","""",""3"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;
"A performance evaluation study of pipeline TMR systems,""P. D. Ezhilchelvan"; I. Mitrani;" S. K. Shrivastava"",""Computing Laboratory, University of Newcastle, UK"; Computing Laboratory, University of Newcastle, UK;" Computing Laboratory, University of Newcastle, UK"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""4"",""442"",""456"",""A distributed system in which a job can be broken into a number of subjobs which are processed sequentially at various processors is considered. The performance of such a system is then compared to the replicated (triple modular redundant, or TMR) version of the system in which each subjob will require concurrent replicated processing with majority voting. The effect of voting times and processor failure rates on the performance of the system is investigated with analytical approximations and computer simulations. The accuracy of the former is examined. The results indicate the possible existence of a threshold voting time, below which the TMR system performs better than the unreplicated one, and above which the situation is reversed. Such thresholds are observed, where possible, in systems with repairable servers, as well as in those with nonrepairable servers.<>"",""1558-2183"","""",""10.1109/71.80173"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80173"","""",""Pipelines";Voting;Nuclear magnetic resonance;Performance analysis;Computational modeling;Power system reliability;Concurrent computing;Delay;Throughput;"Intersymbol interference"","""",""10"","""",""15"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A resilient mutual exclusion algorithm for computer networks,""S. Nishio"; K. F. Li;" E. G. Manning"",""Department of Information and Computer Sciences, Osaka University, Toyonaka, Osaka, Japan"; Department of Electrical and Computer Engineering, University of Victoria, Victoria, BC, Canada;" Department of Electrical and Computer Engineering, University of Victoria, Victoria, BC, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""3"",""344"",""355"",""The authors present an extension to the work of I. Suzuki and T. Kasami (see Proc. 3rd Int. Conf. Distributed Compact Syst., p.365-70 (1982)), where a mutual exclusion algorithm uses a message called a token to transfer the privilege of entering a critical region among the participating sites. The proposed algorithm checks whether the token is lost during network failure, and regenerates it if necessary. The mutual exclusion requirement is satisfied by guaranteeing regeneration of only one token in the network. Failures in a computer network are classified into three types: processor failure, communication controller failure, and communication link failure. To detect failures, a time-out mechanism based on message delay is used. The execution of the algorithm is described for each type of failure";" each site follows a rather simple execution procedure. Each site is not required to observe the failure of other sites or communication links.<>"",""1558-2183"","""",""10.1109/71.80161"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80161"","""",""Computer networks";Chromium;Computer network management;Communication system control;Delay;Distributed control;Concurrency control;Distributed algorithms;"Fault tolerance"","""",""26"",""2"",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A UNITY-style programming logic for shared dataspace programs,""H. C. Cunningham";" G. . -C. Roman"",""Department of Computer and Information Science, University of Mississippi, MS, USA";" Department of Computer Science, Washington University, Saint Louis, MO, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""3"",""365"",""376"",""A proof system for a shared dataspace programming notation called Swarm (a programming logic similar in style to that of UNITY) is specified. Relevant aspects of the Swarm language and model are overviewed. To illustrate the proof system, the Swarm logic is used to verify the correctness of a program for labeling connected equal-intensity regions of a digital image. Like UNITY, the Swarm proof system uses an assertional programming logic which relies upon proof of programwide properties, e.g. global invariants and progress properties. The Swarm logic is defined in terms of the same logical relations as UNITY (unless, ensures, and leads-to), but several of the concepts are reformulated to accommodate Swarm's distinctive features.<>"",""1558-2183"","""",""10.1109/71.80163"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80163"","""",""Logic programming";Concurrent computing;Dynamic programming;Computer languages;Data structures;Production systems;Computer science;Vehicle dynamics;Vehicles;"Artificial intelligence"","""",""35"","""",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"An efficient data dependence analysis for parallelizing compilers,""Z. Li"; P. . -C. Yew;" C. . -Q. Zhu"",""Department of Computer Science, York University, North York, ONT, Canada"; Center for Supercomputing Research and Development, University of Illinois, Urbana-Champaign, Urbana, IL, USA;" Fudan University, Shanghai, China"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""1"",""26"",""34"",""A novel algorithm, called the lambda test, is presented for an efficient and accurate data dependence analysis of multidimensional array references. It extends the numerical methods to allow all dimensions of array references to be tested simultaneously. Hence, it combines the efficiency and the accuracy of both approaches. This algorithm has been implemented in Parafrase, a Fortran program parallelization restructurer developed at the University of Illinois at Urbana-Champaign. Some experimental results are presented to show its effectiveness.<>"",""1558-2183"","""",""10.1109/71.80122"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80122"","""",""Data analysis";Testing;Algorithm design and analysis;Multidimensional systems;Program processors;Linear systems;Linear programming;Log periodic antennas;Phase detection;"Sufficient conditions"","""",""76"","""",""22"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"An empirical study of Fortran programs for parallelizing compilers,""Z. Shen"; Z. Li;" P. . -C. Yew"",""Changsha Institute of Technology, Changsha, China"; Department of Computer Science, York University, North York, ONT, Canada;" Center for Supercomputing Research and Development, University of Illinois, Urbana-Champaign, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""3"",""356"",""364"",""Some results are reported from an empirical study of program characteristics, that are important in parallelizing compiler writers, especially in the area of data dependence analysis and program transformations. The state of the art in data dependence analysis and some parallel execution techniques are examined. The major findings are included. Many subscripts contain symbolic terms with unknown values. A few methods of determining their values at compile time are evaluated. Array references with coupled subscripts appear quite frequently";" these subscripts must be handled simultaneously in a dependence test, rather than being handled separately as in current test algorithms. Nonzero coefficients of loop indexes in most subscripts are found to be simple: they are either 1 or -1. This allows an exact real-valued test to be as accurate as an exact integer-valued test for one-dimensional or two-dimensional arrays. Dependencies with uncertain distance are found to be rather common, and one of the main reasons is the frequent appearance of symbolic terms with unknown values.<>"",""1558-2183"","""",""10.1109/71.80162"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80162"","""",""Program processors";Data analysis;Testing;Scheduling;Statistics;US Department of Energy;NASA;Councils;"Space technology"","""",""81"",""1"",""29"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Analysis of fork-join program response times on multiprocessors,""D. Towsley"; C. G. Rommel;" J. A. Stankovic"",""Department of Computer and Information Science, University of Massachusetts, Amherst, MA, USA"; Eastern Connecticut State University, Williamsburg, CT, USA;" Department of Computer and Information Science, University of Massachusetts, Amherst, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""3"",""286"",""303"",""Models for two processor sharing policies called task scheduling processor sharing and job scheduling processor sharing are developed and analyzed. The first policy schedules each task independently and allows parallel execution of an individual program, whereas the second policy schedules each job as a unit, thereby not allowing parallel execution of an individual program. It is found that task scheduling performs better than job scheduling for most system parameter values. The performance of the task scheduling processor sharing is compared to a first come first serve policy. First come first serve performs better than processor sharing over a wide range of system parameters. Processor sharing performs best when the task service time variability is high. The performance of processor sharing and first come first serve is studied with two classes of jobs, and for when a specific number of processors is statically assigned to each of the classes.<>"",""1558-2183"","""",""10.1109/71.80157"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80157"","""",""Time factors";Processor scheduling;Costs;Degradation;Queueing analysis;Upper bound;Parallel programming;Mathematical model;Information science;"Computational modeling"","""",""32"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Broadcast protocols for distributed systems,""P. M. Melliar-Smith"; L. E. Moser;" V. Agrawala"",""Department of Electrical and Computer Engineering and the Department of Computer Science, University of California, Santa Barbara, CA, USA"; Department of Electrical and Computer Engineering and the Department of Computer Science, University of California, Santa Barbara, CA, USA;" Department of Electrical and Computer Engineering and the Department of Computer Science, University of California, Santa Barbara, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""1"",""17"",""25"",""An innovative approach is presented to the design of fault-tolerant distributed systems that avoids the several rounds of message exchange required by current protocols for consensus agreement. The approach is based on broadcast communication over a local area network, such as an Ethernet or a token ring, and on two novel protocols, the Trans protocol, which provides efficient reliable broadcast communication, and the Total protocol, which with high probability promptly places a total order on messages and achieves distributed agreement even in the presence of fail-stop, omission, timing, and communication faults. Reliable distributed operations, such as locking, update, and commitment, typically require only a single broadcast message rather than the several tens of messages required by current algorithms.<>"",""1558-2183"","""",""10.1109/71.80121"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80121"","""",""Broadcasting";Multicast protocols;Local area networks;Telecommunication network reliability;Fault tolerant systems;Computer science;Distributed databases;Ethernet networks;Token networks;"Timing"","""",""174"",""1"",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Constant time algorithms for the transitive closure and some related graph problems on processor arrays with reconfigurable bus systems,""B. . -F. Wang";" G. . -H. Chen"",""Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan";" Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""4"",""500"",""507"",""The transitive closure problem in O(1) time is solved by a new method that is far different from the conventional solution method. On processor arrays with reconfigurable bus systems, two O(1) time algorithms are proposed for computing the transitive closure of an undirected graph. One is designed on a three-dimensional n*n*n processor array with a reconfigurable bus system, and the other is designed on a two-dimensional n/sup 2/*n/sup 2/ processor array with a reconfigurable bus system, where n is the number of vertices in the graph. Using the O(1) time transitive closure algorithms, many other graph problems are solved in O(1) time. These problems include recognizing bipartite graphs and finding connected components, articulation points, biconnected components, bridges, and minimum spanning trees in undirected graphs.<>"",""1558-2183"","""",""10.1109/71.80177"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80177"","""",""Concurrent computing";Automata;Bridges;Tree graphs;Switches;Algorithm design and analysis;Communication switching;Bipartite graph;Parallel algorithms;"Time sharing computer systems"","""",""133"","""",""42"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Deciding properties of timed transition models,""J. S. Ostroff"",""Department of Computer Science, York University, ONT, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""170"",""183"",""Real-time distributed systems are modeled by a times transition model (TTM). For any finite-state TTM, decision procedures are provided for checking a small but important class of properties (specified in real-time temporal logic). The procedures are linear in the size of the system reachability graph. The class of properties includes invariance, precedence, eventuality and real-time response specifications.<>"",""1558-2183"","""",""10.1109/71.80145"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80145"","""",""Real time systems";Time to market;Logic;Safety;Concurrent computing;Computational modeling;Clocks;Heart;Aerospace electronics;"Performance analysis"","""",""84"","""",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;
"Depth-first search approach for fault-tolerant routing in hypercube multicomputers,""M. . -S. Chen";" K. G. Shin"",""IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA";" Real-Time Computing Laboratory, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""152"",""159"",""Using depth-first search, the authors develop and analyze the performance of a routing scheme for hypercube multicomputers in the presence of an arbitrary number of faulty components. They derive an exact expression for the probability of routing messages by way of optimal paths (of length equal to the Hamming distance between the corresponding pair of nodes) from the source node to an obstructed node. The obstructed node is defined as the first node encountered by the message that finds no optimal path to the destination node. It is noted that the probability of routing messages over an optimal path between any two nodes is a special case of the present results and can be obtained by replacing the obstructed node with the destination node. Numerical examples are given to illustrate the results, and they show that, in the presence of component failures, depth-first search routing can route a message to its destination by means of an optimal path with a very high probability.<>"",""1558-2183"","""",""10.1109/71.80143"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80143"","""",""Fault tolerance";Routing;Hypercubes;Hamming distance;Performance analysis;Parallel processing;Concurrent computing;Application software;Computer network reliability;"Telecommunication network reliability"","""",""119"",""2"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Design and implementation of a Petri net based toolkit for Ada tasking analysis,""S. M. Shatz"; K. Mai; C. Black;" S. Tu"",""Department of Electrical Engineering and Computer Science, University of Illinois, Chicago, Chicago, IL, USA"; AT and T Bell Laboratories, Inc., Naperville, IL, USA; Department of Electrical Engineering and Computer Science, University of Illinois, Chicago, Chicago, IL, USA;" Department of Electrical Engineering and Computer Science, University of Illinois, Chicago, Chicago, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""4"",""424"",""441"",""The use of Petri nets for defining a general static analysis framework for Ada tasking is advocated. The framework has evolved into a collection of tools that have proven to be a very valuable platform for experimental research. The design and implementation of tools that make up the tasking-oriented toolkit for the Ada language (TOTAL) are defined and discussed. Modeling and query/analysis methods and tools are discussed. Example Ada tasking programs are used to demonstrate the utility of each tool individually as well as the way the tools integrate. TOTAL is divided into two major subsystems, the front-end translator subsystem (FETS) and the back-end information display subsystem (BIDS). Three component tools that make up FETS are defined. Examples demonstrate the way these tools integrate in order to perform the translation of Ada source to Petri-net format. The BIDS subsystem and, in particular, the use of tools and techniques to support user-directed, but transparent, searches of Ada-net reachability graphs are discussed.<>"",""1558-2183"","""",""10.1109/71.80172"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80172"","""",""Concurrent computing";Distributed computing;Petri nets;Software tools;Software prototyping;Production;Testing;Packaging;System recovery;"History"","""",""39"","""",""19"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Design, analysis, and simulation of I/O architectures for hypercube multiprocessors,""A. L. N. Reddy";" P. Banerjee"",""Department of Electrical and Computer Engineering and the Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, Urbana, IL, USA";" Department of Electrical and Computer Engineering and the Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""140"",""151"",""Several issues concerning the design of an I/O (input/output) system for a multiprocessor such as a hypercube are examined. A methodology is proposed for connecting the I/O processors to such a system for efficient I/O access. The effect of I/O communication on the multiprocessor network is analyzed. Different disk organizations that can be employed within such a system are evaluated to see which organization has a better performance. It is observed that parallelism in serving an I/O request plays a dominant role in the scientific workload. The problem of mapping specific data structures such as matrices onto the disks so that the data can be accessed efficiently is considered.<>"",""1558-2183"","""",""10.1109/71.80142"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80142"","""",""Analytical models";Hypercubes;Joining processes;Hardware;Distributed computing;Data structures;Message passing;Fault tolerance;Concurrent computing;"Topology"","""",""24"","""",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Designing efficient parallel algorithms on mech-connected computers with multiple broadcasting,""Y. . -C. Chen"; W. . -T. Chen; G. . -H. Chen;" J. . -P. Sheu"",""Institute of Computer Science, National Tsing Hua University, Hsinchu, Taiwan"; Institute of Computer Science, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan;" Department of Electrical Engineering, National Central University, Chungli, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""241"",""246"",""Semigroup and prefix computations on two-dimensional mesh-connected computers with multiple broadcasting (2-MCCMBs) are studied. Previously, only square 2-MCCMBs with N processing elements were considered for semigroup computations of N data items, and O(N/sup 1/6/) time was required. It is found that square machines are not the best form for semigroup computations, and an O(N/sup 1/8/)-time algorithm is derived on an N/sup 5/8/*N/sup 3/8/ rectangular 2-MCCMB. This time complexity can be further reduced to O(N/sup 1/9/) if fewer processing elements are used. Parallel algorithms for prefix computations with the same time complexities are derived.<>"",""1558-2183"","""",""10.1109/71.80135"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80135"","""",""Algorithm design and analysis";Parallel algorithms;Concurrent computing;Broadcasting;Computer architecture;Nearest neighbor searches;Computer science;Hardware;Parallel processing;"Very large scale integration"","""",""52"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Efficient algorithms for list ranking and for solving graph problems on the hypercube,""K. W. Ryu";" J. Jaja"",""Department of Computer Science and the Institute for Advanced Computer Studies, University of Maryland, College Park, MD, USA";" Department of Electrical Engineering, the Institute for Advanced Computer Studies, University of Maryland, College Park, MD, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""1"",""83"",""90"",""A hypercube algorithm to solve the list ranking problem is presented. Let n be the length of the list, and let p be the number of processors of the hypercube. The algorithm described runs in time O(n/p) when n= Omega (p/sup 1+ epsilon /) for any constant epsilon >0, and in time O(n log n/p+log/sup 3/ p) otherwise. This clearly attains a linear speedup when n= Omega (p/sup 1+ epsilon /). Efficient balancing and routing schemes had to be used to achieve the linear speedup. The authors use these techniques to obtain efficient hypercube algorithms for many basic graph problems such as tree expression evaluation, connected and biconnected components, ear decomposition, and st-numbering. These problems are also addressed in the restricted model of one-port communication.<>"",""1558-2183"","""",""10.1109/71.80127"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80127"","""",""Hypercubes";Ear;Computer architecture;Routing;Tree graphs;Load management;Parallel machines;Joining processes;Topology;"Pipeline processing"","""",""18"","""",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Efficient scheduling algorithms for real-time multiprocessor systems,""K. Ramamritham"; J. A. Stankovic;" P. . -F. Shiah"",""Department of Computer and Information Science, University of Massachusetts, Amherst, MA, USA"; Department of Computer and Information Science, University of Massachusetts, Amherst, MA, USA;" Department of Computer and Information Science, University of Massachusetts, Amherst, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""184"",""194"",""Efficient scheduling algorithms based on heuristic functions are developed for scheduling a set of tasks on a multiprocessor system. The tasks are characterized by worst-case computation times, deadlines, and resources requirements. Starting with an empty partial schedule, each step of the search extends the current partial schedule by including one of the tasks yet to be scheduled. The heuristic functions used in the algorithm actively direct the search for a feasible schedule, i.e. they help choose the task that extends the current partial schedule. Two scheduling algorithms are evaluated by simulation. To extend the current partial schedule, one of the algorithms considers, at each step of the search, all the tasks that are yet to be scheduled as candidates. The second focuses its attention on a small subset of tasks with the shortest deadlines. The second algorithm is shown to be very effective when the maximum allowable scheduling overhead is fixed. This algorithm is hence appropriate for dynamic scheduling in real-time systems.<>"",""1558-2183"","""",""10.1109/71.80146"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80146"","""",""Scheduling algorithm";Real time systems;Multiprocessing systems;Optimal scheduling;Processor scheduling;Dynamic scheduling;Power generation;Aerospace control;Aerospace electronics;"Polynomials"","""",""237"",""26"",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Error recovery in shared memory multiprocessors using private caches,""K. . -L. Wu"; W. K. Fuchs;" J. H. Patel"",""Computer Systems Group, Coordinated Science Laboratory, University of Illinois, Urbana, IL, USA"; Computer Systems Group, Coordinated Science Laboratory, University of Illinois, Urbana, IL, USA;" Computer Systems Group, Coordinated Science Laboratory, University of Illinois, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""231"",""240"",""The problem of recovering from processor transient faults in shared memory multiprocessor systems is examined. A user-transparent checkpointing and recovery scheme using private caches is presented. Processes can recover from errors due to faulty processors by restarting from the checkpointed computation state. Implementation techniques using checkpoint identifiers and recovery stacks are examined as a means of reducing performance degradation in processor utilization during normal execution. This cache-based checkpointing technique prevents rollback propagation, provides rapid recovery, and can be integrated into standard cache coherence protocols. An analytical model is used to estimate the relative performance of the scheme during normal execution. Extensions to take error latency into account are presented.<>"",""1558-2183"","""",""10.1109/71.80134"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80134"","""",""Checkpointing";Parallel processing;Hardware;Multiprocessing systems;Protocols;Delay;Concurrent computing;Application software;NASA;"Degradation"","""",""50"",""14"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Experimental application-driven architecture analysis of an SIMD/MIMD parallel processing system,""E. C. Bronson"; T. L. Casavant;" L. H. Jamieson"",""School of Electrical Engineering, Purdue University, West Lafayette, IN, USA"; Department of Electrical and Computer Engineering, University of Iowa, Iowa, IA, USA;" School of Electrical Engineering, Purdue University, West Lafayette, IN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""195"",""205"",""An experimental analysis of the architecture of an SIMD/MIMD parallel processing system is presented. Detailed implementations of parallel fast Fourier transform (FFT) programs were used to examine the performance of the prototype of the PASM (Partitionable SIMD/MIMD) parallel processing system. Detailed execution-time measurements using specialized timing hardware were made for the complete FFT and for components of SIMD, MIMD, and barrier-synchronized MIMD implementations. The component measurements isolated the effects of floating-point arithmetic operations, interconnection network transfer operations, and program control overhead. The measurements allow an accurate extrapolation of the execution time, speedup, and efficiency of the MIMD, SIMD, and barrier-synchronized MIMD programs to a full 1024-processor PASM system. This constitutes one of the first results of this kind, in which controlled experiments on fixed hardware were used to make comparisons of these fundamental modes of computing. Overall, the experimental results demonstrate the value of mixed-mode SIMD/MIMD computing and its suitability for computational intensive algorithms such as the FET.<>"",""1558-2183"","""",""10.1109/71.80147"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80147"","""",""Parallel processing";Hardware;Fast Fourier transforms;Prototypes;Timing;Floating-point arithmetic;Multiprocessor interconnection networks;Velocity measurement;Time measurement;"Extrapolation"","""",""31"",""1"",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Exploiting lookahead in parallel simulation,""Y. . -B. Lin";" E. D. Lazowska"",""Department of Computer Science and Engineering, University of Washington, Seattle, WA, USA";" Department of Computer Science and Engineering, University of Washington, Seattle, WA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""4"",""457"",""469"",""Lookahead is the ability of a process to predict its future behavior. The feasibility of implicit lookahead for non-FCFS stochastic queuing systems is demonstrated. Several lookahead exploiting techniques are proposed for round-robin (RR) system simulations. An algorithm that generates lookahead in O(1) time is described. Analytical models and experiments are constructed to evaluate these techniques. A lookahead technique for preemptive priority (PP) systems is evaluated using an analytical model. The performance metric for these techniques is the lookahead ratio, which is correlated with other performance measures of more direct interest, such as speedup. The analyses show that using implicit lookahead can significantly improve the lookahead ratios of RR and PP system simulations.<>"",""1558-2183"","""",""10.1109/71.80174"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80174"","""",""System recovery";Analytical models;Discrete event simulation;Stochastic systems;Algorithm design and analysis;Round robin;Sea measurements;Velocity measurement;Predictive models;"Oceans"","""",""36"",""1"",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Exploiting parallelism across program execution: a unification technique and its analysis,""V. Rego";" A. P. Mathur"",""Department of Computer Sciences, Purdue University, West Lafayette, IN, USA";" Department of Computer Sciences, Purdue University, West Lafayette, IN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""4"",""399"",""414"",""A new technique for source-to-source transformation of sequential programs is described. It is shown that the transformed programs so generated provide significant speedups over the original program on vector processors and vector multiprocessors. The parallelism that arises when multiple instances of a program are executed on simultaneously available data sets is exploited. This is in contrast to the existing approaches that aim at detecting parallelism within a program. The analytic model is used to prove the optimality of the complete first policy for block selection for a class of program graphs known as nonregressive graphs. Analytic and simulation models of the technique clearly indicate the speedups that could be achieved when several data sets are available simultaneously, as is the case in many fields of interest.<>"",""1558-2183"","""",""10.1109/71.80170"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80170"","""",""Parallel processing";Processor scheduling;Monte Carlo methods;Analytical models;Statistical analysis;Software testing;Program processors;Concurrent computing;Delay;"Parallel machines"","""",""11"","""",""30"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Hardware support for interprocess communication,""U. Ramachandran"; M. Solomon;" M. K. Vernon"",""School of Information and Computer Science, Georgia Institute of Technology, Atlanta, GA, USA"; Department of Computer Science, University of Wisconsin, Madison, Madison, WI, USA;" Department of Computer Science, University of Wisconsin, Madison, Madison, WI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""3"",""318"",""329"",""The use of a special-purpose coprocessor for supporting message passing is proposed. An actual message-based operating system is partitioned into computation and communication parts, executing, respectively, on a host and a message coprocessor which interact through shared queues. Its performance is measured on a multiprocessor. Hardware support in the form of a special-purpose smart bus and smart shared memory is designed. The benefits of these components are demonstrated through analytical modeling using generalized timed Petri nets. The analysis shows good agreement with experimental results and indicates that substantial benefits may be obtained when the software is partitioned between host and the message coprocessor and when a small amount of special-purpose hardware is added.<>"",""1558-2183"","""",""10.1109/71.80159"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80159"","""",""Hardware";Operating systems;Kernel;Message passing;Computer architecture;Costs;Bandwidth;Coprocessors;Petri nets;"Local area networks"","""",""16"",""2"",""31"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Hypertool: a programming aid for message-passing systems,""M. . -Y. Wu";" D. D. Gajski"",""Department of Computer Science, Yale University, New Heaven, CT, USA";" Department of Information and Computer Science, University of California, Irvine, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""3"",""330"",""343"",""Programming assistance, automation concepts, and their application to a message-passing system program development tool called Hypertool are discussed. Hypertool performs scheduling and handles the communication primitive insertion automatically, thereby increasing productivity and eliminating synchronization errors. Two algorithms, based on the critical-path method, are presented for scheduling processes statically. Hypertool also generates the performance estimates and other program quality measures to help programmers improve their algorithms and programs.<>"",""1558-2183"","""",""10.1109/71.80160"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80160"","""",""Programming profession";Processor scheduling;Computer science;Parallel processing;Automation;Scheduling algorithm;Partitioning algorithms;Multiprocessing systems;System recovery;"Data mining"","""",""479"",""7"",""29"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Implementing location independent invocation,""A. P. Black";" Y. Artsy"",""Distributed Systems Advanced Development Group of Digital Equipment Corporation, Littleton, MA, USA";" Distributed Systems Advanced Development Group of Digital Equipment Corporation, Littleton, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""1"",""107"",""119"",""The problems of finding objects in large and wide-area networks where objects may change their location in volatile memory as well as on stable storage are presented. The authors discuss possible solutions and describe those adopted in the Hermes system (a corporate wide, real life office application). They have designed and developed a location-independent-invocation (LII) mechanism that combines finding with invocation, using temporal location information. The mechanism also updates the system's knowledge of an object's location as a side-effect of invocation and object migration. Assumptions about object mobility indicate that objects are likely to be found within a few propagations of an invocation. If they cannot be found in this way, stable-storage and name services are used to locate the object. The major contribution of this work is to show how LII can be achieved in a large and dynamic environment in which objects are supported by neither are operating system nor the programming language.<>"",""1558-2183"","""",""10.1109/71.80129"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80129"","""",""Network servers";File servers;Operating systems;Buildings;Prototypes;Large-scale systems;Programming profession;Protocols;"Data structures"","""",""19"",""4"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"IPS-2: the second generation of a parallel program measurement system,""B. P. Miller"; M. Clark; J. Hollingsworth; S. Kierstead; S. . -S. Lim;" T. Torzewski"",""Computer Sciences Department, University of Wisconsin, Madison, Madison, WI, USA"; UNIX Software Operation, AT and T Bell Laboratories, Inc., Summit, NJ, USA; Computer Sciences Department, University of Wisconsin, Madison, Madison, WI, USA; Computer Sciences Department, University of Wisconsin, Madison, Madison, WI, USA; AT and T Bell Laboratories, Inc., Skokie, IL, USA;" Digital Equipment Corporation, Colorado Springs, CO, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""206"",""217"",""IPS, a performance measurement system for parallel and distributed programs, is currently running on its second implementation. IPS's model of parallel programs uses knowledge about the semantics of a program's structure to provide two important features. First, IPS provides a large amount of performance data about the execution of a parallel program, and this information is organized so that access to it is easy and intuitive. Secondly, IPS provides performance analysis techniques that help to guide the programmer automatically to the location of program bottlenecks. The first implementation of IPS was a testbed for the basic design concepts, providing experience with a hierarchical program and measurement model, interactive program analysis, and automatic guidance techniques. It was built on the Charlotte distributed operating system. The second implementation, IPS-2, extends the basic system with new instrumentation techniques, an interactive and graphical user interface, and new automatic guidance analysis techniques. This implementation runs on 4.3BSD UNIX systems, on the VAX, DECstation, Sun 4, and Sequent Symmetry multiprocessor.<>"",""1558-2183"","""",""10.1109/71.80132"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80132"","""",""Instruments";Measurement;Performance analysis;Programming profession;Automatic testing;Operating systems;Graphical user interfaces;Power system modeling;Sun;"Springs"","""",""111"",""1"",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals"""
"Iterative instructions in the Manchester Dataflow Computer,""A. P. W. Bohm";" J. R. Gurd"",""Department of Computer Science, University of Manchester, Institute of Science and Technology, Manchester, UK";" Department of Computer Science, University of Manchester, Institute of Science and Technology, Manchester, UK"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""129"",""139"",""The authors investigate the nature and extent of the benefits and adverse effects of iterative instructions in the prototype Manchester Dataflow Computer. Iterative instructions are shown to be highly beneficial in terms of the number of instructions executed and the number of tokens transferred between modules during a program run. This benefit is apparent at hardware level, giving significantly reduced program execution times. However, the full benefits are not realized due to interference between lengthy iterative instructions. It is suggested that restructuring of buffers and the function unit array in the prototype hardware configuration can reduce this interference. Other possibilities for improvement are suggested. For example, the slowdown effect observed in hardware speedup curves could be tackled by treating iterative instructions differently from fine-grain instructions. An alternative structure for the processing element in which certain function units are specialized for executing iterative instructions is being investigated in this connection.<>"",""1558-2183"","""",""10.1109/71.80141"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80141"","""",""Computer aided instruction";Switches;Data structures;Prototypes;Parallel processing;Computational modeling;Computer architecture;Tail;Hardware;"Packet switching"","""",""14"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Mapping nested loop algorithms into multidimensional systolic arrays,""P. . -Z. Lee";" Z. M. Kedem"",""Courant Inst. of Math. Sci., New York Univ., NY, USA";" Courant Inst. of Math. Sci., New York Univ., NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""1"",""64"",""76"",""Consideration is given to transforming depth p-nested for loop algorithms into q-dimensional systolic VLSI arrays where 1<or=q<or=p-1. Previously, there existed complete characterizations of correct transformation only for the cases where q=p-1 or q=1. This gap is filled by giving formal necessary and sufficient conditions for correct transformation of a p-nested loop algorithm into a q-dimensional systolic array for any q, 1<or=q<or=p-1. Practical methods are presented. The techniques developed are applied to the automatic design of special purpose and programmable systolic arrays. The results also contribute toward automatic compilation onto more general purpose programmable arrays. Synthesis of linear and planar systolic array implementations for a three-dimensional cube-graph algorithm and a reindexed Warshall-Floyd path-finding algorithm are used to illustrate the method.<<ETX>>"",""1558-2183"","""",""10.1109/71.80125"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80125"","""",""Multidimensional systems";Systolic arrays;Sufficient conditions;Parallel processing;Computer science;Very large scale integration;Transmission line matrix methods;Vectors;History;"Information science"","""",""53"",""1"",""36"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Modelling speedup (n) greater than n,""D. P. Helmbold";" C. E. McDowell"",""Board of Studies in Computer and Information Sciences, University of California, Santa Cruz, Santa Cruz, CA, USA";" Board of Studies in Computer and Information Sciences, University of California, Santa Cruz, Santa Cruz, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""250"",""256"",""A simple model of parallel computation which is capable of explaining speedups greater than n on n processors is presented. Necessary and sufficient conditions for these exceptional speedups are derived from the model. Several of the contradictory previous results relating to parallel speedup are resolved by using the model.<>"",""1558-2183"","""",""10.1109/71.80148"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80148"","""",""Registers";Processor scheduling;Parallel algorithms;Analytical models;"Sufficient conditions"","""",""35"","""",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;
"Odd even shifts in SIMD hypercubes,""S. Ranka";" S. Sahni"",""Center for Science and Technology, Syracuse University, Syracuse, NY, USA";" Department of Computer Science, University of Minnesota, Minneapolis, MN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""1"",""77"",""82"",""A linear-time algorithm is developed to perform all odd (even) length circular shifts of data in an SIMD (single-instruction-stream, multiple-data-stream) hypercube. As an application, the algorithm is used to obtain an O(M/sup 2/+log N) time and O(1) memory per processor algorithm to compute the two-dimensional convolution of an N*N image and an M*M template on an N/sup 2/ processor SIMD hypercube. This improves the previous best complexity of O(M/sup 2/ log M+log N).<>"",""1558-2183"","""",""10.1109/71.80126"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80126"","""",""Hypercubes";Routing;Convolution;Broadcasting;Computer vision;Concurrent computing;Sorting;Linear algebra;Registers;"Clocks"","""",""7"",""3"",""13"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"On mapping systolic algorithms onto the hypercube,""O. H. Ibarra";" S. M. Sohn"",""Department of Computer Science, University of Minnesota, Minneapolis, MN, USA";" Department of Computer Science, University of Minnesota, Minneapolis, MN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""1"",""48"",""63"",""Consideration is given to the problem of mapping systolic array algorithms into efficient algorithms for a fixed-size hypercube architecture. The authors describe in detail several optimal implementations of algorithms given for one-way one- and two-dimensional systolic arrays. Since interprocessor communication is many times slower than local computation in parallel computers built to date, the problem of efficient communication is specifically addressed for these mappings. In order to validate the technique experimentally, five systolic algorithms were mapped in various ways onto a 64-node NCUBE/7 MIMD hypercube machine. The algorithms are for the following problems: the shuffle scheduling problem, finite impulse response filtering, linear context-free language recognition, matrix multiplication, and computing the Boolean transitive closure. Experimental evidence indicates that good performance is obtained for the mappings.<>"",""1558-2183"","""",""10.1109/71.80124"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80124"","""",""Hypercubes";Systolic arrays;Concurrent computing;Computer architecture;Scheduling algorithm;Filtering algorithms;Processor scheduling;Finite impulse response filter;Nonlinear filters;"Context"","""",""25"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Parallel binary search,""S. G. Akl";" H. Meijer"",""Dept. of Comput. & Inf. Sci., Queen's Univ., Kingston, Ont., Canada";" Dept. of Comput. & Inf. Sci., Queen's Univ., Kingston, Ont., Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""247"",""250"",""Two arrays of numbers sorted in nondecreasing order are given: an array A of size n and an array B of size m, where n<m. It is required to determine, for every element of A, the smallest element of B (if one exists) that is larger than or equal to it. It is shown how to solve this problem on the EREW PRAM (exclusive-read exclusive-write parallel random-access machine) in O(logm logn/log log m) time using n processors. The solution is then extended to the case in which fewer than n processors are available. This yields an EREW PRAM algorithm for the problem whose cost is O(n log m, which is O(m)) for n<or=m/log m. It is shown how the solution obtained leads to an improved parallel merging algorithm.<<ETX>>"",""1558-2183"","""",""10.1109/71.80139"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80139"","""",""Phase change random access memory";Merging;Costs;Read-write memory;Computational modeling;Writing;Parallel algorithms;Concurrent computing;Search problems;"Councils"","""",""7"",""1"",""7"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Parallel simulated annealing algorithms for cell placement on hypercube multiprocessors,""P. Banerjee"; M. H. Jones;" J. S. Sargent"",""Department of Electrical Engineering and the Coordinated Science Laboratory, University of Illinois, Urbana, IL, USA"; AT and T Bell Laboratories, Inc., Naperville, IL, USA;" Incredible Technologies, Arlington Heights, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""1"",""91"",""106"",""A discussion is presented of two ways of mapping the cells in a two-dimensional area of a chip onto processors in an n-dimensional hypercube such that both small and large cell moves can be applied. Two types of move are allowed: cell exchanges and cell displacements. The computation of the cost function in parallel among all the processors in the hypercube is described, along with a distributed data structure that needs to be stored in the hypercube to support such a parallel cost evaluation. A novel tree broadcasting strategy is presented for the hypercube that is used extensively in the algorithm for updating cell locations in the parallel environment. A dynamic parallel annealing schedule is proposed that estimates the errors due to interacting parallel moves and adapts the rate of synchronization automatically. Two novel approaches in controlling error in parallel algorithms are described: heuristic cell coloring and adaptive sequence control. The performance on an Intel iPSC-2/D4/MX hypercube is reported.<>"",""1558-2183"","""",""10.1109/71.80128"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80128"","""",""Simulated annealing";Hypercubes;Cost function;Automatic control;Concurrent computing;Distributed computing;Data structures;Broadcasting;Dynamic scheduling;"Error correction"","""",""65"",""11"",""42"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Parallelizing programs with recursive data structures,""L. J. Hendren";" A. Nicolau"",""Department of Computer Science, Cornell University, Ithaca, NY, USA";" Department of Information and Computer Science, University of California, Irvine, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""1"",""35"",""47"",""A study is made of the problem of estimating interference in an imperative language with dynamic data structures. The authors focus on developing efficient and implementable methods for recursive data structures. In particular, they present interference analysis tools and parallelization techniques for imperative programs that contain dynamically updatable trees and directed acyclic graphs. The analysis methods are based on a regular-expression-like representation of the relationship between accessible nodes in the data structure. They authors have implemented their analysis, and they present some concrete examples that have been processed by this system.<>"",""1558-2183"","""",""10.1109/71.80123"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80123"","""",""Data structures";Interference;Concurrent computing;Programming profession;Parallel programming;Parallel processing;Program processors;Computer languages;Computer science;"Information analysis"","""",""108"",""13"",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Pipelined data parallel algorithms-I: concept and modeling,""C. . -T. King"; W. . -H. Chou;" L. M. Ni"",""Department of Computer Science, Michigan State University, East Lansing, MI, USA"; Department of Computer Science, Michigan State University, East Lansing, MI, USA;" Department of Computer Science, Michigan State University, East Lansing, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""4"",""470"",""485"",""The basic concept of pipelined data-parallel algorithms is introduced by contrasting the algorithms with other styles of computation and by a simple example (a pipeline image distance transformation algorithm). Pipelined data-parallel algorithms are a class of algorithms which use pipelined operations and data level partitioning to achieve parallelism. Applications which involve data parallelism and recurrence relations are good candidates for this kind of algorithm. The computations are ideal for distributed-memory multicomputers. By controlling the granularity through data partitioning and overlapping the operations through pipelining, it is possible to achieve a balanced computation on multicomputers. An analytic model is presented for modeling pipelined data-parallel computation on multicomputers. The model uses timed Petri nets to describe data pipelining operations. As a case study, the model is applied to a pipelined matrix multiplication algorithm. Predicted results match closely with the measured performance on a 64-node NCUBE hypercube multicomputer.<>"",""1558-2183"","""",""10.1109/71.80175"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80175"","""",""Signal processing algorithms";Partitioning algorithms;Algorithm design and analysis;Parallel algorithms;Concurrent computing;Parallel processing;Pipeline processing;Distributed computing;Computer science;"Petri nets"","""",""24"","""",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Pipelined data parallel algorithms-II: design,""C. . -T. King"; W. . -H. Chou;" L. M. Ni"",""Department of Computer Science, Michigan State University, East Lansing, MI, USA"; Department of Computer Science, Michigan State University, East Lansing, MI, USA;" Department of Computer Science, Michigan State University, East Lansing, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""4"",""486"",""499"",""For pt.I see ibid., p.470-85. A methodology for designing pipelined data-parallel algorithms on multicomputers is studied. The design procedure starts with a sequential algorithm which can be expressed as a nested loop with constant loop-carried dependencies. The procedure's main focus is on partitioning the loop by grouping related iterations together. Grouping is necessary to balance the communication overhead with the available parallelism and to produce pipelined execution patterns, which result in pipelined data-parallel computations. The grouping should satisfy dependence relationships among the iterations and also allow the granularity to be controlled. Various properties of grouping are studied, and methods for generating communication-efficient grouping are given. Given a grouping and an assignment of the groups to the processors, an analytic model is combined with the grouping results to describe the behavior and to estimate the performance of the resultant parallel program. Expressions characterizing the performance are derived.<>"",""1558-2183"","""",""10.1109/71.80176"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80176"","""",""Algorithm design and analysis";Partitioning algorithms;Processor scheduling;Concurrent computing;Parallel processing;Communication system control;Distributed computing;Pipeline processing;Computer science;"Parallel algorithms"","""",""23"","""",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Predicting performance of parallel computations,""V. W. Mak";" S. F. Lundstrom"",""Distributed Systems Software Research Group, Bell Communications Research, Inc., Morristown, NJ, USA";" Computer Systems Laboratory, University of Stanford, Stanford, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""3"",""257"",""270"",""An accurate and computationally efficient method for predicting the performance of a class of parallel computations running on concurrent systems is described. A parallel computation is modeled as a task system with precedence relationships expressed as a series-parallel directed acyclic graph. Resources in a concurrent system are modeled as service centers in a queuing network model. Using these two models as inputs, the method outputs predictions of expected execution time of the parallel computation and the concurrent system utilization. The method is validated against both detailed simulation and actual execution on a commercial multiprocessor. Using 100 test cases, the average error of the prediction when compared to simulation statistics is 1.7%, with a standard deviation of 1.5%";" the maximum error is about 10%.<>"",""1558-2183"","""",""10.1109/71.80155"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80155"","""",""Concurrent computing";Predictive models;Computational modeling;Delay effects;Prediction methods;Testing;Computer errors;Statistical analysis;Error analysis;"Added delay"","""",""75"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Prefetching in file systems for MIMD multiprocessors,""D. F. Kotz";" C. S. Ellis"",""Department of Computer Science, Duke University, Durham, NC, USA";" Department of Computer Science, Duke University, Durham, NC, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""218"",""230"",""The question of whether prefetching blocks on the file into the block cache can effectively reduce overall execution time of a parallel computation, even under favorable assumptions, is considered. Experiments have been conducted with an interleaved file system testbed on the Butterfly Plus multiprocessor. Results of these experiments suggest that (1) the hit ratio, the accepted measure in traditional caching studies, may not be an adequate measure of performance when the workload consists of parallel computations and parallel file access patterns, (2) caching with prefetching can significantly improve the hit ratio and the average time to perform an I/O (input/output) operation, and (3) an improvement in overall execution time has been observed in most cases. In spite of these gains, prefetching sometimes results in increased execution times (a negative result, given the optimistic nature of the study). The authors explore why it is not trivial to translate savings on individual I/O requests into consistently better overall performance and identify the key problems that need to be addressed in order to improve the potential of prefetching techniques in the environment.<>"",""1558-2183"","""",""10.1109/71.80133"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80133"","""",""Prefetching";File systems;Concurrent computing;Multiprocessing systems;System testing;Time measurement;Performance evaluation;Environmental management;"Operating systems"","""",""34"",""4"",""50"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"The banyan-hypercube networks,""A. S. Youssef";" B. Narahari"",""Department of Electrical Engineering and Computer Science, George Washington University, Washington D.C., DC, USA";" Dept. of Electr. Eng. & Comput. Sci., George Washington Univ., DC, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""2"",""160"",""169"",""The authors introduce a family of networks that are a synthesis of banyans and hypercubes and are called the banyan-hypercubes (BH). They combine the advantageous features of banyans and hypercubes and thus have better communication capabilities. The networks can be viewed as consisting of interconnecting hypercubes. It is shown that many hypercube features can be incorporated into BHs with regard to routing, embedding of rings and meshes, and partitioning, and that improvements over the hypercube result are made. In particular, it is shown that BHs have better diameters and average distances than hypercubes, and they embed pyramids and multiple pyramids with dilation cost 1. An optimal routing algorithm for BHs and an efficient partitioning strategy are presented.<>"",""1558-2183"","""",""10.1109/71.80144"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80144"","""",""Hypercubes";Routing;Costs;Network synthesis;Partitioning algorithms;Parallel machines;Multitasking;Image processing;"Scientific computing"","""",""35"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;
"The performance of spin lock alternatives for shared-money multiprocessors,""T. E. Anderson"",""Department of Computer Science and Engineering FR-35, University of Washington, Seattle, WA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""1"",""6"",""16"",""The author examines the questions of whether there are efficient algorithms for software spin-waiting given hardware support for atomic instructions, or whether more complex kinds of hardware support are needed for performance. He considers the performance of a number of software spin-waiting algorithms. Arbitration for control of a lock is in many ways similar to arbitration for control of a network connecting a distributed system. He applies several of the static and dynamic arbitration methods originally developed for networks to spin locks. A novel method is proposed for explicitly queueing spinning processors in software by assigning each a unique number when it arrives at the lock. Control of the lock can then be passed to the next processor in line with minimal effect on other processors.<>"",""1558-2183"","""",""10.1109/71.80120"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80120"","""",""Hardware";Data structures;Software algorithms;Software performance;Read-write memory;Spinning;Control systems;Costs;Marine technology;"Bandwidth"","""",""343"",""63"",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;
"The use of feedback in multiprocessors and its application to tree saturation control,""S. L. Scott";" G. S. Sohi"",""Computer Sciences Department, University of Wisconsin, Madison, Madison, WI, USA";" Computer Sciences Department, University of Wisconsin, Madison, Madison, WI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""4"",""385"",""398"",""Using feedback control schemes in multiprocessor systems is proposed. In a multiprocessor, individual processors do not have complete control over, nor information about, the overall state of the system. The potential exists, then, for the processors to unknowingly interact in such a way as to degrade the performance of the system. An example of this is the problem of tree saturation caused by hot-spot accesses in multiprocessors using multistage interconnection networks. Tree saturation degrades the performance of all processors in the system, including those not participating in the hot spot activity. Feedback schemes can be used to control tree saturation, reducing degradation to memory request that are not to the hot spot, thereby increasing overall system performance. As a companion to feedback schemes, damping schemes are also considered. Simulation studies show that feedback schemes can improve overall system performance significantly and with relatively little hardware cost in many cases. Damping schemes in conjunction with feedback are shown to further improve.<>"",""1558-2183"","""",""10.1109/71.80178"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80178"","""",""Control systems";Degradation;Multiprocessor interconnection networks;System performance;Output feedback;Damping;Student members;Feedback control;Multiprocessing systems;"Hardware"","""",""44"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"VMMP: a practical tool for the development of portable and efficient programs for multiprocessors,""E. Gabber"",""Computer Science Department, School of Mathematical Sciences, Tel-Aviv University, Tel-Aviv, Israel"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1990"",""1"",""3"",""304"",""317"",""The VMMP (virtual machine for multiprocessors) software package is presented. It provides a coherent set of services for parallel application programs running on diverse multiple input multiple data (MIMD) multiprocessors, including shared memory and message passing multiprocessors. The communication, synchronization, and data distribution requirements of parallel algorithms are analyzed. Related languages and tools are described. VMMP services are identified. VMMP implementation, coding and portability are discussed. Some measurements of the performance of VROMP application programs and VMMP overhead are given. Several hints for improving the performance of application programs are described.<>"",""1558-2183"","""",""10.1109/71.80158"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=80158"","""",""Virtual machining";Message passing;Parallel programming;Concurrent computing;Parallel algorithms;Packaging machines;High level languages;Software performance;"Hardware"","""",""15"","""",""51"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;