"A comparative study of topological properties of hypercubes and star graphs,""K. Day";" A. Tripathi"",""Computer Science Department, University of Bahrain, Isa Town, Bahrain";" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""1"",""31"",""38"",""Undertakes a comparative study of two important interconnection network topologies: the star graph and the hypercube, from the graph theory point of view. Topological properties are derived for the star graph and are compared with the corresponding properties of the hypercube. Among other results, the authors determine necessary and sufficient conditions for shortest path routing and characterize maximum-sized families of parallel paths between any two nodes of the star graph. These parallel paths are proven of minimum length within a small additive constant. They also define greedy and asymptotically balanced spanning trees to support broadcasting and personalized communication on the star graph. These results confirm the already claimed topological superiority of the star graph over the hypercube.<>"",""1558-2183"","""",""10.1109/71.262586"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=262586"","""",""Hypercubes";Tree graphs;Routing;Broadcasting;Concurrent computing;Computer science;Multiprocessor interconnection networks;Network topology;Graph theory;"Additives"","""",""174"",""2"",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A concurrent test architecture for massively parallel computers and its error detection capability,""M. V. A. Hancu"; K. Iwasaki; Y. Sato;" M. Sugie"",""Centre de Recherche Informatique de Montreal, Montreal, QUE, Canada"; Department of Information and Computer Sciences, Faculty of Engineering, Chiba University, Yayoi-cho, Chiba, Japan; Central Research Laboratory, Hitachi and Limited, Kokubunji, Tokyo, Japan;" Central Research Laboratory, Hitachi and Limited, Kokubunji, Tokyo, Japan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""11"",""1169"",""1184"",""Presents new principles for online monitoring in the context of multiprocessors (especially massively parallel processors) and then focuses on the effect of the aliasing probability on the error detection process. In the proposed test architecture, concurrent testing (or online monitoring) at the system level is accomplished by enforcing the run-time testing of the data and control dependences of the algorithm currently being executed on the parallel computer. In order to help in this process, each message contains both source and destination addresses. At each message source, the sequence of destination addresses of the outgoing messages is compressed on a block basis. At the same time, at each destination, the sequence of source addresses of all incoming messages is compressed, also on a block basis. Concurrent compression of the instructions executed by the PEs is also possible. As a result of this procedure, an image of the data dependences and of the control flow of the currently running algorithm is created. This image is compared, at the end of each computational block, with a reference image created at compilation time. The main results of this work are in proposing new principles for the online system-level testing of multiprocessor systems, based on signaturing and monitoring the data dependences together with the control dependences, and in providing an analytical model and analysis for the address compression process used for monitoring the data routing process.<>"",""1558-2183"","""",""10.1109/71.329671"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=329671"","""",""Computer architecture";Concurrent computing;System testing;Image coding;Computerized monitoring;Computer errors;Runtime;Control systems;Multiprocessing systems;"Analytical models"","""","""",""4"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"A decomposition algorithm for optimal static load balancing in tree hierarchy network configurations,""Jie Li";" H. Kameda"",""Institute of Information Sciences and Electronics, University of Tsukuba, Tsukuba, Ibaraki, Japan";" Institute of Information Sciences and Electronics, University of Tsukuba, Tsukuba, Ibaraki, Japan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""5"",""540"",""548"",""We study the static load balancing problem in a distributed computer system with the tree hierarchy configuration. It is formulated as a nonlinear optimization problem. After studying the conditions that the solution to the optimization problem of the tree hierarchy network satisfies, we demonstrate that the special structure of the optimization problem leads to an interesting decomposition technique. A new effective decomposition algorithm to solve the optimization problem is presented. The proposed algorithm Is compared with two other well known algorithms: the Flow Deviation (FD) algorithm and the Dafermos-Sparrow (D-S) algorithm. It is shown that the amounts of the storage required for the proposed algorithm and the FD algorithm are O(n) for load balancing of an n-node system. However, the amount of the storage required for the D-S algorithm is O(n log(n)). By using numerical experiments, we show that both the proposed algorithm and the D-S algorithm have much faster convergence in terms of central processing unit (CPU) time than the FD algorithm.<>"",""1558-2183"","""",""10.1109/71.282565"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=282565"","""",""Load management";Intelligent networks;Computer networks;Central Processing Unit;Workstations;Delay;Distributed computing;Convergence of numerical methods;Network topology;"Scheduling"","""",""14"",""1"",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A fast selection algorithm for meshes with multiple broadcasting,""D. Bhagavathi"; P. J. Looges; S. Olariu; J. L. Schwing;" J. Zhang"",""Department of Computer Science, Southern Illinois University Edwardsville, IL, USA"; Department of Computer Science, Old Dominion University, Norfolk, VA, USA; Department of Computer Science, Old Dominion University, Norfolk, VA, USA; Department of Computer Science, Old Dominion University, Norfolk, VA, USA;" Department of Mathematics and Computer Science, Elizabeth City State University, Elizabeth City, NC, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""7"",""772"",""778"",""One of the fundamental algorithmic problems in computer science involves selecting the kth smallest element in a collection A of n elements. We propose an algorithm design methodology to solve the selection problem on meshes with multiple broadcasting. Our methodology leads to a selection algorithm that runs in O(n/sup 1/8/(log n)/sup 3/4/)) time on a mesh with multiple broadcasting of size n/sup 3/8/(log n)/sup 1/4//spl times/n/sup 5/8//(log n)/sup 1/4/. This result is optimal over a large class of selection algorithms. Our result shows that just as for semigroup computations, selection can be done faster on suitably chosen rectangular meshes than on square meshes.<>"",""1558-2183"","""",""10.1109/71.296326"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=296326"","""",""Broadcasting";Computer science;Very large scale integration;Design methodology;Databases;Computer architecture;Computer vision;Cities and towns;Parallel algorithms;"Image processing"","""",""33"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals"""
"A framework for mapping periodic real-time applications on multicomputers,""S. B. Shukla";" D. P. Agrawal"",""Department of Electrical and Computer Engineering Code EC/Sh, Naval Postgraduate School, Monterrey, CA, USA";" Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""7"",""778"",""784"",""This short paper presents a framework for periodic execution of task-flow graphs that enables schedulability analysis of the communication requirements. The analysis performs the steps of segmenting messages, assigning the segments to specific links and time intervals, and ordering them within the intervals to generate node switching schedules that provide contention-free message routing at run-time. The analysis is also used to integrate task allocation with message routing using a contention-based objective function. Usefulness of the proposed scheme in ensuring guaranteed communication performance is demonstrated by an appropriate example.<>"",""1558-2183"","""",""10.1109/71.296323"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=296323"","""",""Routing";Runtime;Delay;Communication switching;Radar signal processing;Telecommunication traffic;Performance analysis;Mathematical programming;Channel allocation;"Resource management"","""",""11"",""1"",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A general scheme for token- and tree-based distributed mutual exclusion algorithms,""J. . -M. Helary"; A. Mostefaoui;" M. Raynal"",""IRISA Campus de Beaulieu, Université de Rennes, Rennes, France"; IRISA Campus de Beaulieu, Université de Rennes, Rennes, France;" IRISA Campus de Beaulieu, Université de Rennes, Rennes, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""11"",""1185"",""1196"",""In a distributed context, mutual exclusion algorithms can be divided into two families according to their underlying algorithmic principles: those that are permission-based and those that are token-based. Within the latter family, a lot of algorithms use a rooted tree structure to move the requests and the unique token. This paper presents a very general information structure (and the associated generic algorithm) for token- and tree-based mutual exclusion algorithms. This general structure not only covers, as particular cases, several known algorithms, but also allows for the design of new ones that are well suited for various topology requirements.<>"",""1558-2183"","""",""10.1109/71.329670"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=329670"","""",""Permission";Safety;Tree data structures;Algorithm design and analysis;Topology;Distributed algorithms;Communication channels;Clocks;Propagation delay;"Out of order"","""",""35"","""",""15"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"A genetic algorithm for multiprocessor scheduling,""E. S. H. Hou"; N. Ansari;" Hong Ren"",""Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA"; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA;" Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""2"",""113"",""120"",""The problem of multiprocessor scheduling can be stated as finding a schedule for a general task graph to be executed on a multiprocessor system so that the schedule length can be minimized. This scheduling problem is known to be NP-hard, and methods based on heuristic search have been proposed to obtain optimal and suboptimal solutions. Genetic algorithms have recently received much attention as a class of robust stochastic search algorithms for various optimization problems. In this paper, an efficient method based on genetic algorithms is developed to solve the multiprocessor scheduling problem. The representation of the search node is based on the order of the tasks being executed in each individual processor. The genetic operator proposed is based on the precedence relations between the tasks in the task graph. Simulation results comparing the proposed genetic algorithm, the list scheduling algorithm, and the optimal schedule using random task graphs, and a robot inverse dynamics computational task graph are presented.<>"",""1558-2183"","""",""10.1109/71.265940"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=265940"","""",""Genetic algorithms";Processor scheduling;Optimal scheduling;Multiprocessing systems;Scheduling algorithm;Heuristic algorithms;Robustness;Topology;Computational modeling;"Robots"","""",""482"",""11"",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"A pairwise substitutional fault tolerance technique for the cube-connected cycles architecture,""Nian-Feng Tzeng";" Po-Jen Chuang"",""The Center for Advanced Computer Studies, University of Southwestern Louisiana, Lafayette, LA, USA";" The Center for Advanced Computer Studies, University of Southwestern Louisiana, Lafayette, LA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""4"",""433"",""438"",""With all of the salient features of hypercubes, the cube-connected cycles (CCC) structure is an attractive parallel computation network suited for very large scale integration (VLSI) implementation because of its layout regularity. Unfortunately, the classical CCC structure tends to suffer from considerable performance degradation in the presence of faults. The authors deal with a fault-tolerant CCC structure obtained by incorporating a spare PE in each cycle and by adding extra links among PE's to realize dimensional substitutes for failed PE's in the immediate lower dimension. A unique feature of this design lies in that a faulty PE and its laterally connected PE are always replaced at the same time by their immediate vertical successor pair, achieving pairwise substitution to elegantly maintain the rigid full CCC structure after faulty PE's arise. The proposed structure improves reliability substantially without incurring large overhead in layout area. This design is compared with earlier fault-tolerant CCC designs in terms of normalized reliability, which takes area overhead into account. An extension to this fault-tolerant structure is also discussed.<>"",""1558-2183"","""",""10.1109/71.273049"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=273049"","""",""Fault tolerance";Hypercubes;Very large scale integration;Fault tolerant systems;Topology;Computer architecture;Degradation;Parallel processing;Computer networks;"Concurrent computing"","""",""3"","""",""8"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A parallel algorithm for computing Fourier transforms on the star graph,""P. Fragopoulou";" S. G. Akl"",""Department of Computing and Information Science, Queen's University, Kingston, ONT, Canada";" Department of Computing and Information Science, Queen's University, Kingston, ONT, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""5"",""525"",""531"",""The n-star graph, denoted by S/sub n/, is one of the graph networks that have been recently proposed as attractive alternatives to the n-cube topology for interconnecting processors in parallel computers. We present a parallel algorithm for the computation of the Fourier transform on the star graph. The algorithm requires O(n/sup 2/) multiply-add steps for an input sequence of n! elements, and is hence cost-optimal with respect to the sequential algorithm on which it is based. This is believed to be the first algorithm, and the only one to date, for the computation of the Fourier transform on the star graph.<>"",""1558-2183"","""",""10.1109/71.282562"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=282562"","""",""Parallel algorithms";Concurrent computing;Fourier transforms;Telecommunication computing;Network topology;Computer networks;Hypercubes;Cost function;"Fast Fourier transforms"","""",""42"","""",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"A performance model for multilayer neural networks in linear arrays,""D. Naylor";" S. Jones"",""Department of Electronic and Electrical Engineering, Loughborough University of Technology, Loughborough, Leicestershire, UK";" Department of Electronic and Electrical Engineering, Loughborough University of Technology, Loughborough, Leicestershire, UK"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""12"",""1322"",""1328"",""An analytical model is presented for assessing the performance of multilayer neural networks implemented in linear arrays. Metrics to assess latency, throughput rate, and computational and input-output bandwidth are developed. These metrics demonstrate a rich and complex interaction between the performance of the hardware and the number and relative dimensions of the layers in a network. Practical illustration of the use of these metrics is demonstrated for a two-hidden-layer network.<>"",""1558-2183"","""",""10.1109/71.334906"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=334906"","""",""Multi-layer neural network";Neural networks;Intelligent networks;Throughput;Delay;Analytical models;Neural network hardware;Artificial neural networks;Clocks;"Bandwidth"","""",""4"","""",""4"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A performance study of robust distributed load sharing strategies,""A. Leff";" P. S. Yu"",""IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA";" IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""12"",""1286"",""1301"",""In this paper, we examine a set of load sharing strategies that are robust to the unreliable state information that is often present in a distributed database system. In this environment, sites must solve the problem of how alternative sites should be selected to process incoming transactions, given that the information on which the decision is based exhibits varying degrees of obsolescence. A set of regression-based adaptive strategies is examined in which a feedback mechanism is used to compensate for obsolete information. Transaction response time under the different adaptive strategies is evaluated, and the reasons for these performance differences discussed. The key characteristic of the best regression strategy is that transaction site affinity is taken into consideration when adjusting for the effect of information obsolescence.<>"",""1558-2183"","""",""10.1109/71.334902"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=334902"","""",""Robustness";Delay;Routing;Frequency;Database systems;Feedback;Costs;Queueing analysis;Bayesian methods;"Decision theory"","""",""8"","""",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A period-processor-time-minimal schedule for cubical mesh algorithms,""C. Scheiman";" P. Cappello"",""Department of Computer Science, University of California, Santa Barbara, CA, USA";" Department of Computer Science, University of California, Santa Barbara, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""3"",""274"",""280"",""Using a directed acyclic graph (dag) model of algorithms, we investigate precedence-constrained multiprocessor schedules for the n/spl times/n/spl times/n directed mesh. This cubical mesh is fundamental, representing the standard algorithm for square matrix product, as well as many other algorithms. Its completion requires at least 3/sup n/spl minus/2/ multiprocessor steps. Time-minimal multiprocessor schedules that use as few processors as possible are called processor-time-minimal. For the cubical mesh, such a schedule requires at least /spl lsqb/3n/sup 2//4/spl rsqb/ processors. Among such schedules, one with the minimum period (i.e., maximum throughput) is referred to as a period-processor-time-minimal schedule. The period of any processor-time-minimal schedule for the cubical mesh is at least 3/sup n/2/ steps. This lower bound is shown to be exact by constructing, for n a multiple of 6, a period-processor-time-minimal multiprocessor schedule that can be realized on a systolic array whose topology is a toroidally connected n/2/spl times/n/2/spl times/3 mesh.<>"",""1558-2183"","""",""10.1109/71.277790"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=277790"","""",""Scheduling algorithm";Processor scheduling;Computational modeling;Systolic arrays;Very large scale integration;Throughput;Topology;Computational complexity;Boolean functions;"Algorithm design and analysis"","""",""8"","""",""11"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A reconfigurable modular fault-tolerant hypercube architecture,""C. S. Yang"; L. . -P. Zu;" Y. N. Wu"",""Institute of Computer and Information Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan"; Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan;" Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""10"",""1018"",""1032"",""We propose a new fault-tolerant design of a hypercube system. We first build the fault-tolerant modules (FTM's), then we interconnect these FTM's as the modular hypercube. Finally, we obtain our proposed system by augmenting links, called the spare-sharing links (SSL's), in the modular hypercube, which forms a ring connection in our architecture. The characteristic of our system is that the spare nodes in an FTM can be used as local spares to replace the faulty nodes in the FTM, or as remote spares to replace the faulty nodes in other FTM's via the spare-sharing links in the architecture. Thus, the use of spare nodes in any FTM will increase, and the proposed system reliability will improve. In the system, the switch and link failures are also considered. The modular diagnosis and modular reconfiguration are proposed to identify and reconfigure the failure of nodes, switches, and links.<>"",""1558-2183"","""",""10.1109/71.313119"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=313119"","""",""Fault tolerance";Hypercubes;Fault tolerant systems;Switches;Fault diagnosis;Large-scale systems;Computer network reliability;Binary trees;Multiprocessor interconnection networks;"Redundancy"","""",""3"","""",""9"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"A scalable parallel formulation of the backpropagation algorithm for hypercubes and related architectures,""V. Kumar"; S. Shekhar;" M. B. Amin"",""Department of Computer Science, University of Minnesota, Minneapolis, MN, USA"; Department of Computer Science, University of Minnesota, Minneapolis, MN, USA;" Department of Computer Science, University of Minnesota, Minneapolis, MN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""10"",""1073"",""1090"",""We present a new technique for mapping the backpropagation algorithm on hypercube and related architectures. A key component of this technique is a network partitioning scheme called checkerboarding. Checkerboarding allows us to replace the all-to-all broadcast operation performed by the commonly used vertical network partitioning scheme, with operations that are much faster on the hypercubes and related architectures. Checkerboarding can be combined with the pattern partitioning technique to form a hybrid scheme that performs better than either one of these schemes. Theoretical analysis and experimental results on nCUBE and CM5 show that our scheme performs better than the other schemes, for both uniform and nonuniform networks.<>"",""1558-2183"","""",""10.1109/71.313123"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=313123"","""",""Backpropagation algorithms";Hypercubes;Broadcasting;Concurrent computing;Neural networks;Partitioning algorithms;Computer architecture;Performance analysis;"Application software"","""",""46"","""",""45"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"A service acquisition mechanism for server-based heterogeneous distributed systems,""R. N. Chang";" C. V. Ravishankar"",""Bell Communications Research, Inc., Morristown, NJ, USA";" Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""2"",""154"",""169"",""This paper presents a mechanism that facilitates and enhances the use of independently administered remote network servers in the presence of server interface heterogeneity. The mechanism is designed under the client-service model, which extends the client-server model with an abstraction of service to decouple abstract server capabilities from concrete server interface specifics such as server interface binding protocols and the interface operation invocation protocols. The mechanism selects servers, accommodates server interface heterogeneity, and handles server access failures as per the abstract server capabilities desired by the client. It could return the identity of the server used for each service access invocation to facilitate billing, refining service specifications, and reporting server-specific errors. This paper also illustrates a C library interface to this mechanism, and describes a language veneer over the C programming language demonstrating how a typed procedural language could be extended by a few language constructs to support the mechanism under the client-service model. In this language, server capabilities are referenced by abstract data type (ADT) objects, and are accessed by invoking the objects' interface operations using a call-by-value-result paradigm.<>"",""1558-2183"","""",""10.1109/71.265943"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=265943"","""",""Network servers";Object oriented modeling;Software libraries;Concrete;Access protocols;Computer languages;Software systems;Software maintenance;Distributed computing;"Fault tolerant systems"","""",""5"",""7"",""29"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"A systolic-based parallel bin packing algorithm,""J. O. Berkey";" P. Y. Wang"",""Booz Allen and Hamilton, Inc., Vienna, VA, USA";" Department of Computer Science, MS 4A5, George Mason University, Fairfax, VA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""7"",""769"",""772"",""A systolic based parallel approximation algorithm that obtains solutions to the I-D bin packing problem is presented. The algorithm has an asymptotic error bound of 1.5 and time complexity O(n). An experimental study demonstrates that the heuristic offers improved packing and execution performance over parallelizations of two well-known serial algorithms.<>"",""1558-2183"","""",""10.1109/71.296322"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=296322"","""",""Approximation algorithms";Computer science;Concurrent computing;Application software;Operations research;Parallel algorithms;Computational modeling;"Systolic arrays"","""",""6"","""",""9"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Access graphs: a model for investigating memory consistency,""D. H. Linder";" J. C. Harden"",""NSF Engineering Research Center for Computational Field Simulation, Mississippi State University, MS, USA";" Department of Electrical and Computer Engineering and the NSF Engineering Research Center for Computational Field Simulation, Mississippi State University, MS, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""1"",""39"",""52"",""Computer architectures supporting shared memory continue to increase in complexity as designers seek to improve memory performance. This is especially true of proposals for massively parallel systems with distributed, yet shared, memory. The need to maintain a reasonably simple memory model for programmers, in spite of enhancements like caches and access pipelining, is responsible for many of the complications. We develop a novel graph model, access graphs, for visualizing processor/memory interaction. Access graphs symbolically represent the causal relationships between load, store, and synchronization events. The focus is on two classes of access graphs: pseudo and real. A pseudo access graph describes an execution in terms of abstract events familiar to the programmer. If the pseudo access graph is acyclic, then memory consistency is preserved during the execution. A real access graph describes an execution in terms of physical events known to the hardware designer. A real access graph must be acyclic since hardware cannot violate causality. Memory consistency can be verified for a given computer system by proving that for any acyclic real access graph describing a program's execution on that computer, an acyclic pseudo access graph can be derived describing the same execution.<>"",""1558-2183"","""",""10.1109/71.262587"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=262587"","""",""Hardware";Programming profession;Memory architecture;Proposals;Pipeline processing;Visualization;Stress;Message passing;Computational modeling;"Displays"","""",""2"",""1"",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Adaptive binary sorting schemes and associated interconnection networks,""M. V. Chien";" A. Yavuz Oruc"",""Department of Electrical Engineering and lnstitute for Advanced Computcr Studies, University of Maryland, College Park, MD, USA";" PRC, Inc., McLean, VA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""6"",""561"",""572"",""Many routing problems in parallel processing, such as concentration and permutation problems, can be cast as sorting problems. In this paper, we consider the problem of sorting on a new model, called an adaptive sorting network. We show that any sequence of n bits can be sorted on this model in O(lg/sup 2/ n) bit-level delay using O(n) constant fanin gates. This improves the cost complexity of K.E. Batcher's binary sorters (1968) by a factor of O(lg/sup 2/ n) while matching their sorting time. The only other network that can sort binary sequences in O(n) cost is the network version of columnsort algorithm, but this requires excessive pipelining. In addition, using binary sorters, we construct permutation networks with O(n lg n) bit-level cost and O(lg/sup 3/ n) bit-level delay. These results provide the asymptotically least-cost practical concentrators and permutation networks to date. We note, of course, that the well-known AKS sorting network has O(lg n) sorting time and O(n lg n) cost, but the constants hidden in these complexities are so large that our complexities outperform those of the AKS sorting network until n becomes extremely large.<>"",""1558-2183"","""",""10.1109/71.285603"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285603"","""",""Sorting";Multiprocessor interconnection networks;Costs;Switches;Computer networks;Routing;Parallel processing;Adaptive systems;Delay;"Binary sequences"","""",""15"",""2"",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Adaptive deadlock- and livelock-free routing in the hypercube network,""G. D. Pifarre"; L. Gravano; G. Denicolay;" J. L. C. Sanz"",""Advanced Solutions and Innovative Technologies Department, IBM Argentina, Ing., Buenos Aires, Argentina"; Computer Science Department, University of Stanford, Stanford, CA, USA; ESLAI, Escuela Superior Latinoamericana de Informatica, Buenos Aires, Argentina;" Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""11"",""1121"",""1139"",""This paper consists of two parts. In the first one, two new algorithms for wormhole routing on the hypercube network are presented. These techniques are adaptive and are ensured to be deadlock- and livelock-free. These properties are guaranteed by using a small number of resources in the routing node. The first algorithm is adaptive and nonminimal and will be referred to as Nonminimal. In this technique, some moderate derouting is allowed in order to alleviate the potential congestion arising from highly structured communication patterns. The second algorithm, dubbed Subcubes, is adaptive and minimal, and is based on partitioning the hypercube into subcubes of smaller dimension"; This technique requires only two virtual channels per physical link of the node. In the second part of the paper, a wide variety of techniques for wormhole routing in the hypercube are evaluated from an algorithmic point of view. Five partially adaptive algorithms are considered: the Hanging algorithm, the Zenith algorithm, the Hanging-Order algorithm, the Nonminimal algorithm;" and the Subcubes algorithm. One oblivious algorithm, the Dimension-Order, or E-Cube routing algorithm, is also used. Finally, a Fully Adaptive Minimal algorithm is tried. A simple node model was designed and adapted to all the algorithms.<>"",""1558-2183"","""",""10.1109/71.329674"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=329674"","""",""System recovery";Routing;Intelligent networks;Hypercubes;Partitioning algorithms;Adaptive algorithm;Algorithm design and analysis;Computer networks;Concurrent computing;"Computational modeling"","""",""11"",""7"",""42"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals"""
"Adaptive deadlock- and livelock-free routing with all minimal paths in torus networks,""L. Gravano"; G. D. Pifarre; P. E. Berman;" J. L. C. Sanz"",""Computer Science Department, University of Stanford, Stanford, CA, USA"; Departamento de Computación. Fac. de Ciencias Exactas y Naturales, Universidad de Buenos Aires, Argentina; ESLAI, Escuela Superior Latinoamericana de Informática, Buenos Aires, Argentina;" Advances Solutions and Innovative Technologies Department, IBM Argentina, Ing., Buenos Aires, Argentina"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""12"",""1233"",""1251"",""This paper consists of two parts. In the first part, two new algorithms for deadlock- and livelock-free wormhole routing in the torus network are presented. The first algorithm, called Channels, is for the n-dimensional torus network. This technique is fully-adaptive minimal, that is, all paths with a minimal number of hops from source to destination are available for routing, and needs only five virtual channels per bidirectional link, the lowest channel requirement known in the literature for fully-adaptive minimal worm-hole routing. In addition, this result also yields the lowest buffer requirement known in the literature for packet-switched fully-adaptive minimal routing. The second algorithm, called 4-Classes, is for the bidimensional torus network. This technique is fully-adaptive minimal and requires only eight virtual channels per bidirectional link. Also, it allows for a highly parallel implementation of its associated routing node. In the second part of this paper, four worm-hole routing techniques for the two-dimensional torus are experimentally evaluated using a dynamic message injection model and different traffic patterns and message lengths.<>"",""1558-2183"","""",""10.1109/71.334898"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=334898"","""",""System recovery";Routing;Intelligent networks;Computational modeling;Computer networks;Concurrent computing;Computer simulation;Multiprocessor interconnection networks;Computer science;"Hypercubes"","""",""55"",""25"",""47"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Adding multiple-fault tolerance to generalized cube networks,""C. J. Shih";" K. E. Batcher"",""Department of Computer and Information Science, Youngstown State University, Youngstown, OH, USA";" Department of Mathematics and Computer Science, Kent University, Kent, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""8"",""785"",""792"",""Generalized cube networks are limited to single-fault tolerance with respect to permutation connections. The vector space approach presented here yields many fault-tolerance schemes that can tolerate two and three faults. In each scheme, redundant switches and links are added to networks and interconnected in certain ways. These redundancies are represented by a matrix called the redundancy matrix. A fault-free network without redundancy is represented by an identity matrix. As faulty switches and links are discovered, the remaining switches and links are remapped to establish an intact network. The remapping is analogous to converting an invertible redundancy matrix back to an identity matrix.<>"",""1558-2183"","""",""10.1109/71.298202"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298202"","""",""Switches";Fault tolerance;Redundancy;Matrix converters;Hypercubes;Computer aided instruction;Computer networks;Concurrent computing;Parallel processing;"Hardware"","""",""8"",""1"",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Aggressive transmissions of short messages over redundant paths,""B. Kao"; H. Garcia-Molina;" D. Barbara"",""Department of Computer Science, Princeton University, Princeton, NJ, USA"; Department of Computer Science, University of Stanford, Stanford, CA, USA;" M.I.T.I., Princeton, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""1"",""102"",""109"",""Fault-tolerant computer systems have redundant paths connecting their components. Given these paths, it is possible to use aggressive techniques to reduce the average value and variability of the response time for short, critical messages. One technique is to send a copy of a packet over an alternate path before it is known whether the first copy failed or was delayed. A second technique is to split a single stream of packets over multiple paths. The authors analyze both approaches and show that they can provide significant improvements over conventional, conservative mechanisms.<>"",""1558-2183"","""",""10.1109/71.262594"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=262594"","""",""Switches";Computer science;Delay effects;Fault tolerance;Application software;Computer applications;Computer network reliability;Telecommunication network reliability;Local area networks;"Joining processes"","""",""29"",""2"",""19"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Algorithms and average time bounds of sorting on a mesh-connected computer,""Qian Ping Gu";" Jun Gu"",""Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada";" Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""3"",""308"",""315"",""We give three new parallel sorting algorithms on a mesh-connected computer with wraparound connections (i.e. a torus). These three algorithms, with the minimum queue size of 1, sort n/sup 2/ random input data items into a blocked snakelike row major order, a row major order, and a snakelike row major order, in 1.5n+o(n), 2n+o(n), and 2n+o(n) average steps, respectively. These results improve the previous results of 2n+o(n), 2.5n+o(n), and 2.5n+o(n), respectively. In addition, we prove that the distance bound n on a torus is an average-time lower bound independent of indexing schemes of sorting random input data items on it.<>"",""1558-2183"","""",""10.1109/71.277787"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=277787"","""",""Sorting";Concurrent computing;Computational modeling;Parallel algorithms;Very large scale integration;Indexing;History;Upper bound;Software;"Cities and towns"","""",""10"","""",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Allocating precise submeshes in mesh connected systems,""Po-Jen Chuang";" Nian-Feng Tzeng"",""Department of Electrical Engineering, Tamkang University, Taipei, Taiwan";" Center for Advanced Computer Studies, University of Southwestern Louisiana, Lafayette, LA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""2"",""211"",""217"",""We propose a new processor allocation strategy that applies to any mesh system and recognizes submeshes of arbitrary sizes at any locations in a mesh system. The proposed strategy allocates a submesh of exactly the size requested by an incoming task, completely avoiding internal fragmentation. Because of its efficient allocation, this strategy exhibits better performance than an earlier allocation strategy based on the buddy principle. An efficient implementation of this strategy is presented. Extensive simulation runs are carried out to collect experimental cost and performance measures of interest under different allocation schemes.<>"",""1558-2183"","""",""10.1109/71.265948"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=265948"","""",""Costs";Very large scale integration;Topology;Distributed control;Parallel architectures;Prototypes;Image processing;Partial differential equations;Supercomputers;"Memory management"","""",""46"","""",""11"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Allocating tree structured programs in a distributed system with uniform communication costs,""A. Billionnet"",""Institut dInformatique dEnterprise, CEDRIC, Evry, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""4"",""445"",""448"",""Studies the complexity of the problem of allocating m modules to n processors in a distributed system to minimize total communication and execution costs. When the communication graph is a tree, Bokhari has shown that the optimum allocation can be determined in O(mn/sup 2/) time. Recently, this result has been generalized by Fernandez-Baca, who has proposed an allocation algorithm in O(mn/sup k+1/) when the communication graph is a partial k-tree. The author shows that in the case where communication costs are uniform, the module allocation problem can be solved in O(mn) time if the communication graph is a tree. This algorithm is asymptotically optimum.<>"",""1558-2183"","""",""10.1109/71.273051"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=273051"","""",""Tree graphs";Polynomials;Computer networks;Cost function;Distributed computing;"Approximation algorithms"","""",""16"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;
"Almost certain fault diagnosis through algorithm-based fault tolerance,""D. M. Blough";" A. Pelc"",""Department of Electrical and Computer Engineering, University of California, Irvine, CA, USA";" Département dInfomatique, Université du Quàbec à Hull, QUE, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""5"",""532"",""539"",""Algorithm-based fault tolerance has been proposed as a technique to detect incorrect computations in multiprocessor systems. In algorithm-based fault tolerance, processors produce data elements that are checked by concurrent error detection mechanisms. We investigate the efficacy of this approach for diagnosis of processor faults. Because checks are performed on data elements, the problem of location of data errors must first be solved. We propose a probabilistic model for the faults and errors in a multiprocessor system and use it to evaluate the probabilities of correct error location and fault diagnosis. We investigate the number of checks that are necessary to guarantee error location with high probability. We also give specific check assignments that accomplish this goal. We then consider the problem of fault diagnosis when the locations of erroneous data elements are known. Previous work on fault diagnosis required that the data sets produced by different processors be disjoint. We show, for the first time, that fault diagnosis is possible with high probability, even in systems where processors combine to produce individual data elements.<>"",""1558-2183"","""",""10.1109/71.282563"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=282563"","""",""Fault diagnosis";Fault tolerance;Fault detection;Error correction;Multiprocessing systems;Fault tolerant systems;Testing;Computer errors;Failure analysis;"Transient analysis"","""",""7"","""",""22"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"An equivalence theorem for labeled marked graphs,""Y. Wolfstahl";" M. Yoeli"",""Adv. Technol. Centers, IBM Res. Group, Haifa, Israel";" Department of Computer Science, Technion-Israel Institute of Technology, Haifa, Israel"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""8"",""886"",""891"",""Petri nets and their languages are a useful model of systems exhibiting concurrent behavior. The sequential language associated with a given Petri net S consists of all possible firing sequences of S, where each element of a firing sequence is a single transition. The concurrent language associated with S consists of all possible concurrent firing sequences of S, where each element of a concurrent firing sequence is a set of transitions. The sequential language and the concurrent language associated with S are denoted by (L)(S) and (/spl pi/)(S), respectively. In this paper, we consider an important special ease of Petri nets, called labeled marked graphs. The main result derived in this paper states that if /spl Gammasub 1/ and /spl Gammasub 2/ are two structurally deterministic labeled marked graphs, then (L)(/spl Gammasub 1/)=L(/spl Gammasub 2/)/spl rlhar2spl pi/(/spl Gammasub 1/)=/spl pi/(/spl Gammasub 2/).<>"",""1558-2183"","""",""10.1109/71.298217"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298217"","""",""Petri nets";Concurrent computing;"Bars"","""",""2"","""",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;
"An optimal strategy for comparing file copies,""K. A. S. Abdel-Ghaffar";" A. El Abbadi"",""Department of Electrical Engineering and Computer Science, University of California, Davis, CA, USA";" Department of Computer Science, University of California, Santa Barbara, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""1"",""87"",""93"",""We study the problem of identifying corrupted pages between two remotely located copies of a file in a distributed system. An efficient deterministic algorithm is presented to identify up to any given number of differing pages. The algorithm requires a single exchange of messages and is based on the structure of the Reed-Solomon code. In order to identify up to f corrupted pages, 2f signatures are transmitted. The algorithm requires less communication costs than previously proposed solutions. In fact, we prove that our algorithm is optimal, in the sense that no other algorithm is guaranteed to identify with probability 1 the corrupted pages by exchanging less information.<>"",""1558-2183"","""",""10.1109/71.262591"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=262591"","""",""Broadcasting";Reed-Solomon codes;Costs;Distributed computing;Database systems;Availability;Communication system control;Access protocols;File servers;"Network servers"","""",""21"",""3"",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Analysis of asynchronous polynomial root finding methods on a distributed memory multicomputer,""M. Cosnard";" P. Fraigniaud"",""Ecole Normale Supérieure de Lyon, Lyon, France";" Ecole Normale Supérieure de Lyon, Lyon, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""6"",""639"",""648"",""We have studied various implementations of iterative polynomial root finding methods on a distributed memory multicomputer. These methods are based on the construction of a sequence of approximations that converge to the set of zeros. The synchronous version consists in sharing the computation of the next iterate among the processors and updating their data through a total exchange of their results. In order to decrease the communication cost, we introduce asynchronous versions. The computation of the next iterate is still shared among the processor, but the updating is done by using only nearest neighbor communications. We prove that under weak conditions, these asynchronous versions are still locally convergent, even if their convergence orders are reduced. We analyze the behavior of the asynchronous methods in function of their delay, the topology of the interconnection network, and the elementary computation and communication times. We have implemented and compared these methods on a hypercube multicomputer.<>"",""1558-2183"","""",""10.1109/71.285609"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285609"","""",""Polynomials";Convergence;Newton method;Costs;Nearest neighbor searches;Network topology;Multiprocessor interconnection networks;Computer networks;Hypercubes;"Distributed computing"","""",""16"","""",""62"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Analysis of processor allocation in multiprogrammed, distributed-memory parallel processing systems,""S. K. Setia"; M. S. Squillante;" S. K. Tripathi"",""Department of Computer Science, George Mason University, Fairfax, VA, USA"; IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA;" Department of Computer Science and the Institute for Advanced Computer Studies, University of Maryland, College Park, MD, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""4"",""401"",""420"",""A main objective of scheduling independent jobs composed of multiple sequential tasks in shared-memory and distributed-memory multiprocessor computer systems is the assignment of these tasks to processors in a manner that ensures efficient operation of the system. Achieving this objective requires the analysis of a fundamental tradeoff between maximizing parallel execution, suggesting that the tasks of a job be spread across all system processors, and minimizing synchronization and communication overheads, suggesting that the job's tasks be executed on a single processor. The authors consider a class of scheduling policies that represent the essential aspects of this processor allocation tradeoff, and model the system as a distributed fork-join queueing system. They derive an approximation for the expected job response time, which includes the important effects of various parallel processing overheads (such as task synchronization and communication) induced by the processor allocation policy.<>"",""1558-2183"","""",""10.1109/71.273047"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=273047"","""",""Parallel processing";Costs;Processor scheduling;Concurrent computing;Delay;Distributed computing;Queueing analysis;Computer science;Senior members;"Adaptive scheduling"","""",""17"","""",""49"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Communication aspects of the star graph interconnection network,""J. Misic";" Z. Jovanovic"",""Computer Systems Design Laboratory, Department 270, Vinća Institute of Nuclear Sciences, Belgrade, Serbia";" Department of Computer Science, University of Belgrade, Belgrade, Serbia"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""7"",""678"",""687"",""Basic communication algorithms for star graph interconnection networks are developed by using the hierarchical properties of the star graph, with the assumption that one input channel can drive only one output communication channel at a time. With this constraint, communication algorithms for each node can be expressed only as sequences of generators corresponding to the communication channels. Sequences that are identical exploit the symmetry and hierarchical properties of the star graph and can be easily integrated in communication hardware. Their time complexities are evaluated and compared with the corresponding results for the hypercube.<>"",""1558-2183"","""",""10.1109/71.296314"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=296314"","""",""Multiprocessor interconnection networks";Routing;System recovery;Broadcasting;Communication channels;Algorithm design and analysis;Fault tolerance;Sorting;Scattering;"Hardware"","""",""30"",""4"",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Communication-free data allocation techniques for parallelizing compilers on multicomputers,""Tzung-Shi Chen";" Jang-Ping Sheu"",""Department of Computer Science and Information Engineering, National Central University, Chungli, Taiwan";" Department of Computer Science and Information Engineering, National Central University, Chungli, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""9"",""924"",""938"",""In distributed memory multicomputers, local memory accesses are much faster than those involving interprocessor communication. For the sake of reducing or even eliminating the interprocessor communication, the array elements in programs must be carefully distributed to local memory of processors for parallel execution. We devote our efforts to the techniques of allocating array elements of nested loops onto multicomputers in a communication-free fashion for parallelizing compilers. We first analyze the pattern of references among all arrays referenced by a nested loop, and then partition the iteration space into blocks without interblock communication. The arrays can be partitioned under the communication-free criteria with nonduplicate or duplicate data. Finally, a heuristic method for mapping the partitioned array elements and iterations onto the fixed-size multicomputers under the consideration of load balancing is proposed. Based on these methods, the nested loops can execute without any communication overhead on the distributed memory multicomputers. Moreover, the performance of the strategies with nonduplicate and duplicate data for matrix multiplication is studied.<>"",""1558-2183"","""",""10.1109/71.308531"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=308531"","""",""Parallel processing";Program processors;Random access memory;Data mining;Parallel machines;Pattern analysis;Load management;Councils;Computer science;"Magnetic heads"","""",""34"","""",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Compiling for distributed memory architectures,""A. Rogers";" K. Pingali"",""Department of Computer Science, Princeton University, Princeton, NJ, USA";" Department of Computer Science, Cornell University, Ithaca, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""3"",""281"",""298"",""The lack of high-level languages and good compilers for parallel machines hinders their widespread acceptance and use. Programmers must address issues such as process decomposition, synchronization, and load balancing. We have developed a parallelizing compiler that, given a sequential program and a memory layout of its data, performs process decomposition while balancing parallelism against locality of reference. A process decomposition is obtained by specializing the program for each processor to the data that resides on that processor. If this analysis fails, the compiler falls back to a simple but inefficient scheme called run-time resolution. Each process's role in the computation is determined by examining the data required for execution at run-time. Thus, our approach to process decomposition is data-driven rather than program-driven. We discuss several message optimizations that address the issues of overhead and synchronization in message transmission. Accumulation reorganizes the computation of a commutative and associative operator to reduce message traffic. Pipelining sends a value as close to its computation as possible to increase parallelism. Vectorization of messages combines messages with the same source and the same destination to reduce overhead. Our results from experiments in parallelizing SIMPLE, a large hydrodynamics benchmark, for the Intel iPSC/2, show a speedup within 60% to 70% of handwritten code.<>"",""1558-2183"","""",""10.1109/71.277789"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=277789"","""",""Memory architecture";Parallel processing;Runtime;High level languages;Parallel machines;Programming profession;Load management;Program processors;Failure analysis;"Commutation"","""",""27"",""1"",""35"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Computing network flow on a multiple processor pipeline,""P. Agrawal";" A. Ng"",""AT and T Bell Laboratories, Inc., Murray Hill, NJ, USA";" Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""6"",""653"",""658"",""We demonstrate the feasibility of a distributed implementation of the Goldberg-Tarjan algorithm for finding the maximum flow in a network. Unlike other parallel implementations of this algorithm, where the network graph is partitioned among many processors, we partition the algorithm among processors arranged in a pipeline. The network graph data are distributed among the processors according to local requirements. The partitioned algorithm is implemented on six processors within a 15-processor pipelined message-passing multicomputer operating at 5 MHz. We used randomly generated networks with integer capacities as examples. Performance estimates based upon a six-processor pipelined implementation indicated a speedup between 3.8 and 5.9 over a single processor.<>"",""1558-2183"","""",""10.1109/71.285611"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285611"","""",""Computer networks";Pipelines;Fault tolerance;Signal processing algorithms;Partitioning algorithms;Equations;Fault tolerant systems;Operations research;Linear code;"Signal processing"","""","""","""",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Concurrent communication in high-speed wide area networks,""J. K. Antonio"",""School of Electrical Engineering, Purdue University, West Lafayette, IN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""3"",""264"",""273"",""A performance metric called receptivity is introduced for quantifying the degree of concurrent communication possible in high-speed wide area networks (WAN's). Given a stochastic demand pattern model, receptivity is defined to be the probability that all requested connections can be established concurrently. Because calculation of the exact value of receptivity is shown to (generally) have an exponential complexity, an analytic estimate for its value is derived. The derived estimate is dependent on network parameters such as the number of links, link capacity values, and a weighted hop distance metric (which depends on the topological structure of the network and its relationship to parameter values of the stochastic model for the demand patterns). The derived estimate for the proposed metric compares reasonably well with simulated values for several asymmetric topological structures ranging from planar meshes to random graphs. The utility of the estimate is twofold. First, it can be computed quickly, i.e., in polynomial time. Second, its simple analytic form provides the network architect with insight into some of the inherent limitations and consequences associated with topological design choices for high-speed WAN's.<>"",""1558-2183"","""",""10.1109/71.277791"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=277791"","""",""Intelligent networks";Wide area networks;Network topology;Stochastic processes;Propagation delay;Bandwidth;Delay estimation;Measurement;Computational modeling;"Polynomials"","""",""1"","""",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Concurrent processing of linearly ordered data structures on hypercube multicomputers,""J. Ghosh"; S. K. Das;" A. John"",""Department of Electrical and Computer Engineering, University of Texas, Austin, TX, USA"; Center for Research in Parallel and Distributed Computing, Department of Computer Science, University of North Texas, Denton, TX, USA;" Department of Computer Science, University of Technology, Austin, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""9"",""898"",""911"",""The paper presents a simple and effective method for the concurrent manipulation of linearly ordered data structures on hypercube systems. The method Is based on the existence of an augmented binomial search tree, called the pruned binomial tree, rooted at any arbitrary processor node of the hypercube such that"; every edge of the tree corresponds to a direct link between a pair of hypercube nodes;" and the tree spans any arbitrary sequence of n consecutive nodes containing the root, using a fanout of at most [log/sub 2/ n] and a depth of at most [log/sub 2/ n]+1. Search trees spanning nonoverlapping processor lists are formed using only local information, and can be used concurrently without contention problems. Thus, they can be used for performing operations such as broadcast and merge simultaneously on sets with nonuniform sizes. Extensions of the tree to k-ary n-cubes and faulty hypercubes are presented. Applications of this concurrent data structure to low- and intermediate-level image processing algorithms, and for dictionary operations involving multiple keys, are also outlined.<>"",""1558-2183"","""",""10.1109/71.308529"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=308529"","""",""Data structures";Hypercubes;Broadcasting;Tree data structures;USA Councils;Dictionaries;Reflective binary codes;Distributed computing;Computer science;"Image processing"","""",""1"","""",""44"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Constant-time parallel algorithms for image labeling on a reconfigurable network of processors,""H. M. Alnuweiri"",""Department of Electrical Engineering and the Centre for Integrated Computer Research Systems, University of British Columbia, Vancouver, BC, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""3"",""320"",""326"",""A constant-time algorithm for labeling the connected components of an N/spl times/N image on a reconfigurable network of N/sup 3/ processors is presented. The main contribution of the algorithm is a novel constant-time technique for determining the minimum-labeled PE in each component. The number of processors used by the algorithm can be reduced to N/sup 2+(1/d/), for any 1/spl les/d/spl les/log N, if O(d) time is allowed.<>"",""1558-2183"","""",""10.1109/71.277785"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=277785"","""",""Parallel algorithms";Labeling;Computer networks;Concurrent computing;Very large scale integration;Pixel;Parallel architectures;Computer network management;Network topology;"Computer architecture"","""",""11"",""2"",""15"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Constructive methods for scheduling uniform loop nests,""A. Darte";" Y. Robert"",""Laboratoire LIP-IMAG Ecole Normale Supérieure de Lyon, Lyon, France";" Laboratoire LIP-IMAG Ecole Normale Supérieure de Lyon, Lyon, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""8"",""814"",""822"",""This paper surveys scheduling techniques for loop nests with uniform dependences. First, we introduce the hyperplane method and related variants. Then we extend it by using a different affine scheduling for each statement within the nest. In both cases, we present a new, constructive, and efficient method to determine optimal solutions, i.e., schedules whose total execution time is minimum.<>"",""1558-2183"","""",""10.1109/71.298207"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298207"","""",""Optimal scheduling";Vectors;Linear programming;Heart;Supercomputers;Parallel machines;Councils;"Timing"","""",""73"",""1"",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Deadlock-free multicast wormhole routing in 2-D mesh multicomputers,""Xiaola Lin"; P. K. McKinley;" L. M. Ni"",""Department of Computer Science, Michigan State University, East Lansing, MI, USA"; Department of Computer Science, Michigan State University, East Lansing, MI, USA;" Department of Computer Science, Michigan State University, East Lansing, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""8"",""793"",""804"",""Multicast communication services, in which the same message is delivered from a source node to an arbitrary number of destination nodes, are being provided in new-generation multicomputers. Broadcast is a special case of multicast in which a message is delivered to all nodes in the network. The nCUBE-2, a wormhole-routed hypercube multicomputer, provides hardware support for broadcast and a restricted form of multicast in which the destinations form a subcube. However, the broadcast routing algorithm adopted in the nCUBE-2 is not deadlock-free. In this paper, four multicast wormhole routing strategies for 2-D mesh multicomputers are proposed and studied. All of the algorithms are shown to be deadlock-free. These are the first deadlock-free multicast wormhole routing algorithms ever proposed. A simulation study has been conducted that compares the performance of these multicast algorithms under dynamic network traffic conditions in a 2-D mesh. The results indicate that a dual-path routing algorithm offers performance advantages over tree-based, multipath, and fixed-path algorithms.<>"",""1558-2183"","""",""10.1109/71.298203"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298203"","""",""System recovery";Routing;Multicast algorithms;Broadcasting;Telecommunication traffic;Multicast communication;Concurrent computing;Heuristic algorithms;Network topology;"Bandwidth"","""",""198"",""4"",""31"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Design and evaluation of effective load sharing in distributed real-time systems,""K. G. Shin";" Chao-Ju Hou"",""Real-Time Computing Laboratory, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA";" Department of Electrical and Computer Engineering, University of Wisconsin, Madison, WI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""7"",""704"",""719"",""In a distributed real-time system, uneven task arrivals temporarily overload some nodes and leave others idle or underloaded. Consequently, some tasks may miss their deadlines even if the overall system has the capacity to meet the deadlines of all tasks. An effective load-sharing (LS) scheme is proposed as a solution to this problem. Upon arrival of a task at a node, the node determines whether the node can complete the task in time under the minimum-laxity first-served policy. If the task cannot be guaranteed, or if guarantees of some other tasks are to be violated as a result of the addition of this task to the existing schedule, the node looks up the list of loss-minimizing decisions and determines the best node among a set of nodes in its physical proximity, called its buddy set, to which the task(s) may be transferred. This list of decisions is periodically updated using Bayesian decision analysis and prior/posterior state distributions. These probability distributions are derived from the information collected via time-stamped state-region change broadcasts within each buddy set. By characterizing the inconsistency between a node's """"observed"""" state and the corresponding true state with prior and posterior distributions, the node can first estimate the states of other nodes, and then use them to reduce the probability of transferring a task to an """"incapable"""") node. Moreover, the use of prior and posterior distributions and Bayesian analysis has made the proposed scheme robust to the variation of design parameters that usually require fine-tuning for adaptive LS. The performance of the proposed scheme is evaluated via simulation, along with five other schemes: no LS, LS with state probing, LS with random selection, LS with focused addressing, and perfect LS.<>"",""1558-2183"","""",""10.1109/71.296317"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=296317"","""",""Real time systems";Bayesian methods;Performance analysis;Robustness;Analytical models;Delay;Pattern analysis;Chaos;Probability distribution;"Broadcasting"","""",""38"","""",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Design of algorithm-based fault-tolerant multiprocessor systems for concurrent error detection and fault diagnosis,""B. Vinnakota";" N. K. Jha"",""Department of Electrical Engineering, University of Minnesota, Minneapolis, MN, USA";" Department of Electrical Engineering, Princeton University, Princeton, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""10"",""1099"",""1106"",""Algorithm-based fault tolerance (ABPT) is a low-overhead system-level concurrent error detection and fault location scheme for multiprocessor systems. We present new methods for the design of ABFT systems. Our design procedure is applicable to a wide range of systems in which processors share data elements. A feature of our design approach is that the type of checks to be used in the final system can be controlled by the system designer. We also present some new bounds on the number of checks needed in ABFT system design.<>"",""1558-2183"","""",""10.1109/71.313125"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=313125"","""",""Algorithm design and analysis";Fault tolerant systems;Multiprocessing systems;Fault detection;Signal processing algorithms;Fault tolerance;Fault location;Design methodology;Fault diagnosis;"Control systems"","""",""5"",""3"",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Detection of weak unstable predicates in distributed programs,""V. K. Garg";" B. Waldecker"",""Department of Electrical and Computer Engineering, University of Technology, Austin, TX, USA";" Austin System Center of Schlumberger Well Services, Austin, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""3"",""299"",""307"",""This paper discusses detection of global predicates in a distributed program. Earlier algorithms for detection of global predicates proposed by Chandy and Lamport (1985) work only for stable predicates. A predicate is stable if it does not turn false once it becomes true. Our algorithms detect even unstable predicates, without excessive overhead. In the past, such predicates have been regarded as too difficult to detect. The predicates are specified by using a logic described formally in this paper. We discuss detection of weak conjunctive predicates that are formed by conjunction of predicates local to processes in the system. Our detection methods will detect whether such a predicate is true for any interleaving of events in the system, regardless of whether the predicate is stable. Also, any predicate that can be reduced to a set of weak conjunctive predicates is detectable. This class of predicates captures many global predicates that are of interest to a programmer. The message complexity of our algorithm is bounded by the number of messages used by the program. The main applications of our results are in debugging and testing of distributed programs. Our algorithms have been incorporated in a distributed debugger that runs on a network of Sun workstations in UNIX.<>"",""1558-2183"","""",""10.1109/71.277788"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=277788"","""",""Logic";Debugging;Event detection;Testing;Interleaved codes;Programming profession;Sun;Workstations;Communication networks;"Distributed computing"","""",""116"",""1"",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Distributed performance monitoring: methods, tools, and applications,""R. Hofmann"; R. Klar; B. Mohr; A. Quick;" M. Siegle"",""Inst. fur Math. Maschinen, Erlangen-Nurnberg Univ., Germany"; Institüt für Mathematics Maschinen, Universität Erlangen-Nämberg, Erlangen, Germany; Institüt für Mathematics Maschinen, Universität Erlangen-Nämberg, Erlangen, Germany; Institüt für Mathematics Maschinen, Universität Erlangen-Nämberg, Erlangen, Germany;" Institüt für Mathematics Maschinen, Universität Erlangen-Nämberg, Erlangen, Germany"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""6"",""585"",""598"",""A method for analyzing the functional behavior and the performance of programs in distributed systems is presented. We use hybrid monitoring, a technique which combines advantages of both software monitoring and hardware monitoring. The paper contains a description of a hardware monitor and a software package (ZM4/SIMPLE) which make our concepts available to programmers, assisting them in debugging and tuning of their code. A short survey of related monitor systems highlights the distinguishing features of our implementation. As an application of our monitoring and evaluation system, the analysis of a parallel ray tracing program running on the SUPRENUM multiprocessor is described. It is shown that monitoring and modeling both rely on a common abstraction of a system's dynamic behavior and therefore can be integrated to one comprehensive methodology. This methodology is supported by a set of tools.<>"",""1558-2183"","""",""10.1109/71.285605"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285605"","""",""Monitoring";Hardware;Debugging;Application software;Performance analysis;Predictive models;Packaging;Programming profession;Ray tracing;"Instruments"","""",""46"",""6"",""45"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals"""
"DSC: scheduling parallel tasks on an unbounded number of processors,""Tao Yang";" A. Gerasoulis"",""Department of Computer Science, University of California, Santa Barbara, CA, USA";" Department of Computer Science, Rutgers University, New Brunswick, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""9"",""951"",""967"",""We present a low-complexity heuristic, named the dominant sequence clustering algorithm (DSC), for scheduling parallel tasks on an unbounded number of completely connected processors. The performance of DSC is on average, comparable to, or even better than, other higher-complexity algorithms. We assume no task duplication and nonzero communication overhead between processors. Finding the optimum solution for arbitrary directed acyclic task graphs (DAG's) is NP-complete. DSC finds optimal schedules for special classes of DAG's, such as fork, join, coarse-grain trees, and some fine-grain trees. It guarantees a performance within a factor of 2 of the optimum for general coarse-grain DAG's. We compare DSC with three higher-complexity general scheduling algorithms: the ETF by J.J. Hwang, Y.C. Chow, F.D. Anger, and C.Y. Lee (1989)"; V. Sarkar's (1989) clustering algorithm;" and the MD by M.Y. Wu and D. Gajski (1990). We also give a sample of important practical applications where DSC has been found useful.<>"",""1558-2183"","""",""10.1109/71.308533"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=308533"","""",""Processor scheduling";Optimal scheduling;Tree graphs;Clustering algorithms;Scheduling algorithm;Computer science;Parallel processing;Multiprocessor interconnection networks;Program processors;"Network topology"","""",""423"",""12"",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"E-kernel: an embedding kernel on the IBM victor V256 multiprocessor for program mapping and network reconfiguration,""E. Ma";" D. G. Shea"",""Department of Computer Science, Rensselaer Polytechnic Institute, Troy, NY, USA";" IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""9"",""977"",""994"",""We present the design of E-kernel, an embedding kernel on the Victor V256 message-passing partitionable multiprocessor, developed for the support of program mapping and network reconfiguration. E-kernel supports the embedding of a new network topology onto Victor's 2D mesh and also the embedding of a task graph onto the 2D mesh network or the reconfigured network. In the current implementation, the reconfigured network can be a line or an even-size ring, and the task graphs meshes or tori of a variety of dimensions and shapes or graphs with similar topologies. For application programs having these task graph topologies and that are designed according to the communication model of E-kernel, they can be run without any change on partitions connected by the 2D mesh, line, or ring. Further, E-kernel attempts the communication optimization of these programs on the different networks automatically, thus making both the network topology and the communication optimization attempt completely transparent to the application programs. Many of the embeddings used in E-kernel are optimal or asymptotically optimal (with respect to minimum dilation cost). The implementation of E-kernel translated some of the many theoretical results in graph embeddings into practical tools for program mapping and network reconfiguration in a parallel system. E-kernel is functional on Victor V256. Measurements of E-kernel's performance on V256 are also included.<>"",""1558-2183"","""",""10.1109/71.308535"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=308535"","""",""Kernel";Network topology;Councils;Computational efficiency;Mesh networks;Shape;Cost function;Message passing;"Monitoring"","""","""",""18"",""41"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Efficient EREW PRAM algorithms for parentheses-matching,""S. K. Prasad"; S. K. Das;" C. C. . -Y. Chen"",""Department of Mathematics and Computer, Georgia State University, Atlanta, CA, USA"; Department of Computer Science, University of North Texas, Denton, TX, USA;" Department of Computer and Information Engineering, Tamkang University, Taipei, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""9"",""995"",""1008"",""We present four polylog-time parallel algorithms for matching parentheses on an exclusive-read and exclusive-write (EREW) parallel random-access machine (PRAM) model. These algorithms provide new insights into the parentheses-matching problem. The first algorithm has a time complexity of O(log/sup 2/ n) employing O(n/(log n)) processors for an input string containing n parentheses. Although this algorithm is not cost-optimal, it is extremely simple to implement. The remaining three algorithms, which are based on a different approach, achieve O(log n) time complexity in each case, and represent successive improvements. The second algorithm requires O(n) processors and working space, and it is comparable to the first algorithm in its ease of implementation. The third algorithm uses O(n/(log n)) processors and O(n log n) space. Thus, it is cost-optimal, but uses extra space compared to the standard stack-based sequential algorithm. The last algorithm reduces the space complexity to O(n) while maintaining the same processor and time complexities. Compared to other existing time-optimal algorithms for the parentheses-matching problem that either employ extensive pipelining or use linked lists and comparable data structures, and employ sorting or a linked list ranking algorithm as subroutines, the last two algorithms have two distinct advantages. First, these algorithms employ arrays as their basic data structures, and second, they do not use any pipelining, sorting, or linked list ranking algorithms.<>"",""1558-2183"","""",""10.1109/71.308536"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=308536"","""",""Phase change random access memory";Parallel algorithms;Pipeline processing;Data structures;Sorting;Computer science;Read-write memory;Writing;"Computer networks"","""",""6"","""",""34"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Efficient mappings of pyramid networks,""A. Dingle";" I. H. Sudborough"",""Department of Electrical Engineering and Computer Science, Lehigh University, Bethlehem, PA, USA";" Computer Science, University of Texas, Dallas, Richardson, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""10"",""1009"",""1017"",""We consider primarily the simulation of large networks by smaller ones-an important consideration, because interconnection networks are typically of a fixed size, and yet applications may employ networks of a larger size. Current research (Dingle and Sudborough, 1993) describes methods to simulate common data structures and network architectures on the pyramid. However, these simulations assume that the pyramid grows with the size of the network or data structure. Because unbounded growth is not feasible, we address the issue of mapping several points of the guest data structure or network to a single host processor. We determine how a small pyramid may efficiently simulate the computation of a larger pyramid as well as that of tree networks.<>"",""1558-2183"","""",""10.1109/71.313118"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=313118"","""",""Computational modeling";Data structures;Costs;Tree graphs;Image processing;Multiprocessor interconnection networks;Computer networks;Load management;Load modeling;"Pixel"","""",""4"","""",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Embedding binary X-trees and pyramids in processor arrays with spanning buses,""Zicheng Guo";" R. G. Melhem"",""Department of Electrical Engineering, Louisiana Tech University, Ruston, LA, USA";" Department of Computer Science, University of Pittsburgh, Pittsburgh, PA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""6"",""664"",""672"",""We study the problem of network embeddings in 2-D array architectures in which each row and column of processors are interconnected by a bus. These architectures are especially attractive if optical buses are used that allow simultaneous access by multiple processors through either wavelength division multiplexing or message pipelining, thus overcoming the bottlenecks caused by the exclusive access of buses. In particular, we define S-trees to include both binary X-trees and pyramids, and present two embeddings of X-trees into 2-D processor arrays with spanning buses. The first embedding has the property that all neighboring nodes in X-trees are mapped to the same bus in the target array, thus allowing any two neighbors in the embedded S-trees to communicate with each other in one routing step. The disadvantage of this embedding is its relatively high expansion cost. In contrast, the second embedding has an expansion cost approaching unity, but does not map all neighboring nodes in X-trees to the same bus. These embeddings allow all algorithms designed for binary trees, pyramids, as well as X-trees to be executed on the target arrays.<>"",""1558-2183"","""",""10.1109/71.285613"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285613"","""",""Optical arrays";Optical waveguides;Pipeline processing;Concurrent computing;Wavelength division multiplexing;Costs;Embedded computing;Algorithm design and analysis;Broadcasting;"Writing"","""",""8"",""1"",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Evaluation of a parallel branch-and-bound algorithm on a class of multiprocessors,""M. K. Yang";" C. R. Das"",""Hyundai Electronics Industries Company Limited, Kyunggi, South Korea";" Department of Computer Science and Engineering, Pennsylvania State University, University Park, PA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""1"",""74"",""86"",""We propose and evaluate a parallel """"decomposite best-first"""" search branch-and-bound algorithm (dbs) for MIN-based multiprocessor systems. We start with a new probabilistic model to estimate the number of evaluated nodes for a serial best-first search branch-and-bound algorithm. This analysis is used in predicting the parallel algorithm speed-up. The proposed algorithm initially decomposes a problem into N subproblems, where N is the number of processors available in a multiprocessor. Afterwards, each processor executes the serial best-first search to find a local feasible solution. Local solutions are broadcasted through the network to compute the final solution. A conflict-free mapping scheme, known as the step-by-step spread, is used for subproblem distribution on the MIN. A speedup expression for the parallel algorithm is then derived using the serial best-first search node evaluation model. Our analysis considers both computation and communication overheads for providing realistic speed-up. Communication modeling is also extended for the parallel global best-first search technique. All the analytical results are validated via simulation. For large systems, when communication overhead is taken into consideration, it is observed that the parallel decomposite best-first search algorithm provides better speed-up compared to other reported schemes.<>"",""1558-2183"","""",""10.1109/71.262590"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=262590"","""",""Algorithm design and analysis";Multiprocessing systems;Parallel algorithms;Search problems;Broadcasting;Computer networks;Computational modeling;Analytical models;Traveling salesman problems;"Linear programming"","""",""15"",""3"",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Fault-tolerant algorithms for fair interprocess synchronization,""Yih-Kuen Tsay";" R. L. Bagrodia"",""Department of Computer Systems, University of Uppsala, Uppsala, Sweden";" Department of Computer Science, University of California, Los Angeles, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""7"",""737"",""748"",""The implementation of nondeterministic pairwise synchronous communication among a set of asynchronous processes is modeled as the binary interaction problem. The paper describes an algorithm for this problem that satisfies a strong fairness property that guarantees freedom from process starvation. This is the first algorithm for binary interactions with strong fairness whose message cost and response time are independent of the total number of processes in the system. The paper also describes how the fair algorithm may be extended to tolerate detectable fail-stop failures. Finally, we show how any solution to the dining philosophers problem can be embedded to design a fair algorithm for binary interactions. In particular, this embedding is used to derive a fair algorithm that can cope with undetectable fail-stop failures.<>"",""1558-2183"","""",""10.1109/71.296319"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=296319"","""",""Fault tolerance";Algorithm design and analysis;Computer science;Costs;Delay;Distributed algorithms;Computer languages;"Postal services"","""",""9"","""",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Fault-tolerant clock synchronization in large multicomputer systems,""A. Olson";" K. G. Shin"",""Real-Time Computing Laboratory, Computer Science and Engineering Division, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA";" Real-Time Computing Laboratory, Computer Science and Engineering Division, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""9"",""912"",""923"",""The cost of synchronizing a multicomputer increases with system size. For large multicomputers, the time and resources spent to enable each node to estimate the clock value of every other node in the system can be prohibitive. We show how to reduce the cost of synchronization by assigning each node to one or more groups, then having each node estimate the clock values of only those nodes with which it shares a group. Since each node estimates the clock value of only a subset of the nodes, the cost of synchronization can be significantly reduced. We also provide a method for computing the maximum skew between any two nodes in the multicomputer, and a method for computing the maximum time between synchronizations. We also show how the fault tolerance of the synchronization algorithm may be determined.<>"",""1558-2183"","""",""10.1109/71.308530"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=308530"","""",""Fault tolerant systems";Synchronization;Costs;Hardware;Fault tolerance;Atomic clocks;Energy consumption;Control systems;Current measurement;"Time measurement"","""",""20"","""",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Fault-tolerant de Bruijn and shuffle-exchange networks,""J. Bruck"; R. Cypher;" Ching-Tien Ho"",""IBM Research Division, Almaden Research Center, San Jose, CA, USA"; IBM Research Division, Almaden Research Center, San Jose, CA, USA;" IBM Research Division, Almaden Research Center, San Jose, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""5"",""548"",""553"",""This paper addresses the problem of creating a fault-tolerant interconnection network for a parallel computer. Three topologies, namely, the base-2 de Bruijn graph, the base-m de Bruijn graph, and the shuffle-exchange, are studied. For each topology an N+k node fault-tolerant graph is defined. These fault-tolerant graphs have the property that given any set of k node faults, the remaining N nodes contain the desired topology as a subgraph. All of the constructions given are the best known in terms of the degree of the fault-tolerant graph. We also investigate the use of buses to reduce the degrees of the fault-tolerant graphs still further.<>"",""1558-2183"","""",""10.1109/71.282566"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=282566"","""",""Fault tolerance";Network topology;Computer networks;Distributed computing;Delay;Load management;Hypercubes;Telecommunication traffic;Traffic control;"Communication networks"","""",""16"","""",""13"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Fault-tolerant routing in mesh architectures,""A. Olson";" K. G. Shin"",""Real-Time Computing Laboratory, Department of Electrical Engineering and Computer Science, Computer Science and Engineering Division, University of Michigan, Ann Arbor, MI, USA";" Real-Time Computing Laboratory, Department of Electrical Engineering and Computer Science, Computer Science and Engineering Division, University of Michigan, Ann Arbor, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""11"",""1225"",""1232"",""It is important for a distributed computing system to be able to route messages around whatever faulty links or nodes may be present. We present a fault-tolerant routing algorithm that assures the delivery of every message as long as there is a path between its source and destination. The algorithm works on many common mesh architectures such as the torus and hexagonal mesh. The proposed scheme can also detect the nonexistence of a path between a pair of nodes in a finite amount of time. Moreover, the scheme requires each node in the system to know only the state (faulty or not) of each of its own links. The performance of the routing scheme is simulated for both square and hexagonal meshes while varying the physical distribution of faulty components. It is shown that a shortest path between the source and destination of each message is taken with a high probability, and, if a path exists, it is usually found very quickly.<>"",""1558-2183"","""",""10.1109/71.329665"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=329665"","""",""Fault tolerance";Routing;Circuit faults;Hypercubes;Fault tolerant systems;Computer architecture;Distributed computing;Broadcasting;Delay;"Computer science"","""",""2"","""",""7"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Fully adaptive minimal deadlock-free packet routing in hypercubes, meshes, and other networks: algorithms and simulations,""G. D. Pifarre"; L. Gravano; S. A. Felperin;" J. L. C. Sanz"",""Adv. Solutions Group, IBM, Buenos Aires, Argentina"; Department of Computer Science, University of Stanford, Stanford, CA, USA; Computer Science Department, IBM Almaden Research Center, San Jose, CA, USA;" Coordinated Science Lab and Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""3"",""247"",""263"",""This paper deals with the problem of packet-switched routing in parallel machines. Several new routing algorithms for different interconnection networks are presented. While the new techniques apply to a wide variety of networks, routing algorithms will be shown for the hypercube, the two-dimensional mesh, and the shuffle-exchange. Although the new techniques are designed for packet routing, they can be used alternatively for virtual cut-through routing models. The techniques presented for hypercubes and meshes are fully-adaptive and minimal. A fully-adaptive and minimal routing is one in which all possible minimal paths between a source and a destination are of potential use at the time a message is injected into the network. Minimal paths followed by messages ultimately depend on the local congestion encountered in each node of the network. All of the new techniques are completely free of deadlock situations.<>"",""1558-2183"","""",""10.1109/71.277792"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=277792"","""",""System recovery";Routing;Intelligent networks;Hypercubes;Multiprocessor interconnection networks;Computer science;Packet switching;Telecommunication traffic;Traffic control;"Throughput"","""",""31"",""2"",""55"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Hierarchical compilation of macro dataflow graphs for multiprocessors with local memory,""G. N. Srinivasa Prasanna"; A. Agarwal;" B. R. Musicus"",""Laboratory for Computer Science, Massachusetts Institute of Technology, Cambridge, MA, USA"; Laboratory for Computer Science, Massachusetts Institute of Technology, Cambridge, MA, USA;" Laboratory for Computer Science, Massachusetts Institute of Technology, Cambridge, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""7"",""720"",""736"",""This paper presents a hierarchical approach for compiling macro dataflow graphs for multiprocessors with local memory. Macro dataflow graphs comprise several nodes (or macro operations) that must be executed subject to prespecified precedence constraints. Programs consisting of multiple nested loops, where the precedence constraints between the loops are known, can be viewed as macro dataflow graphs. The hierarchical compilation approach comprises a processor allocation phase followed by a partitioning phase. In the processor allocation phase, using estimated speedup functions for the macro nodes, computationally efficient techniques establish the sequencing and parallelism of macro operations for close-to-optimal run-times. The second phase partitions the computations in each macro node to maximize communication locality for the level of parallelism determined by the processor allocation phase. The same approach can also be used for programs consisting of multiple loop nests, when each of the nested loops can be characterized by a speedup function. These ideas have been implemented in a prototype structure-driven compiler, SDC, for expressions of matrix operations. The paper presents the performance of the compiler for several matrix expressions on a simulator of the Alewife multiprocessor.<>"",""1558-2183"","""",""10.1109/71.296318"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=296318"","""",""Processor scheduling";Laboratories;Concurrent computing;Runtime;Phase estimation;Parallel processing;Prototypes;Computational modeling;Resource management;"Distributed computing"","""",""14"",""1"",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Highly reliable symmetric networks,""L. M. Huisman";" S. Kundu"",""IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA";" IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""1"",""94"",""97"",""We generalize directed loop networks to loop-symmetric networks in which there are N nodes and in which each node has in-degree and out-degree k, subject to the condition that 2/sup k/ does not exceed N. We show that by proper selection of links one can obtain generalized loop networks with optimal or close to optimal diameter and connectivity. The optimized diameter is less than k/spl lsqb/N/sup 1/k//spl rsqb/, where /spl lsqb/x/spl rsqb/ indicates the ceiling of x. We also show that these networks are rather compact in that the diameter is not more than twice the average distance. Roughly 1/2(k/spl minus/1)N/sup 1/k/ nodes can be removed such that the network of remaining nodes is still strongly connected, if all remaining nodes have at least one incoming and one outgoing link left.<>"",""1558-2183"","""",""10.1109/71.262592"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=262592"","""",""Network topology";Fault tolerance;Joining processes;Local area networks;Computer network reliability;Computer networks;Distributed computing;Maintenance;Equations;"Routing"","""",""7"","""",""9"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Implementation of speculative parallelism in functional languages,""P. V. R. Murthy";" V. Rajaraman"",""Supercomputer Education and Research Centre, Indian Institute of Science, Bangalore, India";" Supercomputer Education and Research Centre, Indian Institute of Science, Bangalore, India"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""11"",""1197"",""1205"",""A compile-time analysis technique is developed to derive the probability with which a user-defined function or a supercombinator requires each one of its arguments. This provides a basis for identifying useful speculative parallelism in a program. The performance of speculative evaluation is compared with that of lazy evaluation, and the necessary conditions under which speculative evaluation performs better are identified.<>"",""1558-2183"","""",""10.1109/71.329669"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=329669"","""",""Parallel processing";Concurrent computing;Performance evaluation;Processor scheduling;Availability;Supercomputers;Runtime;"Closed-form solution"","""",""1"","""",""11"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Improved lower bounds on the reliability of hypercube architectures,""Sieteng Soh"; S. Rai;" J. L. Trahan"",""Department of Electrical & Computer Engineering, Louisiana State University, Baton Rouge, LA, USA"; Department of Electrical & Computer Engineering, Louisiana State University, Baton Rouge, LA, USA;" Department of Electrical & Computer Engineering, Louisiana State University, Baton Rouge, LA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""4"",""364"",""378"",""The hypercube topology, also known as the Boolean n-cube, has recently been used for multiprocessing systems. The paper considers two structural-reliability models, namely, terminal reliability (TR) and network reliability (NR), for the hypercube. Terminal (network) reliability is defined as the probability that there exists a working path connecting two (all) nodes. There are no known polynomial time algorithms for exact computation of TR or NR for the hypercube. Thus, lower-bound computation is a better alternative, because it is more efficient computationally, and the system will be at least as reliable as the bound. The paper presents algorithms to compute lower bounds on TR and NR for the hypercube considering node and/or link failures. These algorithms provide tighter bounds for both TR and NR than known results and run in time polynomial in the cube dimension n, specifically, within time O(n/sup 2/).<>"",""1558-2183"","""",""10.1109/71.273045"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=273045"","""",""Hypercubes";Computer network reliability;Computer networks;Performance analysis;Network topology;Polynomials;Computer architecture;Military computing;Multiprocessing systems;"Joining processes"","""",""38"","""",""28"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Incomplete star: an incrementally scalable network based on the star graph,""S. Latifi";" N. Bagherzadeh"",""Department of Electrical and Computer Engineering, University of Nevada, Las Vegas, NV, USA";" Department of Electrical and Computer Engineering, University of California, Irvine, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""1"",""97"",""102"",""Introduces a new interconnection network for massively parallel systems called the incomplete star graph. The authors describe unique ways of interconnecting and labeling the nodes and routing point-to-point communications within this network. In addition, they provide an analysis of a special class of incomplete star graph called C/sup n/spl minus/1/ graph and obtain the diameter and average distance for this network. For the C/sup n/spl minus/1/ graph, an efficient broadcasting scheme is presented. Furthermore, it is proven that a C/sup n/spl minus/1/ with N nodes (i.e. N=m(n/spl minus/1)!) is Hamiltonian if m=4 or m=3k, and k/spl ne/2.<>"",""1558-2183"","""",""10.1109/71.262593"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=262593"","""",""Fault tolerance";Network topology;Computer networks;Multiprocessor interconnection networks;Routing;Distributed computing;Telecommunication traffic;Graph theory;Circuits;"Machinery"","""",""38"",""2"",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Index transformation algorithms in a linear algebra framework,""A. Edelman"; S. Heller;" S. Lennart Johnsson"",""Department of Mathematics, Massachusetts Institute of Technology, Cambridge, MA, USA"; Thinking Machines Corporation, Cambridge, MA, USA;" Thinking Machines Corporation, Cambridge, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""12"",""1302"",""1309"",""We present a linear algebraic formulation for a class of index transformations such as Gray code encoding and decoding, matrix transpose, bit reversal, vector reversal, shuffles, and other index or dimension permutations. This formulation unifies, simplifies, and can be used to derive algorithms for hypercube multiprocessors. We show how all the widely known properties of Gray codes, and some not so well-known properties as well, can be derived using this framework. Using this framework, we relate hypercube communications algorithms to Gauss-Jordan elimination on a matrix of 0's and 1's.<>"",""1558-2183"","""",""10.1109/71.334903"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=334903"","""",""Linear algebra";Hypercubes;Reflective binary codes;Encoding;Decoding;Vectors;Business continuity;Gaussian processes;Routing;"Books"","""",""15"",""2"",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Interleaved all-to-all reliable broadcast on meshes and hypercubes,""Sunggu Lee";" K. G. Shin"",""Department of Electrical Engineering, Pohang University, Pohang, Gyeongbuk, South Korea";" Real-Time Computing Laboratory, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""5"",""449"",""458"",""All-to-all (ATA) reliable broadcast is the problem of reliably distributing information from every node to every other node in point-to-point interconnection networks. A good solution to this problem is essential for clock synchronization, distributed agreement, etc. We propose a novel solution in which the reliable broadcasts from individual nodes are interleaved in such a manner that no two packets contend for the same link at any given time-this type of method is particularly suited for systems which use virtual cut-through or wormhole routing for fast communication between nodes. Our solution, called the IHC Algorithm, can be used on a large class of regular interconnection networks including regular meshes and hypercubes. By adjusting a parameter /spl eta/ referred to as the interleaving distance, we can flexibly decrease the link utilization of the IHC algorithm (for normal traffic) at the expense of an increase in the time required for ATA reliable broadcast. We compare the IHC algorithm to several other possible virtual cut-through solutions and a store-and-forward solution. The IHC algorithm with the minimum value of /spl eta/ is shown to be optimal in minimizing the execution time of ATA reliable broadcast when used in a dedicated mode (with no other network traffic).<>"",""1558-2183"","""",""10.1109/71.282556"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=282556"","""",""Broadcasting";Hypercubes;Multiprocessor interconnection networks;Time of arrival estimation;Telecommunication traffic;Clocks;Synchronization;Telecommunication network reliability;Routing;"Interleaved codes"","""",""18"",""35"",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Interleaved parallel schemes,""A. Seznec";" J. Lenfant"",""Campus de Beaulieu, Institut de Recherches en Informatiques et Systèmes aléatoires, Rennes, France";" Campus de Beaulieu, Institut de Recherches en Informatiques et Systèmes aléatoires, Rennes, France"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""12"",""1329"",""1334"",""On vector supercomputers, vector register processors share a global highly interleaved memory. In order to optimize memory throughput, a single-instruction, multiple-data (SIMD) synchronization mode may be used on vector sections. We present an interleaved parallel scheme (IPS). Using IPS ensures an equitable distribution of elements on a highly interleaved memory for a wide range of vector strides. Access to memory may be organized in such a way that conflicts are avoided on memory and on the interconnection network.<>"",""1558-2183"","""",""10.1109/71.334907"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=334907"","""",""Throughput";Registers;Multiprocessor interconnection networks;Supercomputers;Concurrent computing;Intelligent networks;Arithmetic;Computer networks;Vector processors;"Manufacturing processes"","""",""4"",""1"",""8"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Job scheduling is more important than processor allocation for hypercube computers,""P. Krueger"; Ten-Hwang Lai;" V. A. Dixit-Radiya"",""Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA"; Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA;" Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""5"",""488"",""497"",""Managing computing resources in a hypercube entails two steps. First, a job must be chosen to execute from among those waiting (job scheduling). Next a particular subcube within the hypercube must be allocated to that job (processor allocation). Whereas processor allocation has been well studied, job scheduling has been largely neglected. The goal of this paper is to compare the roles of processor allocation and job scheduling in achieving good performance on hypercube computers. We show that job scheduling has far more impact on performance than does processor allocation. We propose a new family of scheduling disciplines, called Scan, that have particular performance advantages. We show that performance problems that cannot be resolved through careful processor allocation can be solved by using Scan job-scheduling disciplines. Although the Scan disciplines carry far less overhead than is incurred by even the simplest processor allocation strategies, they are far more able to improve performance than even the most sophisticated strategies. Furthermore, when Scan disciplines are used, the abilities of sophisticated processor allocation strategies to further improve performance are limited to negligible levels. Consequently, a simple O(n) allocation strategy can be used in place of these complex strategies.<>"",""1558-2183"","""",""10.1109/71.282559"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=282559"","""",""Processor scheduling";Hypercubes;Dynamic scheduling;Real time systems;Tail;Job design;Multiprocessing systems;Scalability;Topology;"Communication channels"","""",""68"",""2"",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Low-latency, concurrent checkpointing for parallel programs,""Kai Li"; J. F. Naughton;" J. S. Plank"",""Department of Computer Science, Princeton University, Princeton, NJ, USA"; Department of Computer Science, University of Wisconsin, Madison, WI, USA;" Department of Computer Science, University of Tennessee, Knoxville, TN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""8"",""874"",""879"",""Presents the results of an implementation of several algorithms for checkpointing and restarting parallel programs on shared-memory multiprocessors. The algorithms are compared according to the metrics of overall checkpointing time, overhead imposed by the checkpointer on the target program, and amount of time during which the checkpointer interrupts the target program. The best algorithm measured achieves its efficiency through a variation of copy-on-write, which allows the most time-consuming operations of the checkpoint to be overlapped with the running of the program being checkpointed.<>"",""1558-2183"","""",""10.1109/71.298215"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298215"","""",""Checkpointing";Fault tolerance;Computer science;Central Processing Unit;Benchmark testing;Fault tolerant systems;Concurrent computing;Delay;"Registers"","""",""68"",""9"",""30"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Lower and upper bounds on time for multiprocessor optimal schedules,""K. Kumar Jain";" V. Rajaraman"",""Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India";" Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""8"",""879"",""886"",""The lower and upper bounds on the minimum time needed to process a given directed acyclic task graph for a given number of processors are derived. It is proved that the proposed lower bound on time is not only sharper than the previously known values but also easier to calculate. The upper bound on time, which is useful in determining the worst case behavior of a given task graph, is presented. The lower and upper bounds on the minimum number of processors required to process a given task graph in the minimum possible time are also derived. It is seen with a number of randomly generated dense task graphs that the lower and upper bounds we derive are equal, thus giving the optimal time for scheduling directed acyclic task graphs on a given set of processors.<>"",""1558-2183"","""",""10.1109/71.298216"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298216"","""",""Optimal scheduling";Processor scheduling;Upper bound;Parallel processing;Random number generation;Parallel algorithms;Concurrent computing;NP-complete problem;Scheduling algorithm;"Tree graphs"","""",""15"","""",""22"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Machine independent AND and OR parallel execution of logic programs. I. The binding environment,""B. Ramkumar";" L. V. Kale"",""Department of Electrical and Computer Engineering, University of Iowa, Iowa, IA, USA";" Department of Computer Science, University of Illinois, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""2"",""170"",""180"",""We describe a binding environment for the AND and OR parallel execution of logic programs that is suitable for both shared and nonshared memory multiprocessors. The binding environment was designed with a view of rendering a compiler using this binding environment machine independent. The binding environment is similar to closed environments proposed by J. Conery. However, unlike Conery's scheme, it supports OR and independent AND parallelism on both types of machines. The term representation, the algorithms for unification and the join algorithms for parallel AND branches are presented in this paper. We also detail the differences between our scheme and Conery's scheme. A compiler based on this binding environment has been implemented on a platform for machine independent parallel programming called the Chare Kernel.<>"",""1558-2183"","""",""10.1109/71.265944"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=265944"","""",""Parallel processing";Program processors;Logic programming;Parallel machines;Hypercubes;Parallel programming;Random access memory;Kernel;Computer languages;"Parallel languages"","""",""6"","""",""37"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Machine independent AND and OR parallel execution of logic programs. II. Compiled execution,""B. Ramkumar";" L. V. Kale"",""Department of Electrical and Computer Engineering, University of Iowa, Iowa, IA, USA";" Department of Computer Science, University of Illinois, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""2"",""181"",""192"",""For pt.I. see ibid., p. 170-80. In pt.I, we presented a binding environment for the AND and OR parallel execution of logic programs. This environment was instrumental in rendering a compiler for the AND and OR parallel execution of logic programs machine independent. In this paper, we describe a compiler based on the Reduce-OR process model (ROPM) for the parallel execution of Prolog programs, and provide performance of the compiler on five parallel machines: the Encore Multimax, the Sequent Symmetry, the NCUBE 2, the Intel i860 hypercube and a network of Sun workstations. The compiler is part of a machine independent parallel Prolog development system built on top of a run time environment for parallel programming called the Chare kernel, and runs unchanged on these multiprocessors. In keeping with the objectives behind the ROPM, the compiler supports both on and independent AND parallelism in Prolog programs and is suitable for execution on both shared and nonshared memory machines. We discuss the performance of the Prolog compiler in some detail and describe how grain size can be used to deliver performance that is within 10% of the underlying sequential Prolog compiler on one processor, and scale linearly with increasing number of processors on problems exhibiting sufficient parallelism. The loose coupling between parallel and sequential components makes it possible to use the best available sequential compiler as the sequential component of our compiler.<>"",""1558-2183"","""",""10.1109/71.265945"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=265945"","""",""Logic";Program processors;Instruments;Parallel machines;Hypercubes;Sun;Workstations;Parallel programming;Kernel;"Grain size"","""",""5"","""",""47"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"MAGIC: a multiattribute declustering mechanism for multiprocessor database machines,""S. Ghandeharizadeh";" D. J. DeWitt"",""Department of Computer Science, University of Southern California, Los Angeles, CA, USA";" Computer Science Department, University of Wisconsin, Madison, WI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""5"",""509"",""524"",""During the past decade, parallel database systems have gained increased popularity due to their high performance, scalability, and availability characteristics. With the predicted future database sizes and complexity of queries, the scalability of these systems to hundreds and thousands of processors is essential for satisfying the projected demand. Several studies have repeatedly demonstrated that both the performance and scalability of a parallel database system are contingent on the physical layout of the data across the processors of the system. If the data are not declustered appropriately, the execution of an operation might waste system resources, reducing the overall processing capability of the system. With earlier, single-attribute partitioning mechanisms such as those found in the Tandem, Teradata, Gamma, and Bubba parallel database systems, range selections on any attribute other than the partitioning attribute must be sent to all processors containing tuples of the relation, while range selections on the partitioning attribute can be directed to only a subset of the processors. Although using all the processors for an operation is reasonable for resource intensive operations, directing a query with minimal resource requirements to processors that contain no relevant tuples wastes CPU cycles, communication bandwidth, and I/O bandwidth. As a solution, this paper describes a new partitioning strategy, multiattribute grid declustering (MAGIC), which can use two or more attributes of a relation to decluster its tuples across multiple processors and disks. In addition, MAGIC declustering, unlike other multiattribute partitioning mechanisms that have been proposed, is able to support range selections as well as exact match selections on each of the partitioning attributes. This capability enables a greater variety of selection operations to be directed to a restricted subset of the processors in the system. Finally, MAGIC partitions each relation based on the resource requirements of the queries that constitute the workload for the relation and the processing capacity of the system in order to ensure that the proper number of processors are used to execute queries that reference the relation.<>"",""1558-2183"","""",""10.1109/71.282561"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=282561"","""",""Database machines";Database systems;Scalability;Bandwidth;Computer science;Availability;Stock markets;Volcanoes;Disk drives;"Prototypes"","""",""14"",""5"",""33"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Massively parallel algorithms for trace-driven cache simulations,""D. M. Nicol"; A. G. Greenberg;" B. D. Lubachevsky"",""Department of Computer Science, College of William and Mary, Williamsburg, VA, USA"; AT and T Bell Laboratories, Inc., Murray Hill, NJ, USA;" AT and T Bell Laboratories, Inc., Murray Hill, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""8"",""849"",""859"",""Considers the use of massively parallel architectures to execute a trace-driven simulation of a single cache set. A method is presented for the least-recently-used (LRU) policy, which, regardless of the set size C, runs in time O(log N) using N processors on the EREW (exclusive read, exclusive write) parallel model. A simpler LRU simulation algorithm is given that runs in O(C log N) time using N/log N processors. We present timings of this algorithm's implementation on the MasPar MP-1, a machine with 16384 processors. A broad class of reference-based line replacement policies are considered, which includes LRU as well as the least-frequently-used (LFU) and random replacement policies. A simulation method is presented for any such policy that, on any trace of length N directed to a C line set, runs in O(C log N) time with high probability using N processors on the EREW model. The algorithms are simple, have very little space overhead, and are well suited for SIMD implementation.<>"",""1558-2183"","""",""10.1109/71.298211"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298211"","""",""Parallel algorithms";Computational modeling;Microprocessors;Timing;Computer architecture;Reduced instruction set computing;NASA;Permission;Conferences;"Councils"","""",""23"",""1"",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Memory bandwidth analysis of hierarchical multiprocessors using model decomposition and steady-state flow analysis,""S. M. Mahmud";" L. T. Samaratunga"",""Department of Electrical and Computer Engineering, Wayne State University, Detroit, MI, USA";" Department of Electrical and Computer Engineering, Wayne State University, Detroit, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""5"",""553"",""560"",""For memory bandwidth analysis, researchers generally discard requests that are not accepted during a memory cycle. This assumption simplifies the analysis and produces negligible discrepancies with actual results for a system with a non-hierarchical interconnection network. However, the assumption, """"the requests that are not occupied during a memory cycle are discarded,"""" cannot be used for a multiprocessor system with a hierarchical interconnection network (HIN), because the error introduced assumption can be several orders of magnitude higher than the actual bandwidth. An improved analytical model to determine the bandwidth of a HIN-based system is presented.<>"",""1558-2183"","""",""10.1109/71.282567"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=282567"","""",""Bandwidth";Steady-state;Analytical models;Performance analysis;Hierarchical systems;Multiprocessor interconnection networks;Computational modeling;"Multiprocessing systems"","""",""1"","""",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Multiclass replicated data management: exploiting replication to improve efficiency,""P. Triantafillou";" D. J. Taylor"",""School of Computing Science, Simon Fraser University, Burnaby, BC, Canada";" Department of Computer Science, University of Waterloo, Waterloo, ONT, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""2"",""121"",""138"",""Research efforts in replication-control protocols primarily use replication as a means of increasing availability in distributed systems. It is well-known, however, that replication can reduce the costs of accessing remotely-stored data in distributed systems. We contribute a classification of replicas and a replication-control protocol which introduce the availability benefits of replication and, at the same time, exploit replication to improve performance, by reducing response time. Each replica class has different consistency requirements. Metareplicas keep track of up-to-date replicas for recently-accessed objects and help exploit data-reference localities. Thus they allow many transaction operations to execute synchronously at only a single (and often local) replica. Pseudoreplicas are nonpermanent replicas that facilitate """"localized execution"""" of transaction operations. True replicas are ordinary, permanent replicas as used in other replication schemes. For many commonly occurring replication scenarios, the protocol outperforms both replication-control protocols in the literature and nonreplicated systems, while offering the availability benefits of replication.<>"",""1558-2183"","""",""10.1109/71.265941"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=265941"","""",""Access protocols";Costs;Distributed computing;Availability;Delay;Concurrency control;Computational modeling;Councils;Scholarships;"Computer science"","""",""9"",""2"",""28"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"New model and algorithms for leader election in synchronous fiber-optic networks,""H. Abu-Amara";" V. Gummadi"",""Department of Electrical Engineering, Texas A and M University, College Station, TX, USA";" Department of Electrical Engineering, Texas A and M University, College Station, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""8"",""891"",""896"",""We improve on I. Cidon, I. Gopal and S. Kutten's leader election algorithm (Proc. 7th ACM Symp. Principles Distrib. Computing, Toronto, Ont., Canada. Aug. 1988) by presenting an algorithm that uses only O(/spl radic/n log D + f) time units to run on synchronous networks of degree f and diameter D, where f/spl ges/3. When f is 2, the algorithm uses only O(log D) time units.<>"",""1558-2183"","""",""10.1109/71.298218"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298218"","""",""Nominations and elections";Intelligent networks;Optical fiber networks;Petri nets;Permission;Distributed algorithms;Clocks;Concurrent computing;Conferences;"Distributed databases"","""",""1"","""",""11"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"On loop transformations for generalized cycle shrinking,""Weijia Shang"; M. T. O'Keefe;" J. A. B. Fortes"",""Department of Computer Engineerng, Santa Clara University, Santa Clara, CA, USA"; Department of Electrical Engineering, University of Minnesota, Minneapolis, MN, USA;" Department of Electrical Engineering, Purdue University, West Lafayette, IN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""2"",""193"",""204"",""This paper describes several loop transformation techniques for extracting parallelism from nested loop structures. Nested loops can then be scheduled to run in parallel so that execution time is minimized. One technique is called selective cycle shrinking, and the other is called true dependence cycle shrinking. It is shown how selective shrinking is related to linear scheduling of nested loops and how true dependence shrinking is related to conflict-free mappings of higher dimensional algorithms into lower dimensional processor arrays. Methods are proposed in this paper to find the selective and true dependence shrinkings with minimum total execution time by applying the techniques of finding optimal linear schedules and optimal and conflict-free mappings proposed by W. Shang and A.B. Fortes.<>"",""1558-2183"","""",""10.1109/71.265946"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=265946"","""",""Processor scheduling";Parallel processing;Optimizing compilers;Program processors;Contracts;Signal processing;Image processing;"Image segmentation"","""",""15"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"On parallelizing the EM algorithm for PET image reconstruction,""Chung-Ming Chen";" Soo-Young Lee"",""School of Electrical Engineering, Cornell University, NY, USA";" School of Electrical Engineering, Cornell University, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""8"",""860"",""873"",""The expectation maximization (EM) algorithm is one of the most suitable iterative methods for positron emission tomography (PET) image reconstruction";" however, it requires a long computation time and an enormous amount of memory space. To overcome these problems, we present two classes of highly efficient parallelization schemes: homogeneous and inhomogeneous partitionings. The essential difference between these two classes is that the inhomogeneous partitioning schemes may partially overlap the communication with computation by deliberate exploitation of the inherent data access pattern with a multiple-ring communication pattern. In theory, the inhomogeneous partitioning schemes may outperform the homogeneous partitioning schemes. However, the latter require a simpler communication pattern. In an attempt to estimate the achievable performance and to analyze the performance degradation factors without actual implementation, we have derived efficiency prediction formulas for closely estimating the performance for the proposed parallelization schemes. We propose new integration and broadcasting algorithms for hypercube, ring, and n-D mesh topologies, which are more efficient than the conventional algorithms when the link setup time is relatively negligible. The concept of the proposed task and data partitioning schemes, the integration and broadcasting algorithms, and the efficiency estimation methods can be applied to many other problems that are rich in data parallelism, but without balanced exclusive partitioning.<>"",""1558-2183"","""",""10.1109/71.298213"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298213"","""",""Positron emission tomography";Image reconstruction;Partitioning algorithms;Iterative algorithms;Broadcasting;Iterative methods;Performance analysis;Degradation;Hypercubes;"Topology"","""",""19"",""3"",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"On probabilistic diagnosis of multiprocessor systems using multiple syndromes,""Sunggu Lee";" K. G. Shin"",""Department of Electronic and Electrical Engineering, Pohang University of Science and Technology, Pohang, South Korea";" Real-Time Computing Laboratory, Division of Computer Science and Engineering, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""6"",""630"",""638"",""This paper addresses the distributed self-diagnosis of a multiprocessor/multicomputer system based on fault syndromes formed by comparison testing. The authors show that by using multiple fault syndromes, it is possible to achieve significantly better diagnosis than by using a single fault syndrome, even when the amount of time devoted to testing is the same. They derive a multiple syndrome diagnosis algorithm that in terms of the level of diagnostic accuracy achieved, is globally suboptimal, but optimal among all diagnosis algorithms of a certain type to be defined. The diagnosis algorithm produces good results, even with sparse interconnection networks and interprocessor tests with low fault coverage. It is also proven that the diagnosis algorithm produces 100% correct diagnosis as N, the number of nodes in the system, approaches /spl infin/, provided that the interconnection network has connectivity greater than or equal to 2 and that the number of syndromes produced grows faster than log N. This solution and another multiple syndrome diagnosis solution by Fussell and Rangarajan (1989) are comparatively evaluated, both analytically and with simulations.<>"",""1558-2183"","""",""10.1109/71.285608"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285608"","""",""Multiprocessing systems";Circuit faults;Fault diagnosis;Circuit testing;Automatic testing;Multiprocessor interconnection networks;Built-in self-test;Upper bound;System testing;"Analytical models"","""",""7"","""",""11"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"On the performance of synchronized programs in distributed networks with random processing times and transmission delays,""S. Rajsbaum";" M. Sidi"",""Instituto de Matematicas, UNAM, Ciudad Universitaria, Mexico";" Department of Electrical Engineering, Technion-Israel Institute of Technology, Haifa, Israel"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""9"",""939"",""950"",""A synchronizer is a compiler that transforms a program designed to run in a synchronous network into a program that runs in an asynchronous network. The behavior of a simple synchronizer, which also represents a basic mechanism for distributed computing and for the analysis of marked graphs, was studied by S. Even and S. Rajsbaum (1990) under the assumption that message transmission delays and processing times are constant. We study the behavior of the simple synchronizer when processing times and transmission delays are random. The main performance measure is the rate of a network, i.e., the average number of computational steps executed by a processor in the network per unit time. We analyze the effect of the topology and the probability distributions of the random variables on the behavior of the network. For random variables with exponential distribution, we provide tight (i.e., attainable) bounds and study the effect of a bottleneck processor on the rate.<>"",""1558-2183"","""",""10.1109/71.308532"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=308532"","""",""Intelligent networks";Synchronization;Clocks;Program processors;Distributed computing;Computer networks;Random variables;Delay effects;Time measurement;"Network topology"","""",""13"","""",""38"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Operationally enhanced folded hypercubes,""J. Kim";" K. G. Shin"",""Dept. of Comput. Sci. & Eng., Pohang Inst. of Sci. & Technol., South Korea";" NA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""12"",""1310"",""1316"",""Recently, several variations of the hypercube have been proposed to enhance its performance and reliability. The folded hypercube is one of these variations, in which an extra link is added to each node providing a direct connection to the node located farthest from it. In this paper, we propose a new operation mode of the folded hypercube to enhance its performance and fault-tolerance. There are (/sub ksup n+1/) regular k-cubes within a folded hypercube of dimension n, denoted by FQ/sub n/. We introduce another type of hypercube, called the twisted hypercube, to improve the performance and fault tolerance of the folded hypercube. The problems of finding a subcube of given size in an FQ/sub n/ and routing messages within the subcube are addressed for the proposed operation mode. The advantages of the proposed operation mode over the regular-hypercube operation mode are analyzed in terms of dependability and robustness. The proposed operation mode is shown to make significant improvements over the regular-hypercube operation mode in both dependability and robustness. Because the new operation mode can be applied to only an (n-1)-subcube level for a given FQ/sub n/, we present general form of folded hypercube, thus enhancing the availability of subcubes of any dimension m<n.<<ETX>>"",""1558-2183"","""",""10.1109/71.334904"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=334904"","""",""Hypercubes";Fault tolerance;Robustness;Multiprocessor interconnection networks;Computer science;Performance analysis;Routing;Computer architecture;Fault tolerant systems;"Multiprocessing systems"","""",""11"","""",""13"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Optimal NODUP all-to-all broadcast schemes in distributed computing systems,""M. . -S. Chen"; P. S. Yu;" K. . -L. Wu"",""IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"; IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA;" IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""12"",""1275"",""1285"",""Broadcast, referring to a process of information dissemination in a distributed system whereby a message originating from a certain node is sent to all other nodes in the system, is a very important issue in distributed computing. All-to-all broadcast means the process by which every node broadcasts its certain piece of information to all other nodes. In this paper, we first develop the optimal all-to-all broadcast scheme for the case of one-port communication, which means that each node can only send out one message in one communication step, and then, extend our results to the case of multi-port communication, i.e., k-port communication, meaning that each node can send out k messages in one communication step. We prove that the proposed schemes are optimal for the model considered in the sense that they not only require the minimal number of communication steps, but also incur the minimal number of messages.<>"",""1558-2183"","""",""10.1109/71.334901"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=334901"","""",""Broadcasting";Distributed computing;Availability;Protocols;High performance computing;Costs;Clocks;Synchronization;"Message passing"","""",""6"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Optimal processor assignment for a class of pipelined computations,""A. N. Choudhary"; B. Narahari; D. M. Nicol;" R. Simha"",""Department of Electrical and Computer Engineering, Syracuse University, Syracuse, NY, USA"; Department of Electrical Engineering and Computer Science, George Washington University, Washington D.C., DC, USA; Department of Computer Science, College of William and Mary, Williamsburg, VA, USA;" Department of Computer Science, College of William and Mary, Williamsburg, VA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""4"",""439"",""445"",""The availability of large-scale multitasked parallel architectures introduces the following processor assignment problem. We are given a long sequence of data sets, each of which is to undergo processing by a collection of tasks whose intertask data dependencies form a series-parallel partial order. Each individual task is potentially parallelizable, with a known experimentally determined execution signature. Recognizing that data sets can be pipelined through the task structure, the problem is to find a """"good"""" assignment of processors to tasks. Two objectives interest us: minimal response time per data set, given a throughput requirement, and maximal throughput, given a response time requirement. Our approach is to decompose a series-parallel task system into its essential """"serial"""" and """"parallel"""" components"; our problem admits the independent solution and recomposition of each such component. We provide algorithms for the series analysis, and use an algorithm due to Krishnamurti and Ma for the parallel analysis. For a p processor system and a series-parallel precedence graph with n constituent tasks, we give a O(np/sup 2/) algorithm that finds the optimal assignment (over a broad class of assignments) for the response time optimization problem;" we find the assignment optimizing the constrained throughput in O(np/sup 2/ log p) time. These techniques are applied to a task system in computer vision.<>"",""1558-2183"","""",""10.1109/71.273050"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=273050"","""",""Delay";Concurrent computing;Throughput;Computer networks;Very large scale integration;Fault tolerance;Independent component analysis;Algorithm design and analysis;Constraint optimization;"Parallel architectures"","""",""38"","""",""35"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals"""
"Optimal sequencing and arrangement in distributed single-level tree networks with communication delays,""V. Bharadwaj"; D. Ghose;" V. Mani"",""Department of Aerospace Engineering, Indian Institute of Science, Bangalore, India"; Department of Aerospace Engineering, Indian Institute of Science, Bangalore, India;" Department of Aerospace Engineering, Indian Institute of Science, Bangalore, India"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""9"",""968"",""976"",""The problem of obtaining optimal processing time in a distributed computing system consisting of (N+1) processors and N communication links, arranged in a single-level tree architecture, is considered. It is shown that optimality can be achieved through a hierarchy of steps involving optimal load distribution, load sequencing, and processor-link arrangement. Closed-form expressions for optimal processing time is derived for a general case of networks with different processor speeds and different communication link speeds. Using these closed-form expressions, the paper analytically proves a number of significant results that in earlier studies were only conjectured from computational results. In addition, it also extends these results to a more general framework. The above analysis is carried out for the cases in which the root processor may or may not be equipped with a front-end processor. Illustrative examples are given for all cases considered.<>"",""1558-2183"","""",""10.1109/71.308534"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=308534"","""",""Intelligent networks";Closed-form solution;Intelligent sensors;Distributed computing;Delay effects;Computer architecture;Computer networks;Distributed processing;"Signal processing"","""",""68"",""2"",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Optimal VLSI networks for multidimensional transforms,""H. M. Alnuweiri"",""Department of Electrical Engineering, University of British Columbia, Vancouver, BC, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""7"",""763"",""769"",""This paper presents a new class of AT/sup 2/-optimal networks for computing the multidimensional discrete Fourier transform. Although optimal networks have been proposed previously, the networks proposed in this paper are based on a new methodology for mapping large K-shuffle networks, K/spl ges/2, onto smaller area networks that maintain the optimality of the DFT network. Such networks are used to perform the index-rotation operations needed by the multidimensional computation. The resulting networks have simple regular layouts, and can be easily partitioned among several chips in order to reduce the number of input-output pins per chip.<>"",""1558-2183"","""",""10.1109/71.296321"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=296321"","""",""Very large scale integration";Multidimensional systems;Discrete Fourier transforms;Computer networks;Concurrent computing;Computer architecture;Fourier transforms;Pins;Discrete transforms;"Parallel processing"","""",""3"","""",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Parallel algorithms for the longest common subsequence problem,""Mi Lu";" Hua Lin"",""Department of Electrical Engineering, Texas A and M University, College Station, TX, USA";" Department of Electrical Engineering, Texas A and M University, College Station, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""8"",""835"",""848"",""A subsequence of a given string is any string obtained by deleting none or some symbols from the given string. A longest common subsequence (LCS) of two strings is a common subsequence of both that is as long as any other common subsequences. The problem is to find the LCS of two given strings. The bound on the complexity of this problem under the decision tree model is known to be mn if the number of distinct symbols that can appear in strings is infinite, where m and n are the lengths of the two strings, respectively, and m/spl les/n. In this paper, we propose two parallel algorithms far this problem on the CREW-PRAM model. One takes O(log/sup 2/ m + log n) time with mn/log m processors, which is faster than all the existing algorithms on the same model. The other takes O(log/sup 2/ m log log m) time with mn/(log/sup 2/ m log log m) processors when log/sup 2/ m log log m > log n, or otherwise O(log n) time with mn/log n processors, which is optimal in the sense that the time/spl times/processors bound matches the complexity bound of the problem. Both algorithms exploit nice properties of the LCS problem that are discovered in this paper.<>"",""1558-2183"","""",""10.1109/71.298210"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298210"","""",""Parallel algorithms";Decision trees;Phase change random access memory;Genetic engineering;Data compression;Error correction;Pattern recognition;Parallel processing;Algorithm design and analysis;"Read-write memory"","""",""39"","""",""13"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Parallel architecture for fast transforms with trigonometric kernel,""F. Arguello"; J. D. Bruguera; R. Doallo;" E. L. Zapata"",""Departamento de Electróica, Facultad de Física, Universidad Santiago de Compostela, Santiago de Compostela, Spain"; Departamento de Electróica, Facultad de Física, Universidad Santiago de Compostela, Santiago de Compostela, Spain; Departamento de Electróica, Facultad de Física, Universidad Santiago de Compostela, Santiago de Compostela, Spain;" Departamento de Arquitectura de Computadores, Universidad de Málaga, Malaga, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""10"",""1091"",""1099"",""We present an unified parallel architecture for four of the most important fast orthogonal transforms with trigonometric kernel: Complex Valued Fourier (CFFT), Real Valued Fourier (RFFT), Hartley (FHT), and Cosine (FCT). Out of these, only the CFFT has a data flow coinciding with the one generated by the successive doubling method, which can be transformed on a constant geometry flow using perfect unshuffle or shuffle permutations. The other three require some type of hardware modification to guarantee the constant geometry of the successive doubling method. We have defined a generalized processing section (PS), based on a circular CORDIC rotator, for the four transforms. This PS section permits the evaluation of the CFFT and FCT transforms in n data recirculations and the RFFT and FHT transforms in n-1 data recirculations, with n being the number of stages of a transform of length N=r/sup n/. Also, the efficiency of the partitioned parallel architecture is optimum because there is no cycle loss in the systolic computation of all the butterflies for each of the four transforms.<>"",""1558-2183"","""",""10.1109/71.313124"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=313124"","""",""Parallel architectures";Kernel;Fast Fourier transforms;Signal processing algorithms;Partitioning algorithms;Parallel processing;Geometry;Discrete transforms;Discrete Fourier transforms;"Algorithm design and analysis"","""",""10"",""2"",""33"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Parallel dynamic programming,""S. . -H. S. Huang"; Hongfei Liu;" V. Viswanathan"",""Department of Computer Science, University of Houston, Houston, TX, USA"; Department of Computer Science, University of Houston, Houston, TX, USA;" Department of Computer Science, University of Houston, Houston, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""3"",""326"",""328"",""Recurrence formulations for various problems, such as finding an optimal order of matrix multiplication, finding an optimal binary search tree, and optimal triangulation of polygons, assume a similar form. A. Gibbons and W. Rytter (1988) gave a CREW PRAM algorithm to solve such dynamic programming problems. The algorithm uses O(n/sup 6//log n) processors and runs in O(log/sup 2/ n) time. In this article, a modified algorithm is presented that reduces the processor requirement to O(n/sup 6//log /sup 5/n) while maintaining the same time complexity of O(log/sup 2/ n).<>"",""1558-2183"","""",""10.1109/71.277784"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=277784"","""",""Dynamic programming";Concurrent computing;Parallel processing;Very large scale integration;Binary search trees;Phase change random access memory;Labeling;Conferences;Computer architecture;"Histograms"","""",""14"","""",""5"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Partitioned encoding schemes for algorithm-based fault tolerance in massively parallel systems,""J. Rexford";" N. K. Jha"",""Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA";" Department of Electrical Engineering, Princeton University, Princeton, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""6"",""649"",""653"",""Considers the applicability of algorithm based fault tolerance (ABET) to massively parallel scientific computation. Existing ABET schemes can provide effective fault tolerance at a low cost For computation on matrices of moderate size";" however, the methods do not scale well to floating-point operations on large systems. This short note proposes the use of a partitioned linear encoding scheme to provide scalability. Matrix algorithms employing this scheme are presented and compared to current ABET schemes. It is shown that the partitioned scheme provides scalable linear codes with improved numerical properties with only a small increase in hardware and time overhead.<>"",""1558-2183"","""",""10.1109/71.285610"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285610"","""",""Encoding";Partitioning algorithms;Fault tolerant systems;Signal processing algorithms;Fault detection;Error correction codes;Fault tolerance;Matrix decomposition;Linear code;"Hardware"","""",""15"","""",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Partitioning message patterns for bundled omega networks,""P. J. Bernhard";" D. J. Rosenkrantz"",""Harris Space Systems Corporation, Rockledge, FL, USA";" Department of Computer Science, State University of New York, Albany, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""4"",""353"",""363"",""Considers a strategy for dealing with communication conflicts in omega networks. Specifically, the authors consider the problem of partitioning a set of conflicting messages into a minimum number of subsets, called rounds, each free of communication conflicts. In addition to standard omega networks, they consider this problem for a more general class of networks called bundled omega networks, where interconnection links in the network are replaced by bundles of wires. Although the partitioning problem has previously been considered in the literature, its computational complexity has remained open. The authors show that for a number of cases, the problem is NP-complete, but for certain special cases, it is solvable in polynomial time. In addition, they present a class of distributed, on-line heuristics for the problem. Finally, they give a lower bound of /spl Omega/(log N) on the performance ratio for one of these heuristics.<>"",""1558-2183"","""",""10.1109/71.273044"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=273044"","""",""Routing";Hypercubes;Wires;Computational complexity;Polynomials;Telephony;Communication switching;Computer science;Sorting;"Circuits"","""",""3"","""",""35"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Performance analysis of mesh interconnection networks with deterministic routing,""V. S. Adve";" M. K. Vernon"",""Center for Research on Parallel Computation, Rice University, Houston, TX, USA";" Department of Computer Sciences, University of Wisconsin, Madison, WI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""3"",""225"",""246"",""This paper develops detailed analytical performance models for k-ary n-cube networks with single-hit or infinite buffers, wormhole routing, and the nonadaptive deadlock-free routing scheme proposed by Dally and Seitz (1987). In contrast to previous performance studies of such networks, the system is modeled as a closed queueing network that: includes the effects of blocking and pipelining of messages in the network"; allows for arbitrary source-destination probability distributions;" and explicitly models the virtual channels used in the deadlock-free routing algorithm. The models are used to examine several performance issues for 2-D networks with shared-memory traffic. These results should prove useful for engineering high-performance systems based on low-dimensional k-ary n-cube networks.<>"",""1558-2183"","""",""10.1109/71.277793"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=277793"","""",""Performance analysis";Multiprocessor interconnection networks;Routing;System recovery;Analytical models;Pipeline processing;Probability distribution;Telecommunication traffic;Traffic control;"Systems engineering and theory"","""",""93"",""38"",""23"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Performance analysis of two different algorithms for Ethernet-FDDI interconnection,""G. Bucci"; A. Del Bimbo;" S. Santini"",""Dipartimento di Sistemi e Informatica, Università di Firenze, Florence, Italy"; Dipartimento di Sistemi e Informatica, Università di Firenze, Florence, Italy;" Dipartimento di Sistemi e Informatica, Università di Firenze, Florence, Italy"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""6"",""614"",""629"",""Fiber Distributed Data Interface (FDDI) local area networks (LAN's) are used either as high-speed links between computers and peripherals, or as backbones for lower-speed LAN's, such as Ethernet and Token Ring. The availability of such a high-speed channel will lead to the implementation of high-performance distributed environments spread over a wider area than that allowed by commonly used LAN's. The performance of such distributed environments will strongly depend on that of the interconnecting devices. In this paper, two different algorithms for packet filtering are discussed, referring to bridges interconnecting Ethernet LAN's to FDDI backbones. Algorithm performance is compared with respect to 1) the traffic increase produced on a local Ethernet, and 2) the maximum allowed traffic on remote Ethernets.<>"",""1558-2183"","""",""10.1109/71.285607"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285607"","""",""Performance analysis";Ethernet networks;FDDI;Spine;LAN interconnection;Local area networks;Computer interfaces;Computer networks;Computer peripherals;"Distributed computing"","""",""1"",""10"",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Performance evaluation of an efficient multiple copy update algorithm,""T. V. Lakshman";" Dipak Ghosal"",""Bell Communications Research, Inc., Red Bank, NJ, USA";" Bell Communications Research, Inc., Red Bank, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""2"",""217"",""224"",""A well-known algorithm for updating multiple copies is the Thomas majority consensus algorithm. This algorithm, before performing an update, needs to obtain permission from a majority of the nodes in the system. We study the response-time behavior of a symmetric (each node seeks permission from the same number of other nodes and each node receives requests for update permission from the same number of other nodes) distributed update-synchronization algorithm where nodes need to obtain permission from only O(/spl radic/N) (N being the number of database copies) other nodes before performing an update. The algorithm we use is an adaptation of Maekawa's O(/spl radic/N) distributed mutual exclusion algorithm to multiple-copy update-synchronization. This increase in the efficiency of the update-synchronization algorithm enhances performance in two ways. First, the reduction in transaction service time reduces the response time. Second, for a given arrival rate of transactions, the decrease in response time reduces the number of waiting transactions in the system. This reduces the probability of conflict between transactions. To capture the interaction between the probability of conflict and the transaction response time, we define a new measure called the conflict response-time product. Based on the solution of a queueing model we show that optimizing this measure yields a different and more appropriate choice of system parameters than simply minimizing the mean transaction response time.<>"",""1558-2183"","""",""10.1109/71.265949"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=265949"","""",""Delay";Permission;Transaction databases;Time measurement;Distributed databases;Time factors;Concurrency control;Throughput;Springs;"Availability"","""","""","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Performance evaluation of scheduling precedence-constrained computations on message-passing systems,""M. Al-Mouhamed";" A. Al-Maasarani"",""King Fahd University of Petroleum & Minerals, Dhahran, SA";" Dept. of Comput. Eng., King Fahd Univ. of Pet. & Miner., Dhahran, Saudi Arabia"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""12"",""1317"",""1321"",""Using knowledge on computation, communication, and multiprocessor topology, a class of global priority-based scheduling heuristics, called generalized list scheduling (GLS) is proposed. Task-priority is defined as the completion time of the task following backward scheduling the computation over the multiprocessor by using the best local heuristic. GLS scheduling consists of using the task-priority in forward, graph-driven scheduling. Evaluation of local (ETF) and GLS heuristics is carried out by altering over the communication, parallelism, and system topology. Analysis shows that local heuristics rely on locally maximizing the efficiency and gives acceptable solutions only when the parallelism is large enough to cover the communication (bounded speedup). GLS scheduling outperforms the local approaches versus change in parallelism, communication, and network topology. The time complexity of GLS heuristics is O(pn/sup 2/), where p and n are the number of processors and that of the tasks, respectively.<>"",""1558-2183"","""",""10.1109/71.334905"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=334905"","""",""Processor scheduling";Parallel processing;Network topology;Merging;Delay;Computer architecture;Petroleum;Minerals;Computer networks;"Computational modeling"","""",""13"","""",""10"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Performance evaluation of transaction processing coupling architectures for handling system dynamics,""P. S. Yu";" A. Dan"",""IBM Research Division, IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA";" IBM Research Division, IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""2"",""139"",""153"",""As the demand for high volume transaction processing grows, coupling multiple computing nodes becomes increasingly attractive. This paper presents a comparison on the resilience of the performance to system dynamics of three architectures for transaction processing. In the shared nothing (SN) architecture, neither disks nor memory is shared. In the shared disk (SD) architecture, all disks are accessible to all nodes while in the shared intermediate memory (SIM) architecture, a shared intermediate level of memory is introduced. A transaction processing system needs to be configured with enough capacity to cope with the dynamic variation of load or with a node failure. Three specific scenarios are considered: 1) a sudden surge in load of one transaction class, 2) varying transaction rates for all transaction classes, and 3) failure of a single processing node. We find that the different architectures require different amounts of capacity to be reserved to cope with these dynamic situations. We further show that the data sharing architecture, especially in the case with shared intermediate memory, is more resilient to system dynamics and requires far less contingency capacity compared to the SN architecture.<>"",""1558-2183"","""",""10.1109/71.265942"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=265942"","""",""Computer architecture";Tin;Surges;Resilience;Memory architecture;Performance analysis;Transaction databases;Availability;Costs;"Steady-state"","""",""21"",""1"",""28"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Pipelining and bypassing in a VLIW processor,""A. Abnous";" N. Bagherzadeh"",""Department of Electrical and Computer Engineering, University of California, Irvine, CA, USA";" Department of Electrical and Computer Engineering, University of California, Irvine, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""6"",""658"",""664"",""This short note describes issues involved in the bypassing mechanism for a very long instruction word (VLIW) processor and its relation to the pipeline structure of the processor. The authors first describe the pipeline structure of their processor and analyze its performance and compare it to typical RISC-style pipeline structures given the context of a processor with multiple functional units. Next they study the performance effects of various bypassing schemes in terms of their effectiveness in resolving pipeline data hazards and their effect on the processor cycle time.<>"",""1558-2183"","""",""10.1109/71.285612"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285612"","""",""Pipeline processing";VLIW;Computer architecture;Registers;Reduced instruction set computing;Processor scheduling;Hardware;Hazards;Parallel processing;"Performance analysis"","""",""17"",""1"",""14"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Probabilistic clock synchronization in distributed systems,""K. Arvind"",""Digital Equipment Corporation, Littleton, MA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""5"",""474"",""487"",""Presents and analyzes a new probabilistic clock synchronization algorithm that can guarantee a much smaller bound on the clock skew than most existing algorithms. The algorithm is probabilistic in the sense that the bound on the clock skew that it guarantees has a probability of invalidity associated with it. However, the probability of invalidity may be made extremely small by transmitting a sufficient number of synchronization messages. It is shown that an upper bound on the probability of invalidity decreases exponentially with the number of synchronization messages transmitted. A closed-form expression that relates the probability of invalidity to the clock skew and the number of synchronization messages is also derived.<>"",""1558-2183"","""",""10.1109/71.282558"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=282558"","""",""Clocks";Synchronization;Upper bound;Algorithm design and analysis;Hardware;Closed-form solution;Master-slave;Protocols;Time measurement;"Real time systems"","""",""103"",""5"",""19"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Processor membership in asynchronous distributed systems,""L. E. Moser"; P. M. Melliar-Smith;" V. Agrawala"",""Department of Electrical & Computer Engineering, University of California, Santa Barbara, CA, USA"; Department of Electrical & Computer Engineering, University of California, Santa Barbara, CA, USA;" Siemens AG Corporate Research and Development, Princeton, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""5"",""459"",""473"",""Presents protocols for determining processor membership in asynchronous distributed systems that are subject to processor and communication faults. These protocols depend on the placement of a total order on broadcast messages. The types of systems for which each of these protocols is applicable are characterized by the properties of the communication mechanisms and by the availability of stable storage. In the absence of stable storage or of a mechanism for distinguishing promptly delivered messages, the authors show that no membership protocol can exist. They also discuss their experience in implementing these membership protocols.<>"",""1558-2183"","""",""10.1109/71.282557"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=282557"","""",""Protocols";Broadcasting;Fault tolerant systems;Fault tolerance;Marine vehicles;Delay;"Resilience"","""",""24"",""11"",""22"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"Reaching approximate agreement with mixed-mode faults,""R. M. Kieckhafer";" M. H. Azadmanesh"",""Department of Computer Science and Engineering, University of Nebraska, Lincoln, Lincolnshire, NE, USA";" Department of Computer Science and Engineering, University of Nebraska, Lincoln, Lincolnshire, NE, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""1"",""53"",""63"",""In a fault-tolerant distributed system, different non-faulty processes may arrive at different values for a given system parameter. To resolve this disagreement, processes must exchange and vote upon their respective local values. Faulty processes may attempt to inhibit agreement by acting in a malicious or """"Byzantine"""" manner. Approximate agreement defines one form of agreement in which the voted values obtained by the non-faulty processes need not be identical. Instead, they need only agree to within a predefined tolerance. Approximate agreement can be achieved by a sequence of convergent voting rounds, in which the range of values held by non-faulty processes is reduced in each round. Historically, each new convergent voting algorithm has been accompanied by ad-hoc proofs of its convergence rate and fault-tolerance, using an overly conservative fault model in which all faults exhibit worst-case Byzantine behavior. This paper presents a general method to quickly determine convergence rate and fault-tolerance for any member of a broad family of convergent voting algorithms. This method is developed under a realistic mixed-mode fault model comprised of asymmetric, symmetric, and benign fault modes. These results are employed to more accurately analyze the properties of several existing voting algorithms, to derive a sub-family of optimal mixed-mode voting algorithms, and to quickly determine the properties of proposed new voting algorithms.<>"",""1558-2183"","""",""10.1109/71.262588"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=262588"","""",""Voting";Fault tolerance;Convergence;Clocks;Synchronization;Fault tolerant systems;Algorithm design and analysis;Computer science;Hardware;"Application software"","""",""87"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Reading many variables in one atomic operation: solutions with linear or sublinear complexity,""L. M. Kirousis"; P. Spirakis;" P. Tsigas"",""Department of Computer Engineering and Informatics, University of Patras, Patras, Greece"; Department of Computer Engineering and Informatics, University of Patras, Patras, Greece;" Department of Computer Engineering and Informatics, University of Patras, Patras, Greece"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""7"",""688"",""696"",""We address the problem of reading several variables (components) X/sub 1/,...,X/sub c/, all in one atomic operation, by only one process, called the reader, while each of these variables are being written by a set of writers. All operations (i.e., both reads and writes) are assumed to be totally asynchronous and wait-free. For this problem, only algorithms that require at best quadratic time and space complexity can be derived from the existing literature. (The time complexity of a construction is the number of suboperations of a high-level operation and its space complexity is the number of atomic shared variables it needs) In this paper, we provide a deterministic protocol that has linear (in the number of processes) space complexity, linear time complexity for a read operation, and constant time complexity for a write. Our solution does not make use of time-stamps. Rather, it is the memory location where a write writes that differentiates it from the other writes. Also, introducing randomness in the location where the reader gets the value that it returns, we get a conceptually very simple probabilistic algorithm. This algorithm has an overwhelmingly small, controllable probability of error. Its space complexity, and also the time complexity of a read operation, are sublinear. The time complexity of a write is constant. On the other hand, under the Archimedean time assumption, we get a protocol whose time and space complexity do not depend on the number of writers, but are linear in the number of components only. (The time complexity of a write operation is still constant.).<>"",""1558-2183"","""",""10.1109/71.296315"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=296315"","""",""Protocols";Registers;Data structures;Error correction;Distributed algorithms;Informatics;Read-write memory;"Microwave integrated circuits"","""",""17"","""",""11"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Real-time communication in multihop networks,""D. D. Kandhlur"; K. G. Shin;" D. Ferrari"",""IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA"; Real-Time Computing Laboratory, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA;" Computer Science Division, Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""10"",""1044"",""1056"",""Communication in real-time systems has to be predictable, because unpredictable delays in the delivery of messages can adversely affect the execution of tasks dependent on these messages. We develop a scheme for providing predictable interprocess communication in real-time systems with (partially connected) point-to-point interconnection networks, which provide guarantees on the maximum delivery time for messages. This scheme is based on the concept of a real-time channel, a unidirectional connection between source and destination. A real-time channel has parameters that describe the performance requirements of the source-destination communication, e.g., from a sensor station to a control site. Once such a channel is established, the communications subsystem guarantees that these performance requirements will be met. We concentrate on methods to compute guarantees for the delivery time of messages belonging to real-time channels. We also address problems associated with allocating buffers for these messages and develop a scheme that preserves delivery time guarantees.<>"",""1558-2183"","""",""10.1109/71.313121"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=313121"","""",""Intelligent networks";Spread spectrum communication;Real time systems;Multiprocessor interconnection networks;Delay;Communication system control;Time factors;Access protocols;Scheduling algorithm;"Sensor phenomena and characterization"","""",""106"",""5"",""25"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Reconfiguration with time division multiplexed MIN's for multiprocessor communications,""Chunming Qiao";" R. Melhem"",""Department of Computer Science, University of Pittsburgh, Pittsburgh, PA, USA";" Department of Electrical and Computer Engineering, State University of New York, Buffalo, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""4"",""337"",""352"",""Time division multiplexed multistage interconnection networks (TDM-MIN's) are proposed for multiprocessor communications. Connections required by an application are partitioned into a number of subsets, called mappings, such that connections in each mapping can be established in an MIN without conflict. Switch settings for establishing connections in each mapping are determined and stored in shift registers. By repeatedly changing switch settings, connections in each mapping are established for a time slot in a round-robin fashion. Thus, all connections required by an application may be established in an MIN in a time division multiplexed way. TDM-MIN's can emulate a completely connected network using N time slots. It can also emulate regular networks such as rings, meshes, cube-connected-cycles (CCC), binary trees, and n-dimensional hypercubes using 2, 4, 3, 4, and n time slots, respectively. The problem of partitioning an arbitrary set of requests into a minimal number of mappings is NP-hard. Simple heuristic algorithms are presented and their performances are shown to be close to optimal. The flexibility of TDM-MIN's allows for the support of run-time requests through dynamic reconfigurations. The techniques are especially suitable for hybrid electro-optical systems with optical interconnects.<>"",""1558-2183"","""",""10.1109/71.273043"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=273043"","""",""Time division multiplexing";Switches;Communication switching;Multiprocessor interconnection networks;Shift registers;Binary trees;Hypercubes;Heuristic algorithms;Partitioning algorithms;"Runtime"","""",""49"",""1"",""39"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Reducing PE/memory traffic in multiprocessors by the difference coding of memory addresses,""D. M. Koppelman"",""Department of Electrical and Computer Engineering, Louisiana State University, Baton Rouge, LA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""11"",""1156"",""1168"",""A method of reducing the volume of data flowing through the network in a shared memory parallel computer (multiprocessor) is described. The reduction is achieved by difference coding the memory addresses in messages sent between processing elements (PE's) and memories. In an implementation, each PE would store the last address sent to each memory, and vice versa. Messages that would normally contain an address instead contain the difference between the address associated with the current and most recent messages. Trace-driven simulation shows that only 70% or less of traffic volume (including data and overhead) is necessary, even in systems using coherent caches. The reduction in traffic could result in a lower cost or lower latency network. The cost of the hardware to achieve this is small, and the delay added is insignificant compared to network latency.<>"",""1558-2183"","""",""10.1109/71.329672"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=329672"","""",""Costs";Delay;Telecommunication traffic;Concurrent computing;Computer networks;Traffic control;Hardware;Multiprocessor interconnection networks;Computational modeling;"Intelligent networks"","""",""2"","""",""22"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Repeated computation of global functions in a distributed environment,""V. K. Garg";" J. Ghosh"",""Department of Electrical and Computer Engineering, University of Technology, Austin, TX, USA";" Department of Electrical and Computer Engineering, University of Technology, Austin, TX, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""8"",""823"",""834"",""In a distributed system, many algorithms need repeated computation of a global function. These algorithms generally use a static hierarchy for gathering the necessary data from all processes. As a result, they are unfair to processes at higher levels of the hierarchy, which have to perform more work than processes at lower levels do. In this paper, we present a new revolving hierarchical scheme in which the position of a process in the hierarchy changes with time. This reorganization of the hierarchy is achieved concurrently with its use. It results in algorithms that are not only fair to all processes but also less expensive in terms of messages. The reduction in the number of messages is achieved by reusing messages for more than one computation of the global function. The technique is illustrated for a distributed branch-and-bound problem and for asynchronous computation of fixed points.<>"",""1558-2183"","""",""10.1109/71.298209"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298209"","""",""Distributed computing";Concurrent computing;System recovery;Protocols;Clocks;Synchronization;Relays;Military computing;Fault tolerant systems;"Computer worms"","""",""7"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Request combining in multiprocessors with arbitrary interconnection networks,""A. R. Lebeck";" G. S. Sohi"",""Computer Sciences Department, University of Wisconsin, Madison, WI, USA";" Computer Sciences Department, University of Wisconsin, Madison, WI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""11"",""1140"",""1155"",""Several techniques have been proposed to allow parallel access to a shared memory location by combining requests. They have one or more of the following attributes: requirements for a priori knowledge of the request to combine, restrictions on the routing of messages in the network, or the use of sophisticated interconnection network nodes. We present a new method of combining requests that does not have the above requirements. We obtain this new method for request combining by developing a classification scheme for the existing methods of request combining. This classification scheme is facilitated by separating the request combining process into a two part operation: determining the combining set, which is the set of requests that participate in a combined access";" and distributing the results of the combined access to the members of the combining set. The classification of combining strategies is based upon which system component, processor elements, or interconnection network performs each of these tasks. Our approach, which uses the interconnection network to establish the combining set and the processor elements to distribute the results, lies in an unexplored area of the design space. We also present simulation results to assess the benefits of the proposed approach.<>"",""1558-2183"","""",""10.1109/71.329673"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=329673"","""",""Intelligent networks";Multiprocessor interconnection networks;Delay;Routing;Prefetching;Proposals;Network topology;"Computer networks"","""",""5"",""12"",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"RH: a versatile family of reduced hypercube interconnection networks,""S. G. Ziavras"",""Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""11"",""1210"",""1220"",""The binary hypercube has been one of the most frequently chosen interconnection networks for parallel computers because it provides low diameter and is so robust that it can very efficiently emulate a wide variety of other frequently used networks. However, the major drawback of the hypercube is the increase in the number of communication channels for each processor with an increase in the total number of processors in the system. This drawback has a direct effect on the very large scale integration complexity of the hypercube network. This short note proposes a new topology that is produced from the hypercube by a uniform reduction in the number of edges for each node. This edge reduction technique produces networks with lower complexity than hypercubes while maintaining, to a high extent, the powerful hypercube properties. An extensive comparison of the proposed reduced hypercube (RH) topology with the conventional hypercube is included. It is also shown that several copies of the popular cube-connected cycles network can be emulated simultaneously by an RH with dilation 1.<>"",""1558-2183"","""",""10.1109/71.329667"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=329667"","""",""Hypercubes";Multiprocessor interconnection networks;Circuit faults;Integrated circuit interconnections;Doped fiber amplifiers;Computer networks;Concurrent computing;Sufficient conditions;Circuit testing;"Network topology"","""",""52"",""1"",""29"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Scalability of parallel algorithm-machine combinations,""Xian-He Sun";" D. T. Rover"",""NASA Langley Research Center, ICASE, Hampton, VA, USA";" Department of Electrical Engineering, Michigan State University, East Lansing, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""6"",""599"",""613"",""Scalability has become an important consideration in parallel algorithm and machine designs. The word scalable, or scalability, has been widely and often used in the parallel processing community. However, there is no adequate, commonly accepted definition of scalability available. Scalabilities of computer systems and programs are difficult to quantify, evaluate, and compare. In this paper, scalability is formally defined for algorithm-machine combinations. A practical method is proposed to provide a quantitative measurement of the scalability. The relation between the newly proposed scalability and other existing parallel performance metrics is studied. A harmony between speedup and scalability has been observed. Theoretical results show that a large class of algorithm-machine combinations is scalable and the scalability can be predicted through premeasured machine parameters. Two algorithms have been studied on an nCUBE 2 multicomputer and on a MasPar MP-1 computer. These case studies have shown how scalabilities can be measured, computed, and predicted. Performance instrumentation and visualization tools also have been used and developed to understand the scalability related behavior.<>"",""1558-2183"","""",""10.1109/71.285606"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285606"","""",""Scalability";Parallel processing;Parallel algorithms;Sun;Algorithm design and analysis;High performance computing;Concurrent computing;Application software;Computer architecture;"NASA"","""",""109"","""",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Scheduling DAG's for asynchronous multiprocessor execution,""B. A. Malloy"; E. L. Lloyd;" M. L. Soffa"",""Department of Computer Science, Clemson University, Clemson, SC, USA"; Department of Information and Computer Sciences, University of Delaware, Newark, DE, USA;" Department of Computer Science, University of Pittsburgh, Pittsburgh, PA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""5"",""498"",""508"",""A new approach is given for scheduling a sequential instruction stream for execution """"in parallel"""" on asynchronous multiprocessors. The key idea in our approach is to exploit the fine grained parallelism present in the instruction stream. In this context, schedules are constructed by a careful balancing of execution and communication costs at the level of individual instructions, and their data dependencies. Three methods are used to evaluate our approach. First, several existing methods are extended to the fine grained situation. Our approach is then compared to these methods using both static schedule length analyses, and simulated executions of the scheduled code. In each instance, our method is found to provide significantly shorter schedules. Second, by varying parameters such as the speed of the instruction set, and the speed/parallelism in the interconnection structure, simulation techniques are used to examine the effects of various architectural considerations on the executions of the schedules. These results show that our approach provides significant speedups in a wide-range of situations. Third, schedules produced by our approach are executed on a two-processor Data General shared memory multiprocessor system. These experiments show that there is a strong correlation between our simulation results, and these actual executions, and thereby serve to validate the simulation studies. Together, our results establish that fine grained parallelism can be exploited in a substantial manner when scheduling a sequential instruction stream for execution """"in parallel"""" on asynchronous multiprocessors.<>"",""1558-2183"","""",""10.1109/71.282560"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=282560"","""",""Parallel processing";VLIW;Processor scheduling;Concurrent computing;Computer science;Context;Costs;Analytical models;Multiprocessing systems;"Image processing"","""",""28"",""1"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Scheduling precedence constrained task graphs with non-negligible intertask communication onto multiprocessors,""S. Selvakumar";" C. Siva Ram Murthy"",""Department of Computer Science and Engineering, Indian Institute of Technology, Chennai, India";" Department of Computer Science and Engineering, Indian Institute of Technology, Chennai, India"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""3"",""328"",""336"",""The multiprocessor scheduling problem is the problem of scheduling the tasks of a precedence constrained task graph (representing a parallel program) onto the processors of a multiprocessor in a way that minimizes the completion time. Since this problem is known to be NP-hard in the strong sense in all but a few very restricted eases, heuristic algorithms are being developed which obtain near optimal schedules in a reasonable amount of computation time. We present an efficient heuristic algorithm for scheduling precedence constrained task graphs with nonnegligible intertask communication onto multiprocessors taking contention in the communication channels into consideration. Our algorithm for obtaining satisfactory suboptimal schedules is based on the classical list scheduling strategy. It simultaneously exploits the schedule-holes generated in the processors and in the communication channels during the scheduling process in order to produce better schedules. We demonstrate the effectiveness of our algorithm by comparing with two competing heuristic algorithms available in the literature.<>"",""1558-2183"","""",""10.1109/71.277783"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=277783"","""",""Parallel algorithms";Optimal scheduling;Processor scheduling;Binary trees;Tree graphs;Algorithm design and analysis;Dynamic programming;Concurrent computing;Cost function;"Binary search trees"","""",""37"","""",""26"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Shared memory multimicroprocessor operating system with an extended Petri net model,""F. Vallejo"; J. A. Gregorio; M. Gonzalez Harbour;" J. M. Drake"",""Departamento de Electrónica, Universidad de Cantabria, Santander, Spain"; Departamento de Electrónica, Universidad de Cantabria, Santander, Spain; Departamento de Electrónica, Universidad de Cantabria, Santander, Spain;" Departamento de Electrónica, Universidad de Cantabria, Santander, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""7"",""749"",""762"",""We propose a methodology for programming multiprocessor event-driven systems. This methodology is based on two programming levels: the task level, which involves programming the basic actions that may be executed in the system as units with a single control thread";" and the job level, on which parallel programs to be executed by the complete multiprocessor system are developed. We also present the structure and implementation of an operating system designed as the programming support for software development under the proposed methodology. The model that has been chosen for the representation of the system software is based on an extended Petri net, which provides a well-established conceptual model for the development of the tasks, thus allowing a totally independent and generic development. This model also facilitates job-level programming, since the Petri net is a very powerful description tool for the parallel program.<>"",""1558-2183"","""",""10.1109/71.296320"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=296320"","""",""Operating systems";Application software;Parallel programming;Power system modeling;Robotics and automation;Hardware;Software systems;Control systems;"Multiprocessing systems"","""",""4"",""4"",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Spoken language recognition on a DSP array processor,""S. Glinski";" D. Roe"",""AT and T Bell Laboratories, Inc., Murray Hill, NJ, USA";" AT and T Bell Laboratories, Inc., Murray Hill, NJ, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""7"",""697"",""703"",""A new architecture is presented to support the general class of real-time large-vocabulary speaker-independent continuous speech recognizers incorporating language models. Many such recognizers require multiple high-performance central processing units (CPU's) as well as high interprocessor communication bandwidth. This array processor provides a peak CPU performance of 2.56 giga-floating point operations per second (GFLOPS) as well as a high-speed communication network. In order to efficiently utilize these resources, algorithms were devised for partitioning speech models for mapping into the array processor. Also, a novel scheme is presented for a functional partitioning of the speech recognizer computations. The recognizer is functionally partitioned into six stages, namely, the linear predictive coding (LPC) based feature extractor, mixture probability computer, (phone) state probability computer, word probability computer, phrase probability computer, and traceback computer. Each of these stages is further subdivided as many times as necessary to fit the individual processing elements (PE's). The functional stages are pipelined and synchronized with the frame rate of the incoming speech signal. This partitioning also allows a multistage stack decoder to be implemented for reduction of computation.<>"",""1558-2183"","""",""10.1109/71.296316"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=296316"","""",""Natural languages";Digital signal processing;Speech recognition;Central Processing Unit;Linear predictive coding;Bandwidth;Communication networks;Partitioning algorithms;Speech processing;"Feature extraction"","""",""6"",""15"",""5"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Static and run-time algorithms for all-to-many personalized communication on permutation networks,""S. Ranka"; J. . -C. Wang;" G. C. Fox"",""Center for Science and Technology, School of Computer and Information Science, Syracuse University, Syracuse, NY, USA"; Department of Computer Science, University of Illinois, Urbana-Champaign, Urbana, IL, USA;" Center for Science and Technology, School of Computer and Information Science, Syracuse University, Syracuse, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""12"",""1266"",""1274"",""With the advent of new routing methods, the distance that a message is sent is becoming relatively less and less important. Thus, assuming no link contention, permutation seems to be an efficient collective communication primitive. In this paper, we present several algorithms for decomposing all-to-many personalized communication into a set of disjoint partial permutations. We discuss several algorithms and study their effectiveness from the view of static scheduling as well as run-time scheduling. An approximate analysis shows that with n processors, and assuming that every processor sends and receives d messages to random destinations, our algorithm can perform the scheduling in O(dn In d) time, on average, and can use an expected number of d+log d partial permutations to carry out the communication. We present experimental results of our algorithms on the CM-5.<>"",""1558-2183"","""",""10.1109/71.334900"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=334900"","""",""Runtime";Processor scheduling;Routing;Scheduling algorithm;Parallel processing;Load management;Matrix decomposition;Performance analysis;Algorithm design and analysis;"Concurrent computing"","""",""6"","""",""21"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"Static processor allocation in a soft real-time multiprocessor environment,""B. M. Carlson";" L. W. Dowdy"",""College of Business and Information Systems, Dakota State University, Madison, SD, USA";" Department of Computer Science, Vanderbilt University, Nashville, TN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""3"",""316"",""320"",""Soft real-time environments consist of jobs that must receive service within a particular time interval. If service for a specific job is not completed by the end of its time interval, it is said to be lost";" in addition, the computation time expended on the job is wasted, and any further computation for the job is discontinued. The goal of a system designer is to provide an environment that minimizes the number of jobs that are lost. If a parallel environment is available, the system designer has two options: Allow each processor to execute a job individually, or let multiple processors cooperate in executing a job. This article shows, for two classes of static allocation policies, that simple comparative analytical models may be used to indicate which option minimizes the number of lost jobs, as a function of workload intensity. The first class of policies, called equal partitions, statically decomposes the system into equal-size sets of processors and executes one job per partition. These policies are frequently employed in other contexts. The second class of policies, called two partitions, statically partitions the processors into two sets, not necessarily of the same size. Surprisingly, it is observed mathematically that even for statistically identical jobs, this class of policies is superior to equal partitions under certain loadings. The analysis is validated experimentally with a workload executed on a 16-node iPSC/2 hypercube.<>"",""1558-2183"","""",""10.1109/71.277786"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=277786"","""",""Real time systems";Job design;Multiprocessing systems;Hypercubes;Random variables;Computer science;Processor scheduling;Analytical models;Throughput;"Delay"","""",""6"","""",""20"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"Structuring fault-tolerant object systems for modularity in a distributed environment,""S. K. Shrivastava";" D. L. McCue"",""Department of Computing Science, University of Newcastle, Newcastle-upon-Tyne, UK";" Xerox Corporation, Webster, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""4"",""421"",""432"",""The object-oriented approach to system structuring has found widespread acceptance among designers and developers of robust computing systems. The authors propose a system structure for distributed programming systems that support persistent objects and describe how properties such as persistence and recoverability can be implemented. The proposed structure is modular, permitting easy exploitation of any distributed computing facilities provided by the underlying system. An existing system constructed according to the principles espoused here is examined to illustrate the practical utility of the proposed approach to system structuring.<>"",""1558-2183"","""",""10.1109/71.273048"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=273048"","""",""Fault tolerant systems";Distributed computing;Computer crashes;Computational modeling;Object oriented modeling;Computer architecture;Robustness;Robust control;Concurrent computing;"Message passing"","""",""16"",""7"",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Task allocation in the star graph,""S. Latifi"",""Department of Electrical and Computer Engineering, University of Nevada, Las Vegas, NV, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""11"",""1220"",""1224"",""The star graph has been known as an attractive candidate for interconnecting a large number of processors. The hierarchy of the star graph allows the assignment of its special subgraphs (substars), which have the same topological features as the original graph, to a sequence of incoming tasks. The paper proposes a new code, called star code (SC), to recognize available substars of the required size in the star graph. It is shown that task allocation based on the SC is statically optimal. The recognition ability of a given SC or a class of SC's is derived. The optimal number of SC's required for the complete substar recognition in an n-dimensional star is shown to be 2/sup n-2/.<>"",""1558-2183"","""",""10.1109/71.329666"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=329666"","""",""Fault tolerance";Parallel algorithms;Hypercubes;Tree graphs;Network topology;Multiprocessor interconnection networks;Partitioning algorithms;Costs;Routing;"Terminology"","""",""4"","""",""16"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"Testing the dynamic full access property of a class of multistage interconnection networks,""Tsern-Huei Lee";" Jin-Jye Chou"",""Department of Communication Engineering, National Chiao Tung University, Hsinchu, Taiwan";" Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""11"",""1206"",""1210"",""The banyan network, and networks topologically equivalent to it, have recently been adopted as interconnection networks in multiprocessor systems. Often, a multiprocessor system is reconfigured when the banyan network becomes faulty. It is possible to avoid a complicated reconfiguration process as long as the faulty banyan network still possesses the dynamic full access (DFA) property. In this paper, we determine a necessary and sufficient condition for a faulty banyan network to possess the DFA property and design a test procedure based on the condition. The test procedure can be used to decompose a faulty banyan network into subsystems possessing the DFA property. We also evaluate the probability that a banyan network loses the DFA property, given the number of faulty switching elements. It is found that as long as faults do not occur in switching elements located in the first and last stages, this probability is very small, even when there are quite a few faulty switching elements.<>"",""1558-2183"","""",""10.1109/71.329668"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=329668"","""",""Testing";Multiprocessor interconnection networks;Doped fiber amplifiers;Multiprocessing systems;Sufficient conditions;Fault tolerant systems;Routing;Fault tolerance;Councils;"Fault detection"","""",""2"","""",""12"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"The classification, fusion, and parallelization of array language primitives,""D. . -C. R. Ju"; Chuan-Lin Wu;" P. Carini"",""IBM Santa Teresa Laboratory, San Jose, CA, USA"; Department of Electrical and Computer Engineering, University of Texas, Austin, TX, USA;" IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""10"",""1113"",""1120"",""We present a classification scheme for array language primitives that quantifies the variation in parallelism and data locality that results from the fusion of any two primitives. We also present an algorithm based on this scheme that efficiently determines when it is beneficial to fuse any two primitives. Experimental results show that five LINPACK routines report 50% performance improvement from the fusion of array operators.<>"",""1558-2183"","""",""10.1109/71.313127"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=313127"","""",""Parallel processing";Program processors;Fuses;Optimizing compilers;Computer languages;Programming profession;Degradation;Laboratories;Concurrent computing;"Heuristic algorithms"","""",""4"",""3"",""17"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"The combining DAG: a technique for parallel data flow analysis,""R. Kramer"; R. Gupta;" M. L. Soffa"",""Department of Computer Science, University of Pittsburgh, Pittsburgh, PA, USA"; Department of Computer Science, University of Pittsburgh, Pittsburgh, PA, USA;" Department of Computer Science, University of Pittsburgh, Pittsburgh, PA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""8"",""805"",""813"",""As the number of available multiprocessors increases, so does the importance of providing software support for these systems, including parallel compilers. Data flow analysis, an important component of software tools, may be computed many times during the compilation of a program, especially when compiling for a multiprocessor. Although converting a sequential data flow algorithm to a parallel algorithm can present some opportunities for computing data flow in parallel, more parallelism can be exposed by the development of new parallel data flow algorithms. We present a technique that computes rapid data flow problems in parallel and thus is applicable for commonly used classical data flow problems, including reaching definitions, reachable uses, available expressions, and very busy expressions. Unlike previous techniques, our technique exploits the inherent parallelism in the data flow computation that occurs across independent paths, within linear paths, and in paths through loops of a control flow graph. The technique first changes cyclic structures in a control flow graph to acyclic structures and then builds a combining directed acyclic graph (DAG) that represents the paths through the control flow graph needed to compute data flow. Data flow is then computed using two passes over the DAG by computing the data flow for the nodes on each level of the DAG in parallel. We also present experimental results comparing the performance of our algorithm with a sequential algorithm and a parallelized sequential algorithm.<>"",""1558-2183"","""",""10.1109/71.298205"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298205"","""",""Data analysis";Data flow computing;Flow graphs;Concurrent computing;Parallel processing;Parallel algorithms;Iterative algorithms;Software tools;Iterative methods;"Availability"","""",""18"",""51"",""18"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;
"The fault-tolerant extension problem for complete multipartite networks,""A. A. Farrag";" R. J. Dawson"",""Department of Mathematics and Computing Science, Dalhousie University, Halifax, NS, Canada";" Department of Mathematics and Computing Science, Dalhousie University, Halifax, NS, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""2"",""205"",""210"",""We develop a characterization for m-fault-tolerant extensions, and for optimal m-fault-tolerant extensions, of a complete multipartite graph. Our formulation shows that this problem is equivalent to an interesting combinatorial problem on the partitioning of integers. This characterization leads to a new procedure for constructing an optimal m-fault-tolerant extension of any complete multipartite graph, for any m/spl ges/0. The proposed procedure is mainly useful when the size of the graph is relatively small, because the search time required is exponential. This exponential search, however, is not always necessary. We prove several necessary conditions that help us, in several cases, to identify some optimal m-fault-tolerant extensions without performing any search.<>"",""1558-2183"","""",""10.1109/71.265947"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=265947"","""",""Fault tolerance";Mathematics;Tree graphs;"Tree data structures"","""",""7"","""",""15"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;
"The hierarchical hypercube: a new interconnection topology for massively parallel systems,""Q. M. Malluhi";" M. A. Bayoumi"",""Center for Advanced Computer Studies, University of Southwestern Louisiana, Lafayette, LA, USA";" Center for Advanced Computer Studies, University of Southwestern Louisiana, Lafayette, LA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""1"",""17"",""30"",""Interconnection networks play a crucial role in the performance of parallel systems. This paper introduces a new interconnection topology that is called the hierarchical hypercube (HHC). This topology is suitable for massively parallel systems with thousands of processors. An appealing property of this network is the low number of connections per processor, which enhances the VLSI design and fabrication of the system. Other alluring features include symmetry and logarithmic diameter, which imply easy and fast algorithms for communication. Moreover, the HHC is scalable";" that is it can embed HHC's of lower dimensions. The paper presents two algorithms for data communication in the HHC. The first algorithm is for one-to-one transfer, and the second is for one-to-all broadcasting. Both algorithms take O(log/sub 2/ k), where k is the total number of processors in the system. A wide class of problems, the divide & conquer class (D&Q), is shown to be easily and efficiently solvable on the HHC topology. Parallel algorithms are provided to describe how a D&Q problem can be solved efficiently on an HHC structure. The solution of a D&Q problem instance having up to k inputs requires a time complexity of O(log/sub 2/ k).<>"",""1558-2183"","""",""10.1109/71.262585"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=262585"","""",""Hypercubes";Network topology;Multiprocessor interconnection networks;Very large scale integration;Broadcasting;Bandwidth;Fabrication;Data communication;Parallel algorithms;"Parallel processing"","""",""94"",""7"",""15"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;
"The impact of parallel loop scheduling strategies on prefetching in a shared memory multiprocessor,""D. J. Lilja"",""Department of Electrical Engineering, University of Minnesota, Minneapolis, MN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""6"",""573"",""584"",""Trace-driven simulations of numerical Fortran programs are used to study the impact of the parallel loop scheduling strategy on data prefetching in a shared memory multiprocessor with private data caches. The simulations indicate that to maximize memory performance, it is important to schedule blocks of consecutive iterations to execute on each processor, and then to adaptively prefetch single-word cache blocks to match the number of iterations scheduled. Prefetching multiple single-word cache blocks on a miss reduces the miss ratio by approximately 5% to 30% compared to a system with no prefetching. In addition, the proposed adaptive prefetching scheme further reduces the miss ratio while significantly reducing the false sharing among cache blocks compared to nonadaptive prefetching strategies. Reducing the false sharing causes fewer coherence invalidations to be generated, and thereby reduces the total network traffic. The impact of the prefetching and scheduling strategies on the temporal distribution of coherence invalidations also is examined. It is found that invalidations tend to be evenly distributed throughout the execution of parallel loops, but tend to be clustered when executing sequential program sections. The distribution of invalidations in both types of program sections is relatively insensitive to the prefetching and scheduling strategy.<>"",""1558-2183"","""",""10.1109/71.285604"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285604"","""",""Prefetching";Processor scheduling;Pollution;Multiprocessor interconnection networks;Numerical simulation;Large-scale systems;Application software;Hardware;Software performance;"Dynamic scheduling"","""",""8"",""1"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;
"The impact of pipelined channels on k-ary n-cube networks,""S. L. Scott";" J. R. Goodman"",""Cray Research, Inc., Chippewa Falls, WI, USA";" Department of Computer Sciences, University of Wisconsin, Madison, WI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""1"",""2"",""16"",""In a pipelined-channel interconnection network, multiple bits may be simultaneously in flight on a single wire. This allows the cycle time of the network to be independent of the wire lengths, significantly affecting the network design trade-offs. This paper investigates the design and performance of pipelined channel k-ary n-cube networks, with particular emphasis on the choice of dimensionality and radix. Networks are investigated under the constant link width, constant node size and constant bisection constraints. We find that the optimal dimensionality of pipelined-channel networks is higher than that of nonpipelined-channel networks, with the difference being greater under looser wiring constraints. Their radix should remain roughly constant as network size is grown, decreasing slightly for some unidirectional tori and increasing slightly for some bidirectional meshes. Pipelined-channel networks are shown to provide lower latency and higher bandwidth than their nonpipelined-channel counterparts, especially for high-dimensional networks. The paper also investigates the effects of switching overhead and message lengths, indicating where results agree with and differ from previous results obtained for nonpipelined-channel networks.<>"",""1558-2183"","""",""10.1109/71.262584"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=262584"","""",""Multiprocessor interconnection networks";Wire;Delay;Performance analysis;Hypercubes;Telecommunication traffic;Wiring;Bandwidth;"System performance"","""",""80"","""",""31"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;;
"The performance of cache-based error recovery in multiprocessors,""B. Janssens";" W. K. Fuchs"",""Center for Reliable and High-Performance Computing, Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, Urbana, IL, USA";" Center for Reliable and High-Performance Computing, Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, Urbana, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""10"",""1033"",""1043"",""Several variations of cache-based checkpointing for rollback error recovery from transient errors in shared-memory multiprocessors have been recently developed. By modifying the cache replacement policy, these techniques use the inherent redundancy in the memory hierarchy to periodically checkpoint the computation state. Three schemes, different in the manner in which they avoid rollback propagation, are evaluated in this paper. By simulation with address traces from parallel applications running on an Encore Multimax shared-memory multiprocessor, we evaluate the performance effect of integrating the recovery schemes in the cache coherence protocol. Our results indicate that the cache-based schemes can provide checkpointing capability with low performance overhead, but with uncontrollable high variability in the checkpoint interval.<>"",""1558-2183"","""",""10.1109/71.313120"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=313120"","""",""Checkpointing";Redundancy;Computational modeling;Protocols;Fault tolerant systems;Hardware;NASA;Registers;Fault detection;"Error analysis"","""",""21"",""6"",""27"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Unicast-based multicast communication in wormhole-routed networks,""P. K. McKinley"; H. Xu; A. . -H. Esfahanian;" L. M. Ni"",""Department of Computer Science, Michigan State University, East Lansing, MI, USA"; Department of Computer Science, Michigan State University, East Lansing, MI, USA; Department of Computer Science, Michigan State University, East Lansing, MI, USA;" Department of Computer Science, Michigan State University, East Lansing, MI, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""12"",""1252"",""1265"",""Multicast communication, in which the same message is delivered from a source node to an arbitrary number of destination nodes, is being increasingly demanded in parallel computing. System supported multicast services can potentially offer improved performance, increased functionality, and simplified programming, and may in turn be used to support various higher-level operations for data movement and global process control. This paper presents efficient algorithms to implement multicast communication in wormhole-routed direct networks, in the absence of hardware multicast support, by exploiting the properties of the switching technology. Minimum-time multicast algorithms are presented for n-dimensional meshes and hypercubes that use deterministic, dimension-ordered routing of unicast messages. Both algorithms can deliver a multicast message to m-1 destinations in [log/sub 2/ m] message passing steps, while avoiding contention among the constituent unicast messages. Performance results of implementations on a 64-node nCUBE-2 hypercube and a 168-node Symult 2010 2-D mesh are given.<>"",""1558-2183"","""",""10.1109/71.334899"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=334899"","""",""Multicast communication";Multicast algorithms;Hypercubes;Unicast;Parallel processing;Functional programming;Process control;Hardware;Communication switching;"Routing"","""",""209"",""1"",""30"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;
"Unstructured tree search on SIMD parallel computers,""G. Karypis";" V. Kumar"",""Department of Computer Science, University of Minnesota, Minneapolis, MN, USA";" Department of Computer Science, University of Minnesota, Minneapolis, MN, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""10"",""1057"",""1072"",""We present new methods for load balancing of unstructured tree computations on large-scale SIMD machines, and analyze the scalability of these and other existing schemes. An efficient formulation of tree search on an SIMD machine consists of two major components: a triggering mechanism, which determines when the search space redistribution must occur to balance the search space over processors, and a scheme to redistribute the search space. We have devised a new redistribution mechanism and a new triggering mechanism. Either of these can be used in conjunction with triggering and redistribution mechanisms developed by other researchers. We analyze the scalability of these mechanisms and verify the results experimentally. The analysis and experiments show that our new load-balancing methods are highly scalable on SIMD architectures. Their scalability is shown to he no worse than that of the best load-balancing schemes on MIMD architectures. We verify our theoretical results by implementing the 15-puzzle problem on a CM-2 SIMD parallel computer.<>"",""1558-2183"","""",""10.1109/71.313122"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=313122"","""",""Concurrent computing";Scalability;Load management;Large-scale systems;Artificial intelligence;Central Processing Unit;Parallel processing;Operations research;Monte Carlo methods;"Partitioning algorithms"","""",""21"","""",""49"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Using Petri nets for the design of conversation boundaries in fault-tolerant software,""Jie Wu";" E. B. Fernandez"",""Department of Computer Science and Engineering, Florida Atlantic University, Boca Raton, FL, USA";" Dept. of Comput. Sci. & Eng., Florida Atlantic Univ., Boca Raton, FL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""10"",""1106"",""1112"",""Only a few mechanisms have been proposed for the design of fault-tolerant software. One of these is the conversation, which, though it has some drawbacks, is a potentially promising structure. One of the problems with conversations is that they must be defined and verified by the user. In this short note, a systematic method for generating the boundaries of conversations directly from the specification is proposed. This method can also be used to verify conversations selected by the user. The specification is described by a high-level modified Petri net which can easily be transformed into a state model called an action-ordered tree. The conversation boundaries are then determined from this tree. It is proved that the method proposed is complete in the sense that all of the possible boundaries can be determined, and it has the merit of simplicity. A robot arm control system is used to illustrate the idea. The proposed method can serve as the basis of a tool to assist in conversation designs.<>"",""1558-2183"","""",""10.1109/71.313126"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=313126"","""",""Petri nets";Fault tolerance;Testing;Communication system software;Software design;Fault tolerant systems;PROM;Robot sensing systems;Robot control;"Communication system control"","""",""1"","""",""28"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Using processor affinity in loop scheduling on shared-memory multiprocessors,""E. P. Markatos";" T. J. LeBlanc"",""Department of Computer Science, University of Rochester, Rochester, NY, USA";" Department of Computer Science, University of Rochester, Rochester, NY, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""4"",""379"",""400"",""Loops are the single largest source of parallelism in many applications. One way to exploit this parallelism is to execute loop iterations in parallel on different processors. Previous approaches to loop scheduling attempted to achieve the minimum completion time by distributing the workload as evenly as possible while minimizing the number of synchronization operations required. The authors consider a third dimension to the problem of loop scheduling on shared-memory multiprocessors: communication overhead caused by accesses to nonlocal data. They show that traditional algorithms for loop scheduling, which ignore the location of data when assigning iterations to processors, incur a significant performance penalty on modern shared-memory multiprocessors. They propose a new loop scheduling algorithm that attempts to simultaneously balance the workload, minimize synchronization, and co-locate loop iterations with the necessary data. They compare the performance of this new algorithm to other known algorithms by using five representative kernel programs on a Silicon Graphics multiprocessor workstation, a BBN Butterfly, a Sequent Symmetry, and a KSR-1, and show that the new algorithm offers substantial performance improvements, up to a factor of 4 in some cases. The authors conclude that loop scheduling algorithms for shared-memory multiprocessors cannot afford to ignore the location of data, particularly in light of the increasing disparity between processor and memory speeds.<>"",""1558-2183"","""",""10.1109/71.273046"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=273046"","""",""Processor scheduling";Scheduling algorithm;Parallel processing;Dynamic scheduling;Computer science;Runtime;Load management;Kernel;Silicon;"Graphics"","""",""109"",""4"",""32"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;
"Voting as the optimal static pessimistic scheme for managing replicated data,""M. Spasojevic";" P. Berman"",""Transarc Corporation, Pittsburgh, PA, USA";" Department of Computer Science, Pennsylvania State University, University Park, PA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""6 Aug 2002"",""1994"",""5"",""1"",""64"",""73"",""This paper investigates the problem of finding an optimal static pessimistic replica control scheme. It has been widely accepted that coteries (proposed by Garcia-Molina and Barbara) provide the most general framework for such schemes. We demonstrate that voting schemes, a very small subset of static pessimistic schemes, are optimal for fully connected networks with negligible link failure rates, as well as for Ethernet systems. We also show that voting is not optimal for somewhat more general systems. We propose a modification of the algorithm of Z. Tong and R.Y. Kain (1988) for computing optimal voting in operation independent case, so that it runs in linear (rather than exponential) time. Finally, we propose the first efficient algorithm for computing the optimal vote assignment and appropriate thresholds for fully connected networks when relative frequencies of read and write operations are known. We also extend this result to Ethernet systems.<>"",""1558-2183"","""",""10.1109/71.262589"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=262589"","""",""Voting";Protocols;Ethernet networks;Computer networks;Availability;Optimal control;Frequency;Database systems;Telecommunication traffic;"Delay"","""",""31"","""",""24"",""IEEE"",""6 Aug 2002"","""","""",""IEEE"",""IEEE Journals""";;;;;;