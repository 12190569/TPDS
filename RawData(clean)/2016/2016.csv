"A 2-Approximation Algorithm for Scheduling Parallel and Time-Sensitive Applications to Maximize Total Accrued Utility Value,""S. Li"; M. Song; P. -J. Wan;" S. Ren"",""Department of Engineering Mechanics, Dalian University of Technology, Dalian, China"; Department of Computer Science, Illinois Institute of Technology, Chicago, IL; Department of Computer Science, Illinois Institute of Technology, Chicago, IL;" Department of Computer Science, Illinois Institute of Technology, Chicago, IL"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""1864"",""1878"",""For a time-sensitive application, the usefulness of its end results (also called the application's accrued utility value in the paper) depends on the time when the application is completed and its results are delivered. In this paper, we address the accrued utility value maximization problem for narrow parallel and time-sensitive applications. We first consider the problem in the context of a discrete time domain and present the Spatial-Temporal Interference Based (STIB) scheduling algorithm. We formally prove that the STIB algorithm is a 2-approximation algorithm. Second, we extend our work to a continuous time domain and present a heuristic scheduling algorithm, i.e., the Continuous Spatial-Temporal Interference Based (STIB-C) algorithm to maximize the system's total accrued utility value when the system operates in a continuous time domain. The extensive empirical evaluations reveal that: (1) in a discrete time domain, the systems' total accrued utility values obtained through the STIB algorithm are consistent with the theoretic bound, i.e., they never go below 50 percent of the optimal value. In fact, on average, the STIB algorithm can achieve over 92.5 percent of the optimal value";" (2) compared to other scheduling policies listed in the literature, the developed STIB and STIB-C algorithms have clear advantages in terms of the system's total accrued utility value and the profitable application ratio. In particular, in terms of the system's total accrued utility value, both the STIB and the STIB-C algorithms achieve as much as six times for both the First Come First Come Serve(FCFS) with backfilling algorithm and the Gang Earliest Deadline First (EDF) algorithm, and 4.5 times for the 0-1 Knapsack based scheduling algorithm. In terms of the profitable application ratio, both the STIB and the STIB-C algorithms obtain as much as four times for both the FCFS with backfilling algorithm and the Gang EDF algorithm, and two times for the 0-1 Knapsack based scheduling algorithm."",""1558-2183"","""",""10.1109/TPDS.2015.2474360"",""US National Science Foundation(grant numbers:CNS-1018731,CNS-0746643(CAREER))";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7229345"",""Parallel";time-sensitive;scheduling;approximation algorithm;Parallel;time-sensitive;scheduling;"approximation algorithm"",""Interference";Scheduling algorithms;Schedules;Scheduling;Time-domain analysis;"Optimal scheduling"","""",""6"","""",""35"",""IEEE"",""28 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Cloud Gaming System Based on User-Level Virtualization and Its Resource Scheduling,""Y. Zhang"; P. Qu; J. Cihang;" W. Zheng"",""Department of Computer Science and Technology, Tsinghua University, Beijing, China"; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China;" Department of Computer Science and Technology, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1239"",""1252"",""Many believe the future of gaming lies in the cloud, namely Cloud Gaming, which renders an interactive gaming application in the cloud and streams the scenes as a video sequence to the player over Internet. This paper proposes GCloud, a GPU/CPU hybrid cluster for cloud gaming based on the user-level virtualization technology. Specially, we present a performance model to analyze the server-capacity and games' resource-consumptions, which categorizes games into two types: CPU-critical and memory-of-critical. Consequently, several scheduling strategies have been proposed to improve the resource-utilization and compared with others. Simulation tests show that both of the First-Fit-like and the Best-Fit-like strategies outperform the other(s)";" especially they are near optimal in the batch processing mode. Other test results indicate that GCloud is efficient: An off-the-shelf PC can support five high-end video-games run at the same time. In addition, the average per-frame processing delay is 8~19 ms under different image-resolutions, which outperforms other similar solutions."",""1558-2183"","""",""10.1109/TPDS.2015.2433916"",""High Tech. R&D Program of China(grant numbers:2013AA01A215)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7109163"",""cloud computing";cloud gaming;resource scheduling;user-level virtualization;Cloud computing;cloud gaming;resource scheduling;"user-level virtualization"",""Games";Servers;Graphics processing units;Delays;Virtualization;Rendering (computer graphics);"Streaming media"","""",""17"","""",""40"",""IEEE"",""15 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"A Comment on “Fast Bloom Filters and Their Generalization”,""P. Reviriego"; K. Christensen;" J. A. Maestro"",""Universidad Antonio de Nebrija, C/ Pirineos, Madrid, Spain"; University of South Florida, 4202 East Fowler Avenue, ENB 118, Tampa, FL, USA;" Universidad Antonio de Nebrija, C/ Pirineos, Madrid, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""303"",""304"",""A Bloom filter is a data structure that provides probabilistic membership checking. Bloom filters have many applications in computing and communications systems. The performance of a Bloom filter is measured by false positive rate, memory size requirement, and query (or memory look-up) overhead. A recent paper by Qiao et al. proposes the Fast Bloom Filter, also called Bloom-1, which requires only a single memory look-up for a membership test. Bloom-1 achieves a reduced query overhead at the expense of a slightly higher false positive rate for a given memory size. The false positive rate of Bloom-1 has been analyzed theoretically by Qiao et al. relying on a well-known, but flawed, approximation for the false positive rate for a Bloom filter. In this comment paper we show that the Qiao et al. analysis of Bloom-1 under-estimates the false positive rate for low loads. We provide a correct analysis of Bloom-1 yielding an expression for the exact false positive rate."",""1558-2183"","""",""10.1109/TPDS.2014.2378268"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7012061"",""Bloom filter";false positive;memory access;Bloom filter;false positive;"memory access"",""Information filters";Equations;Mathematical model;Approximation methods;Memory management;"Load modeling"","""",""10"","""",""5"",""IEEE"",""16 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Constraint Programming Scheduler for Heterogeneous High-Performance Computing Machines,""T. Bridi"; A. Bartolini; M. Lombardi; M. Milano;" L. Benini"",""Department of Computer Science and Engineering (DISI), University of Bologna, Viale Risorgimento 2, Bologna, Italy"; Department of Electrical, Electronic and Information Engineering (DEI), University of Bologna, Viale Risorgimento 2, Bologna, Italy; Department of Computer Science and Engineering (DISI), University of Bologna, Viale Risorgimento 2, Bologna, Italy; Department of Computer Science and Engineering (DISI), University of Bologna, Viale Risorgimento 2, Bologna, Italy;" Department of Electrical, Electronic and Information Engineering (DEI), University of Bologna, Viale Risorgimento 2, Bologna, Italy"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2781"",""2794"",""Scheduling and dispatching tools for high-performance computing (HPC) machines have the key role of mapping jobs to the available resources, trying to maximize performance and quality-of-service (QoS). Allocation and Scheduling in the general case are well-known NP-hard problems, forcing commercial schedulers to adopt greedy approaches to improve performance and QoS. Search-based approaches featuring the exploration of the solution space have seldom been employed in this setting, but mostly applied in off-line scenarios. In this paper, we present the first search-based approach to job allocation and scheduling for HPC machines, working in a production environment. The scheduler is based on Constraint Programming, an effective programming technique for optimization problems. The resulting scheduler is flexible, as it can be easily customized for dealing with heterogeneous resources, user-defined constraints and different metrics. We evaluate our solution both on virtual machines using synthetic workloads, and on the Eurora HPC with production workloads. Tests on a wide range of operating conditions show significant improvements in waitings and QoS in mid-tier HPC machines w.r.t state-of-the-art commercial rule-based dispatchers. Furthermore, we analyze the conditions under which our approach outperforms commercial approaches, to create a portfolio of scheduling algorithms that ensures robustness, flexibility and scalability."",""1558-2183"","""",""10.1109/TPDS.2016.2516997"",""ERC(grant numbers:291125)"; YINS RTD project(grant numbers:20NA21 150939); NSF; CINECA;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7378987"",""Constraint programming";optimization;HPC;scheduling;resource allocation;"supercomputer"",""Processor scheduling";Scheduling;Optimization;Quality of service;Programming;"Resource management"","""",""18"","""",""34"",""IEEE"",""12 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"A Crowdsourcing Worker Quality Evaluation Algorithm on MapReduce for Big Data Applications,""D. Dang"; Y. Liu; X. Zhang;" S. Huang"",""College of Information Science and Technology, Beijing Normal University, Beijing, China"; College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China;" College of Information Science and Technology, Beijing Normal University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""1879"",""1888"",""Crowdsourcing is a new emerging distributed computing and business model on the backdrop of Internet blossoming. With the development of crowdsourcing systems, the data size of crowdsourcers, contractors and tasks grows rapidly. The worker quality evaluation based on big data analysis technology has become a critical challenge. This paper first proposes a general worker quality evaluation algorithm that is applied to any critical tasks such as tagging, matching, filtering, categorization and many other emerging applications, without wasting resources. Second, we realize the evaluation algorithm in the Hadoop platform using the MapReduce parallel programming model. Finally, to effectively verify the accuracy and the effectiveness of the algorithm in a wide variety of big data scenarios, we conduct a series of experiments. The experimental results demonstrate that the proposed algorithm is accurate and effective. It has high computing performance and horizontal scalability. And it is suitable for large-scale worker quality evaluations in a big data environment."",""1558-2183"","""",""10.1109/TPDS.2015.2457924"",""National Natural Science Foundation of China(grant numbers:60940032,61073034,61370064)"; Program for New Century Excellent Talents in University; Ministry of Education of China(grant numbers:NCET-10-0239); Science Foundation of Ministry of Education of China; China Mobile Communicaions Corporation(grant numbers:MCM20130371);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273904"",""crowdsourcing systems";quality control;Big data;MapReduce;Hadoop;Crowdsourcing systems;quality control;big data;mapreduce;"hadoop"",""Accuracy";Crowdsourcing;Algorithm design and analysis;Big data;Computational modeling;Quality control;"Data models"","""",""21"","""",""47"",""IEEE"",""22 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;
"A Delayed Container Organization Approach to Improve Restore Speed for Deduplication Systems,""J. Liu"; Y. Chai; C. Yan;" X. Wang"",""Key Laboratory of Data Engineering and Knowledge Engineering, Ministry of Education, School of Information, Renmin University of China, Beijing, China"; Key Laboratory of Data Engineering and Knowledge Engineering, Ministry of Education, School of Information, Renmin University of China, Beijing, China; Department of Electrical and Computer Engineering, College of Engineering, Boston University, Boston, MA;" School of Computer Science and Technology, Tianjin University, Tianjin, China"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2477"",""2491"",""Data deduplication has become necessary to improve the space-efficiency of large-scale distributed storage systems, as the global data have accumulated at an exponential rate and they have significant redundancy. However, the negative impact on restore performance is a main challenge for deduplication systems. One of the key reasons is that when restoring data, the low average useful data ratio (UDR) of containers wastes a considerable part of disk bandwidth to read useless data. This is mainly attributed to the uncontrollable compositions of containers. To solve this problem, we propose a new approach called Delayed Container Organization (DCO) to delay the construction of containers after accumulating some redundant data chunks in fast Non-Volatile Memory (NVM) devices to organize high-UDR containers. For example, data chunks in the intersection of some data segments can be organized together in one container to achieve both high deduplication ratio and high UDRs when restoring these related data segments. DCO is implemented in a prototype deduplication system. The experimental results indicate that compared with Capping, DCO promotes the average UDR of containers by 38.30 percent, improves the restore performance by a factor of 2.2, and achieves better space-efficiency and higher cost performance."",""1558-2183"","""",""10.1109/TPDS.2015.2509060"",""National Natural Science Foundation of China(grant numbers:61202115)"; State Key Laboratory of Computer Architecture; Institute of Computing Technology; Chinese Academy of Science(grant numbers:CARCH201302); National High-tech R&D Program of China(grant numbers:2013AA013204);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358159"",""Deduplication";NVM;SSD;restore;"UDR"",""Containers";Nonvolatile memory;Organizations;Acceleration;Distributed databases;Redundancy;"Bandwidth"","""",""9"","""",""43"",""IEEE"",""17 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"A Distributed and Scalable Approach to Semi-Intrusive Load Monitoring,""G. Tang"; K. Wu;" J. Lei"",""Department of Computer Science, University of Victoria, Victoria, B.C, Canada"; Department of Computer Science, University of Victoria, Victoria, B.C, Canada;" School of Computer and Information Engineering, Shanghai University of Electric Power, Shanghai, China"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1553"",""1565"",""Non-intrusive appliance load monitoring (NIALM) helps identify major energy guzzlers in a building without introducing extra metering cost. It motivates users to take proper actions for energy saving and greatly facilitates demand response (DR) programs. Nevertheless, NIALM of large-scale appliances is still an open challenge. To pursue a scalable solution to energy monitoring for contemporary large-scale appliance groups, we propose a distributed metering platform and use parallel optimization for semi-intrusive appliance load monitoring (SIALM). Based on a simple power model, a sparse switching event recovering (SSER) model is established to recover appliance states from their aggregated load data. Furthermore, the sufficient conditions for unambiguous state recovery of multiple appliances are presented. By considering these conditions as well as the electrical network topology constraint, a minimum number of meters are obtained to correctly recover the energy consumption of individual appliances. We evaluate the performance of both SIALM and NIALM with real-world trace data and synthetic data. The results demonstrate that with the help of a small number of meters, the SIALM approach significantly improves the accuracy of energy disaggregation for large-scale appliances."",""1558-2183"","""",""10.1109/TPDS.2015.2470238"",""Natural Sciences and Engineering Research Council of Canada(grant numbers:195819339)"; Natural Science Foundation of China(grant numbers:61373152,61272437,61472236); Shanghai Municipal Education Commission(grant numbers:13ZZ131,14ZZ150); Shanghai Science and Technology Committee(grant numbers:12JC1404500,13JC1403503); Shanghai Science and Technology Committee(grant numbers:14110500800);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7210212"",""Semi-intrusive appliance load monitoring";energy disaggregation;optimization;measurement;Semi-intrusive appliance load monitoring;energy disaggregation;optimization;"measurement"",""Home appliances";Monitoring;Optimization;Switches;Buildings;Hidden Markov models;"Mathematical model"","""",""25"","""",""31"",""IEEE"",""19 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"A Family of Fault-Tolerant Efficient Indirect Topologies,""D. F. Bermúdez Garzón"; C. G. Requena; M. E. Gómez; P. López;" J. Duato"",""DISCA, Universitat Politècnica de València, Valencia, Spain"; DISCA, Universitat Politècnica de València, Valencia, Spain; DISCA, Universitat Politècnica de València, Valencia, Spain; DISCA, Universitat Politècnica de València, Valencia, Spain;" DISCA, Universitat Politècnica de València, Valencia, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""927"",""940"",""On the one hand, performance and fault-tolerance of interconnection networks are key design issues for high performance computing (HPC) systems. On the other hand, cost should be also considered. Indirect topologies are often chosen in the design of HPC systems. Among them, the most commonly used topology is the fat-tree. In this work, we focus on getting the maximum benefits from the network resources by designing a simple indirect topology with very good performance and fault-tolerance properties, while keeping the hardware cost as low as possible. To do that, we propose some extensions to the fat-tree topology to take full advantage of the hardware resources consumed by the topology. In particular, we propose three new topologies with different properties in terms of cost, performance and fault-tolerance. All of them are able to achieve a similar or better performance results than the fat-tree, providing also a good level of fault-tolerance and, contrary to most of the available topologies, these proposals are able to tolerate also faults in the links that connect to end nodes."",""1558-2183"","""",""10.1109/TPDS.2015.2430863"",""Spanish Ministerio de Economía y Competitividad"; FEDER(grant numbers:TIN2012-38341-C04-01);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7103363"",""Regular Indirect Topologies";Fat-Trees;Adaptive and Deterministic Routing;RUFT;Fault–Tolerance;Regular indirect topologies;fat-trees;adaptive and deterministic routing;RUFT;"fault-tolerance"",""Topology";Ports (Computers);Fault tolerance;Fault tolerant systems;Network topology;Hardware;"Complexity theory"","""",""8"","""",""27"",""IEEE"",""7 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;
"A Fast Discrete Wavelet Transform Using Hybrid Parallelism on GPUs,""T. M. Quan";" W. -K. Jeong"",""Department of Electrical and Computer Engineering, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Korea";" Department of Electrical and Computer Engineering, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Korea"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3088"",""3100"",""Wavelet transform has been widely used in many signal and image processing applications. Due to its wide adoption for time-critical applications, such as streaming and real-time signal processing, many acceleration techniques were developed during the past decade. Recently, the graphics processing unit (GPU) has gained much attention for accelerating computationally-intensive problems and many solutions of GPU-based discrete wavelet transform (DWT) have been introduced, but most of them did not fully leverage the potential of the GPU. In this paper, we present various state-of-the-art GPU optimization strategies in DWT implementation, such as leveraging shared memory, registers, warp shuffling instructions, and thread- and instruction-level parallelism (TLP, ILP), and finally elaborate our hybrid approach to further boost up its performance. In addition, we introduce a novel mixed-band memory layout for Haar DWT, where multi-level transform can be carried out in a single fused kernel launch. As a result, unlike recent GPU DWT methods that focus mainly on maximizing ILP, we show that the optimal GPU DWT performance can be achieved by hybrid parallelism combining both TLP and ILP together in a mixed-band approach. We demonstrate the performance of our proposed method by comparison with other CPU and GPU DWT methods."",""1558-2183"","""",""10.1109/TPDS.2016.2536028"",""Institute for Information & communications Technology Promotion"; Korea government(grant numbers:R0190-15-2012); High Performance Big Data Analytics Platform Performance Acceleration Technologies Development); R&D program of MOTIE/KEIT(grant numbers:10054548); Basic Science Research Program; National Research Foundation of Korea; Ministry of Education(grant numbers:NRF-2014R1A1A2058773);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422119"",""Wavelet transform";hybrid parallelism;lifting scheme;bit rotation;"GPU computing"",""Discrete wavelet transforms";Graphics processing units;Parallel processing;Acceleration;"Registers"","""",""11"","""",""33"",""IEEE"",""29 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Framework for Practical Dynamic Software Updating,""G. Chen"; H. Jin; D. Zou; Z. Liang; B. B. Zhou;" H. Wang"",""Cluster and Grid Computing Lab, Services Computing Technology and System Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"; Cluster and Grid Computing Lab, Services Computing Technology and System Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; Cluster and Grid Computing Lab, Services Computing Technology and System Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; Department of Computer Science, School of Computing, National University of Singapore, Singapore; Centre for Distributed and High Performance Computing, School of Information Technologies, University of Sydney, NSW, Australia;" Cluster and Grid Computing Lab, Services Computing Technology and System Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""941"",""950"",""Dynamic software updating (DSU) enables a program to be patched on the fly without being shutdown. This paper addresses the practicality problem of the recent research on DSU systems, and presents Replus, a new DSU system that balances practicality and functionality. Replus aims to retain backward binary compatibility and support multi-threaded programs. In addition, it does not require customers to have developer-level software knowledge. More importantly, without specific compiler support, Replus can patch programs that are difficult to be updated at runtime, as well as programs that may incur an indefinite delay in DSU. The key technique of our solution is to update the stack elements for the patched program using two new mechanisms: Immediate Stack Updating, which immediately updates the stack of a thread, and timely stack updating, which only updates the stack frames of the necessary functions without affecting others. Replus also develops an Instruction Level Updating  mechanism, which is more efficient for certain security patches. We used popular server applications as test suites to evaluate the effectiveness of Replus. The experimental results demonstrated that Replus can successfully update all the test suites with negligible impact on application performance."",""1558-2183"","""",""10.1109/TPDS.2015.2430854"",""National 973 Fundamental Basic Research Program(grant numbers:2014CB340600)"; National Science Foundation of China(grant numbers:61272072); Program for New Century Excellent Talents in University(grant numbers:NCET-13-0241);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7103360"",""Dynamic Software Updating";Stack Updating;Instruction Updating;Dynamic software updating;stack updating;"patching"",""Software";Servers;Security;Computer bugs;Runtime;Delays;"Electronic mail"","""",""8"","""",""28"",""IEEE"",""7 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;
"A Framework of Price Bidding Configurations for Resource Usage in Cloud Computing,""K. Li"; C. Liu; K. Li;" A. Y. Zomaya"",""College of Information Science and Engineering, Hunan University, and National Supercomputing Center in Changsha, Hunan, China"; College of Information Science and Engineering, Hunan University, and National Supercomputing Center in Changsha, Hunan, China; Department of Computer Science, State University of New York, New Paltz, New York;" School of Information Technologies, University of Sydney, Sydney, NSW, Australia"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2168"",""2181"",""In this paper, we focus on price bidding strategies of multiple users competition for resource usage in cloud computing. We consider the problem from a game theoretic perspective and formulate it into a non-cooperative game among the multiple cloud users, in which each cloud user is informed with incomplete information of other users. For each user, we design a utility function which combines the net profit with time efficiency and try to maximize its value. We design a mechanism for the multiple users to evaluate their utilities and decide whether to use the cloud service. Furthermore, we propose a framework for each cloud user to compute an appropriate bidding price. At the beginning, by relaxing the condition that the allocated number of servers can be fractional, we prove the existence of Nash equilibrium solution set for the formulated game. Then, we propose an iterative algorithm ( $\mathcal {IA}$ ), which is designed to compute a Nash equilibrium solution. The convergency of the proposed algorithm is also analyzed and we find that it converges to a Nash equilibrium if several conditions are satisfied. Finally, we revise the obtained solution and propose a near-equilibrium price bidding algorithm ( $\mathcal {NPBA}$ ) to characterize the whole process of our proposed framework. The experimental results show that the obtained near-equilibrium solution is close to the equilibrium one."",""1558-2183"","""",""10.1109/TPDS.2015.2495120"",""National Natural Science Foundation of China(grant numbers:61133005,61432005)"; National Natural Science Foundation of China(grant numbers:61370095,61472124,61402400); International Science & Technology Cooperation Program of China(grant numbers:2015DFA11240);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307193"",""Cloud computing";nash equilibrium;non-cooperative game theory;"price bidding strategy"",""Servers";Games;Nash equilibrium;Resource management;Algorithm design and analysis;"Cloud computing"","""",""61"","""",""33"",""IEEE"",""26 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A General Approach to Scalable Buffer Pool Management,""X. Ding"; J. Shan;" S. Jiang"",""Computer Science Department, New Jersey Institute of Technology, Newark, NJ"; Computer Science Department, New Jersey Institute of Technology, Newark, NJ;" Department of Electrical and Computer Engineering, Wayne State University, MI"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2182"",""2195"",""In high-end data processing systems, such as databases, the execution concurrency level rises continuously since the introduction of multicore processors. This happens both on premises and in the cloud. For these systems, a buffer pool management of high scalability plays an important role on overall system performance. The scalability of buffer pool management is largely determined by its data replacement algorithm, which is a major component in the buffer pool management. It can seriously degrade the scalability if not designed and implemented properly. The root cause is its use of lock-protected data structures that incurs high contention with concurrent accesses. A common practice is to modify the replacement algorithm to reduce the contention on the lock(s), such as approximating the LRU replacement with the CLOCK algorithm or partitioning the data structures and using distributed locks. Unfortunately, the modification usually compromises the algorithm's hit ratio, a major performance goal. It may also involve significant effort on overhauling the original algorithm design and implementation. This paper provides a general solution to improve the scalability of a buffer pool management using any replacement algorithms for the data processing systems on physical on-premises machines and virtual machines in the cloud. Instead of making a difficult trade-off between the high hit ratio of a replacement algorithm and the low lock contention of its approximation, we design a system framework, called BP-Wrapper, that eliminates almost all lock contention without requiring any changes to an existing algorithm. In BP-Wrapper, we use a dynamic batching technique and a prefetching technique to reduce lock contention and to retain high hit ratio. The implementation of BP-Wrapper in PostgreSQL adds only about 300 lines of C code. It can increase the throughput by up to two folds compared with the replacement algorithms with lock contention when running TPC-C-like and TPC-W-like workloads."",""1558-2183"","""",""10.1109/TPDS.2015.2484321"",""US National Science Foundation(grant numbers:CNS-1409523,CNS-1217948)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7286847"",""Buffer pool management";replacement algorithm;lock contention;"multi-core"",""Data structures";Heuristic algorithms;Algorithm design and analysis;Approximation algorithms;Clocks;Prefetching;"Approximation methods"","""",""4"","""",""38"",""IEEE"",""1 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Heuristic Clustering-Based Task Deployment Approach for Load Balancing Using Bayes Theorem in Cloud Environment,""J. Zhao"; K. Yang; X. Wei; Y. Ding; L. Hu;" G. Xu"",""College of Computer Science and Technology, the Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, No. 2699 Qianjin Street, Changchun, China"; Computer Science and Electronic Engineering, University of Essex, Wivenhoe Park, Colchester, United Kingdom; College of Computer Science and Technology and the Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, No. 2699 Qianjin Street, Changchun, China; College of Computer Science and Technology and the Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, No. 2699 Qianjin Street, Changchun, China; College of Computer Science and Technology and the Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, No. 2699 Qianjin Street, Changchun, China;" College of Computer Science and Technology and the Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, No. 2699 Qianjin Street, Changchun, China"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""305"",""316"",""Aiming at the current problems that most physical hosts in the cloud data center are so overloaded that it makes the whole cloud data center'load imbalanced and that existing load balancing approaches have relatively high complexity, this paper has focused on the selection problem of physical hosts for deploying requested tasks and proposed a novel heuristic approach called Load Balancing based on Bayes and Clustering (LB-BC). Most previous works, generally, utilize a series of algorithms through optimizing the candidate target hosts within an algorithm cycle and then picking out the optimal target hosts to achieve the immediate load balancing effect. However, the immediate effect doesn't guarantee high execution efficiency for the next task although it has abilities in achieving high resource utilization. Based on this argument, LB-BC introduces the concept of achieving the overall load balancing in a long-term process in contrast to the immediate load balancing approaches in the current literature. LB-BC makes a limited constraint about all physical hosts aiming to achieve a task deployment approach with global search capability in terms of the performance function of computing resource. The Bayes theorem is combined with the clustering process to obtain the optimal clustering set of physical hosts finally. Simulation results show that compared with the existing works, the proposed approach has reduced the failure number of task deployment events obviously, improved the throughput, and optimized the external services performance of cloud data centers."",""1558-2183"","""",""10.1109/TPDS.2015.2402655"",""National Science-Technology Support Project(grant numbers:2014BAH02F02)"; National Natural Science Foundation of China(grant numbers:61133011); Natural Science Foundation of Jilin(grant numbers:20101533); UK EPSRC(grant numbers:EP/L026031/1); EU FP7(grant numbers:GA-2011-295222); CLIMBER(grant numbers:GA-2012-318939); CROWN(grant numbers:GA-2013-610524);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7039230"",""Task Deployment";Load Balancing;Bayes Theorem;Clustering;Cloud Computing;Task deployment;load balancing;Bayes theorem;clustering;"cloud computing"",""Load management";Virtual machining;Cloud computing;Educational institutions;Heuristic algorithms;Dynamic scheduling;"Distributed databases"","""",""110"","""",""28"",""IEEE"",""11 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;
"A High Performance Parallel and Heterogeneous Approach to Narrowband Beamforming,""C. Sarofeen";" P. Gillett"",""Computational Analysis and Design, Naval Surface Warfare Center, Carderock Division, West Bethesda, MD";" Hydroacoustics and Propulsor Development, Naval Surface Warfare Center, Carderock Division, West Bethesda, MD"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2196"",""2207"",""This paper describes a high performing, hybrid parallel, and heterogeneous algorithmic approach to narrowband Delay-Sum Beamforming (DSB) in the frequency domain using a Just-In-Time Asynchronous Data Method (JIT-ADM) parallel pattern. JIT-ADM is a novel asynchronous parallel programming pattern that unifies various levels of asynchronous concurrency available with distributed heterogeneous computing. The computational performance of this DSB algorithm was analyzed on a 50 node Cray XC30 with a single 10-core Intel Xeon E5-2670 v2 and NVIDIA Tesla K20X general purpose Graphics Processing Unit (GPU) on each node. The algorithm exhibits well behaved weak scalability with 92.7 percent parallel efficiency at 50 nodes compared to maximum performance observed. It is also shown that the algorithm efficiently utilizes a large portion of the available hardware. During beamforming the GPU is utilized at 51.8 percent of its maximum double precision floating point throughput whereas a comparable Central Processing Unit (CPU) version utilizes 60.0 percent of its maximum expected floating point throughput. Across the weak scalability study, utilizing GPUs for processing, a 2-5x performance gain is achieved compared to using CPUs. A brief derivation and validation of the implemented DSB is also presented."",""1558-2183"","""",""10.1109/TPDS.2015.2494038"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7305825"",""Beamforming";delay-sum beamforming;distributed computing;heterogeneous computing;"hybrid parallel programming"",""Graphics processing units";Array signal processing;Sensor arrays;Synchronization;Instruction sets;"Hardware"","""",""2"","""",""46"",""USGov"",""26 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Hop-by-Hop Routing Mechanism for Green Internet,""Y. Yang"; M. Xu; D. Wang;" S. Li"",""Tsinghua National Laboratory for Information Science and Technology (TNList), and Department of Computer Science and Technology, Tsinghua University"; Tsinghua National Laboratory for Information Science and Technology (TNList), and Department of Computer Science and Technology, Tsinghua University; Department of Computing, Hong Kong Polytechnic University, Kowloon, Hong Kong;" CERNET National Network Center, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""2"",""16"",""In this paper we study energy conservation in the Internet. We observe that different traffic volumes on a link can result in different energy consumption";" this is mainly due to such technologies as trunking (IEEE 802.1AX), adaptive link rates, etc. We design a green Internet routing scheme, where the routing can lead traffic in a way that is green. We differ from previous studies where they switch network components, such as line cards and routers, into sleep mode. We do not prune the Internet topology. We first develop a power model, and validate it using real commercial routers. Instead of developing a centralized optimization algorithm, which requires additional protocols such as MPLS to materialize in the Internet, we choose a hop-by-hop approach. It is thus much easier to integrate our scheme into the current Internet. We progressively develop three algorithms, which are loop-free, substantially reduce energy consumption, and jointly consider green and QoS requirements such as path stretch. We further analyze the power saving ratio, the routing dynamics, and the relationship between hop-by-hop green routing and QoS requirements. We comprehensively evaluate our algorithms through simulations on synthetic, measured, and real topologies, with synthetic and real traffic traces. We show that the power saving in the line cards can be as much as 50 percent."",""1558-2183"","""",""10.1109/TPDS.2015.2394794"",""National Basic Research Program of China(grant numbers:2012CB315803)"; National Natural Science Foundation of China(grant numbers:61133015,61161140454); Doctoral Program of Higher Education(grant numbers:20120002110060); National Natural Science Foundation of China(grant numbers:61272464); RGC; GRF(grant numbers:PolyU 5264/13E,PolyU G-YM06,A-PK95,1-ZVC2);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7017539"",""energy conservation";Internet routing;hop-by-hop routing;routing algebra;Energy conservation;internet routing;hop-by-hop routing;"routing algebra"",""Routing";Green products;Power demand;Internet;Energy conservation;Energy consumption;"Switches"","""",""12"","""",""43"",""IEEE"",""21 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;
"A Hybrid Parallel Solving Algorithm on GPU for Quasi-Tridiagonal System of Linear Equations,""K. Li"; W. Yang;" K. Li"",""College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan, China"; College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan, China;" College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2795"",""2808"",""There are some quasi-tridiagonal system of linear equations arising from numerical simulations, and some solving algorithms encounter great challenge on solving quasi-tridiagonal system of linear equations with more than millions of dimensions as the scale of problems increases. We present a solving method which mixes direct and iterative methods, and our method needs less storage space in a computing process. A quasi-tridiagonal matrix is split into a tridiagonal matrix and a sparse matrix using our method and then the tridiagonal equation can be solved by the direct methods in the iteration processes. Because the approximate solutions obtained by the direct methods are closer to the exact solutions, the convergence speed of solving the quasi-tridiagonal system of linear equations can be improved. Furthermore, we present an improved cyclic reduction algorithm using a partition strategy to solve tridiagonal equations on GPU, and the intermediate data in computing are stored in shared memory so as to significantly reduce the latency of memory access. According to our experiments on 10 test cases, the average number of iterations is reduced significantly by using our method compared with Jacobi, GS, GMRES, and BiCG respectively, and close to those of BiCGSTAB, BiCRSTAB, and TFQMR. For parallel mode, the parallel computing efficiency of our method is raised by partition strategy, and the performance using our method is better than those of the commonly used iterative and direct methods because of less amount of calculation in an iteration."",""1558-2183"","""",""10.1109/TPDS.2016.2516988"",""National Natural Science Foundation of China(grant numbers:61133005,61432005)"; National Natural Science Foundation of China(grant numbers:61370095,61472124,61572175); International Science & Technology Cooperation Program of China(grant numbers:2015DFA11240); Science and technology project of Hunan Province(grant numbers:2015SK20062);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7378515"",""Execution time";GPU;hybrid parallel algorithm;linear equation;"quasi-tridiagonal matrix"",""Sparse matrices";Mathematical model;Graphics processing units;Iterative methods;Instruction sets;Convergence;"Partitioning algorithms"","""",""39"","""",""40"",""IEEE"",""12 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Hybrid Static-Dynamic Classification for Dual-Consistency Cache Coherence,""A. Ros";" A. Jimborean"",""Computer Engineering Department, University of Murcia, Murcia, Spain";" Department of Information Technology, Uppsala University, Uppsala, Sweden"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3101"",""3115"",""Traditional cache coherence protocols manage all memory accesses equally and ensure the strongest memory model, namely, sequential consistency. Recent cache coherence protocols based on self-invalidation advocate for the model sequential consistency for data-race-free, which enables powerful optimizations for race-free code. However, for racy code these cache coherence protocols provide sub-optimal performance compared to traditional protocols. This paper proposes SPEL++, a dual-consistency cache coherence protocol that supports two execution modes: a traditional sequential-consistent protocol and a protocol that provides weak consistency (or sequential consistency for data-race-free). SPEL++ exploits a static-dynamic hybrid classification of memory accesses based on (i) a compile-time identification of extended data-race-free code regions for OpenMP applications and (ii) a runtime classification of accesses based on the operating system's memory page management. By executing racy code under the sequential-consistent protocol and race-free code under the cache coherence protocol that provides sequential consistency for data-race-free, the end result is an efficient execution of the applications while still providing sequential consistency. Compared to a traditional protocol, we show improvements in performance from 19 to 38 percent and reductions in energy consumption from 47 to 53 percent, on average for different benchmark suites, on a 64-core chip multiprocessor."",""1558-2183"","""",""10.1109/TPDS.2016.2528241"",""Fundación Seneca-Agencia de Ciencia y Tecnología de la Región de Murcia"; Jóvenes Líderes en Investigación(grant numbers:18956/JLI/13); Swedish Research Council; UPMARC Linnaeus Centre; Efficient Modeling of Heterogeneity in the Era of Dark Silicon(grant numbers:106201305/C0533201); European 7th Framework Programme(grant numbers:ICT-287759); HiPEAC;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404282"",""Multiprocessors";cache coherence;classification of accesses;runtime;compiler;consistency model;"data races"",""Protocols";Coherence;Synchronization;Memory management;Optimization;Runtime;"Instruction sets"","""",""11"","""",""52"",""IEEE"",""11 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"A Learning Algorithm for Bayesian Networks and Its Efficient Implementation on GPUs,""Y. Wang"; W. Qian; S. Zhang; X. Liang;" B. Yuan"",""Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China"; UM-SJTU Joint Institute, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China;" Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""17"",""30"",""The wide application of omics research has produced a burst of biological data in recent years, which has in turn increased the need to infer biological networks from data. Learning biological networks from experimental data can help detect and analyze aberrant signaling pathways, which can be used in diagnosis of diseases at an early stage. Most networks can be modeled as Bayesian networks (BNs). However, because of its combinatorial nature, computational learning of dependent relationships underlying complex networks is NP-complete. To reduce the complexity, researchers have proposed to use Markov chain Monte Carlo (MCMC) methods to sample the solution space. MCMC methods guarantee convergence and traversability. However, MCMC is not scalable for networks with more than 40 nodes because of the computational complexity. In this work, we optimize an MCMC-based learning algorithm and implement it on a general-purpose graphics processing unit (GPGPU). We achieve a 2.46× speedup by optimizing the algorithm and an additional 58-fold acceleration by implementing it on a GPU. In total, we speed up the algorithm by 143×. As a result, we can apply this system to networks with up to 125 nodes, a size that is of interest to many biologists. Furthermore, we add artificial interventions to the scores in order to incorporate prior knowledge of interactions into the Bayesian inference, which increases the accuracy of the results. Our system provides biologists with a more computational efficient tool at a lower cost than previous works."",""1558-2183"","""",""10.1109/TPDS.2014.2387285"",""National Natural Science Foundation of China(grant numbers:61472243,61202026,61332001)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7001096"",""Bayesian Networks";GPU;MCMC;Priors;Parallel Computing;Bayesian networks;GPU;MCMC;priors;"parallel computing"",""Indexes";Graphics processing units;Bayes methods;Clustering algorithms;Biological system modeling;"Markov processes"","""",""4"","""",""31"",""IEEE"",""1 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"A Lock-Free Priority Queue Design Based on Multi-Dimensional Linked Lists,""D. Zhang";" D. Dechev"",""Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL";" Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""613"",""626"",""The throughput of concurrent priority queues is pivotal to multiprocessor applications such as discrete event simulation, best-first search and task scheduling. Existing lock-free priority queues are mostly based on skiplists, which probabilistically create shortcuts in an ordered list for fast insertion of elements. The use of skiplists eliminates the need of global rebalancing in balanced search trees and ensures logarithmic sequential search time on average, but the worst-case performance is linear with respect to the input size. In this paper, we propose a quiescently consistent lock-free priority queue based on a multi-dimensional list that guarantees worst-case search time of $\mathcal {O}(\log N)$  for key universe of size $N$ . The novel multi-dimensional list (MDList) is composed of nodes that contain multiple links to child nodes arranged by their dimensionality. The insertion operation works by first injectively mapping the scalar key to a high-dimensional vector, then uniquely locating the target position by using the vector as coordinates. Nodes in MDList are ordered by their coordinate prefixes and the ordering property of the data structure is readily maintained during insertion without rebalancing nor randomization. In our experimental evaluation using a micro-benchmark, our priority queue achieves an average of $50$  percent speedup over the state of the art approaches under high concurrency."",""1558-2183"","""",""10.1109/TPDS.2015.2419651"",""Division of Computer and Network Systems(grant numbers:NSF ACI-1440530)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079379"",""Concurrent Data Structure";Priority Queue;Lock-freedom;Multi-dimensional List;Skiplist;Concurrent data structure;priority queue;lock-freedom;multi-dimensional List;"skiplist"",""Vectors";Arrays;Algorithm design and analysis;Indexes;Semantics;"Throughput"","""",""24"",""1"",""27"",""IEEE"",""3 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Loosely-Coupled Full-System Multicore Simulation Framework,""W. Zhang"; H. Wang; Y. Lu; H. Chen;" W. Zhao"",""Parallel Processing Institute, Fudan University"; Parallel Processing Institute, Fudan University; Parallel Processing Institute, Fudan University; Institute of Parallel and Distributed Systems, Shanghai Jiaotong University, Shanghai, China;" Parallel Processing Institute, Fudan University"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1566"",""1578"",""Full-system simulation is critical in evaluating design alternatives for multicore processors. However, state-of-the-art multicore simulators either lack good extensibility due to their tightly-coupled design between functional model (FM) and timing model (TM), or cannot guarantee cycle-accuracy. This paper conducts a comprehensive study on factors affecting cycle-accuracy and uncovers several contributing factors less studied before. Based on these insights, we propose a loosely-coupled functional-driven full-system simulator for multicore, namely Transformer. To ensure extensibility and cycle-accuracy, Transformer leverages an architecture-independent interface between FM and TM and uses a lightweight scheme to detect and recover from execution divergence between FM and TM. Built upon Transformer and its foundational simulator components, a graduate student only needed to write about 180 lines of code to extend an X86 functional model (QEMU) in Transformer. Moreover, the loosely-coupled design also removes the complex interaction between FM and TM and opens the opportunity to parallelize FM and TM to improve performance. Experimental results show that Transformer achieves an average of 8.4 and 7.0 percent performance improvement over GEMS in 4-core and 8-core configuration while guaranteeing cycle-accuracy. A further parallelization between FM and TM leads to 35.3 and 29.7 percent performance improvement respectively."",""1558-2183"","""",""10.1109/TPDS.2015.2455499"",""National High Technology Research and Development Program of China(grant numbers:2012AA010905)"; National Natural Science Foundation of China(grant numbers:61370081); Shanghai Committee of Science and Technology(grant numbers:13DZ1108800);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155591"",""Functional-driven";Multicore simulation;Full-system;Functional-driven;multicore simulation;full-system;"extension"",""Frequency modulation";Multicore processing;Timing;Benchmark testing;Data models;Computational modeling;"Accuracy"","""",""3"","""",""24"",""IEEE"",""13 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"A Multi-Objective Approach to Real-Time In-Situ Processing of Mobile-Application Workflows,""H. Viswanathan"; E. K. Lee;" D. Pompili"",""NSF Center for Cloud and Autonomic Computing, Department of Electrical and Computer Engineering, Rutgers University–New Brunswick, NJ"; NSF Center for Cloud and Autonomic Computing, Department of Electrical and Computer Engineering, Rutgers University–New Brunswick, NJ;" NSF Center for Cloud and Autonomic Computing, Department of Electrical and Computer Engineering, Rutgers University–New Brunswick, NJ"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3116"",""3130"",""Innovative mobile applications that rely on real-time in-situ processing of data collected in the field need  to tap into the heterogeneous sensing and computing capabilities of sensor nodes, mobile handhelds as well as computing and storage servers in remote datacenters. There is, however, uncertainty associated with the quality and quantity of data from mobile sensors as well as with the  availability and capabilities of mobile computing resources on the field. Data and computing-resource uncertainty, if unchecked, may propagate up the “raw data $\rightarrow$ information $\rightarrow$ knowledge” chain and have an adverse effect on the relevance of the generated results. A generalized workflow representation scheme that can represent a wide variety of data- and task-parallel ubiquitous mobile applications is presented. A unified uncertainty-aware framework for data and computing-resource management to enable real-time, in-situ processing of applications is proposed and evaluated. The framework employs a two-phase solution that captures the propagation of data uncertainty up the data-processing chain using interval arithmetic in the first phase and that employs multi-objective optimization for task allocation in the second phase. The results of a case study to assess effectiveness the proposed framework are discussed in detail. Results reaffirm that i) data-uncertainty awareness helps control the uncertainty in the final result and ii) multi-objective combinatorial approach for task allocation significantly outperforms the single-objective approaches in terms of makespan (15 percent improvement), fairness in battery drain (56 percent improvement), and network load (54 percent improvement)."",""1558-2183"","""",""10.1109/TPDS.2016.2532864"",""Office of Naval Research—Young Investigator Program(grant numbers:11028418)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422143"",""Data uncertainty";workflows;mobile grid computing;in-situ processing;interval arithmetic;"multi-objective optimization"",""Mobile communication";Uncertainty;Real-time systems;Sensors;Computational modeling;Data models;"Mobile applications"","""",""7"","""",""41"",""IEEE"",""29 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Nearly Optimal Comparison-Based Diagnosis Algorithm for Systems of Arbitrary Topology,""R. P. Ziwich";" E. P. Duarte"",""Department Informatics, Federal University of Paraná (UFPR), PR, Brazil";" Department Informatics, Federal University of Paraná (UFPR), PR, Brazil"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3131"",""3143"",""Comparison-based diagnosis is a practical approach to detect faults in hardware, software, and parallel and distributed systems. Diagnosis is based on the comparison of task outputs returned by pairs of system units. This work introduces a novel diagnosis algorithm to identify faults in $t$  -diagnosable systems of arbitrary topology under the MM* model. The complexity of the proposed algorithm is $O(t^2 \Delta N)$  in the worst case for a system with $N$  units, where  $t$  denotes the maximum number of faulty units allowed and $\Delta$  corresponds to the maximum degree of a unit in the system. This complexity is nearly optimal in the sense that it is very close to that of traversing the syndrome once. Besides the algorithm specification and correctness proofs, simulations results are also presented, showing the typical performance of the algorithm for different systems."",""1558-2183"","""",""10.1109/TPDS.2016.2524004"",""Conselho Nacional de Desenvolvimento Científico e Tecnológico(grant numbers:309143/2012-8)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399770"",""Comparison-based diagnosis";system-level diagnosis;MM* model;multiprocessor systems;"arbitrary topology networks"",""Topology";Complexity theory;Network topology;Observers;Software algorithms;Fault diagnosis;"Hypercubes"","""",""8"","""",""42"",""IEEE"",""5 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Performance Debugging Framework for Unnecessary Lock Contentions with Record/Replay Techniques,""X. Liao"; L. Zheng; B. He; S. Wu;" H. Jin"",""Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"; Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Engineering, Nanyang Technological University, Singapore; Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China;" Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""1889"",""1901"",""Locks have been widely used as an effective synchronization mechanism among processes and threads. However, we observe that, a large number of false inter-thread dependencies (i.e., unnecessary lock contentions) exist during the program execution on multicore processors, incurring significant performance overhead. This paper presents a performance debugging framework, PERFPLAY, to facilitate the identification of unnecessary lock contentions and to guide programmers to improve the program performance by eliminating the unnecessary lock contentions. Since the performance debugging of unnecessary lock contentions is input-sensitive, we first identify the representative inputs for performance debugging. Next, PERFPLAY quantifies the performance impact of unnecessary lock contention code regions for each candidate input. Taking into account conflicting attribute of performance impact and input coverage in the real world, we finally make the tradeoff between performance impact and input coverage to recommend the optimal unnecessary lock contention code regions. Our final results on five real-world programs and PARSEC benchmarks demonstrate the significant performance overhead of unnecessary lock contentions, and the effectiveness of PERFPLAY in troubleshooting the target unnecessary lock contention code regions with the consideration of both performance impact and input coverage."",""1558-2183"","""",""10.1109/TPDS.2015.2472412"",""National High-tech Research and Development Program of China(grant numbers:2012AA010905)"; National Natural Science Foundation of China(grant numbers:61322210,61272408,61433019); Doctoral Fund of Ministry of Education of China(grant numbers:20130142110048); MoE AcRF Tier 1(grant numbers:2014-T1-001-145);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7222463"",""record/replay";unnecessary lock contention;performance impact;multiple input;program debugging;Record/replay;unnecessary lock contention;performance impact;multiple input;"program debugging"",""Debugging";Optimization;Synchronization;Benchmark testing;Instruction sets;Transforms;"Message systems"","""",""2"","""",""36"",""IEEE"",""25 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;
"A Performance Study of CUDA UVM versus Manual Optimizations in a Real-World Setup: Application to a Monte Carlo Wave-Particle Event-Based Interaction Model,""J. M. Nadal-Serrano";" M. Lopez-Vallejo"",""Department of de Electronic Engineering, Universidad Politécnica de Madrid, Madrid, Spain";" Department of de Electronic Engineering, Universidad Politécnica de Madrid, Madrid, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1579"",""1588"",""The performance of a Monte Carlo model for the simulation of electromagnetic wave propagation in particle-filled atmospheres has been conducted for different CUDA versions and design approaches. The proposed algorithm exhibits a high degree of parallelism, which allows favorable implementation in a GPU. Practical implementation aspects of the model have been also explained and their impact assessed, such as the use of the different types of memories present in a GPU. A number of setups have been chosen in order to compare performance for manually optimized versus Unified Virtual Memory (UVM ) implementations for different CUDA versions. Features and relative performance impact of the different options have been discussed, extracting practical hints and rules useful to speed up CUDA programs."",""1558-2183"","""",""10.1109/TPDS.2015.2463813"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7175058"",""Compute Unified Device Architecture (CUDA)";electromagnetic scattering model;manual optimization;Compute unified device architecture (CUDA);electromagnetic scattering model;graphics processing unit (GPU);Monte Carlo model;parallel computing optimization;unified virtual memory (UVM);"manual optimization"",""Graphics processing units";Atmospheric modeling;Computational modeling;Photonics;Scattering;"Geometry"","""",""8"","""",""21"",""IEEE"",""3 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Practical Large-Capacity Three-Stage Buffered Clos-Network Switch Architecture,""Y. Xia"; M. Hamdi;" H. J. Chao"",""College of Computer Science, Sichuan Normal University"; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong;" Department of Electrical and Computer Engineering, Polytechnic Institute of New York University, Brooklyn, NY"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""317"",""328"",""This paper proposes a three-stage buffered Clos-network switch (TSBCS) architecture along with a novel batch scheduling (BS) mechanism. We found that TSBCS/BS can be mapped to a “fat” combined input-crosspoint queued (CICQ) switch. Consequently, the well-studied CICQ scheduling algorithms can be directly applied in TSBCS. Moreover, BS drastically reduces the time complexity of TSBCS scheduling when compared with ordinary CICQ switches of the same number of switch ports, which enables us to build a larger-capacity switch with reasonable scheduling complexity. We further show that TSBCS/BS can achieve 100 percent throughput under any admissible traffic if a stable CICQ scheduling algorithm is used. Direct cell forwarding schemes are proposed to overcome the performance drawback of BS under light traffic loads. With extensive simulations, we show that the performance of TSBCS/BS is comparable to that of output-queued switches and the latter are usually considered as theoretical optimal."",""1558-2183"","""",""10.1109/TPDS.2015.2408614"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7054539"",""packet switch";distributed shared-memory;Clos network;batch scheduling;Packet switch;distributed shared-memory;Clos network;"batch scheduling"",""Switches";Computer architecture;Microprocessors;Ports (Computers);Out of order;Radiation detectors;"Throughput"","""",""16"","""",""51"",""IEEE"",""4 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Real-Time Information Based Demand-Side Management System in Smart Grid,""F. Ye"; Y. Qian;" R. Q. Hu"",""Department of Electrical and Computer Engineering, University of Nebraska-Lincoln, NE, Omaha"; Department of Electrical and Computer Engineering, University of Nebraska-Lincoln, NE, Omaha;" Department of Electrical and Computer Engineering, Utah State University, UT, Logan"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""329"",""339"",""In this paper, we study a real-time information based demand-side management (DSM) system with advanced communication networks in smart grid. DSM can smooth peak-to-average ratio (PAR) of power usage in the grid, which in turn reduces the waste of fuel and the emission of greenhouse gas. We first target to minimize PAR with a centralized scheme. To motivate power suppliers, we further propose another centralized scheme targeting minimum power generation cost. However, customers may not be motivated by a centralized scheme since such a scheme requires total control and privacy from them. A centralized scheme also requires too much real-time data exchange for frequent DSM deployment. To tackle these issues, we propose game theoretical approaches so that most of the computation is performed locally. In the proposed game, all the customers are motivated by extra savings if participating. Moreover, we prove that all parties benefit from the DSM system to the same level because both the centralized schemes and the game theoretical approach minimize global PAR. Such an analysis is further demonstrated by the simulation results and discussions. Additionally, we evaluate the performance of several (partially) distributed approaches in order to find the best way to deploy DSM system."",""1558-2183"","""",""10.1109/TPDS.2015.2403833"",""National Science Foundation(grant numbers:CNS-1423348,CNS-1423408)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7042318"",""Smart grid";demand-side management system;peak-to-average ratio;Smart grid;demand-side management system;"peak-to-average ratio"",""Home appliances";Games;Generators;Energy consumption;Schedules;Peak to average power ratio;"Power grids"","""",""54"","""",""25"",""IEEE"",""13 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Round-based Data Replication Strategy,""M. Bsoul"; A. E. Abdallah; K. Almakadmeh;" N. Tahat"",""Department of Computer Science and Applications, Hashemite University, Zarqa, Jordan"; Department of Computer Science and Applications, Hashemite University, Zarqa, Jordan; Department of Software Engineering, Hashemite University, Zarqa, Jordan;" Department of Mathematics, Hashemite University, Zarqa, Jordan"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""31"",""39"",""Data Grid allows many organizations to share data across large geographical area. The idea behind data replication is to store copies of the same file at different locations. Therefore, if a copy at a location is lost or not available, it can be brought from another location. Additionally, data replication results in a reduced time and bandwidth because of bringing the file from a closer location. However, the files that need to be replicated have to be selected wisely. In this paper, a round-based data replication strategy is proposed to select the most appropriate files for replication at the end of each round based on a number of factors. The proposed strategy is based on Popular File Replicate First (PFRF) strategy, and it overcomes the drawbacks of PFRF. The simulation results show that the proposed strategy yields better performance in terms of average file delay per request, average file bandwidth consumption per request, and percentage of files found."",""1558-2183"","""",""10.1109/TPDS.2015.2388449"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004058"",""Data Grid";Replication strategy;PFRF;Round-based;Simulation;Data Grid;replication strategy;PFRF;round-based;"simulation"",""Heuristic algorithms";Clustering algorithms;Bandwidth;Distributed databases;Servers;Educational institutions;"Electronic mail"","""",""14"","""",""19"",""IEEE"",""7 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"A Scalable, Non-Parametric Method for Detecting Performance Anomaly in Large Scale Computing,""L. Yu";" Z. Lan"",""Department of Computer Science, Illinois Institute of Technology, Chicago, IL";" Department of Computer Science, Illinois Institute of Technology, Chicago, IL"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""1902"",""1914"",""As computer systems continue to grow in scale and complexity, performance problems become common and a major concern for large-scale computing. Performance anomalies caused by application bugs, hardware or software faults, or resource contention can have great impact on system-wide performance and could lead to significant economic losses for service providers. While many detection methods have been presented in the past, the newly emerging challenges are detection scalability and practical use. In this paper, we propose a scalable, non-parametric method for effectively detecting performance anomalies in large-scale systems. The design is generic for anomaly detection in a variety of parallel and distributed systems exhibiting peer-comparable property. It adopts a divide-and-conquer approach to address the scalability challenge and explores the use of non-parametric clustering and two-phase majority voting to improve detection flexibility and accuracy. We derive probabilistic models to quantitatively evaluate our decentralized design. Experiments with a suite of applications on production systems demonstrate that this method outperforms existing methods in terms of detection accuracy with a negligible runtime overhead."",""1558-2183"","""",""10.1109/TPDS.2015.2475741"",""US National Science Foundation(grant numbers:CCF-1422009)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7236888"",""Large-scale Systems";Performance Anomalies;Hierarchical Grouping;Non-parametric Clustering;Large-scale systems;performance anomalies;hierarchical grouping;"non-parametric clustering"",""Peer-to-peer computing";Accuracy;Silicon;Hardware;Performance evaluation;Feature extraction;"Principal component analysis"","""",""15"","""",""59"",""IEEE"",""2 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Secure and Dynamic Multi-Keyword Ranked Search Scheme over Encrypted Cloud Data,""Z. Xia"; X. Wang; X. Sun;" Q. Wang"",""Jiangsu Engineering Center of Network Monitoring, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, and School of Computer and Software, Nanjing University of Information Science & Technology, Nanjing, China"; Jiangsu Engineering Center of Network Monitoring, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, and School of Computer and Software, Nanjing University of Information Science & Technology, Nanjing, China; Jiangsu Engineering Center of Network Monitoring, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, and School of Computer and Software, Nanjing University of Information Science & Technology, Nanjing, China;" Key Lab of Aerospace Information Security and Trusted Computing, School of Computer, Wuhan University, Wuhan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""340"",""352"",""Due to the increasing popularity of cloud computing, more and more data owners are motivated to outsource their data to cloud servers for great convenience and reduced cost in data management. However, sensitive data should be encrypted before outsourcing for privacy requirements, which obsoletes data utilization like keyword-based document retrieval. In this paper, we present a secure multi-keyword ranked search scheme over encrypted cloud data, which simultaneously supports dynamic update operations like deletion and insertion of documents. Specifically, the vector space model and the widely-used TF x IDF model are combined in the index construction and query generation. We construct a special tree-based index structure and propose a “Greedy Depth-first Search” algorithm to provide efficient multi-keyword ranked search. The secure kNN algorithm is utilized to encrypt the index and query vectors, and meanwhile ensure accurate relevance score calculation between encrypted index and query vectors. In order to resist statistical attacks, phantom terms are added to the index vector for blinding search results. Due to the use of our special tree-based index structure, the proposed scheme can achieve sub-linear search time and deal with the deletion and insertion of documents flexibly. Extensive experiments are conducted to demonstrate the efficiency of the proposed scheme."",""1558-2183"","""",""10.1109/TPDS.2015.2401003"",""NSFC(grant numbers:61173141,61232016,U1405254,61173142,61173136,61103215,61373132,61373133,61300237,61373167,GYHY201206033,201301030,2013DFG12860,BC2013012)"; Jiangsu Engineering Center of Network Monitoring(grant numbers:KJR1308,KJR1402); MOE Internet Innovation Platform(grant numbers:KJRP1403); Natural Science Foundation of Hubei Province(grant numbers:2013CFB297); PAPD;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7039216"",""Searchable encryption";multi-keyword ranked search;dynamic update;cloud computing;Searchable encryption;multi-keyword ranked search;dynamic update;"cloud computing"",""Indexes";Vectors;Servers;Encryption;Keyword search;"Clouds"","""",""867"","""",""39"",""IEEE"",""11 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"A Secure Anti-Collusion Data Sharing Scheme for Dynamic Groups in the Cloud,""Z. Zhu";" R. Jiang"",""School of Information Science and Engineering, Southeast University, Nanjing, China";" School of Information Science and Engineering, Southeast University, Nanjing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Dec 2015"",""2016"",""27"",""1"",""40"",""50"",""Benefited from cloud computing, users can achieve an effective and economical approach for data sharing among group members in the cloud with the characters of low maintenance and little management cost. Meanwhile, we must provide security guarantees for the sharing data files since they are outsourced. Unfortunately, because of the frequent change of the membership, sharing data while providing privacy-preserving is still a challenging issue, especially for an untrusted cloud due to the collusion attack. Moreover, for existing schemes, the security of key distribution is based on the secure communication channel, however, to have such channel is a strong assumption and is difficult for practice. In this paper, we propose a secure data sharing scheme for dynamic members. First, we propose a secure way for key distribution without any secure communication channels, and the users can securely obtain their private keys from group manager. Second, our scheme can achieve fine-grained access control, any user in the group can use the source in the cloud and revoked users cannot access the cloud again after they are revoked. Third, we can protect the scheme from collusion attack, which means that revoked users cannot get the original data file even if they conspire with the untrusted cloud. In our approach, by leveraging polynomial function, we can achieve a secure user revocation scheme. Finally, our scheme can achieve fine efficiency, which means previous users need not to update their private keys for the situation either a new user joins in the group or a user is revoked from the group."",""1558-2183"","""",""10.1109/TPDS.2015.2388446"",""National Natural Science Foundation of China(grant numbers:61202448)"; Information Network Security of Ministry of Public Security(grant numbers:C14610);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004069"",""Access control";Privacy-preserving;Key distribution;Cloud computing;Access control;privacy-preserving;key distribution;"cloud computing"",""Access control";Cloud computing;Communication channels;Encryption;"Educational institutions"","""",""41"","""",""21"",""IEEE"",""7 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Survey of Software Techniques for Using Non-Volatile Memories for Storage and Main Memory Systems,""S. Mittal";" J. S. Vetter"",""Future Technologies Group, Oak Ridge National Laboratory, Oak Ridge, TN";" Future Technologies Group, Oak Ridge National Laboratory, Oak Ridge, TN"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1537"",""1550"",""Non-volatile memory (NVM) devices, such as Flash, phase change RAM, spin transfer torque RAM, and resistive RAM, offer several advantages and challenges when compared to conventional memory technologies, such as DRAM and magnetic hard disk drives (HDDs). In this paper, we present a survey of software techniques that have been proposed to exploit the advantages and mitigate the disadvantages of NVMs when used for designing memory systems, and, in particular, secondary storage (e.g., solid state drive) and main memory. We classify these software techniques along several dimensions to highlight their similarities and differences. Given that NVMs are growing in popularity, we believe that this survey will motivate further research in the field of software technology for NVMs."",""1558-2183"","""",""10.1109/TPDS.2015.2442980"",""U.S. Department of Energy"; Office of Science; Advanced Scientific Computing Research;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120149"",""Review";classification;non-volatile memory (NVM) (NVRAM;flash memory;phase change RAM (PCM) (PCRAM);spin transfer torque RAM (STT-RAM) (STT-MRAM);resistive RAM (ReRAM) (RRAM);storage class memory (SCM);Solid State Drive (SSD);Review;classification;non-volatile memory (NVM) (NVRAM);flash memory;phase change RAM (PCM) (PCRAM);spin transfer torque RAM (STT-RAM) (STT-MRAM);resistive RAM (ReRAM) (RRAM);storage class memory (SCM);"solid state drive (SSD)"",""Nonvolatile memory";Flash memories;Phase change materials;Software;Memory management;"Phase change random access memory"","""",""191"",""1"",""139"",""IEEE"",""9 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;
"A Survey of Task Allocation and Load Balancing in Distributed Systems,""Y. Jiang"",""College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""585"",""599"",""In past decades, significant attention has been devoted to the task allocation and load balancing in distributed systems. Although there have been some related surveys about this subject, each of which only made a very preliminary review on the state of art of one single type of distributed systems. To correlate the studies in varying types of distributed systems and make a comprehensive taxonomy on them, this survey mainly categorizes and reviews the representative studies on task allocation and load balancing according to the general characteristics of varying distributed systems. First, this survey summarizes the general characteristics of distributed systems. Based on these general characteristics, this survey reviews the studies on task allocation and load balancing with respect to the following aspects: 1) typical control models"; 2) typical resource optimization methods; 3) typical methods for achieving reliability; 4) typical coordination mechanisms among heterogeneous nodes;" and 5) typical models considering network structures. For each aspect, we summarize the existing studies and discuss the future research directions. Through the survey, the related studies in this area can be well understood based on how they can satisfy the general characteristics of distributed systems."",""1558-2183"","""",""10.1109/TPDS.2015.2407900"",""National Natural Science Foundation of China(grant numbers:61170164,61472079)"; Natural Science Foundation of Jiangsu Province(grant numbers:BK2012020); Program for Distinguished Talents of Six Domains in Jiangsu Province(grant numbers:2011-DZ023);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051215"",""Distributed systems";task allocation;load balancing;network;resource allocation;taxonomy;Distributed systems;task allocation;load balancing;networks;resource allocation;survey;"taxonomy"",""Resource management";Peer-to-peer computing;Load management;Load modeling;Reliability;Computational modeling;"Time factors"","""",""131"","""",""96"",""IEEE"",""27 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;
"A Survey Of Techniques for Architecting DRAM Caches,""S. Mittal";" J. S. Vetter"",""Future Technologies Group, Oak Ridge National Laboratory, Oak Ridge, TN";" Future Technologies Group, Oak Ridge National Laboratory, Oak Ridge, TN"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1852"",""1863"",""Recent trends of increasing core-count and memory/bandwidth-wall have led to major overhauls in chip architecture. In face of increasing cache capacity demands, researchers have now explored DRAM, which was conventionally considered synonymous to main memory, for designing large last level caches. Efficient integration of DRAM caches in mainstream computing systems, however, also presents several challenges and several recent techniques have been proposed to address them. In this paper, we present a survey of techniques for architecting DRAM caches. Also, by classifying these techniques across several dimensions, we underscore their similarities and differences. We believe that this paper will be very helpful to researchers for gaining insights into the potential, tradeoffs and challenges of DRAM caches."",""1558-2183"","""",""10.1109/TPDS.2015.2461155"",""US Department of Energy"; Office of Science; Advanced Scientific Computing Research;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7181712"",""Review";classification;last level cache;Review;classification;last level cache;die-stacking;3D;stacked DRAM;bandwidth wall;extreme-scale system;"architectural techniques"",""Random access memory";Bandwidth;Three-dimensional displays;Program processors;Memory management;"Multicore processing"","""",""39"","""",""67"",""IEEE"",""6 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"A Survey of Techniques for Modeling and Improving Reliability of Computing Systems,""S. Mittal";" J. S. Vetter"",""Future Technologies Group, Oak Ridge National Laboratory, Oak Ridge, TN";" Georgia Institute of Technology, Atlanta, GA"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1226"",""1238"",""Recent trends of aggressive technology scaling have greatly exacerbated the occurrences and impact of faults in computing systems. This has made `reliability' a first-order design constraint. To address the challenges of reliability, several techniques have been proposed. This paper provides a survey of architectural techniques for improving resilience of computing systems. We especially focus on techniques proposed for microarchitectural components, such as processor registers, functional units, cache and main memory etc. In addition, we discuss techniques proposed for non-volatile memory, GPUs and 3D-stacked processors. To underscore the similarities and differences of the techniques, we classify them based on their key characteristics. We also review the metrics proposed to quantify vulnerability of processor structures. We believe that this survey will help researchers, system-architects and processor designers in gaining insights into the techniques for improving reliability of computing systems."",""1558-2183"","""",""10.1109/TPDS.2015.2426179"",""Oak Ridge National Laboratory";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7094277"",""Review,";classification;reliability;resilience;fault-tolerance;vulnerability;architectural vulnerability factor;soft/transient error;architectural techniques;Review;classification;reliability;resilience;fault-tolerance;vulnerability;architectural vulnerability factor;soft/transient error;"architectural techniques"",""Measurement";Computational modeling;Registers;Circuit faults;Integrated circuit reliability;"Nonvolatile memory"","""",""59"","""",""114"",""IEEE"",""24 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;
"A Systematic Methodology for Evaluating the Error Resilience of GPGPU Applications,""B. Fang"; K. Pattabiraman; M. Ripeanu;" S. Gurumurthi"",""Department of Electrical and Computer Engineering, University of British Columbia"; Department of Electrical and Computer Engineering, University of British Columbia; Department of Electrical and Computer Engineering, University of British Columbia;" Cloud Innovation Lab, IBM Corporation"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3397"",""3411"",""The wide adoption of graphics processing units (GPUs) as accelerators for general-purpose applications makes the end-to-end reliability implications of their use increasingly significant. Fault injection is a widely adopted method to evaluate the resilience of applications. However, building a fault injector for general-purpose GPU applications is challenging due to their massive parallelism, which makes it difficult to achieve representativeness while being time-efficient. This paper makes four key contributions. First, it presents a fault-injection methodology to evaluate the end-to-end reliability properties of application kernels running on GPUs. Second, it introduces GPU-Qin, a fault-injection tool that uses real GPU hardware and offers a tunable and efficient balance between the representativeness and the cost of a fault-injection campaign. Third, it characterizes the error resilience characteristics of seventeen application kernels. Finally, it provides preliminary insights on correlations between the algorithmic properties of applications and their error resilience."",""1558-2183"","""",""10.1109/TPDS.2016.2517633"",""NSERC"; NVIDIA;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426849"",""GPU";fault tolerance;"error resilience"",""Error correction";Graphics processing units;Fault tolerance;Instruction sets;Transient analysis;"Microarchitecture"","""",""17"","""",""45"",""IEEE"",""7 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"A Taxonomy of Job Scheduling on Distributed Computing Systems,""R. V. Lopes";" D. Menascé"",""Departmento de Sistemas e Computação, Universidade Federal de Campina Grande, Paraiba, Brazil";" Department of Computer Science, George Mason University, Fairfax, VA"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3412"",""3428"",""Hundreds of papers on job scheduling for distributed systems are published every year and it becomes increasingly difficult to classify them. Our analysis revealed that half of these papers are barely cited. This paper presents a general taxonomy for scheduling problems and solutions in distributed systems. This taxonomy was used to classify and make publicly available the classification of 109 scheduling problems and their solutions. These 109 problems were further clustered into ten groups based on the features of the taxonomy. The proposed taxonomy will facilitate researchers to build on prior art, increase new research visibility, and minimize redundant effort."",""1558-2183"","""",""10.1109/TPDS.2016.2537821"",""CNPq(grant numbers:203418/2014-0)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425222"",""Taxonomy";scheduling;distributed jobs;cluster;grid computing;"cloud computing"",""Job shop scheduling";Taxonomy;Processor scheduling;Cloud computing;Distributed processing;Grid computing;"Cluster approximation"","""",""28"","""",""99"",""IEEE"",""3 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"AC-WAR: Architecting the Cache Hierarchy to Improve the Lifetime of a Non-Volatile Endurance-Limited Main Memory,""P. Abad"; P. Prieto; V. Puente;" J. -A. Gregorio"",""Computer Architecture Group, University of Cantabria, Santander, Spain"; Computer Architecture Group, University of Cantabria, Santander, Spain; Computer Architecture Group, University of Cantabria, Santander, Spain;" Computer Architecture Group, University of Cantabria, Santander, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""66"",""77"",""This work shows how by adapting replacement policies in contemporary cache hierarchies it is possible to extend the lifespan of a write endurance-limited main memory by almost one order of magnitude. The inception of this idea is that during cache residency 1) blocks are modified in a bimodal way: either most of the content of the block is modified or most of the content of the block never changes, and 2) in most applications, the majority of blocks are only slightly modified. When those facts are considered by the cache replacement algorithms, it is possible to significantly reduce the number of bit-flips per write-back to main memory. Our proposal favors the off-chip eviction of slightly modified blocks according to an adaptive replacement algorithm that operates coordinately in L2 and L3. This way it is possible to improve significantly system memory lifetime, with negligible performance degradation. We found that using a few bits per block to track changes in cache blocks with respect to the main memory content is enough. With a slightly modified sectored LRU and a simple cache performance predictor it is possible to achieve a simple implementation with minimal cost in area and no impact on cache access time. On average, our proposal increases the memory lifetime obtained with an LRU policy up to 10 times (10×) and 15 times (15×) when combined with other memory centric techniques. In both cases, the performance degradation could be considered negligible."",""1558-2183"","""",""10.1109/TPDS.2015.2390225"",""Spanish Ministry of Economy(grant numbers:TIN2013-43228-P)"; HiPEAC European Network of Excellence;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006735"",""Cache Memories";Memory Hierarchy;Replacement Algorithm;Endurance;Cache memories;memory hierarchy;replacement algorithm;"endurance"",""Random access memory";Nonvolatile memory;Proposals;Memory management;Phase change materials;Vectors;"Servers"","""",""2"","""",""39"",""IEEE"",""12 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Accelerated Deformable Part Models on GPUs,""M. Hirabayashi"; S. Kato; M. Edahiro; K. Takeda;" S. Mita"",""Graduate School of Information Science, Nagoya University, Nagoya, Aichi, Japan"; Graduate School of Information Science, Nagoya University, Nagoya, Aichi, Japan; Graduate School of Information Science, Nagoya University, Nagoya, Aichi, Japan; Graduate School of Information Science, Nagoya University, Nagoya, Aichi, Japan;" Research Center for Smart Vehicles, Toyota Technological Institute, Nagoya, Aichi, Japan"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1589"",""1602"",""Object detection is a fundamental challenge facing intelligent applications. Image processing is a promising approach to this end, but its computational cost is often a significant problem. This paper presents schemes for accelerating the deformable part models (DPM) on graphics processing units (GPUs). DPM is a well-known algorithm for image-based object detection, and it achieves high detection rates at the expense of computational cost. GPUs are massively parallel compute devices designed to accelerate data-parallel compute-intensive workload. According to an analysis of execution times, approximately 98 percent of DPM code exhibits loop processing, which means that DPM could be highly parallelized by GPUs. In this paper, we implement DPM on the GPU by exploiting multiple parallelization schemes. Results of an experimental evaluation of this GPU-accelerated DPM implementation demonstrate that the best scheme of GPU implementations using an NVIDIA GPU achieves a speed up of 8.6x over a naive CPU-based implementation."",""1558-2183"","""",""10.1109/TPDS.2015.2453962"",""Center of Innovation Program"; JST;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152943"",""Deformable Part Models (DPM)";Graphics Processing Unit (GPU),;Image Processing;Deformable part models (DPM);graphics processing unit (GPU);"image processing"",""Graphics processing units";Instruction sets;Arrays;Object detection;Acceleration;Hardware;"Computational modeling"","""",""7"",""1"",""36"",""IEEE"",""8 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Accelerating Irregular Computation in Massive Short Reads Mapping on FPGA Co-Processor,""G. Tan"; C. Zhang; W. Tang; P. Zhang;" N. Sun"",""State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China"; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China;" State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1253"",""1264"",""Because there is an enormous amount of genomic data, next-generation sequencing (NGS) applications pose significant challenges to current computing systems. In this study, we investigate both algorithmic and architectural strategies to accelerate an NGS data analysis algorithm—short read mapping on commodity multi-core platform and customizable field programmable gate array (FPGA) co-processor architecture, respectively. A workload analysis reveals that conventional memory optimization is limited in its irregular computation of low arithmetic intensity and non-contiguous memory access pattern. To mitigate the inherent irregular computation in mapping, we have developed a FPGA co-processor based on Convey computer, which employs a scatter-gather memory mechanism that exploits both bit-level and word-level parallelism. The customized FPGA co-processor achieves a throughput of  $947$ Gbp per day, about $189$  times higher than that of current mapping tools on single CPU core. Moreover, the co-processor's power efficiency is $29$  times higher than that of a conventional 64-core multi-processor."",""1558-2183"","""",""10.1109/TPDS.2015.2444393"",""National Natural Science Foundation of China(grant numbers:61272134,31327901,91430218,60921002,60925009,61472395)"; National 863 Program(grant numbers:2009AA01A129); 973 Program(grant numbers:2012CB316502,2011CB302502);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7122363"",""Short Reads Mapping";Irregular Computation;FPGA;Multicore Parallelism;Short read mapping;irregular computation;FPGA;"multicore parallelism"",""Indexes";Field programmable gate arrays;Genomics;Bioinformatics;Multicore processing;"Bandwidth"","""",""5"","""",""36"",""IEEE"",""11 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"Acceleration of a Full-Scale Industrial CFD Application with OP2,""I. Z. Reguly"; G. R. Mudalige; C. Bertolli; M. B. Giles; A. Betts; P. H. J. Kelly;" D. Radford"",""PPCU ITK, Budapest, Hungary"; Oxford e-Research Centre, University of Oxford, 7, Keble Road, Oxford OX1 3QG, United Kingdom; IBM TJ Watson Research Centre, New York, NY; Oxford e-Research Centre, University of Oxford, 7, Keble Road, Oxford OX1 3QG, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom;" Rolls Royce plc. Derby, United Kingdom"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1265"",""1278"",""Hydra is a full-scale industrial CFD application used for the design of turbomachinery at Rolls Royce plc., capable of performing complex simulations over highly detailed unstructured mesh geometries. Hydra presents major challenges in data organization and movement that need to be overcome for continued high performance on emerging platforms. We present research in achieving this goal through the OP2 domain-specific high-level framework, demonstrating the viability of such a high-level programming approach. OP2 targets the domain of unstructured mesh problems and enables execution on a range of back-end hardware platforms. We chart the conversion of Hydra to OP2, and map out the key difficulties encountered in the process. Specifically we show how different parallel implementations can be achieved with an active library framework, even for a highly complicated industrial application and how different optimizations targeting contrasting parallel architectures can be applied to the whole application, seamlessly, reducing developer effort and increasing code longevity. Performance results demonstrate that not only the same runtime performance as that of the hand-tuned original code could be achieved, but it can be significantly improved on conventional processor systems, and many-core systems. Our results provide evidence of how high-level frameworks such as OP2 enable portability across a wide range of contrasting platforms and their significant utility in achieving high performance without the intervention of the application programmer."",""1558-2183"","""",""10.1109/TPDS.2015.2453972"",""U.K. Technology Strategy Board"; Rolls-Royce; Siloet project; U.K. Engineering and Physical Sciences Research Council(grant numbers:EP/I006079/1,EP/I00677X/1); Multi-layered Abstractions for PDEs; Algorithms, Software for Emerging Architectures(grant numbers:EP/J010553/1);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152942"",""Unstructured Mesh Applications";Domain Specific Language;Active Library;Unstructured mesh applications;domain specific language;active library;OP2;OpenMP;GPU;CUDA;"CFD"",""Libraries";Optimization;Hardware;Algorithms;Graphics processing units;Computational fluid dynamics;"Kernel"","""",""30"","""",""40"",""IEEE"",""8 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;
"Achieving Optimal Block Pipelining in Organized Network Coded Gossip,""M. Khabbazian";" D. Niu"",""Department of Electrical and Computer Engineering, University of Alberta";" Department of Electrical and Computer Engineering, University of Alberta"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""627"",""639"",""We use randomized network coding (RNC) with simple connection topology control to approach the theoretical limit on finish time of disseminating $k$  blocks in a server cluster of $n$  nodes. Unlike prior gossip literature which relies on completely random contact, we prove that with RNC, any receiver selection following a simple permutation rule can achieve a broadcast completion time of $k+n$  and that a time-varying random ring topology achieves a completion time of $k+o(k)+O(\log \,n)$ , both with high probability. Since the theoretical limit on finish time is  $k+\lceil \log _2 \,n\rceil$ , our simple permutation algorithms achieve absolutely optimal (not only order-optimal) block pipelining for the $k$  blocks. Our results hold for both one-to-all (broadcast) and all-to-all transfers. We demonstrate the usefulness of the proposed organized network coded gossip with an application to content distribution in cluster computing systems like MapReduce, and discuss practical block dividing strategies to hide the negative effect of computation overhead of network coding."",""1558-2183"","""",""10.1109/TPDS.2015.2417163"",""Natural Sciences and Engineering Research Council of Canada";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7069277"",""network coding";gossip;broadcast finish time;optimal block pipelining;computer cluster;content distribution;randomized algorithms;Network coding;gossip;broadcast finish time;optimal block pipelining;computer cluster;content distribution;"randomized algorithms"",""Vectors";Servers;Clustering algorithms;Data transfer;Pipeline processing;Network coding;"Topology"","""","""","""",""24"",""IEEE"",""26 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Achieving Optimal Traffic Engineering Using a Generalized Routing Framework,""K. Xu"; M. Shen; H. Liu; J. Liu; F. Li;" T. Li"",""Tsinghua National Laboratory for Information Science and Technology (TNList), Department of Computer Science, Tsinghua University, Beijing, China"; School of Computer Science, Beijing Institute of Technology, Beijing, China; School of Mathematics and Systems Science, Beihang University, Beijing, China; School of Computing Science, Simon Fraser University, BC, Canada; School of Computer Science, Beijing Institute of Technology, Beijing, China;" Tsinghua National Laboratory for Information Science and Technology (TNList), Department of Computer Science, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""51"",""65"",""The open shortest path first (OSPF) protocol has been widely applied to intra-domain routing in today's Internet. Since a router running OSPF distributes traffic uniformly over equal-cost multi-path (ECMP), the OSPF-based optimal traffic engineering (TE) problem (i.e., deriving optimal link weights for a given traffic demand) is computationally intractable for large-scale networks. Therefore, many studies resort to multi-protocol label switching (MPLS) based approaches to solve the optimal TE problem. In this paper we present a generalized routing framework to realize the optimal TE, which can be potentially implemented via OSPFor MPLS-based approaches. We start with viewing the conventional optimal TE problem in a fresh way, i.e., optimally allocating the residual capacity to every link. Then we make a generalization of network utility maximization (NUM) to close this problem, where the network operator is associated with a utility function of the residual capacity to be maximized. We demonstrate that under this framework, the optimal routes resulting from the optimal TE are also the shortest paths in terms of a set of non-negative link weights that are explicitly determined by the optimal residual capacity and the objective function. The network entropy maximization theory is employed to enable routers to exponentially, instead of uniformly, split traffic over ECMP. The shortest-path penalizing exponential flow-splitting (SPEF) is designed as a link-state protocol with hop-by-hop forwarding to implement our theoretical findings. An alternative MPLS-based implementation is also discussed here. Numerical simulation results have demonstrated the effectiveness of the proposed framework as well as SPEF."",""1558-2183"","""",""10.1109/TPDS.2015.2392760"",""NSERC(grant numbers:61170292,61472212,61172060,61370192,61432015)"; National Science and Technology(grant numbers:2012ZX03005001); 973 Project of China(grant numbers:2012CB315803); 863 Project of China(grant numbers:2013AA013302,2015AA010203); EU MARIE CURIE ACTIONS EVANS(grant numbers:GA-2010-269323,GA-2013-610524); Beijing Institute of Technology Research;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7010944"",""Traffic engineering";Routing;OSPF;MPLS;Utility;Load balancing;Traffic engineering;routing;OSPF;MPLS;utility;"load balancing"",""Routing";Load management;Linear programming;Delays;Vectors;Optimization;"Educational institutions"","""",""19"","""",""45"",""IEEE"",""15 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;
"Adaptive Impact-Driven Detection of Silent Data Corruption for HPC Applications,""S. Di";" F. Cappello"",""Mathematics and Computer Science (MCS) Division, Argonne National Laboratory, Lemont, IL";" Mathematics and Computer Science (MCS) Division, Argonne National Laboratory, Lemont, IL"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2809"",""2823"",""For exascale HPC applications, silent data corruption (SDC) is one of the most dangerous problems because there is no indication that there are errors during the execution. We propose an adaptive impact-driven method that can detect SDCs dynamically. The key contributions are threefold. (1) We carefully characterize 18 HPC applications/benchmarks and discuss the runtime data features, as well as the impact of the SDCs on their execution results. (2) We propose an impact-driven detection model that does not blindly improve the prediction accuracy, but instead detects only influential SDCs to guarantee user-acceptable execution results. (3) Our solution can adapt to dynamic prediction errors based on local runtime data and can automatically tune detection ranges for guaranteeing low false alarms. Experiments show that our detector can detect 80-99.99 percent of SDCs with a false alarm rate less that 1 percent of iterations for most cases. The memory cost and detection overhead are reduced to 15 and 6.3 percent, respectively, for a large majority of applications."",""1558-2183"","""",""10.1109/TPDS.2016.2517639"",""U.S. Department of Energy"; Office of Science; Advanced Scientific Computing Research Program(grant numbers:DE-AC02-06CH11357); ANR RESCUE; INRIA-Illinois-ANL-BSC Joint Laboratory; Extreme Scale Computing, and Center for Exascale Simulation of Advanced Reactors (CESAR); UChicago Argonne; LLC; Argonne National Laboratory; U.S. Department of Energy Office of Science laboratory(grant numbers:DE-AC02-06CH11357);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7393580"",""Fault tolerance";silent data corruption;"exascale HPC"",""Distributed databases";Detectors;Sensitivity;Feature extraction;Runtime;Data models;"Electric shock"","""",""34"","""",""47"",""IEEE"",""26 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"AM$^3$ : Towards A Hardware Unix Accelerator for Many-Cores,""R. Poss";" K. Koning"",""Institute for Informatics, Vrije Universiteit Amsterdam, Netherlands";" Institute for Informatics, Vrije Universiteit Amsterdam, Netherlands"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2208"",""2221"",""This article advocates the use of new architectural features commonly found in many-cores to replace the machine model underlying Unix-like operating systems. We present a general Abstract Many-core Machine Model (AM $^3$ ), a proof-of-concept implementation and first evaluation results in the context of an emerging many-core, hardware multi-threaded architecture without support for interrupts. Our proposed approach makes it possible to reuse off-the-shelf multithreaded/multiprocess software on massively parallel architectures, without need to change code to use custom programming models like CUDA or OpenCL. Benefits include higher hardware utilization, higher performance and higher energy efficiency for workloads common to general-purpose platforms, such as in datacenters and clouds. The benefits also include simpler software control over the hardware platform, an enabling factor for the further evolution of parallel programming languages."",""1558-2183"","""",""10.1109/TPDS.2015.2492542"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300441"",""Multi-cores";operating systems;"computing models"",""Hardware";Tin;Context;Instruction sets;Message systems;"Registers"","""","""","""",""47"",""IEEE"",""19 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"An Analytical Solution for Probabilistic Guarantees of Reservation Based Soft Real-Time Systems,""L. Palopoli"; D. Fontanelli; L. Abeni;" B. V. Frías"",""Dipartimento di Ingegneria e Scienza dell'Informazione, University of Trento"; Dipartimento di Ingegneria Industriale, University of Trento, Trento, Italy; Dipartimento di Ingegneria e Scienza dell'Informazione, University of Trento;" Dipartimento di Ingegneria e Scienza dell'Informazione, University of Trento"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""640"",""653"",""We show a methodology for the computation of the probability of deadline miss for a periodic real-time task scheduled by a resource reservation algorithm. We propose a modelling technique for the system that reduces the computation of such a probability to that of the steady state probability of an infinite state Discrete Time Markov Chain with a periodic structure. This structure is exploited to develop an efficient numeric solution where different accuracy/computation time trade-offs can be obtained by operating on the granularity of the model. More importantly we offer a closed form conservative bound for the probability of a deadline miss. Our experiments reveal that the bound remains reasonably close to the experimental probability in one real-time application of practical interest. When this bound is used for the optimisation of the overall Quality of Service for a set of tasks sharing the CPU, it produces a good sub-optimal solution in a small amount of time."",""1558-2183"","""",""10.1109/TPDS.2015.2416732"",""European Union FP7 Programme(grant numbers:FP7/2007-2013,ICT-2011-288917)"; DALi-Devices for Assisted Living(grant numbers:FP7-ICT-257462); HYCON2 NoE; European Union H2020 programme(grant numbers:643544); ACANTO;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7070759"",""Real–time systems";Scheduling;Probabilistic Guarantees;Real-time systems;scheduling;"probabilistic guarantees"",""Mathematical model";Processor scheduling;Probabilistic logic;Computational modeling;Equations;Stochastic processes;"Approximation methods"","""",""13"","""",""37"",""IEEE"",""27 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"An Efficient GPU Implementation of Inclusion-Based Pointer Analysis,""Y. Su"; D. Ye; J. Xue;" X. -K. Liao"",""Programming Language and Compilers Group, School of Computer Science and Engineering, UNSW, Australia"; Programming Language and Compilers Group, School of Computer Science and Engineering, UNSW, Australia; Programming Language and Compilers Group, School of Computer Science and Engineering, UNSW, Australia;" School of Computer Science, National University of Defense Technology, China"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""353"",""366"",""We present an efficient GPU implementation of Andersen's whole-program inclusion-based pointer analysis, a fundamental analysis on which many others are based, including optimising compilers, bug detection and security analyses. Andersen's algorithm makes extensive modifications to the graph that represents the pointer-manipulating statements in a program. These modifications are highly irregular, input-dependent and statically unpredictable, making it much more challenging to balance such graph workloads across a multitude of GPU cores than those dealt with by traditional graph algorithms such as DFS and BFS. To parallelise Andersen's analysis efficiently on GPUs, we introduce an imbalance-aware workload partitioning scheme that divides its workload dynamically among the concurrent warps, initially in a warp-centric manner (during the coarsegrain stage) but later switches to a task-pool-based model when a workload imbalance is detected (during the fine-grain stage). We improve further its performance by using an adaptive group propagation scheme to reduce some redundant traversals. For a set of 14 C benchmarks evaluated, our parallel implementation of Andersen's analysis achieves a significant speedup of 46 percent on average over the state-of-the art on an NVIDIA Tesla K20c GPU."",""1558-2183"","""",""10.1109/TPDS.2015.2397933"",""Australian Research Council(grant numbers:DP130101970,DP150102109)"; National Natural Science Foundation of China(grant numbers:61170049);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7029117"",""Parallel graph algorithms";GPGPU,;pointer analysis;compilers;Parallel graph algorithms;GPGPU;pointer analysis;"compilers"",""Graphics processing units";Algorithm design and analysis;Vectors;Instruction sets;Partitioning algorithms;Synchronization;"Adaptation models"","""",""6"","""",""50"",""OAPA"",""2 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"An Efficient Implementation of the Bellman-Ford Algorithm for Kepler GPU Architectures,""F. Busato";" N. Bombieri"",""Department of Computer Science, University of Verona, Italy";" Department of Computer Science, University of Verona, Italy"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2222"",""2233"",""Finding the shortest paths from a single source to all other vertices is a common problem in graph analysis. The Bellman-Ford's algorithm is the solution that solves such a single-source shortest path (SSSP) problem and better applies to be parallelized for many-core architectures. Nevertheless, the high degree of parallelism is guaranteed at the cost of low work efficiency, which, compared to similar algorithms in literature (e.g., Dijkstra's) involves much more redundant work and a consequent waste of power consumption. This article presents a parallel implementation of the Bellman-Ford algorithm that exploits the architectural characteristics of recent GPU architectures (i.e., NVIDIA Kepler, Maxwell) to improve both performance and work efficiency. The article presents different optimizations to the implementation, which are oriented both to the algorithm and to the architecture. The experimental results show that the proposed implementation provides an average speedup of $5 \times$  higher than the existing most efficient parallel implementations for SSSP, that it works on graphs where those implementations cannot work or are inefficient (e.g., graphs with negative weight edges, sparse graphs), and that it sensibly reduces the redundant work caused by the parallelization process."",""1558-2183"","""",""10.1109/TPDS.2015.2485994"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7287776"",""SSSP";Bellman-Ford;GPU;CUDA;"Kepler"",""Graphics processing units";Instruction sets;Parallel processing;Heuristic algorithms;Computer architecture;Optimization;"Kernel"","""",""42"","""",""42"",""IEEE"",""2 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"An Efficient Privacy-Preserving Ranked Keyword Search Method,""C. Chen"; X. Zhu; P. Shen; J. Hu; S. Guo; Z. Tari;" A. Y. Zomaya"",""State Key Laboratory Of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China"; State Key Laboratory Of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; State Key Laboratory Of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Cyber Security Lab, School of Engineering and IT, University of New South Wales at the Australian Defence Force Academy, Canberra, Australia; School of Computer Science and Engineering, The University of Aizu, Japan; School of Computer Science, RMIT University, Australia;" School of Information Technologies, The University of Sydney, Australia"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""951"",""963"",""Cloud data owners prefer to outsource documents in an encrypted form for the purpose of privacy preserving. Therefore it is essential to develop efficient and reliable ciphertext search techniques. One challenge is that the relationship between documents will be normally concealed in the process of encryption, which will lead to significant search accuracy performance degradation. Also the volume of data in data centers has experienced a dramatic growth. This will make it even more challenging to design ciphertext search schemes that can provide efficient and reliable online information retrieval on large volume of encrypted data. In this paper, a hierarchical clustering method is proposed to support more search semantics and also to meet the demand for fast ciphertext search within a big data environment. The proposed hierarchical approach clusters the documents based on the minimum relevance threshold, and then partitions the resulting clusters into sub-clusters until the constraint on the maximum size of cluster is reached. In the search phase, this approach can reach a linear computational complexity against an exponential size increase of document collection. In order to verify the authenticity of search results, a structure called minimum hash sub-tree is designed in this paper. Experiments have been conducted using the collection set built from the IEEE Xplore. The results show that with a sharp increase of documents in the dataset the search time of the proposed method increases linearly whereas the search time of the traditional method increases exponentially. Furthermore, the proposed method has an advantage over the traditional method in the rank privacy and relevance of retrieved documents."",""1558-2183"","""",""10.1109/TPDS.2015.2425407"",""Strategic Priority Re-search Program of Chinese Academy of Sciences(grant numbers:XDA06040601)"; Xinjiang Uygur Autonomous Region science and technology plan(grant numbers:201230121); Strategic Priority Research Program of Chinese Academy of Sciences(grant numbers:XDA06010701); National High Technology Research and Development Program of China(grant numbers:2013AA01A24);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091954"",""Cloud computing";ciphertext search;ranked search;multi-keyword search;hierarchical clustering;big data;security;Cloud computing;ciphertext search;ranked search;multi-keyword search;hierarchical clustering;"security"",""Servers";Indexes;Privacy;Computer architecture;"Encryption"","""",""119"","""",""41"",""OAPA"",""22 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;
"An Efficient Wait-Free Vector,""S. Feldman"; C. Valera-Leon;" D. Dechev"",""Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL"; Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL;" Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""654"",""667"",""The vector is a fundamental data structure, which provides constant-time access to a dynamically-resizable range of elements. Currently, there exist no wait-free vectors. The only non-blocking version supports only a subset of the sequential vector API and exhibits significant synchronization overhead caused by supporting opposing operations. Since many applications operate in phases of execution, wherein each phase only a subset of operations are used, this overhead is unnecessary for the majority of the application. To address the limitations of the non-blocking version, we present a new design that is wait-free, supports more of the operations provided by the sequential vector, and provides alternative implementations of key operations. These alternatives allow the developer to balance the performance and functionality of the vector as requirements change throughout execution. Compared to the known non-blocking version and the concurrent vector found in Intel’s TBB library, our design outperforms or provides comparable performance in the majority of tested scenarios. Over all tested scenarios, the presented design performs an average of 4.97 times more operations per second than the non-blocking vector and 1.54 more than the TBB vector. In a scenario designed to simulate the filling of a vector, performance improvement increases to 13.38 and 1.16 times. This work presents the first ABA-free non-blocking vector. Unlike the other non-blocking approach, all operations are wait-free and bounds-checked and elements are stored contiguously in memory."",""1558-2183"","""",""10.1109/TPDS.2015.2417887"",""National Science Foundation(grant numbers:CCF-1218100,CCF-1218179)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7073592"",""vector";non-blocking;wait-free;concurrent;resizable;ABA;Vector;non-blocking;wait-free;concurrent;resizable;"ABA"",""Vectors";Arrays;Indexes;Algorithm design and analysis;Instruction sets;Libraries;"Complexity theory"","""",""7"","""",""13"",""IEEE"",""31 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"An Evolutionary Technique for Performance-Energy-Temperature Optimized Scheduling of Parallel Tasks on Multi-Core Processors,""H. F. Sheikh"; I. Ahmad;" D. Fan"",""Department of Computer Science and Engineering, 500 UTA Blvd, Arlington, TX"; Department of Computer Science and Engineering, 500 UTA Blvd, Arlington, TX;" SKL Computer Architecture, Haidian District Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""668"",""681"",""This paper proposes a multi-objective evolutionary algorithm (MOEA)-based task scheduling approach for determining Pareto optimal solutions with simultaneous optimization of performance (P), energy (E ), and temperature (T). Our algorithm includes problem-specific solution encoding, determining the initial population of the solution space, and the genetic operators that collectively work on generating efficient solutions in fast turnaround time. Multiple schedules offer a diverse range of values for makespan, energy consumed, and peak temperature and thus present an efficient way of identifying trade-offs among the desired objectives, for a given application and machine pair. We also present a methodology for selecting one solution from the Pareto front given the user's preference. The proposed algorithm for scheduling tasks to cores achieves three-way optimization with fast turnaround time. The proposed algorithm is advantageous because it reduces both energy and temperature together rather than in isolation. We evaluate the proposed algorithm using implementation and simulation, and compare it with integer linear programming as well as with other scheduling algorithms that are energy- or thermal-aware. The time complexity of the proposed scheme is considerably better than the compared algorithms."",""1558-2183"","""",""10.1109/TPDS.2015.2421352"",""National Natural Science Foundation of China(grant numbers:61173007,61332009)"; National Grand Fundamental Research 973 Program of China(grant numbers:2011CB302501);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7083753"",""Energy-efficient computing";thermal-efficient computing;task allocation;evolutionary algorithms;task graphs;static scheduling;Energy-efficient computing;thermal-efficient computing;task allocation;evolutionary algorithms;task graphs;"static scheduling"",""Sociology";Statistics;Optimization;Resource management;Scheduling;Multicore processing;"Schedules"","""",""83"","""",""43"",""IEEE"",""9 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"An OpenMP Extension that Supports Thread-Level Speculation,""S. Aldea"; A. Estebanez; D. R. Llanos;" A. Gonzalez-Escribano"",""Departamento de Informática, Universidad de Valladolid, Campus Miguel Delibes, Valladolid, Spain"; Departamento de Informática, Universidad de Valladolid, Campus Miguel Delibes, Valladolid, Spain; Departamento de Informática, Universidad de Valladolid, Campus Miguel Delibes, Valladolid, Spain;" Departamento de Informática, Universidad de Valladolid, Campus Miguel Delibes, Valladolid, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""78"",""91"",""OpenMP directives are the de-facto standard for shared-memory parallel programming. However, OpenMP does not guarantee the correctness of the parallel execution of a given loop if runtime data dependences arise. Consequently, many highly-parallel regions cannot be safely parallelized with OpenMP due to the possibility of a dependence violation. In this paper, we propose to augment OpenMP capabilities, by adding thread-level speculation (TLS) support. Our contribution is threefold. First, we have defined a new speculative clause for variables inside parallel loops. This clause ensures that all accesses to these variables will be carried out according to sequential semantics. Second, we have created a new, software-based TLS runtime library to ensure correctness in the parallel execution of OpenMP loops that include speculative variables. Third, we have developed a new GCC plugin, which seamlessly translates our OpenMP speculative clause into calls to our TLS runtime engine. The result is the ATLaS C Compiler framework, which takes advantage of TLS techniques to expand OpenMP functionalities, and guarantees the sequential semantics of any parallelized loop."",""1558-2183"","""",""10.1109/TPDS.2015.2393870"",""Castilla-Leon Regional Government"; Ministerio de Industria; MICINN; European Union FEDER(grant numbers:TIN2011-25639,TIN2010-12011-E,TIN2011-15734-E);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014262"",""Parallelism and concurrency";code generation;thread-level speculation;optimistic parallelization;Parallelism and concurrency;code generation;thread-level speculation;"optimistic parallelization"",""Runtime";Runtime library;Proposals;Data structures;Libraries;Semantics;"Standards"","""",""18"","""",""46"",""IEEE"",""19 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"Analysis of CSMA/CA Mechanism of IEEE 802.15.6 under Non-Saturation Regime,""S. Rashwand"; J. Mišić;" V. B. Mišić"",""Department of Computer Science, Ryerson University, 350 Victoria Street, Toronto, Canada"; Department of Computer Science, Ryerson University, 350 Victoria Street, Toronto, Canada;" Department of Computer Science, Ryerson University, 350 Victoria Street, Toronto, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1279"",""1288"",""We have developed an analytical model for a non-saturated IEEE 802.15.6 wireless body area network (WBAN) operating under an error-prone channel. The most suitable vehicle for improving network performance was found to be the choice of access phase lengths based on traffic loads for different user priorities (UPs). It was also found that the deployment of exclusive access phase (EAP) is not necessary in a typical WBAN";" in fact, short exclusive and random access phases (EAP and RAP, respectively) lead to inefficient use of available bandwidth. We have also found that four user priorities (out of the eight available) typically suffice to achieve even the most stringent requirements for WBAN performance."",""1558-2183"","""",""10.1109/TPDS.2015.2447528"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7128741"",""wireless body area network (WBANs)";IEEE 802.15.6;probabilistic analysis;access priorities;Wireless body area networks (WBANs);IEEE 802.15.6;probabilistic analysis;"access priorities"",""Markov processes";Multiaccess communication;IEEE 802.15 Standards;Radiation detectors;Analytical models;"Probability"","""",""40"","""",""28"",""IEEE"",""19 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Analysis of Parallel Computing Strategies to Accelerate Ultrasound Imaging Processes,""D. Romero-Laorden"; J. Villazón-Terrazas; O. Martínez-Graullera; A. Ibáñez; M. Parrilla;" M. S. Peñas"",""Instituto de Tecnologías Físicas y de la Información, Spanish National Research Council, C/Serrano 144, Madrid, Spain"; Instituto de Tecnologías Físicas y de la Información, Spanish National Research Council, C/Serrano 144, Madrid, Spain; Instituto de Tecnologías Físicas y de la Información, Spanish National Research Council, C/Serrano 144, Madrid, Spain; Instituto de Tecnologías Físicas y de la Información, Spanish National Research Council, C/Serrano 144, Madrid, Spain; Instituto de Tecnologías Físicas y de la Información, Spanish National Research Council, C/Serrano 144, Madrid, Spain;" Dpto. Arquitectura de Computadores y Automática, Facultad de Informática, Universidad Complutense de Madrid, Madrid, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3429"",""3440"",""This work analyses the use of parallel processing techniques in synthetic aperture ultrasonic imaging applications. In particular, the Total Focussing Method, which is a O(N2 x P) problem, is studied. This work presents different parallelization strategies for multicore CPU and GPU architectures. The parallelization processes on both platforms are discussed and optimized in order to achieve real-time performance."",""1558-2183"","""",""10.1109/TPDS.2016.2544312"",""Spanish Government(grant numbers:DPI2010-19376,FIS2013-46829R)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7437495"",""Ultrasound imaging";GPGPU;multicore;signal processing;parallel computing;"CUDA"",""Array signal processing";Real-time systems;Graphics processing units;Ultrasonic imaging;Parallel processing;Multicore processing;"Transducers"","""",""13"","""",""34"",""IEEE"",""21 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"ASP: Abstraction Subspace Partitioning for Detection of Atomicity Violations with an Empirical Study,""S. Wu"; C. Yang; C. Jia;" W. K. Chan"",""Department of Computer Science, City University of Hong Kong, Tat Chee Avenue, Hong Kong"; Department of Computer Science, City University of Hong Kong, Tat Chee Avenue, Hong Kong; Department of Computer Science, City University of Hong Kong, Tat Chee Avenue, Hong Kong;" Department of Computer Science, City University of Hong Kong, Tat Chee Avenue, Hong Kong"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""724"",""734"",""Dynamic concurrency bug detectors predict and then examine suspicious instances of atomicity violations from executions of multithreaded programs. Only few predicted instances are real bugs. Prioritizing such instances can make the examinations cost-effective, but is there any design factor exhibiting significant influence? This work presents the first controlled experiment that studies two design factors, abstraction level and subspace, in partitioning such instances through 35 resultant partition-based techniques on 10 benchmarks with known vulnerability-related bugs. The empirical analysis reveals significant findings. First, partition-based prioritization can significantly improve the fault detection rate. Second, coarse-grained techniques are more effective than fine-grained ones, and using some one-dimensional subspaces is more effective than using other dimensional subspaces. Third, eight previously unknown techniques can be more effective than the technique modeled after a state-of-the-art dynamic detector."",""1558-2183"","""",""10.1109/TPDS.2015.2412544"",""Council of Hong Kong(grant numbers:125113,11201114)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7059243"",""Atomicity violations";concurrency;testing and debugging;abstraction;partitioning;multithreaded programs;Atomicity violations;concurrency;testing;debugging;abstraction;partitioning;multithreaded programs;vulnerability;"bug localization"",""Benchmark testing";Detectors;Computer bugs;Context;Instruction sets;"Concurrent computing"","""",""8"","""",""31"",""IEEE"",""12 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;
"Assessing the Suitability of King Topologies for Interconnection Networks,""E. Stafford"; J. L. Bosque; C. Martínez; F. Vallejo; R. Beivide; C. Camarero;" E. Castillo"",""Ing. Informática y Electrónica, Universidad de Cantabria, Santander, Cantabria, Spain"; Ing. Informática y Electrónica, Universidad de Cantabria, Santander, Cantabria, Spain; Ing. Informática y Electrónica, Universidad de Cantabria, Santander, Cantabria, Spain; Ing. Informática y Electrónica, Universidad de Cantabria, Santander, Cantabria, Spain; Ing. Informática y Electrónica, Universidad de Cantabria, Santander, Cantabria, Spain; Ing. Informática y Electrónica, Universidad de Cantabria, Santander, Cantabria, Spain;" Ing. Informática y Electrónica, Universidad de Cantabria, Santander, Cantabria, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""682"",""694"",""In the late years many different interconnection networks have been used with two main tendencies. One is characterized by the use of high-degree routers with long wires while the other uses routers of much smaller degree. The latter rely on two-dimensional mesh and torus topologies with shorter local links. This paper focuses on doubling the degree of common 2D meshes and tori while still preserving an attractive layout for VLSI design. By adding a set of diagonal links in one direction, diagonal networks are obtained. By adding a second set of links, networks of degree eight are built, named king networks. This research presents a comprehensive study of these networks which includes a topological analysis, the proposal of appropriate routing procedures and an empirical evaluation. King networks exhibit a number of attractive characteristics which translate to reduced execution times of parallel applications. For example, the execution times NPB suite are reduced up to a 30 percent. In addition, this work reveals other properties of king networks such as perfect partitioning that deserves further attention for its convenient exploitation in forthcoming high-performance parallel systems."",""1558-2183"","""",""10.1109/TPDS.2015.2409865"",""Spanish Ministry of Education(grant numbers:AP2010-4900,FPU12/02254)"; Spanish Science and Technology Commission(grant numbers:TIN2010-21291-C02-02); HiPEAC European Network of Excellence;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7054511"",""Topology, interconnections (subsystems), data communications, hardware, on-chip interconnection networks, parallel architectures, processor architectures, computer systems organization, interprocessor communications, general, communication/networking and information technology, computer systems organization topology, on-chip interconnection networks, interprocessor communications"",""Routing";Topology;Network topology;System recovery;Bandwidth;Multiprocessor interconnection;"System-on-chip"","""",""1"","""",""40"",""IEEE"",""4 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Authenticated Key Exchange Protocols for Parallel Network File Systems,""H. W. Lim";" G. Yang"",""School of Computing, National University of Singapore, Singapore";" School of Computer Science and Software Engineering, University of Wollongong, Australia"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""92"",""105"",""We study the problem of key establishment for secure many-to-many communications. The problem is inspired by the proliferation of large-scale distributed file systems supporting parallel access to multiple storage devices. Our work focuses on the current Internet standard for such file systems, i.e., parallel Network File System (pNFS), which makes use of Kerberos to establish parallel session keys between clients and storage devices. Our review of the existing Kerberos-based protocol shows that it has a number of limitations: (i) a metadata server facilitating key exchange between the clients and the storage devices has heavy workload that restricts the scalability of the protocol"; (ii) the protocol does not provide forward secrecy;" (iii) the metadata server generates itself all the session keys that are used between the clients and storage devices, and this inherently leads to key escrow. In this paper, we propose a variety of authenticated key exchange protocols that are designed to address the above issues. We show that our protocols are capable of reducing up to approximately 54 percent of the workload of the metadata server and concurrently supporting forward secrecy and escrow-freeness. All this requires only a small fraction of increased computation overhead at the client."",""1558-2183"","""",""10.1109/TPDS.2015.2388447"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004049"",""Parallel sessions";authenticated key exchange;network file systems;forward secrecy;key escrow;Parallel sessions;authenticated key exchange;network file systems;forward secrecy;"key escrow"",""Servers";Protocols;Performance evaluation;Authentication;Silicon;"Layout"","""",""3"",""1"",""55"",""IEEE"",""7 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Automated Data Partitioning for Highly Scalable and Strongly Consistent Transactions,""A. Turcu"; R. Palmieri; B. Ravindran;" S. Hirve"",""Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA"; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA;" Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""106"",""118"",""Modern transactional processing systems need to be fast and scalable, but this means many such systems settled for weak consistency models. It is however possible to achieve all of strong consistency, high scalability and high performance, by using fine-grained partitions and light-weight concurrency control that avoids superfluous synchronization and other overheads such as lock management. Independent transactions are one such mechanism, that rely on good partitions and appropriately defined transactions. On the downside, it is not usually straightforward to determine optimal partitioning schemes, especially when dealing with non-trivial amounts of data. Our work attempts to solve this problem by automating the partitioning process, choosing the correct transactional primitive, and routing transactions appropriately."",""1558-2183"","""",""10.1109/TPDS.2015.2388448"",""Division of Computer and Network Systems(grant numbers:1217385)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004087"",""Distributed databases";code generation;concurrent programming;Distributed databases;code generation;"concurrent programming"",""Routing";Distributed databases;Data models;Scalability;Programming;Computer languages;"Synchronization"","""",""18"","""",""35"",""IEEE"",""7 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Autonomic Performance and Power Control for Co-Located Web Applications in Virtualized Datacenters,""P. Lama"; Y. Guo; C. Jiang;" X. Zhou"",""Department of Computer Science, University of Texas, San Antonio, TX"; Department of Computer Science, University of Colorado, Colorado Springs, CO; Department of Computer Science & Technology, Tongji University, Shanghai, China;" Department of Computer Science, University of Colorado, Colorado Springs, CO"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1289"",""1302"",""In a datacenter, complex and time-varying interactions between various tiers and services of web applications, and the contention of shared resources among co-located virtual machines have significant impact on the user perceived performance and power consumption of the underlying system. We propose and develop APPLEware, an autonomic middleware for joint performance and power control of co-located web applications in virtualized datacenters. It features a distributed control structure that provides predictable performance and energy efficiency for large complex systems. It applies machine learning based self-adaptive modeling to capture the complex and time-varying relationship between the application performance and allocation of resources to various application components, in the face of highly dynamic and bursty workloads. The distributed controllers coordinate with each other and allocate resources to meet the service level agreements of applications in an agile and energy-efficient manner. Experimental results based on a testbed implementation with benchmark applications and large scale simulations demonstrate APPLEware's effectiveness, energy efficiency and scalability."",""1558-2183"","""",""10.1109/TPDS.2015.2453971"",""US National Science Foundation (NSF)(grant numbers:CNS-0844983,CNS-1217979)"; NSF(grant numbers:61328203);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152934"",""Joint performance and power control";autonomic systems;virtualized servers;distributed fuzzy MIMO control;co-located multi-service applications;Joint performance and power control;autonomic systems;virtualized servers;distributed fuzzy MIMO control;"co-located multi-service applications"",""Servers";Resource management;Scalability;Computational modeling;Interference;Power control;"Computer architecture"","""",""12"","""",""42"",""IEEE"",""8 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"Best-Harmonically-Fit Periodic Task Assignment Algorithm on Multiple Periodic Resources,""C. Guo"; X. Hua; H. Wu; D. Lautner;" S. Ren"",""Computer Science Department, Illinois Institute of Technology, Chicago, IL"; Computer Science Department, Illinois Institute of Technology, Chicago, IL; Computer Science Department, Illinois Institute of Technology, Chicago, IL; Computer Science Department, Illinois Institute of Technology, Chicago, IL;" Computer Science Department, Illinois Institute of Technology, Chicago, IL"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1303"",""1315"",""The periodic task set assignment problem in the context of multiple processors has been studied for decades. Different heuristic approaches have been proposed, such as the Best-Fit (BF), the First-Fit (FF), and the Worst-Fit (WF) task assignment algorithms. However, when processors are not dedicated but only periodically available to the task set, whether existing approaches still provide good performance or if there is a better task assignment approach in the new context are research problems which, to our best knowledge, have not been studied by the real-time research community. In this paper, we present the Best-Harmonically-Fit (BHF) task assignment algorithm to assign periodic tasks on multiple periodic resources. By periodic resource we mean that for every fixed time interval, i.e., the period, the resource always provides the same amount of processing capacity to a given task set. Our formal analysis indicates that if a harmonic task set is also harmonic with a resource's period, the resource capacity can be fully utilized by the task set. Based on this analysis, we present the Best-Harmonically-Fit task assignment algorithm. The experimental results show that, on average, the BHF algorithm results in  $53.26$ , $42.54$ , and  $27.79$  percent higher resource utilization rate than the Best-Fit Decreasing (BFD), the First-Fit Decreasing (FFD), and the Worst-Fit Decreasing (WFD) task assignment algorithms, respectively";" but comparing to the optimal resource utilization rate found by exhaustive search, it is about  $11.63$  percent lower."",""1558-2183"","""",""10.1109/TPDS.2015.2437379"",""US National Science Foundation(grant numbers:CAREER 0746643,CNS 1018731,CNS 1035894)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7112525"",""Real-time systems";task assignment;periodic resource;best-harmonically-fit;Real-time systems;task assignment;periodic resource;"best-harmonically-fit"",""Harmonic analysis";Real-time systems;Program processors;Resource management;Scheduling algorithms;"Context"","""",""6"","""",""32"",""IEEE"",""25 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"BLISS: Balancing Performance, Fairness and Complexity in Memory Access Scheduling,""L. Subramanian"; D. Lee; V. Seshadri; H. Rastogi;" O. Mutlu"",""Intel Labs, Carnegie Mellon University"; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University;" Carnegie Mellon University"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""3071"",""3087"",""In a multicore system, applications running on different cores interfere at main memory. This inter-application interference degrades overall system performance and unfairly slows down applications. Prior works have developed application-aware memory request schedulers to tackle this problem. State-of-the-art application-aware memory request schedulers prioritize memory requests of applications that are vulnerable to interference, by ranking individual applications based on their memory access characteristics and enforcing a total rank order. In this paper, we observe that state-of-the-art application-aware memory schedulers have two major shortcomings. First, such schedulers trade off hardware complexity in order to achieve high performance or fairness, since ranking applications individually with a total order based on memory access characteristics leads to high hardware cost and complexity. Such complexity could prevent the scheduler from meeting the stringent timing requirements of state-of-the-art DDR protocols. Second, ranking can unfairly slow down applications that are at the bottom of the ranking stack, thereby sometimes leading to high slowdowns and low overall system performance. To overcome these shortcomings, we propose the Blacklisting Memory Scheduler (BLISS), which achieves high system performance and fairness while incurring low hardware cost and complexity. BLISS design is based on two new observations. First, we find that, to mitigate interference, it is sufficient to separate applications into only two groups, one containing applications that are vulnerable to interference and another containing applications that cause interference, instead of ranking individual applications with a total order. Vulnerable-to-interference group is prioritized over the interference-causing group. Second, we show that this grouping can be efficiently performed by simply counting the number of consecutive requests served from each application. We evaluate BLISS across a wide variety of workloads and system configurations and compare its performance and hardware complexity (via RTL implementations), with five state-of-the-art memory schedulers. Our evaluations show that BLISS achieves 5 percent better system performance and 25 percent better fairness than the best-performing previous memory scheduler while greatly reducing critical path latency and hardware area cost of the memory scheduler (by 79 and 43 percent, respectively), thereby achieving a good trade-off between performance, fairness and hardware complexity."",""1558-2183"","""",""10.1109/TPDS.2016.2526003"",""Google"; IBM; Intel; Microsoft; Nvidia; Qualcomm; Samsung; VMware; US National Science Foundation(grant numbers:0953246,1212962,1320531,1409723,ISTC-CC); SRC; John and Claire Bertucci fellowship;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399423"","""",""Interference";Complexity theory;Hardware;System performance;Multicore processing;Random access memory;"Scheduling"","""",""53"","""",""58"",""IEEE"",""4 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;
"Boosting Parallel File System Performance via Heterogeneity-Aware Selective Data Layout,""S. He"; Y. Wang;" X. -H. Sun"",""State Key Laboratory of Software Engineering, Computer School, Wuhan University, Luojiashan, Hubei, Wuhan, China"; Shenzhen Institute of Advanced Technology, Shenzhen University Town, Shenzhen, China;" Department of Computer Science, Illinois Institute of Technology, Chicago, IL"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2492"",""2505"",""Hybrid parallel file systems (PFS) that combine HDD servers with SSD servers provide a promising solution for data intensive applications. The efficiency of a hybrid PFS relies on the data layout schemes. However, most current layout strategies are designed for homogeneous servers, which neither address the heterogeneity of servers nor the varying access patterns of applications. In this paper, we propose HAS, a novel heterogeneity-aware selective data layout scheme for hybrid PFSs. HAS alleviates inter-server load imbalance through skewing data distribution on heterogeneous servers based on their storage performance. Furthermore, to obtain the optimal performance for a specific access pattern, HAS selects one static data layout policy with lowest access cost from three typical layout candidates as the final file data layout method. To adapt to the mixed access patterns within an application, HAS uses a dynamic data layout scheme, which stores file with multiple copies, each using a different data layout policy, and then selects the copy with the lowest access cost to serve file requests. We have implemented HAS within MPICH2 and OrangeFS. Experimental results show that HAS can significantly increase the I/O throughput of hybrid PFSs, compared to existing data layout optimization methods."",""1558-2183"","""",""10.1109/TPDS.2015.2504969"",""China National Basic Research Program(grant numbers:2015CB352400)"; NSFC(grant numbers:U1401258,61572377,61572370,61373040); PhD Programs Foundation of Ministry of Education of China(grant numbers:20120141110073); Natural Science Foundation of Hubei Province(grant numbers:2014CFB239); HPCL(grant numbers:201512-02); SKLSE(grant numbers:2015-A-06); US National Science Foundation(grant numbers:CNS-1162540);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7345596"",""Parallel I/O system";parallel file system;data layout;"solid state drive"",""Layout";Servers;Throughput;Distributed databases;System performance;Data models;"Bandwidth"","""",""12"","""",""38"",""IEEE"",""3 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Building Semi-Elastic Virtual Clusters for Cost-Effective HPC Cloud Resource Provisioning,""S. Niu"; J. Zhai; X. Ma; X. Tang; W. Chen;" W. Zheng"",""Department of Computer Science and Technology, Tsinghua University, Beijing, China"; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Qatar Computing Research Institute, Doha, Qatar; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China;" Department of Computer Science and Technology, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""1915"",""1928"",""Recent studies have found cloud environments increasingly appealing for executing HPC applications, including tightly coupled parallel simulations. At the same time, while public clouds offer elastic, on-demand resource provisioning and pay-as-you-go pricing, individual users setting up their on-demand virtual clusters may not be able to take full advantage of common cost-saving opportunities, such as reserved instances. In this paper, we propose a Semi-Elastic Cluster (SEC) computing model for organizations to reserve and dynamically resize a virtual cloud-based cluster. We present a set of integrated batch scheduling plus resource scaling strategies uniquely enabled by SEC, as well as an online reserved instance provisioning algorithm based on job history. Our trace-driven simulation results show that such a model has a 61.0 percent cost saving than individual users acquiring and managing cloud resources without causing longer average job wait time. Moreover, to exploit the advantages of different public clouds, we also extend SEC to a multi-cloud environment, where SEC can get a lower cost than on any single cloud. We design and implement a prototype system of the SEC model and evaluate it in terms of management overhead and average job wait time. Experimental results show that the management overhead is negligible with respect to the job wait time."",""1558-2183"","""",""10.1109/TPDS.2015.2476459"",""Chinese National High-Tech Research and Development Plan(grant numbers:2012AA01A302)"; NSFC(grant numbers:61232008,61472201); Research Fund for Taishan Scholar Project of Shandong Province; US National Science Foundation(grant numbers:0915861,0937908,0958311,1318564); ORNL; NCSU; Tsinghua University;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7239625"",""Cloud Computing";Semi-Elastic Cluster;Resource Provisioning;Job Scheduling;Trace-Driven Simulation;Cloud computing;job scheduling;resource provisioning;semi-elastic cluster;"trace-driven simulation"",""Cloud computing";Pricing;Scheduling;Computational modeling;Organizations;Heuristic algorithms;"Resource management"","""",""22"",""1"",""38"",""IEEE"",""3 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;
"Burstiness-Aware Resource Reservation for Server Consolidation in Computing Clouds,""S. Zhang"; Z. Qian; Z. Luo; J. Wu;" S. Lu"",""State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China"; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; David Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; Department of Computer and Information Sciences, Temple University, Philadelphia, PA;" State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""964"",""977"",""In computing clouds, burstiness of a virtual machine (VM) workload widely exists in real applications, where spikes usually occur aperiodically with low frequency and short duration. This could be effectively handled through dynamically scaling up/down in a virtualization-based computing cloud";" however, to minimize energy consumption, VMs are often highly consolidated with the minimum number of physical machines (PMs) used. In this case, to meet the dynamic runtime resource demands of VMs in a PM, some VMs have to be migrated to some other PMs, which may cause potential performance degradation. In this paper, we investigate the burstiness-aware server consolidation problem from the perspective of resource reservation, i.e., reserving a certain amount of extra resources on each PM to avoid live migrations, and propose a novel server consolidation algorithm, QUEUE. We first model the resource requirement pattern of each VM as a two-state Markov chain to capture burstiness, then we design a resource reservation strategy for each PM based on the stationary distribution of a Markov chain. Finally, we present QUEUE, a complete server consolidation algorithm with a reasonable time complexity. We also show how to cope with heterogenous spikes and provide remarks on several extensions. Simulation and testbed results show that, QUEUE improves the consolidation ratio by up to 45 percent with large spike size and around 30 percent with normal spike size compared with the strategy that provisions for peak workload, and achieves a better balance between performance and energy consumption in comparison with other commonly-used consolidation algorithms."",""1558-2183"","""",""10.1109/TPDS.2015.2425403"",""NSFC(grant numbers:61472181,61202113,61321491,91218302)"; IRSES MobileCloud Project(grant numbers:612212); Key Project of Jiangsu Research Program(grant numbers:BE2013116); China Postdoctor Science Fund(grant numbers:2015M570434); Collaborative Innovation Center of Novel Software Technology and Industrialization;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091926"",""Bursty workload";Markov chain;resource reservation;server consolidation;stationary distribution;Bursty workload;Markov chain;resource reservation;server consolidation;"stationary distribution"",""Markov processes";Cloud computing;Servers;Switches;Capacity planning;Energy consumption;"Computational modeling"","""",""47"","""",""37"",""IEEE"",""22 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;
"Cache Line Aware Algorithm Design for Cache-Coherent Architectures,""S. Ramos";" T. Hoefler"",""Scalable Parallel Computing Lab, Computer Science Department, ETH Zürich, Switzerland";" Scalable Parallel Computing Lab, Computer Science Department, ETH Zürich, Switzerland"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2824"",""2837"",""The increase in the number of cores per processor and the complexity of memory hierarchies make cache coherence key for programmability of current shared memory systems. However, ignoring its detailed architectural characteristics can harm performance significantly. In order to assist performance-centric programming, we propose a methodology to allow semi-automatic performance tuning with the systematic translation from an algorithm to an analytic performance model for cache line transfers. For this, we design a simple interface for cache line aware optimization, a translation methodology, and a full performance model that exposes the block-based design of caches to middleware designers. We investigate two different architectures to show the applicability of our techniques and methods: the many-core accelerator Intel Xeon Phi and a multi-core processor with a NUMA configuration (Intel Sandy Bridge). We use mathematical optimization techniques to tune synchronization algorithms to the microarchitectures, identifying three techniques to design and optimize data transfers in our model: single-use, single-step broadcast, and private cache lines."",""1558-2183"","""",""10.1109/TPDS.2016.2516540"",""Ministry of Economy and Competitiveness of Spain"; FEDER(grant numbers:TIN2013-42148-P);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7378320"",""Cache coherence";shared memory;communication algorithms;performance modeling;Xeon Phi;"Sandy Bridge"",""Coherence";Algorithm design and analysis;Sockets;Bridges;Protocols;Mathematical model;"Analytical models"","""",""9"","""",""36"",""IEEE"",""11 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Carbon-Aware Online Control of Geo-Distributed Cloud Services,""Z. Zhou"; F. Liu; R. Zou; J. Liu; H. Xu;" H. Jin"",""Services Computing Technology and System Lab, Cluster and Grid Computing Lab in the School of Computer Science and Technology, Huazhong University of Science and Technology, 1037 Luoyu Road, Wuhan, China"; Services Computing Technology and System Lab, Cluster and Grid Computing Lab in the School of Computer Science and Technology, Huazhong University of Science and Technology, 1037 Luoyu Road, Wuhan, China; Services Computing Technology and System Lab, Cluster and Grid Computing Lab in the School of Computer Science and Technology, Huazhong University of Science and Technology, 1037 Luoyu Road, Wuhan, China; School of Computing Science, Simon Fraser University, Burnaby, BC, Canada; Department of Computer Science, City University of Hong Kong, 83 Tat Chee Avenue, Kowloon, Hong Kong, China;" Services Computing Technology and System Lab, Cluster and Grid Computing Lab in the School of Computer Science and Technology, Huazhong University of Science and Technology, 1037 Luoyu Road, Wuhan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2506"",""2519"",""Recently, datacenter carbon emission has become an emerging concern for the cloud service providers. Previous works are limited on cutting down the power consumption of datacenters to defuse such a concern. In this paper, we show how the spatial and temporal variabilities of the electricity carbon footprint can be fully exploited to further green the cloud running on top of geographically distributed datacenters. Specifically, we first verify that electricity cost minimization conflicts with carbon emission minimization, based on an empirical study of several representative geo-distributed cloud services. We then jointly consider the electricity cost, service level agreement (SLA) requirement, and emission reduction budget. To navigate such a three-way tradeoff, we take advantage of Lyapunov optimization techniques to design and analyze a carbon-aware control framework, which makes online decisions on geographical load balancing, capacity right-sizing, and server speed scaling. Results from rigorous mathematical analysis and real-world trace-driven evaluation demonstrate the effectiveness of our framework in reducing both electricity cost and carbon emission."",""1558-2183"","""",""10.1109/TPDS.2015.2504978"",""National Natural Science Foundation of China(grant numbers:61520106005)"; National 973 Basic Research Program(grant numbers:2014CB347800); HKRGC-ECS(grant numbers:21201714); CityU HK(grant numbers:7200366);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7345588"",""Carbon reduction";load balancing;capacity right-sizing;geo-distributed datacenters;three-way tradeoff;"online control"",""Carbon dioxide";Servers;Google;Facebook;Correlation;Carbon tax;"Minimization"","""",""57"","""",""47"",""IEEE"",""3 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;
"Circuit Ciphertext-Policy Attribute-Based Hybrid Encryption with Verifiable Delegation in Cloud Computing,""J. Xu"; Q. Wen; W. Li;" Z. Jin"",""State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China"; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China;" State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""119"",""129"",""In the cloud, for achieving access control and keeping data confidential, the data owners could adopt attribute-based encryption to encrypt the stored data. Users with limited computing power are however more likely to delegate the mask of the decryption task to the cloud servers to reduce the computing cost. As a result, attribute-based encryption with delegation emerges. Still, there are caveats and questions remaining in the previous relevant works. For instance, during the delegation, the cloud servers could tamper or replace the delegated ciphertext and respond a forged computing result with malicious intent. They may also cheat the eligible users by responding them that they are ineligible for the purpose of cost saving. Furthermore, during the encryption, the access policies may not be flexible enough as well. Since policy for general circuits enables to achieve the strongest form of access control, a construction for realizing circuit ciphertext-policy attribute-based hybrid encryption with verifiable delegation has been considered in our work. In such a system, combined with verifiable computation and encrypt-then-mac mechanism, the data confidentiality, the fine-grained access control and the correctness of the delegated computing results are well guaranteed at the same time. Besides, our scheme achieves security against chosen-plaintext attacks under the k-multilinear Decisional Diffie-Hellman assumption. Moreover, an extensive simulation campaign confirms the feasibility and efficiency of the proposed solution."",""1558-2183"","""",""10.1109/TPDS.2015.2392752"",""NSFC(grant numbers:61300181,61272057,61202434,61170270,61100203,61121061)"; Fundamental Research Funds for the Central Universities(grant numbers:2012RC0612,2011YB01);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7010954"",""Ciphertext-policy attribute-based encryption";Circuits;Verifiable delegation;Multilinear map;Hybrid encryption;Ciphertext-policy attribute-based encryption;circuits;verifiable delegation;multilinear map;"hybrid encryption"",""Encryption";Servers;Logic gates;Access control;"Wires"","""",""43"","""",""24"",""IEEE"",""15 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Cloud Customer's Historical Record Based Resource Pricing,""M. Aazam"; E. -N. Huh; M. St-Hilaire; C. -H. Lung;" I. Lambadaris"",""Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada"; Computer Engineering Department, Kyung Hee University, Korea; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada;" Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""1929"",""1940"",""Media content in its digital form has been rapidly scaling up, resulting in popularity gain of cloud computing. Cloud computing makes it easy to manage the vastly increasing digital content. Moreover, additional features like, omnipresent access, further service creation, discovery of services, and resource management also play an important role in this regard. The forthcoming era is interoperability of multiple clouds, known as cloud federation or inter-cloud computing. With cloud federation, services would be provided through two or more clouds. Once matured and standardized, inter-cloud computing is supposed to provide services which would be more scalable, better managed, and efficient. Such tasks are provided through a middleware entity called cloud broker. A broker is responsible for reserving resources, managing them, discovering services according to customer's demands, Service Level Agreement (SLA) negotiation, and match-making between the involved service provider and the customer. So far existing studies discuss brokerage in a narrow focused way. In the research outcome presented in this paper, we provide a holistic brokerage model to manage on-demand and advance service reservation, pricing, and reimbursement. A unique feature of this study is that we have considered dynamic management of customer's characteristics and historical record in evaluating the economics related factors. Additionally, a mechanism of incentive and penalties is provided, which helps in trust build-up for the customers and service providers, prevention of resource underutilization, and profit gain for the involved entities. For practical implications, the framework is modeled on Amazon Elastic Compute Cloud (EC2) On-Demand and Reserved Instances service pricing. For certain features required in the model, data was gathered from Google Cluster trace."",""1558-2183"","""",""10.1109/TPDS.2015.2473850"",""Basic Science Research Program"; National Research Foundation of Korea; Ministry of Education(grant numbers:NRF-2013R1A1A2013620); Institute for Information & communications Technology Promotion (IITP); Korea government(grant numbers:B0101-15-0535); Development of Modularized In-Memory Virtual Desktop System Technology;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7226829"",""cloud broker";resource management;pricing;Inter-cloud computing;cloud federation;Cloud broker;resource management;pricing;inter-cloud computing;"cloud federation"",""Pricing";Resource management;Mathematical model;Cloud computing;Quality of service;Economics;"Electronic mail"","""",""25"","""",""42"",""IEEE"",""27 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;
"Cloud Performance Modeling with Benchmark Evaluation of Elastic Scaling Strategies,""K. Hwang"; X. Bai; Y. Shi; M. Li; W. -G. Chen;" Y. Wu"",""Departments of Electrical Engineering and Computer Science, University of Southern California, Los Angeles, CA"; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Electrical Engineering, University of Southern California, Los Angeles, CA; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China;" Department of Computer Science and Technology, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""130"",""143"",""In this paper, we present generic cloud performance models for evaluating Iaas, PaaS, SaaS, and mashup or hybrid clouds. We test clouds with real-life benchmark programs and propose some new performance metrics. Our benchmark experiments are conducted mainly on IaaS cloud platforms over scale-out and scale-up workloads. Cloud benchmarking results are analyzed with the efficiency, elasticity, QoS, productivity, and scalability of cloud performance. Five cloud benchmarks were tested on Amazon IaaS EC2 cloud: namely YCSB, CloudSuite, HiBench, BenchClouds, and TPC-W. To satisfy production services, the choice of scale-up or scale-out solutions should be made primarily by the workload patterns and resources utilization rates required. Scaling-out machine instances have much lower overhead than those experienced in scale-up experiments. However, scaling up is found more cost-effective in sustaining heavier workload. The cloud productivity is greatly attributed to system elasticity, efficiency, QoS and scalability. We find that auto-scaling is easy to implement but tends to over provision the resources. Lower resource utilization rate may result from auto-scaling, compared with using scale-out or scale-up strategies. We also demonstrate that the proposed cloud performance models are applicable to evaluate PaaS, SaaS and hybrid clouds as well."",""1558-2183"","""",""10.1109/TPDS.2015.2398438"",""National Basic Research (973) Program of China(grant numbers:2011CB302505)"; High-Tech Research and Development (863) Programs of China(grant numbers:2012AA012600); National Science Foundation of China(grant numbers:61472196,61433008,61073003); University of Southern California; EMC Co.; Intellectual Ventures Inc.;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7027861"",""Cloud computing";performance evaluation;cloud benchmarks;"and resources scaling"",""Productivity";Benchmark testing;Measurement;Quality of service;Scalability;Computational modeling;"Availability"","""",""83"",""2"",""37"",""IEEE"",""30 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;
"CloudArmor: Supporting Reputation-Based Trust Management for Cloud Services,""T. H. Noor"; Q. Z. Sheng; L. Yao; S. Dustdar;" A. H. H. Ngu"",""College of Computer Science and Engineering, Taibah University, Yanbu, Medinah, Saudi Arabia"; School of Computer Science, The University of Adelaide, Adelaide, SA, Australia; School of Computer Science, The University of Adelaide, Adelaide, SA, Australia; Distributed Systems Group, Vienna University of Technology, Austria;" Department of Computer Science, Texas State University, San Marcos, TX"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""367"",""380"",""Trust management is one of the most challenging issues for the adoption and growth of cloud computing. The highly dynamic, distributed, and non-transparent nature of cloud services introduces several challenging issues such as privacy, security, and availability. Preserving consumers' privacy is not an easy task due to the sensitive information involved in the interactions between consumers and the trust management service. Protecting cloud services against their malicious users (e.g., such users might give misleading feedback to disadvantage a particular cloud service) is a difficult problem. Guaranteeing the availability of the trust management service is another significant challenge because of the dynamic nature of cloud environments. In this article, we describe the design and implementation of CloudArmor, a reputation-based trust management framework that provides a set of functionalities to deliver trust as a service (TaaS), which includes i) a novel protocol to prove the credibility of trust feedbacks and preserve users' privacy, ii) an adaptive and robust credibility model for measuring the credibility of trust feedbacks to protect cloud services from malicious users and to compare the trustworthiness of cloud services, and iii) an availability model to manage the availability of the decentralized implementation of the trust management service. The feasibility and benefits of our approach have been validated by a prototype and experimental studies using a collection of real-world trust feedbacks on cloud services."",""1558-2183"","""",""10.1109/TPDS.2015.2408613"",""King Abdullah's Postgraduate Scholarships"; Ministry of Higher Education: Kingdom of Saudi Arabia; Australian Research Council (ARC) Discovery(grant numbers:DP140100104,FT140101247);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7054490"",""Cloud computing";trust management;reputation;credibility;credentials;security;privacy;availability;Cloud computing;trust management;reputation;credibility;credentials;security;privacy;"availability"",""Privacy";Availability;Cloud computing;Adaptation models;Measurement;Protocols;"Educational institutions"","""",""122"","""",""35"",""IEEE"",""4 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;
"Clustering-Based Task Scheduling in a Large Number of Heterogeneous Processors,""H. Kanemitsu"; M. Hanada;" H. Nakazato"",""Global Education Center, Waseda University, 1-6-1, Nishiwaseda, Shinjuku, Tokyo, Japan"; Department of Information Systems, Tokyo University of Information Sciences, 4-1, Onaridai, Wakaba-ku, Chiba, Japan;" Department of Communications and Computer Engineering, Waseda University, 3-14-9 Ohkubo, Shinjuku-ku, Japan"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3144"",""3157"",""Parallelization paradigms for effective execution in a Directed Acyclic Graph (DAG) application have been widely studied in the area of task scheduling. Schedule length can be varied depending on task assignment policies, scheduling policies, and heterogeneity in terms of each processor and each communication bandwidth in a heterogeneous system. One disadvantage of existing task scheduling algorithms is that the schedule length cannot be reduced for a data intensive application. In this paper, we propose a clustering-based task scheduling algorithm called Clustering for Minimizing the Worst Schedule Length (CMWSL) to minimize the schedule length in a large number of heterogeneous processors. First, the proposed method derives the lower bound of the total execution time for each processor by taking both the system and application characteristics into account. As a result, the number of processors used for actual execution is regulated to minimize the Worst Schedule Length (WSL). Then, the actual task assignment and task clustering are performed to minimize the schedule length until the total execution time in a task cluster exceeds the lower bound. Experimental results indicate that CMWSL outperforms both existing list-based and clustering-based task scheduling algorithms in terms of the schedule length and efficiency, especially in data-intensive applications."",""1558-2183"","""",""10.1109/TPDS.2016.2526682"",""JSPS KAKENHI(grant numbers:25730077)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7401062"",""Task scheduling";DAG scheduling;task clustering;"heterogeneous systems"",""Program processors";Schedules;Optimal scheduling;Scheduling;Bandwidth;"Scheduling algorithms"","""",""56"","""",""36"",""IEEE"",""8 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Coalition Formation for Cooperative Service-Based Message Sharing in Vehicular Ad Hoc Networks,""B. Das"; S. Misra;" U. Roy"",""Department of Computer and System Sciences, Visva-Bharati, Santiniketan, India"; School of Information Technology, IIT Kharagpur, Kharagpur, India;" Department of Computer and System Sciences, Visva-Bharati, Santiniketan, India"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""144"",""156"",""Reliable message delivery is a challenging task in Vehicular Ad Hoc Networks (VANETs). Current literature on VANETs generalize all messages and use the same strategy to transmit them. In this paper, we model the cooperative service-based message sharing problem in VANETs as a coalition formation game among nodes. Nodes associate with a coalition based on the type of service-message they process. In the proposed model, service-messages are distinguished from one another by their types. Nodes process different types of service-messages and form a coalition based on the type of messages they process at that time. Some nodes within a coalition can work as a relay, which is modeled as a network formation game to select exactly one relay among a group of potential relay nodes to improve efficiency of the network in terms of improved packet reception rate and reducing transmission delay. The nodes form independent disjoint coalitions and tree structure is formed with the relay nodes within a coalition by using the proposed algorithm, COMES. Simulation results show that COMES, which allows nodes to form independent coalitions among themselves, improves the network performance in terms of incentive received by players by at least 40 percent compared to a non-cooperative function."",""1558-2183"","""",""10.1109/TPDS.2014.2387282"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7001099"",""VANETs";Cooperative Communication;Coalition formation game;Network formation game;VANETs;cooperative communication;coalition formation game;"network formation game"",""Games";Relays;Wireless communication;Receivers;Equations;Delays;"Fading"","""",""33"","""",""32"",""IEEE"",""1 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Collaboration- and Fairness-Aware Big Data Management in Distributed Clouds,""Q. Xia"; Z. Xu; W. Liang;" A. Y. Zomaya"",""Research School of Computer Science, Australian National University, Canberra, ACT, Australia"; Research School of Computer Science, Australian National University, Canberra, ACT, Australia; Research School of Computer Science, Australian National University, Canberra, ACT, Australia;" School of Information Technologies, University of Sydney, Sydney, NSW, Australia"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""1941"",""1953"",""With the advancement of information and communication technology, data are being generated at an exponential rate via various instruments and collected at an unprecedented scale. Such large volume of data generated is referred to as big data, which now are revolutionizing all aspects of our life ranging from enterprises to individuals, from science communities to governments, as they exhibit great potentials to improve efficiency of enterprises and the quality of life. To obtain nontrivial patterns and derive valuable information from big data, a fundamental problem is how to properly place the collected data by different users to distributed clouds and to efficiently analyze the collected data to save user costs in data storage and processing, particularly the cost savings of users who share data. By doing so, it needs the close collaborations among the users, by sharing and utilizing the big data in distributed clouds due to the complexity and volume of big data. Since computing, storage and bandwidth resources in a distributed cloud usually are limited, and such resource provisioning typically is expensive, the collaborative users require to make use of the resources fairly. In this paper, we study a novel collaboration- and fairness-aware big data management problem in distributed cloud environments that aims to maximize the system throughout, while minimizing the operational cost of service providers to achieve the system throughput, subject to resource capacity and user fairness constraints. We first propose a novel optimization framework for the problem. We then devise a fast yet scalable approximation algorithm based on the built optimization framework. We also analyze the time complexity and approximation ratio of the proposed algorithm. We finally conduct experiments by simulations to evaluate the performance of the proposed algorithm. Experimental results demonstrate that the proposed algorithm is promising, and outperforms other heuristics."",""1558-2183"","""",""10.1109/TPDS.2015.2473174"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7225163"",""Big data management";dynamic data placement;fair resource allocation;collaborative users;distributed clouds;data sharing;Big data management;dynamic data placement;fair resource allocation;collaborative users;distributed clouds;"data sharing"",""Distributed databases";Big data;Collaboration;Bandwidth;Servers;Approximation algorithms;"Optimization"","""",""35"","""",""28"",""IEEE"",""26 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"Combining Static and Dynamic Data Coalescing in Unified Parallel C,""M. Alvanos"; M. Farreras; E. Tiotto; J. N. Amaral;" X. Martorell"",""Department of Computing Science, Barcelona Supercomputing Center, Barcelona, Spain"; Department of Computing Science, Universitat Politecnica de Catalunya, Barcelona, Spain; IBM Toronto Laboratory, Toronto, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada;" Department of Computing Science, Universitat Politecnica de Catalunya, Barcelona, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""381"",""393"",""Significant progress has been made in the development of programming languages and tools that are suitable for hybrid computer architectures that group several shared-memory multicores interconnected through a network. This paper addresses important limitations in the code generation for partitioned global address space (PGAS) languages. These languages allow fine-grained communication and lead to programs that perform many fine-grained accesses to data. When the data is distributed to remote computing nodes, code transformations are required to prevent performance degradation. Until now code transformations to PGAS programs have been restricted to the cases where both the physical mapping of the data or the number of processing nodes are known at compilation time. In this paper, a novel application of the inspector-executor model overcomes these limitations and allows profitable code transformations, which result in fewer and larger messages sent through the network, when neither the data mapping nor the number of processing nodes are known at compilation time. A performance evaluation reports both scaling and absolute performance numbers on up to 32,768 cores of a Power 775 supercomputer. This evaluation indicates that the compiler transformation results in speedups between 1.15x and 21x over a baseline and that these automated transformations achieve up to 63 percent the performance of the MPI versions."",""1558-2183"","""",""10.1109/TPDS.2015.2405551"",""IBM(grant numbers:CAS2012-069)"; Spanish Ministry of Science and Innovation(grant numbers:TIN2007-60625,TIN2012-34557,CSD2007-00050); European Commission(grant numbers:FP7/ICT 287759); Generalitat de Catalunya(grant numbers:2009-SGR-980); Defense Advanced Research Projects Agency(grant numbers:HR0011-07-9-0002); NSERC Collaborative Research and Development (CRD) program of Canada;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7045602"",""Unified Parallel C";Partitioned Global Address Space;One-Sided Communication;Performance Evaluation;Unified parallel C;partitioned global address space;one-sided communication;"performance evaluation"",""Runtime";Message systems;Distributed databases;Electronics packaging;Indexes;Optimization;"Programming"","""","""","""",""41"",""IEEE"",""19 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;
"Comment on “Harnessing the Cloud for Securely Outsourcing Large-Scale Systems of Linear Equations”,""Z. Cao";" L. Liu"",""Department of Mathematics, Shanghai University, Shangda Road, Shanghai, China";" Department of Mathematics, Shanghai Maritime University, Haigang Avenue, Shanghai, China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1551"",""1552"",""We remark that the Wang et al.'s scheme [IEEE Transanction Parallel Distributed Systems, 24 (6), 1172-1181, 2013] fails because the involved homomorphic encryption system is invalid in the context of the scheme. This is due to that the general arithmetic over the field $\mathbb {R}$ (the outsourced linear equations are constrained to the field) is not compatible with the modular arithmetic over any finite domain (the homomorphic encryption is constrained to the domain)."",""1558-2183"","""",""10.1109/TPDS.2016.2531669"",""National Natural Science Foundation of China(grant numbers:61303200,61411146001)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449034"",""Cloud computing";linear equations;homomorphic encryption;"Paillier's encryption"",""Encryption";Servers;Jacobian matrices;Outsourcing;Large-scale systems;"Public key cryptography"","""",""4"","""",""4"",""IEEE"",""7 Apr 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Conditions and Patterns for Achieving Convergence in OT-Based Co-Editors,""Y. Xu";" C. Sun"",""School of Computer Engineering, Nanyang Technological University, Singapore";" School of Computer Engineering, Nanyang Technological University, Singapore"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""695"",""709"",""In this paper, we report our discovery of general transformation conditions and patterns underlying a range of Operational Transformation (OT) systems for achieving convergence. Based on these conditions and patterns, we have established convergence correctness of seven existing OT systems, and designed two new OT systems with a unique combination of novel features for supporting advanced collaborative applications. These results contribute to the advancement of OT knowledge, technology, and OT-based collaboration editing systems."",""1558-2183"","""",""10.1109/TPDS.2015.2412938"",""MOE";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7060680"",""Operational Transformation";consistency maintenance,;collaborative editing systems;Operational transformation;consistency maintenance;"collaborative editing systems"",""Context";Convergence;Servers;Collaboration;Concurrent computing;Google;"Algorithm design and analysis"","""",""17"","""",""30"",""OAPA"",""13 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Content-Aware Concurrent Multipath Transfer for High-Definition Video Streaming over Heterogeneous Wireless Networks,""J. Wu"; C. Yuen; M. Wang;" J. Chen"",""Engineering Product Development Pillar, Singapore University of Technology and Design, 8 Somapah Road, Singapore, Republic of Singapore"; Engineering Product Development Pillar, Singapore University of Technology and Design, 8 Somapah Road, Singapore, Republic of Singapore; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, P.R. China;" State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, P.R. China"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""710"",""723"",""Delivering high-definition (HD) wireless video under stringent delay constraint is challenging with regard to the limited network resources and high transmission rate. Concurrent multipath transfer (CMT) using stream control transmission protocol (SCTP) exploits the multihoming feature of mobile devices to establish associations with different access networks. In this paper, we study the multihomed HD video communication with SCTP over heterogeneous wireless networks. The existing CMT schemes mainly treat the traffic data in a content-agnostic fashion, and thus cannot effectively leverage the scarce wireless resources to maximize the perceived video quality. To address this critical issue, we propose a content-aware CMT (CMT-CA) solution that featured by the unequal frame-level scheduling based on estimated video parameters and feedback channel status. First, we develop an analytical framework to model the total distortion of parallel video transmission over multiple wireless access networks. Second, we introduce a joint congestion control and data distribution scheme to minimize the total distortion based on online quality evaluation and Markov decision process (MDP). The performance of CMT-CA is evaluated through extensive semi-physical emulations in Exata involving HD video encoded with H.264 codec. Experimental results show that CMT-CA outperforms the reference schemes in terms of video peak signal-to-noise ratio (PSNR), end-to-end delay, and goodput. Or conversely, CMT-CA achieves the same video quality with 20 percent bandwidth conservation."",""1558-2183"","""",""10.1109/TPDS.2015.2416736"",""National Research Foundation"; Prime Minister's Office; IDM; Digital Media Programme Office;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7070701"",""Content-awareness";concurrent multipath transfer;high-definition video streaming;heterogeneous wireless networks;stream control transmission protocol;multihoming;Markov decision process;Content-awareness;concurrent multipath transfer;high-definition video streaming;heterogeneous wireless networks;stream control transmission protocol;multihoming;"Markov decision process"",""Streaming media";Wireless networks;Delays;High definition video;Markov processes;"Propagation losses"","""",""84"",""3"",""50"",""IEEE"",""27 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;
"Continuous Answering Holistic Queries over Sensor Networks,""K. Liu"; L. Chen; Y. Liu; W. Gong;" A. Nayak"",""MOE Key Lab for Information System Security, School of Software, Tsinghua National Lab for Information Science and Technology, Tsinghua University, Beijing, China"; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong; MOE Key Lab for Information System Security, School of Software, Tsinghua National Lab for Information Science and Technology, Tsinghua University, Beijing, China; MOE Key Lab for Information System Security, School of Software, Tsinghua National Lab for Information Science and Technology, Tsinghua University, Beijing, China;" School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""394"",""404"",""Sensor networks are widely used in various domains like the intelligent transportation systems. Users issue queries to sensors and collect sensing data. Due to the low quality sensing devices or random link failures, sensor data are often noisy. In order to increase the reliability of the query results, continuous queries are often employed. In this work we focus on continuous holistic queries like Median. Existing approaches are mainly designed for non-holistic queries like Average. However, it is not trivial to answer holistic ones due to their non-decomposable property. We first propose two schemes based on the data correlation between different rounds, with one for getting the exact answers and the other one for deriving the approximate results. We then combine the two proposed schemes into a hybrid approach, which is adaptive to the data changing speed. We evaluate this design through extensive simulations. The results show that our approach significantly reduces the traffic cost compared with previous works while maintaining the same accuracy."",""1558-2183"","""",""10.1109/TPDS.2015.2407892"",""NSFC(grant numbers:61472218)"; NSFC Distinguished Young Scholars Program(grant numbers:61125020);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051241"",""Ubiquitous computing";Sensor networks;Distributed data structures;Ubiquitous computing;sensor networks;"distributed data structures"",""Aggregates";Approximation algorithms;Histograms;Refining;Sensors;Monitoring;"Query processing"","""",""1"","""",""39"",""IEEE"",""27 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Coral: A Cloud-Backed Frugal File System,""C. Chang"; J. Sun;" H. Chen"",""College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan, China"; College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan, China;" College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""978"",""991"",""With simple access interfaces and flexible billing models, cloud storage has become an attractive solution to simplify the storage management for both enterprises and individual users. However, traditional file systems with extensive optimizations for local disk-based storage backend can not fully exploit the inherent features of the cloud to obtain desirable performance. In this paper, we present the design, implementation, and evaluation of Coral, a cloud based file system that strikes a balance between performance and monetary cost. Unlike previous studies that treat cloud storage as just a normal backend of existing networked file systems, Coral is designed to address several key issues in optimizing cloud-based file systems such as the data layout, block management, and billing model. With carefully designed data structures and algorithms, such as identifying semantically correlated data blocks, kd-tree based caching policy with self-adaptive thrashing prevention, effective data layout, and optimal garbage collection, Coral achieves good performance and cost savings under various workloads as demonstrated by extensive evaluations."",""1558-2183"","""",""10.1109/TPDS.2015.2424705"",""National Natural Science Foundation of China(grant numbers:61272190,61173166)"; Program for New Century Excellent Talents in University; Fundamental Research Funds for the Central Universities of China;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7089277"",""Cloud Storage";File Systems;Cost Optimization;Cache;Billing model;Cloud storage;file systems;cost optimization;cache;"Billing model"",""Cloud computing";Layout;Databases;Measurement;Optimization;Data models;"Correlation"","""",""6"","""",""39"",""IEEE"",""20 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Correlation-Aware Heuristics for Evaluating the Distribution of the Longest Path Length of a DAG with Random Weights,""L. -C. Canon";" E. Jeannot"",""FEMTO-ST / CNRS and the Université de Franche-Comté, Besançon, France";" LaBRI and Inria Bordeaux Sud-Ouest, Talence, France"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3158"",""3171"",""Coping with uncertainties when scheduling task graphs on parallel machines requires to perform non-trivial evaluations. When considering that each computation and communication duration is a random variable, evaluating the distribution of the critical path length of such graphs involves computing maximums and sums of possibly dependent random variables. The discrete version of this evaluation problem is known to be #P-hard. Here, we propose two heuristics, CorLCA and Cordyn, to compute such lengths. They approximate the input random variables and the intermediate ones as normal random variables, and they precisely take into account correlations with two distinct mechanisms: through lowest common ancestor queries for CorLCA and with a dynamic programming approach for Cordyn. Moreover, we empirically compare some classical methods from the literature and confront them to our solutions. Simulations on a large set of cases indicate that CorLCA and Cordyn constitute each a new relevant trade-off in terms of rapidity and precision."",""1558-2183"","""",""10.1109/TPDS.2016.2528983"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7405345"",""Stochastic scheduling";graph heuristic;"PERT"",""Random variables";Schedules;Scheduling;Processor scheduling;Uncertainty;Context;"Standards"","""",""10"","""",""49"",""IEEE"",""11 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Correlation-Aware Traffic Consolidation for Power Optimization of Data Center Networks,""X. Wang"; X. Wang; K. Zheng; Y. Yao;" Q. Cao"",""Department of Electrical and Computer Engineering, The Ohio State University, Columbus, OH"; Department of Electrical and Computer Engineering, The Ohio State University, Columbus, OH; Department of Electrical and Computer Engineering, The Ohio State University, Columbus, OH; Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, TN;" Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, TN"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""992"",""1006"",""Power optimization has become a key challenge in the design of large-scale enterprise data centers. Existing research efforts focus mainly on computer servers to lower their energy consumption, while only few studies have tried to address data center networks (DCNs), which can account for 10-20 percent of the total energy consumption of a data center. In this paper, we propose CARPO, a correlation-aware power optimization algorithm that dynamically consolidates traffic flows onto a small set of links and switches in a DCN and then shuts down unused network devices for energy savings. In sharp contrast to existing work, CARPO is designed based on a key observation from the analysis of real DCN traces that the bandwidth demands of different flows do not peak at exactly the same time. As a result, if the correlations among flows are considered in consolidation, more energy savings can be achieved. In addition, CARPO integrates traffic consolidation with link rate adaptation for maximized energy savings. We implement CARPO on a hardware testbed composed of 10 virtual switches configured with a production 48-port OpenFlow switch and 8 servers. Our empirical results with traces from Wikipedia and Yahoo! data centers demonstrate that CARPO can save up to 50 percent of network energy for a DCN, while having only negligible delay increases. CARPO also outperforms two state-of-the-art baselines by 19.6 and 95 percent on energy savings, respectively. Our simulation results with a large-scale DCN also show that CARPO can achieve more energy savings than the baselines for typical DCN topologies, such as fat tree and BCube."",""1558-2183"","""",""10.1109/TPDS.2015.2421492"",""NSF(grant numbers:CNS-1421452,CNS-1143607,CNS-0953238)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7084121"",""Data center network";energy savings;correlation analysis;traffic consolidation;link rate adaptation;Data center network;energy savings;correlation analysis;traffic consolidation;"link rate adaptation"",""Correlation";Servers;Ports (Computers);Encyclopedias;Bandwidth;"Electronic publishing"","""",""32"","""",""44"",""IEEE"",""10 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"Cost Minimization for Rule Caching in Software Defined Networking,""H. Huang"; S. Guo; P. Li; W. Liang;" A. Y. Zomaya"",""School of Computer Science and Engineering, the University of Aizu, Japan"; School of Computer Science and Engineering, the University of Aizu, Japan; School of Computer Science and Engineering, the University of Aizu, Japan; Research School of Computer Science, the Australian National University, Australia;" School of Information Technologies, the University of Sydney, Australia"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1007"",""1016"",""Software-defined networking (SDN) is an emerging network paradigm that simplifies network management by decoupling the control plane and data plane, such that switches become simple data forwarding devices and network management is controlled by logically centralized servers. In SDN-enabled networks, network flow is managed by a set of associated rules that are maintained by switches in their local Ternary Content Addressable Memories (TCAMs) which support high-speed parallel lookup on wildcard patterns. Since TCAM is an expensive hardware and extremely power-hungry, each switch has only limited TCAM space and it is inefficient and even infeasible to maintain all rules at local switches. On the other hand, if we eliminate TCAM occupation by forwarding all packets to the centralized controller for processing, it results in a long delay and heavy processing burden on the controller. In this paper, we strive for the fine balance between rule caching and remote packet processing by formulating a minimum weighted flow provisioning ( MWFP) problem with an objective of minimizing the total cost of TCAM occupation and remote packet processing. We propose an efficient offline algorithm if the network traffic is given, otherwise, we propose two online algorithms with guaranteed competitive ratios. Finally, we conduct extensive experiments by simulations using real network traffic traces. The simulation results demonstrate that our proposed algorithms can significantly reduce the total cost of remote controller processing and TCAM occupation, and the solutions obtained are nearly optimal."",""1558-2183"","""",""10.1109/TPDS.2015.2431684"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7105417"",""Software-Defined Networking";Approximation Algorithm;Ternary Content Addressable Memories;Software-defined networking;approximation algorithm;"ternary content addressable memories"",""Control systems";Process control;Approximation algorithms;Aerospace electronics;Software;Hardware;"Delays"","""",""47"",""1"",""29"",""IEEE"",""11 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Cost Performance Driven Service Mashup: A Developer Perspective,""S. Deng"; H. Wu; J. Taheri; A. Y. Zomaya;" Z. Wu"",""College of Computer Science and Technology, Zhejiang University"; College of Computer Science and Technology, Zhejiang University; Department of Computer Science, Karlstad University, Karlstad, Sweden; School of Information Technologies, The University of Sydney;" College of Computer Science and Technology, Zhejiang University"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2234"",""2247"",""Service mashups are applications created by combining single-functional services (or APIs) dispersed over the web. With the development of cloud computing and web technologies, service mashups are becoming more and more widely used and a large number of mashup platforms have been produced. However, due to the proliferation of services on the web, how to select component services to create mashups has become a challenging issue. Most developers pay more attention to the quality of service (QoS) and cost of services. Beside service selection, mashup deployment is another pivotal process, as the platform can significantly affect the quality of mashups. In this paper, we focus on creating service mashups from the perspective of developers. A genetic algorithm-based method, genetic algorithm for mashup creation (GA4MC), is proposed to select component services and deployment platforms in order to create service mashups with optimal cost performance. A series of experiments are conducted to evaluate the performance of GA4MC. The results show that the GA4MC method can achieve mashups whose cost performance is extremely close to the optimal. Moreover, the execution time of GA4MC is in a low order of magnitude and the algorithm performs good scalability as the experimental scale increases."",""1558-2183"","""",""10.1109/TPDS.2015.2482980"",""National Natural Science Foundation of China(grant numbers:61170033)"; National High-Tech Research and Development Plan of China(grant numbers:2014BAD10B02);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7279186"",""Cost Performance";mashup deployment;service composition;service mashup;"service selection"",""Mashups";Quality of service;Time factors;Privacy;Context;"Genetic algorithms"","""",""25"","""",""38"",""IEEE"",""28 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Cost-Aware Caching: Caching More (Costly Items) for Less (ISPs Operational Expenditures),""A. Araldo"; D. Rossi;" F. Martignon"",""LRI, Université Paris-Sud, Gyf-sur-Yvette, France"; Telecom ParisTech, INFRES, France;" IUF, Institut Universitaire de France"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1316"",""1330"",""Albeit an important goal of caching is traffic reduction, a perhaps even more important aspect follows from the above achievement: the reduction of internet service provider (ISP) operational costs that comes as a consequence of the reduced load on transit and provider links. Surprisingly, to date this crucial aspect has not been properly taken into account in cache design. In this paper, we show that the classic caching efficiency indicator, i.e., the hit ratio, conflicts with cost. We therefore propose a mechanism whose goal is the reduction of cost and, in particular, we design a cost-aware (CoA) cache decision policy that, leveraging price heterogeneity among external links, tends to store with more probability the objects that the ISP has to retrieve through the most expensive links. We provide a model of our mechanism, based on Che's approximation, and, by means of a thorough simulation campaign, we contrast it with traditional cost-blind schemes, showing that CoA yields a significant cost saving, that is furthermore consistent over a wide range of scenarios. We show that CoA is easy to implement and robust, making the proposal of practical relevance."",""1558-2183"","""",""10.1109/TPDS.2015.2433296"",""Labex DigiCosme(grant numbers:ANR-11-LABEX-0045-DIGICOSME)"; ANR(grant numbers:ANR-11-IDEX-0003-02); LINCS;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7108052"",""Caching, information-centric networks, cost efficiency, internet service providers"",""Catalogs";Approximation methods;Economics;Load modeling;Proposals;Internet;"Computational modeling"","""",""39"",""1"",""43"",""IEEE"",""14 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"CUDAlign 4.0: Incremental Speculative Traceback for Exact Chromosome-Wide Alignment in GPU Clusters,""E. F. d. O. Sandes"; G. Miranda; X. Martorell; E. Ayguade; G. Teodoro;" A. C. M. Melo"",""Department of Computer Science, University of Brasília, Brasília, DF, Brazil"; Barcelona Supercomputing Center, Barcelona, Spain; Barcelona Supercomputing Center, Barcelona, Spain; Barcelona Supercomputing Center, Barcelona, Spain; Department of Computer Science, University of Brasília, Brasília, DF, Brazil;" Department of Computer Science, University of Brasília, Brasília, DF, Brazil"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2838"",""2850"",""This paper proposes and evaluates CUDAlign 4.0, a parallel strategy to obtain the optimal alignment of huge DNA sequences in multi-GPU platforms, using the exact Smith–Waterman (SW) algorithm. In the first phase of CUDAlign 4.0, a huge Dynamic Programming (DP) matrix is computed by multiple GPUs, which asynchronously communicate border elements to the right neighbor in order to find the optimal score. After that, the traceback phase of SW is executed. The efficient parallelization of the traceback phase is very challenging because of the high amount of data dependency, which particularly impacts the performance and limits the application scalability. In order to obtain a multi-GPU highly parallel traceback phase, we propose and evaluate a new parallel traceback algorithm called Incremental Speculative Traceback (IST), which pipelines the traceback phase, speculating incrementally over the values calculated so far, producing results in advance. With CUDAlign 4.0, we were able to calculate SW matrices with up to 60 Peta cells, obtaining the optimal local alignments of all Human and Chimpanzee homologous chromosomes, whose sizes range from 26 Millions of Base Pairs (MBP) up to 249 MBP. As far as we know, this is the first time such comparison was made with the SW exact method. We also show that the IST algorithm is able to reduce the traceback time from 2.15$\times$  up to 21.03 $\times$ , when compared with the baseline traceback algorithm. The human$\times$ chimpanzee chromosome 5 comparison (180 MBP$\times$ 183 MBP) attained 10,370.00 GCUPS (Billions of Cells Updated per Second) using 384 GPUs, with a speculation hit ratio of 98.2 percent."",""1558-2183"","""",""10.1109/TPDS.2016.2515597"",""Severo Ochoa Program(grant numbers:SEV-2015-0493)"; Spanish Government(grant numbers:PHBP14/00081); Spanish Ministry of Education, Culture and Sport(grant numbers:TIN2015-65316); Spanish Ministry of Science and Technology; Generalitat de Catalunya(grant numbers:2014-SGR1051); CNPq(grant numbers:242800/2012-2,313931/2013-5,211456/2013-6,305208/2014-4,446297/2014-3);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7374729"",""Bioinformatics";sequence alignment;parallel algorithms;"GPU"",""Graphics processing units";DNA;Bioinformatics;Heuristic algorithms;Genomics;Biological cells;"Dynamic programming"","""",""46"","""",""31"",""IEEE"",""7 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;
"CUTBUF: Buffer Management and Router Design for Traffic Mixing in VNET-Based NoCs,""D. Zoni"; J. Flich;" W. Fornaciari"",""Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano,, Milano, Italy"; DISCA Department, Universitat Politècnica de València,, Valencia, Spain;" Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano,, Milano, Italy"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1603"",""1616"",""Router's buffer design and management strongly influence energy, area and performance of on-chip networks, hence it is crucial to encompass all of these aspects in the design process. At the same time, the NoC design cannot disregard preventing network-level and protocol-level deadlocks by devoting ad-hoc buffer resources to that purpose. In chip multiprocessor systems the coherence protocol usually requires different virtual networks (VNETs) to avoid deadlocks. Moreover, VNET utilization is highly unbalanced and there is no way to share buffers between them due to the need to isolate different traffic types. This paper proposes CUTBUF, a novel NoC router architecture to dynamically assign virtual channels (VCs) to VNETs depending on the actual VNETs load to significantly reduce the number of physical buffers in routers, thus saving area and power without decreasing NoC performance. Moreover, CUTBUF allows to reuse the same buffer for different traffic types while ensuring that the optimized NoC is deadlock-free both at network and protocol level. In this perspective, all the VCs are considered spare queues not statically assigned to a specific VNET and the coherence protocol only imposes a minimum number of queues to be implemented. Synthetic applications as well as real benchmarks have been used to validate CUTBUF, considering architectures ranging from 16 up to 48 cores. Moreover, a complete RTL router has been designed to explore area and power overheads. Results highlight how CUTBUF can reduce router buffers up to 33 percent with 2 percent of performance degradation, a 5 percent of operating frequency decrease and area and power saving up to 30.6 and 30.7 percent, respectively. Conversely, the flexibility of the proposed architecture improves by 23.8 percent the performance of the baseline NoC router when the same number of buffers is used."",""1558-2183"","""",""10.1109/TPDS.2015.2468716"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202891"",""Networks-on-Chip";performance;power;router architecture;RTL;simulation;Networks-on-chip;performance;power;router architecture;RTL;"simulation"",""Buffer storage";Routing protocols;System recovery;Ports (Computers);Switches;"Resource management"","""",""21"","""",""23"",""IEEE"",""14 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"DCloud: Deadline-Aware Resource Allocation for Cloud Computing Jobs,""D. Li"; C. Chen; J. Guan; Y. Zhang; J. Zhu;" R. Yu"",""Computer Science Department, Tsinghua University, Beijing, China"; Computer Science Department, Tsinghua University, Beijing, China; Computer Science Department, Tsinghua University, Beijing, China; Networking and Mobility Lab, HP Labs, Palo Alto, CA; Computer Science Department, Tsinghua University, Beijing, China;" Computer Science Department, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2248"",""2260"",""With the tremendous growth of cloud computing, it is increasingly critical to provide quantifiable performance to tenants and to improve resource utilization for the cloud provider. Though many recent proposals focus on guaranteeing job performance (with a particular note on network bandwidth) in the cloud, they usually lack efficient utilization of cloud resource, or vice versa. In this paper we present DCloud, which leverages the (soft) deadlines of cloud computing jobs to enable flexible and efficient resource utilization in data centers. With the deadline requirement of a job guaranteed, DCloud employs both time sliding (postponing the launching time of a job) and bandwidth scaling (adjusting the bandwidth associated with VMs) in resource allocation, so as to better match the resource allocated to the job with the cloud's residual resource. Extensive simulations and testbed experiments show that DCloud can accept much more jobs than existing solutions, and significantly increase the cloud provider's revenue with less cost for individual tenants."",""1558-2183"","""",""10.1109/TPDS.2015.2489646"",""National Key Basic Research Program of China(grant numbers:2014CB347800)"; National Natural Science Foundation of China(grant numbers:61522205,61170291,61432002); National High-tech R&D Program of China(grant numbers:2013AA013303); Tsinghua University Initiative Scientific Research Program;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307195"",""Cloud computing";bandwidth guarantee;"resource allocation"",""Bandwidth";Resource management;Yttrium;Servers;Cloud computing;Switches;"Clouds"","""",""43"","""",""25"",""IEEE"",""26 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Deadline Guaranteed Service for Multi-Tenant Cloud Storage,""G. Liu"; H. Shen;" H. Wang"",""Department of Electrical and Computer Engineering, Clemson University, Clemson"; Department of Electrical and Computer Engineering, Clemson University, Clemson;" Department of Electrical and Computer Engineering, Clemson University, Clemson"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2851"",""2865"",""It is imperative for cloud storage systems to be able to provide deadline guaranteed services according to service level agreements (SLAs) for online services. In spite of many previous works on deadline aware solutions, most of them focus on scheduling work flows or resource reservation in datacenter networks but neglect the server overload problem in cloud storage systems that prevents providing the deadline guaranteed services. In this paper, we introduce a new form of SLAs, which enables each tenant to specify a percentage of its requests it wishes to serve within a specified deadline. We first identify the multiple objectives (i.e., traffic and latency minimization, resource utilization maximization) in developing schemes to satisfy the SLAs. To satisfy the SLAs while achieving the multi-objectives, we propose a Parallel Deadline Guaranteed (PDG) scheme, which schedules data reallocation (through load re-assignment and data replication) using a tree-based bottom-up parallel process. The observation from our model also motivates our deadline strictness clustered data allocation algorithm that maps tenants with the similar SLA strictness into the same server to enhance SLA guarantees. We further enhance PDG in supplying SLA guaranteed services through two algorithms: i) a prioritized data reallocation algorithm that deals with request arrival rate variation, and ii) an adaptive request retransmission algorithm that deals with SLA requirement variation. Our trace-driven experiments on a simulator and Amazon EC2 show the effectiveness of our schemes for guaranteeing the SLAs while achieving the multi-objectives."",""1558-2183"","""",""10.1109/TPDS.2015.2513054"",""US National Science Foundation(grant numbers:NSF-1404981,IIS-1354123,CNS-1254006)"; IBM(grant numbers:5501145); Microsoft Research Faculty Fellowship(grant numbers:8300751);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368211"",""Cloud storage";service level agreement (SLA);deadline;"resource utilization"",""Servers";Cloud computing;Resource management;Clustering algorithms;Mathematical model;Object recognition;"Minimization"","""",""8"","""",""44"",""IEEE"",""29 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Deadlock-Free Broadcast Routing in Dragonfly Networks without Virtual Channels,""D. Xiang";" X. Liu"",""School of Software, Tsinghua University, Beijing, China";" School of Software, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2520"",""2532"",""A new deadlock-free unicast-based broadcast scheme is proposed based on a new routing scheme called minus-first routing. Minus-first routing is a partially adaptive routing scheme in dragonfly networks without any virtual channels. The main goals of the broadcast schemes are to minimize the total delivery time, and any router does not receive any message more than once. No channel competition is introduced. Two different broadcast schemes are proposed: (1) the group-first, and (2) the router-first. It is shown that unicast-based broadcast schemes are necessary to avoid deadlocks at the consumption channels. The group-first broadcast scheme delivers a message to all groups as early as possible";" and the router-first scheme minimizes the number of unicast steps to traverse global links. To our knowledge, the method in this paper is the first collective communication work for dragonfly networks in the literature. Simulation results are presented to evaluate the proposed unicast-based broadcast schemes."",""1558-2183"","""",""10.1109/TPDS.2015.2503746"",""National Science Foundation of China(grant numbers:61170063,60910003,61373021)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7337415"",""Dragonfly networks";group-first broadcast;minus-first routing;router-first broadcast;"unicast-based broadcast"",""Routing";System recovery;Unicast;Adaptive systems;Bandwidth;Ports (Computers);"Hardware"","""",""18"","""",""34"",""IEEE"",""25 Nov 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Design and Implementation of a Hybrid Shingled Write Disk System,""D. Luo"; J. Wan; Y. Zhu; N. Zhao; F. Li;" C. Xie"",""Wuhan National Laboratory for Optoelectronics, Department of Computer Science and Technology, Huazhong University of Science and Technology,, Wuhan, Hubei, P.R. China"; Wuhan National Laboratory for Optoelectronics, Department of Computer Science and Technology, Huazhong University of Science and Technology,, Wuhan, Hubei, P.R. China; Department of Electrical and Computer Engineering, University of Maine, Orono, Maine; Wuhan National Laboratory for Optoelectronics, Department of Computer Science and Technology, Huazhong University of Science and Technology,, Wuhan, Hubei, P.R. China; Wuhan National Laboratory for Optoelectronics, Department of Computer Science and Technology, Huazhong University of Science and Technology,, Wuhan, Hubei, P.R. China;" Wuhan National Laboratory for Optoelectronics, Department of Computer Science and Technology, Huazhong University of Science and Technology,, Wuhan, Hubei, P.R. China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1017"",""1029"",""Disk data density improvement will eventually be limited by the super-paramagnetic effect for perpendicular recording. While various approaches to this problem have been proposed, Shingled Magnetic Recording (SMR) holds great promise to mitigate the problem of density scaling cost-effectively by overlapping data tracks. However, the inherent properties of SMR limit Shingled Write Disk (SWD) applicability since writing data to one track destroys the data previously-stored on the overlapping tracks. As a result, various data layout management designs have been proposed. In this paper, we present a hybrid wave-like shingled recording (HWSR) disk system, which can improve both the performance and the capacity of a shingled write disk. We propose a novel segment-based data layout management and a new wave-like shingled recording that overlaps adjacent tracks from two opposite radial directions. This new scheme can not only efficiently reduce the write amplification, but also double the areal density of conventional circular log-based shingled recording. A new replacement policy based on least write amplification is also devised to manage the hybrid system to effectively eliminate the performance degradation. Our measurements on HWSR implemented in Linux kernel 2.6.35.6 show that it provides superb performance. For example, HWSR reduces the average I/O response time by an order of magnitude compared to S-block for Financial1 trace, and provides up to 3.7 speedup over standard hard disks without using shingled magnetic recording technology."",""1558-2183"","""",""10.1109/TPDS.2015.2425402"",""National Natural Science Foundation of China(grant numbers:61472152)"; National Basic Research Program of China(grant numbers:2011CB302303); Fundamental Research Funds for the Central Universities(grant numbers:HUST:2015QN069); National Natural Science Foundation of China(grant numbers:61432007,61300047);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091937"",""Shingled recording";SSD;hybrid system;replacement policy;data layout;Shingled recording;SSD;hybrid system;replacement policy;"data layout"",""Layout";Magnetic recording;Random access memory;Writing;Nonvolatile memory;Hard disks;"Buffer storage"","""",""15"","""",""28"",""IEEE"",""22 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;
"Designing Efficient Index-Digit Algorithms for CUDA GPU Architectures,""J. Lobeiras"; M. Amor;" R. Doallo"",""Computer Architecture Group (GAC), University of A Coruña (UDC), Spain"; Computer Architecture Group (GAC), University of A Coruña (UDC), Spain;" Computer Architecture Group (GAC), University of A Coruña (UDC), Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1331"",""1343"",""Modern graphics processing units (GPUs) offer very high computing power at relatively low cost. Nevertheless, designing efficient algorithms for the GPUs normally requires additional time and effort, even for experienced programmers. In this work we present a tuning methodology that allows the design for CUDA-enabled GPU architectures of index-digit algorithms, that is, algorithms where the data movement can be described as the permutations of the digits comprising the indices of the data elements. This methodology, based on two-stages identified as GPU resource analysis and operators string manipulation, is applied to FFT and tridiagonal systems solver algorithms, analyzing the performance features and the most adequate solutions. The resulting implementation is compact and outperforms other well-known and commonly used state-of-the-art libraries, with an improvement of up to 19.2 percent over NVIDIA's complex CUFFT , and more than 3000 percent over the NVIDIA'sCUDPP for real data tridiagonal systems."",""1558-2183"","""",""10.1109/TPDS.2015.2450718"",""Galician Government"; FEDER(grant numbers:GRC2013/055); Ministry of Economy and Competitiveness of Spain; FEDER(grant numbers:TIN2013-42148-P);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7138631"",""FFT";tridiagonal systems solver;GPGPU;CUDA;operators string;tuning;FFT;tridiagonal systems solver;GPGPU;CUDA;operators string;"tuning"",""Graphics processing units";Instruction sets;Registers;Algorithm design and analysis;Kernel;"Memory management"","""",""10"","""",""38"",""IEEE"",""29 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;
"Developing Graph-Based Co-Scheduling Algorithms on Multicore Computers,""L. He"; H. Zhu;" S. A. Jarvis"",""Department of Computer Science, University of Warwick, Coventry, United Kingdom"; Department of Computer Science, University of Warwick, Coventry, United Kingdom;" Department of Computer Science, University of Warwick, Coventry, United Kingdom"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1617"",""1632"",""It is common that multiple cores reside on the same chip and share the on-chip cache. As a result, resource sharing can cause performance degradation of co-running jobs. Job co-scheduling is a technique that can effectively alleviate this contention and many co-schedulers have been reported in related literature. Most solutions however do not aim to find the optimal co-scheduling solution. Being able to determine the optimal solution is critical for evaluating co-scheduling systems. Moreover, most co-schedulers only consider serial jobs, and there often exist both parallel and serial jobs in real-world systems. In this paper a graph-based method is developed to find the optimal co-scheduling solution for serial jobs";" the method is then extended to incorporate parallel jobs, including multi-process, and multi-threaded parallel jobs. A number of optimization measures are also developed to accelerate the solving process. Moreover, a flexible approximation technique is proposed to strike a balance between the solving speed and the solution quality. Extensive experiments are conducted to evaluate the effectiveness of the proposed co-scheduling algorithms. The results show that the proposed algorithms can find the optimal co-scheduling solution for both serial and parallel jobs. The proposed approximation technique is also shown to be flexible in the sense that we can control the solving speed by setting the requirement for the solution quality."",""1558-2183"","""",""10.1109/TPDS.2015.2468223"",""Royal Society Industry Fellowship Scheme(grant numbers:IF090020/AM)"; Bull Information Systems; Bull/Warwick Premier Partnership; EPSRC; Intel Corporation(grant numbers:38405-2013,15220082-2015);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194818"",""Multicore, scheduling, graph, parallel computing"",""Degradation";Multicore processing;Scheduling;Approximation algorithms;Program processors;Optimization;"Processor scheduling"","""",""10"","""",""37"",""IEEE"",""13 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Dictionary Based Secure Provenance Compression for Wireless Sensor Networks,""C. Wang"; S. R. Hussain;" E. Bertino"",""Department of Computer Science, Purdue University"; Department of Computer Science, Purdue University;" Cyber Center and the Department of Computer Science, Purdue University"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""405"",""418"",""Due to energy and bandwidth limitations of wireless sensor networks (WSNs), it is crucial that data provenance for these networks be as compact as possible. Even if lossy compression techniques are used for encoding provenance information, the size of the provenance increases with the number of nodes traversed by the network packets. To address such issues, we propose a dictionary based provenance scheme. In our approach, each sensor node in the network stores a packet path dictionary. With the support of this dictionary, a path index instead of the path itself is enclosed with each packet. Since the packet path index is a code word of a dictionary, its size is independent of the number of nodes present in the packet's path. Furthermore, as our scheme binds the packet and its provenance through an AM-FM sketch and uses a secure packet sequence number generation technique, it can defend against most of the known provenance attacks. Through simulation and experimental results, we show that our scheme outperforms other compact provenance schemes with respect to provenance size, robustness, and energy consumption."",""1558-2183"","""",""10.1109/TPDS.2015.2402156"",""Purdue Cyber Center"; National Science Foundation(grant numbers:CNS-1111512); Bajian Project for Selected Researchers in Jiangsu University(grant numbers:1213000013);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7038199"",""Provenance";dictionary based compression;sensor network;Provenance;dictionary based compression;"sensor network"",""Dictionaries";Indexes;Encoding;Wireless sensor networks;Security;Decoding;"Entropy"","""",""36"",""1"",""22"",""IEEE"",""10 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Dispersing Instant Social Video Service Across Multiple Clouds,""Z. Wang"; B. Li; L. Sun; W. Zhu;" S. Yang"",""Graduate School at Shenzhen, Tsinghua University, Shenzhen, China"; Department of Electrical and Computer Engineering, University of Toronto; NA; Tsinghua National Laboratory for Information Science and Technology, the Department of Computer Science and Technology, Tsinghua University, Beijing, China;" Tsinghua National Laboratory for Information Science and Technology, the Department of Computer Science and Technology, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""735"",""747"",""Instant social video sharing which combines the online social network and user-generated short video streaming services, has become popular in today’s Internet. Cloud-based hosting of such instant social video contents has become a norm to serve the increasing users with user-generated contents. A fundamental problem of cloud-based social video sharing service is that users are located globally, who cannot be served with good service quality with a single cloud provider. In this paper, we investigate the feasibility of dispersing instant social video contents to multiple cloud providers. The challenge is that inter-cloud social propagation is indispensable with such multi-cloud social video hosting, yet such inter-cloud traffic incurs substantial operational cost. We analyze and formulate the multi-cloud hosting of an instant social video system as an optimization problem. We conduct large-scale measurement studies to show the characteristics of instant social video deployment, and demonstrate the trade-off between satisfying users with their ideal cloud providers, and reducing the inter-cloud data propagation. Our measurement insights of the social propagation allow us to propose a heuristic algorithm with acceptable complexity to solve the optimization problem, by partitioning a propagation-weighted social graph in two phases: a preference-aware initial cloud provider selection and a propagation-aware re-hosting. Our simulation experiments driven by real-world social network traces show the superiority of our design."",""1558-2183"","""",""10.1109/TPDS.2015.2414941"",""National Key Research and Development Program of China(grant numbers:2015CB352300)"; National Natural Science Foundation of China(grant numbers:61402247,61272231,61210008); SZSTI(grant numbers:JCYJ20140417115840259); Beijing Key Laboratory of Networked Multimedia; Tsinghua-Tencent Joint Laboratory for Internet Innovation Technology;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064793"",""Social media, content delivery, cloud-assisted distribution, graph partition"",""Servers";Cloud computing;Social network services;Streaming media;Pricing;"User-generated content"","""",""7"","""",""30"",""IEEE"",""20 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Distance Threshold Similarity Searches: Efficient Trajectory Indexing on the GPU,""M. Gowanlock";" H. Casanova"",""Information and Computer Sciences Department, Haystack Observatory Westford, Honolulu, MA";" Information and Computer Sciences Department, University of Hawai‘i at Mānoa, Honolulu, HI"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2533"",""2545"",""Applications in many domains perform searches over datasets that contain moving object trajectories. A common class of searches are similarity searches that attempt to identify trajectories with similar characteristics. In this work, we focus on the distance threshold similarity search that finds all trajectories within a given distance of a query trajectory over a time interval. This search involves large numbers of Euclidean moving distance calculations, thus making it a good candidate for execution on manycore platforms such as GPUs. However, low search response time is preconditioned on efficient indexing of trajectory data. We propose three indexing schemes designed for the GPU, with spatial, temporal and spatiotemporal selectivity. These schemes differ significantly from traditional tree-based indexing schemes that have been previously proposed for CPU executions. We evaluate implementations of our proposed indexing schemes using two synthetic and one real-world astrophysics dataset, showing under which conditions each scheme achieves high performance. Our broad finding is that a GPU implementation, provided an appropriate indexing scheme is used, can outperform a multithreaded CPU implementation that uses a state-of-the-art index tree. In particular, the performance improvement is large for regimes that are relevant for classes of real-world applications, thereby demonstrating that the GPU is an attractive platform for searching and processing moving object trajectories."",""1558-2183"","""",""10.1109/TPDS.2015.2500896"",""National Aeronautics and Space Administration"; NASA Astrobiology Institute(grant numbers:NNA08DA77A); Office of Space Science;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7330012"","""",""Trajectory";Graphics processing units;Indexing;Spatiotemporal phenomena;"Search problems"","""",""16"","""",""38"",""IEEE"",""17 Nov 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"DistR: A Distributed Method for the Reachability Query over Large Uncertain Graphs,""Y. Cheng"; Y. Yuan; L. Chen; G. Wang; C. Giraud-Carrier;" Y. Sun"",""College of Computer Science and Engineering, Northeastern University, China"; College of Computer Science and Engineering, Northeastern University, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology; College of Computer Science and Engineering, Northeastern University, China; Department of Computer Science, Brigham Young University;" College of Computer Science and Engineering, Northeastern University, China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3172"",""3185"",""Among uncertain graph queries, reachability, i.e., the probability that one vertex is reachable from another, is likely the most fundamental one. Although this problem has been studied within the field of network reliability, solutions are implemented on a single computer and can only handle small graphs. However, as the size of graph applications continually increases, the corresponding graph data can no longer fit within a single computer's memory and must therefore be distributed across several machines. Furthermore, the computation of probabilistic reachability queries is #P-complete making it very expensive even on small graphs. In this paper, we develop an efficient distributed strategy, called DistR, to solve the problem of reachability query over large uncertain graphs. Specifically, we perform the task in two steps: distributed graph reduction and distributed consolidation. In the distributed graph reduction step, we find all of the maximal subgraphs of the original graph, whose reachability probabilities can be calculated in polynomial time, compute them and reduce the graph accordingly. After this step, only a small graph remains. In the distributed consolidation step, we transform the problem into a relational join process and provide an approximate answer to the #P-complete reachability query. Extensive experimental studies show that our distributed approach is efficient in terms of both computational and communication costs, and has high accuracy."",""1558-2183"","""",""10.1109/TPDS.2016.2535444"",""Natural Science Foundation Of China(grant numbers:61332006,61332014,61328202,U1401256)"; NSFC(grant numbers:61572119,61173029); Fundamental Research Funds for the Central Universities(grant numbers:N150402005,N130504006); NSFC(grant numbers:61328202); NSFC(grant numbers:61202807,61572121);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420710"",""Reachability";distributed computing;"uncertain graphs"",""Servers";Social network services;Distributed databases;Computers;Probability;"Computer network reliability"","""",""21"","""",""43"",""IEEE"",""26 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Distributed Control for Charging Multiple Electric Vehicles with Overload Limitation,""B. Yang"; J. Li; Q. Han; T. He; C. Chen;" X. Guan"",""Department of Automation, Ministry of Education of China, Shanghai, China"; A*STAR-NUS Clinical Imaging Research Center, National University of Singapore, Singapore; Department of Automation, Ministry of Education of China, Shanghai, China; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN; Department of Automation, Ministry of Education of China, Shanghai, China;" Department of Automation, Ministry of Education of China, Shanghai, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3441"",""3454"",""Severe pollution induced by traditional fossil fuels arouses great attention on the usage of plug-in electric vehicles (PEVs) and renewable energy. However, large-scale penetration of PEVs combined with other kinds of appliances tends to cause excessive or even disastrous burden on the power grid, especially during peak hours. This paper focuses on the scheduling of PEVs charging process among different charging stations and each station can be supplied by both renewable energy generators and a distribution network. The distribution network also powers some uncontrollable loads. In order to minimize the on-grid energy cost with local renewable energy and non-ideal storage while avoiding the overload risk of the distribution network, an online algorithm consisting of scheduling the charging of PEVs and energy management of charging stations is developed based on Lyapunov optimization and Lagrange dual decomposition techniques. The algorithm can satisfy the random charging requests from PEVs with provable performance. Simulation results with real data demonstrate that the proposed algorithm can decrease the time-average cost of stations while avoiding overload in the distribution network in the presence of random uncontrollable loads."",""1558-2183"","""",""10.1109/TPDS.2016.2533614"",""National Natural Science Foundation of China(grant numbers:61174127,61573245,61221003,61521063,61273181)"; Shanghai Municipal Science and Technology Commission(grant numbers:14511107903); Shanghai Rising-Star Program(grant numbers:15QA1402300); NSF(grant numbers:CNS-1446640); Shanghai Qianren Talent Program; Program of New Century Talents in University of China(grant numbers:NCET-13-0358);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422114"",""Electric vehicle";charging scheduling;renewable energy;smart grid;"Lyapunov optmization"",""Renewable energy sources";Charging stations;Power grids;Energy storage;Electric vehicles;Smart grids;Lyapunov methods;Fossil fuels;"Power distribution planning"","""",""29"","""",""38"",""IEEE"",""29 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;
"Distributed Emergency Guiding with Evacuation Time Optimization Based on Wireless Sensor Networks,""L. -W. Chen"; J. -H. Cheng;" Y. -C. Tseng"",""Department of Information Engineering and Computer Science, Feng Chia University, Taichung, Taiwan"; Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan;" Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""419"",""427"",""This paper proposes a load-balancing framework for distributed emergency guiding based on wireless sensor networks. A load-balancing guiding scheme is designed and an analytical model is derived to reduce the total evacuation time of people indoors. The guiding scheme can provide the fastest path for people to reach an exit according to the evacuation time estimated using the analytical model. Based on thorough research, this is the first distributed solution in which corridor capacity and length, exit capacity, and the concurrent movement and distribution of people are considered in estimating the evacuation time and planning escape paths. Using the proposed framework, congestion in corridors and at exits can be eased to substantially reduce the total evacuation time. Analytical and simulation results show that this approach outperforms existing schemes and can prevent people from following localoptimal guiding directions that increase the evacuation time. A prototype called the Load-balancing Emergency Guiding System (LEGS) is implemented";" this system can be used to compare the evacuation times and guiding directions provided by existing schemes and the proposed scheme for various distributions of people."",""1558-2183"","""",""10.1109/TPDS.2015.2500722"",""NSC(grant numbers:101-2221-E-035-090,102-2221-E-035-031-MY3)"; MoE ATU Plan(grant numbers:101-2221-E-009-024-MY3,102-2218-E-009-002); IVF-NSC(grant numbers:21280013,102-2923-E-009-001-MY2); Academia Sinica(grant numbers:AS-102-TP-A06); ITRI; hTC; D-Link;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328748"",""Emergency Guiding";Home Security;Load Balancing;Pervasive Computing;Wireless Sensor Network;Emergency guiding;home security;load balancing;pervasive computing;"wireless sensor network"",""Sensors";Wireless sensor networks;Capacity planning;Analytical models;Planning;Simulation;"Wireless communication"","""",""23"","""",""24"",""IEEE"",""13 Nov 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;
"Distributed Online En-Route Caching,""A. Gharaibeh"; A. Khreishah; I. Khalil;" J. Wu"",""Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ"; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ; Qatar Computing Research Institute, Hamad bin Khalifa University, 13th Floor, Tornado Tower, Doha, Qatar;" Department of Computer & Information Sciences, Temple University, Philadelphia, PA"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3455"",""3468"",""Content caching at intermediate nodes is an effective way to optimize the operations of Computer networks, so that future requests can be served without going back to the origin of the content. Several caching techniques have been proposed in literature, including techniques that require major changes to the Internet architecture. In this work, we present a low complexity, distributed, and online caching algorithm based on content popularity. Our algorithm performs en-route caching using a simple cost-reward comparison. Therefore, it can be integrated with the current TCP/IP model. We use the concept of competitive ratio to measure the performance of any online caching algorithm, in terms of traffic savings, with respect to the performance of the optimal offline algorithm that has a complete knowledge of the future. We show that under our settings, no online algorithm can achieve a better competitive ratio than Ω(logn), where n is the number of nodes in the network. Furthermore, we show that under realistic scenarios, our algorithm has an asymptotically optimal competitive ratio in terms of the number of nodes in the network. We also study several extensions to the basic algorithm and show their effectiveness through extensive simulations."",""1558-2183"","""",""10.1109/TPDS.2016.2547396"",""US National Science Foundation(grant numbers:ECCS 1331018)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7442568"",""En-route caching";caching incentive;competitive ratio;asymptotic optimality;"quality of service"",""Current measurement";Algorithm design and analysis;Quality of service;Computer architecture;Cache storage;TCPIP;"Complexity theory"","""",""1"","""",""38"",""IEEE"",""28 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Distributed Slicing in Dynamic Systems,""A. F. Anta"; V. Gramoli; E. Jiménez; A. -M. Kermarrec;" M. Raynal"",""IMDEA Networks Institute, Spain"; University of Sydney and NICTA, Australia; EPN, Quito, Ecuador, and Universidad Politécnica de Madrid, Spain; INRIA, France;" Institut Universitaire de France and University of Rennes 1, France"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1030"",""1043"",""Peer to peer (P2P) systems have moved from application specific architectures to a generic service oriented design philosophy. This raised interesting problems in connection with providing useful P2P middleware services capable of dealing with resource assignment and management in a large-scale, heterogeneous and unreliable environment. The slicing problem consists of partitioning a P2P network into $k$  groups (slices) of a given portion of the network nodes that share similar resource values. As the network is large and dynamic this partitioning is continuously updated without any node knowing the network size. In this paper, we propose the first algorithm to solve the slicing problem. We introduce the metric of slice disorder and show that the existing ordering algorithm cannot nullify this disorder. We propose a new algorithm that speeds up the existing ordering algorithm but that suffers from the same inaccuracy. Then, we propose another algorithm based on ranking that is provably convergent under reasonable assumptions. In particular, we notice experimentally that ordering algorithms suffer from resource-correlated churn while the ranking algorithm can cope with it. These algorithms are proved viable theoretically and experimentally."",""1558-2183"","""",""10.1109/TPDS.2015.2430856"",""Regional Government of Madrid (CM)"; Cloud4BigData(grant numbers:S2013/ICE-2894); FSE & FEDER; Spanish Research Council; BigDataPaaS(grant numbers:TIN2013-46883); Australian Government; Department of Communications; Australian Research Council; ICT Centre of Excellence Program;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7103341"",""slice";gossip;churn;peer-to-peer;aggregation;large scale;Slice;gossip;churn;peer-to-peer;aggregation;"large scale"",""Peer-to-peer computing";Nickel;Heuristic algorithms;Sociology;Statistics;Protocols;"Approximation algorithms"","""",""2"","""",""39"",""IEEE"",""7 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;
"DREAM-(L)G: A Distributed Grouping-Based Algorithm for Resource Assignment for Bandwidth-Intensive Applications in the Cloud,""Y. Zhao"; H. Jiang; K. Zhou; Z. Huang;" P. Huang"",""School of Computer Science and Technology, Wuhan National Laboratory for Optoelectronics, Key Laboratory of Information Storage System, Ministry of Education, Huazhong University of Science and Technology, Wuhan, China"; University of Texas at Arlington, TX; School of Computer Science and Technology, Wuhan National Laboratory for Optoelectronics, Key Laboratory of Information Storage System, Ministry of Education, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Wuhan National Laboratory for Optoelectronics, Key Laboratory of Information Storage System, Ministry of Education, Huazhong University of Science and Technology, Wuhan, China;" Virginia Commonwealth University, Virginia, VA"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3469"",""3484"",""Increasingly, many bandwidth-intensive applications have been ported to the cloud platform. In practice, however, some disadvantages including equipment failures, bandwidth overload and long-distance transmission often damage the QoS about data availability, bandwidth provision and access locality respectively. While some recent solutions have been proposed to cope with one or two of disadvantages, but not all. Moreover, as the number of data objects scales, most of the current offline algorithms solving a constraint optimization problem suffer from low computational efficiency. To overcome these problems, in this paper we propose an approach that aims to make fully efficient use of the cloud resources to enable bandwidth-intensive applications to achieve the desirable level of SLA-specified QoS mentioned above cost-effectively and timely. First we devise a constraint-based model that describes the relationship among data object placement, user cells bandwidth allocation, operating costs and QoS constraints. Second, we use the distributed heuristic algorithm, called DREAM-L, that solves the model and produces a budget solution to meet SLA-specified QoS. Third, we propose an object-grouping technique that is integrated into DREAM-L, called DREAM-LG, to significantly improve the computational efficiency of our algorithm. The results of hundreds of thousands of simulation-based experiments demonstrate that DREAM-LG provides much better data availability, bandwidth provision and access locality than the state-of-the-art solutions at modest cloud operating costs and within a small and acceptable range of time."",""1558-2183"","""",""10.1109/TPDS.2016.2537334"",""National Natural Science Foundation of China(grant numbers:61232004,61502189)"; Wuhan National Laboratory for Optoelectronics; Key Laboratory of Information Storage System; Ministry of Education;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423784"",""Bandwidth-intensive applications";cloud system;quality of service;distributed heuristic algorithm;resource scheduling;"optimization model"",""Bandwidth";Cloud computing;Optimization;Quality of service;Heuristic algorithms;Algorithm design and analysis;Channel allocation;Resource management;"Process scheduling"","""",""8"","""",""41"",""IEEE"",""2 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;
"Dynamic Bin Packing for On-Demand Cloud Resource Allocation,""Y. Li"; X. Tang;" W. Cai"",""School of Computer Engineering, Nanyang Technological University, Nanyang Avenue 50,, Singapore"; School of Computer Engineering, Nanyang Technological University, Nanyang Avenue 50,, Singapore;" School of Computer Engineering, Nanyang Technological University, Nanyang Avenue 50,, Singapore"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""157"",""170"",""Dynamic Bin Packing (DBP) is a variant of classical bin packing, which assumes that items may arrive and depart at arbitrary times. Existing works on DBP generally aim to minimize the maximum number of bins ever used in the packing. In this paper, we consider a new version of the DBP problem, namely, the MinTotal DBP problem which targets at minimizing the total cost of the bins used overtime. It is motivated by the request dispatching problem arising from cloud gaming systems. We analyze the competitive ratios of the modified versions of the commonly used First Fit, Best Fit, and Any Fit packing (the family of packing algorithms that open a new bin only when no currently open bin can accommodate the item to be packed) algorithms for the MinTotal DBP problem. We show that the competitive ratio of Any Fit packing cannot be better than μ + 1, where μ is the ratio of the maximum item duration to the minimum item duration. The competitive ratio of Best Fit packing is not bounded for any given μ. For First Fit packing, if all the item sizes are smaller than 1/β of the bin capacity (β> 1 is a constant), the competitive ratio has an upper bound of β/β-1·μ+3β/β-1 + 1. For the general case, the competitive ratio of First Fit packing has an upper bound of 2μ + 7. We also propose a Hybrid First Fit packing algorithm that can achieve a competitive ratio no larger than 5/4 μ + 19/4 when μ is not known and can achieve a competitive ratio no larger than μ + 5 when μ is known."",""1558-2183"","""",""10.1109/TPDS.2015.2393868"",""Multi-plAtform Game Innovation Centre (MAGIC)"; Singapore National Research Foundation; Interactive & Digital Media Programme Office; Media Development Authority;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014234"",""Dynamic bin packing";online algorithms;competitive ratios;Dynamic bin packing;online algorithms;competitive ratios;worst case bounds;"theory"",""Games";Servers;Heuristic algorithms;Cloud computing;Upper bound;Computers;"Graphics processing units"","""",""60"","""",""27"",""IEEE"",""19 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Dynamic Request Redirection and Resource Provisioning for Cloud-Based Video Services under Heterogeneous Environment,""W. Xiao"; W. Bao; X. Zhu; C. Wang; L. Chen;" L. T. Yang"",""Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, Hunan, P.R. China"; Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, Hunan, P.R. China; Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, Hunan, P.R. China; Autonomous Systems, CSIRO DP&S Marsfield, NSW, Australia; Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, Hunan, P.R. China;" Department of Computer Science, St. Francis Xavier University, Antigonish, NS B2G 2W5, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""1954"",""1967"",""Cloud computing provides a new opportunity for Video Service Providers (VSP) to running compute-intensive video applications in a cost effective manner. Under this paradigm, a VSP may rent virtual machines (VMs) from multiple geo-distributed datacenters that are close to video requestors to run their services. As user demands are difficult to predict and the prices of the VMs vary in different time and region, optimizing the number of VMs of each type rented from datacenters located in different regions in a given time frame becomes essential to achieve cost effectiveness for VSPs. Meanwhile, it is equally important to guarantee users' Quality of Experience (QoE) with rented VMs. In this paper, we give a systematic method called Dynamical Request Redirection and Resource Provisioning (DYRECEIVE) to address this problem. We formulate the problem as a stochastic optimization problem and design a Lyapunov optimization framework based online algorithm to solve it. Our method is able to minimize the long-term time average cost of renting cloud resources while maintaining the user QoE. Theoretical analysis shows that our online algorithm can produce a solution within an upper bound to the optimal solution achieved through offline computing. Extensive experiments shows that our method is adaptive to request pattern changes along time and outperforms existing algorithms."",""1558-2183"","""",""10.1109/TPDS.2015.2470676"",""Doctoral Program of Higher Education (RFDP)(grant numbers:20134307110029)"; National Natural Science Foundation of China(grant numbers:91024030,11428101,61405252,61572511); Hunan Provincial Natural Science Foundation of China(grant numbers:2015JJ3023);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217812"",""Cloud computing";Cloud-based Video Service;Request Redirection;Resource Provision;Lyapunov optimization;Cloud computing;cloud-based video service;request redirection;resource provision;"Lyapunov optimization"",""Delays";Optimization;Resource management;Servers;Quality of service;Heuristic algorithms;"Streaming media"","""",""30"","""",""43"",""IEEE"",""21 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;
"Eavesdropping Prevention for Network Coding Encrypted Cloud Storage Systems,""Y. -J. Chen"; L. -C. Wang;" C. -H. Liao"",""Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan"; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan;" Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2261"",""2273"",""Network coding is an important cloud storage technique, which can recover data with small repair bandwidth and high reliability compared to the existing erasure coding and replication methods. However, regardless of which data recovery technique is used, the repaired data in a geographically distributed cloud storage system are easy to be eavesdropped at the transmission link between the local datacenter and its remote backup site. This kind of network security issue is called link eavesdropping in this paper. For a network coded cloud storage system, we propose a systematic design methodology to determine the important data recovery system parameters for any specified security level. Through analysis, we present the performance curves to relate the remote repair bandwidth and the number of coded data fragments. Consequently, all the important system parameters of a network coded data recovery system, including the number of storage nodes and the link capacity between the datacenter and the backup site, can be precisely designed for satisfying different security level requirements."",""1558-2183"","""",""10.1109/TPDS.2015.2486772"",""National Science Council(grant numbers:NSC-102-2221-E-009-012-MY3)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7289458"",""Network coding";distributed storage;"data security"",""Maintenance engineering";Bandwidth;Security;Encoding;Cloud computing;Distributed databases;"Network coding"","""",""17"","""",""42"",""IEEE"",""5 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"EcoUp: Towards Economical Datacenter Upgrading,""G. Yan"; J. Ma; Y. Han;" X. Li"",""State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China"; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China;" State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""1968"",""1981"",""The rapid growth of cloud services dictates increasingly powerful datacenters to maintain the high quality of service (QoS). It's a common practice in virtually all tiers of datacenters to continuously upgrade the datacenters, i.e. replacing outdated and failed servers with more advanced and efficient ones. However, how to upgrade a datacenter in the most cost-efficient strategy remains unclear, and however this problem goes increasingly challenging given the great diversity of applications. In practice, the datacenters' operators usually resort to expending the scale of servers. The preferred servers are either expensive but high-performance, or, by contrast, cheap but low-power. Whatever sever preferences, how to justify the cost-efficiency is still an open problem. We claim that a cost-efficient upgrading strategy should be fully aware of not only the capacity and cost of various servers, but also the resource demands of target applications. We model this strategy as a recommendation problem: recommending the “best” servers to a datacenter. We propose “EcoUp”, a model-based framework that faithfully rates the cost efficiency of server candidates, relying on which an optimal server portfolio can be derived. The performance prediction on candidate servers is realized by employing a sophisticated latent factor model (LFM). The cost mainly involves the server purchasing cost and energy bill. Given the application distribution, EcoUp can give an optimal server portfolio under a certain capital budget. We use Google trace, a big profiling dataset opened by Google, to validate the performance prediction. Experimental results show that the error rate is below 8 percent on average. Meanwhile, we build a comprehensive upgrading procedure on a local cluster to evaluate the potential of EcoUp. The results show that our approach significantly outperforms two conventional upgrading strategies by 12.3 and 33.6 percent in terms of system throughput, respectively."",""1558-2183"","""",""10.1109/TPDS.2015.2477827"",""National Basic Research Program of China(grant numbers:2011CB302503)"; NSFC(grant numbers:61100016,61221062,61376043,61432017,61572470,61532017);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7254219"",""Datacenter upgrading";Cost efficiency;Performance prediction;Recommender systems;Collaborative filtering;Datacenter upgrading;cost efficiency;performance prediction;recommender systems;"collaborative filtering"",""Servers";Google;Portfolios;Quality of service;Sparse matrices;Error analysis;"Predictive models"","""",""4"","""",""51"",""IEEE"",""10 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"Efficient Algorithms for Capacitated Cloudlet Placements,""Z. Xu"; W. Liang; W. Xu; M. Jia;" S. Guo"",""Research School of Computer Science, Australian National University, Canberra, ACT, Australia"; Research School of Computer Science, Australian National University, Canberra, ACT, Australia; College of Computer Science, Sichuan University, Chengdu, P.R. China; Research School of Computer Science, Australian National University, Canberra, ACT, Australia;" School of Computer Science and Engineering, University of Aizu, Aizu-Wakamatsu City, Fukushima, Japan"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2866"",""2880"",""Mobile cloud computing is emerging as a main ubiquitous computing platform to provide rich cloud resources for various applications of mobile devices. Although most existing studies in mobile cloud computing focus on energy savings of mobile devices by offloading computing-intensive jobs from mobile devices to remote clouds, the access delays between mobile users and remote clouds usually are long and sometimes unbearable. Cloudlet as a new technology is capable to bridge this gap, and can enhance the performance of mobile devices significantly while meeting the crisp response time requirements of mobile users. In this paper, we study the cloudlet placement problem in a large-scale Wireless Metropolitan Area Network (WMAN) consisting of many wireless Access Points (APs). We first formulate the problem as a novel capacitated cloudlet placement problem that places  $K$  cloudlets to some strategic locations in the WMAN with the objective to minimize the average access delay between mobile users and the cloudlets serving the users. We then propose an exact solution to the problem by formulating it as an Integer Linear Programming (ILP). Due to the poor scalability of the ILP, we instead propose an efficient heuristic for the problem. For a special case of the problem where all cloudlets have identical computing capacities, we devise novel approximation algorithms with guaranteed approximation ratios. We also devise an online algorithm for dynamically allocating user requests to different cloudlets, if the  $K$  cloudlets have already been placed. We finally evaluate the performance of the proposed algorithms through experimental simulations. Simulation results demonstrate that the proposed algorithms are promising and scalable."",""1558-2183"","""",""10.1109/TPDS.2015.2510638"",""Strategic International Collaborative Research Program"; NSF; BDD;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7362036"",""Cloudlet placement";cloudlet access delay minimization;mobile user request assignment;mobile cloud computing;"approximation algorithms"",""Cloud computing";Mobile communication;Delays;Approximation algorithms;Mobile handsets;Approximation methods;"Heuristic algorithms"","""",""194"","""",""39"",""IEEE"",""22 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Efficient File Search in Delay Tolerant Networks with Social Content and Contact Awareness,""K. Chen"; H. Shen;" L. Yan"",""Department of Electrical and Computer Engineering, Southern Illinois University, Carbondale, IL"; Department of Electrical and Computer Engineering, Clemson University, Clemson, SC;" Department of Electrical and Computer Engineering, Clemson University, Clemson, SC"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""1982"",""1995"",""Distributed file searching in delay tolerant networks formed by mobile devices can potentially support various useful applications. In such networks, nodes often present certain social network properties of their holders in terms of contents (i.e., interests) and contacts. However, current methods in DTNs only consider either content or contact for file searching or dissemination, which limits the file sharing efficiency. In this paper, we first analyze real traces to confirm the importance and necessity of considering both content and contact in file search. We then propose Cont2, a social-aware file search method that exploits both node contents and contact patterns. First, considering people with common interests tend to share files and gather together, Cont2 virtually groups common-interest nodes into a community to direct file search. Second, considering human mobility follows a certain pattern, Cont2 exploits nodes' contact frequencies with a community to expedite file searching. To further improve the searching efficiency, Cont2 also integrates sub-communities and parallel forwarding as optional components for file searching. Trace-driven experiments on the GENI testbed and NS-2 simulator show that Cont2 can effectively improve the search efficiency compared to current methods."",""1558-2183"","""",""10.1109/TPDS.2015.2472005"",""US National Science Foundation(grant numbers:NSF-1404981,IIS-1354123,CNS-1254006,CNS-1249603)"; Microsoft Research Faculty Fellowship(grant numbers:8300751);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219439"",""Social-Aware";File Search;Delay Tolerant Networks;Social-aware;file search;"delay tolerant networks"",""Peer-to-peer computing";Social network services;Routing;Servers;Nickel;Delays;"Mobile handsets"","""",""5"","""",""36"",""IEEE"",""24 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Efficient Parallel Skyline Evaluation Using MapReduce,""J. Zhang"; X. Jiang; W. -S. Ku;" X. Qin"",""Department of Computer Science and Software Engineering, Auburn University, Auburn, AL"; Department of Computer Science, Earlham College, Richmond, IN; Department of Computer Science and Software Engineering, Auburn University, Auburn, AL;" Department of Computer Science and Software Engineering, Auburn University, Auburn, AL"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""1996"",""2009"",""This research develops an advanced two-phase MapReduce solution that is able to efficiently address skyline queries on large datasets. Unlike existing parallel skyline approaches, our scheme considers data partitioning, filtering, and parallel skyline evaluation as a holistic query process. In particular, we apply filtering techniques and angle-based partitioning in the first phase, in which unqualified objects are discarded and the processed objects are partitioned by their angles to the origin.In the second phase, local skyline objects in each partition are calculated in parallel, and global skyline objects are output after a merging skyline process. To improve the parallel local skyline calculation, we propose two partition-aware filtering methods that keep skyline candidates in a balanced manner. The aggressive partition-aware filtering aggressively eliminates objects in the partition with the greatest population of candidate objects, whereas the proportional partition-aware filtering slows down the growth of partition population proportionally. Recognizing the lack of studies that incorporate the MapReduce framework into parallel skyline processing, we propose a partialpresort grid-based partition skyline algorithm that is able to significantly improve the merging skyline computation on large datasets. The presort process can be completed in the shuffle phase with little overhead. Our experimental results show the efficiency and effectiveness of the proposed parallel skyline solution utilizing MapReduce on large-scale datasets."",""1558-2183"","""",""10.1109/TPDS.2015.2472016"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219441"",""Skyline query";MapReduce;Big data;Skyline query;mapreduce;"big data"",""Partitioning algorithms";Indexes;Algorithm design and analysis;Merging;Query processing;Complexity theory;"Peer-to-peer computing"","""",""35"","""",""38"",""IEEE"",""24 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Efficient Storage of Multi-Sensor Object-Tracking Data,""X. Hao"; P. Jin;" L. Yue"",""Science and Technology on Electronic Information Control Laboratory, Chengdu, China"; Science and Technology on Electronic Information Control Laboratory, Chengdu, China;" School of Computer Science and Technology, University of Science and Technology of China, Hefei, China"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2881"",""2894"",""The rapid development of Internet of Things (IoT) enables people to track objects by deploying multiple sensors, e.g., to track people in indoor spaces using RFID sensors. Multi-sensor object-tracking data are usually produced as records, which are thereby organized into small files and written to servers. However, the small-size property and high arriving-rate of multi-sensor object-tracking data will result in poor I/O performance of file systems such as HDFS. In this paper, we propose the first read/write-optimized solution for storing multi-sensor object-tracking data on HDFS. In particular, we exploit a distributed caching mechanism and a parallel file-merging policy to improve the I/O performance of HDFS. With our design, object-tracking data are first cached by a Distributed Memory File System (DMFS) on top of HDFS. These data are further merged into large files, which are then flushed to HDFS in parallel. We demonstrate that this mechanism is able to improve the write throughput of HDFS and outperforms existing centralized-cache-based approaches. In addition, in order to improve the search performance of object queries over multi-sensor object-tracking data, we propose a Sensor-Dependence Graph (SDG) to model sensor dependence and further present an SDG-based algorithm to efficiently cluster sensors. The object-tracking data from the sensors in the same cluster are merged into the same large files, which can reduce file scans during query processing and therefore improve search performance. We conduct extensive experiments to evaluate the performance of our proposal. The results suggest the efficiency of our proposal with respect to disk-write throughput, memory-write throughput, search performance, and sensor clustering."",""1558-2183"","""",""10.1109/TPDS.2015.2511735"",""National Science Foundation of China(grant numbers:61379037,61472376)"; Fundamental Research Funds for the Central Universities; Science and Technology on Electronic Information Control Laboratory;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364275"",""Storage management";"file systems management"",""Sensor systems";File systems;Throughput;Merging;Search problems;"Distributed databases"","""",""14"","""",""31"",""IEEE"",""23 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Efficient TLB-Based Detection of Private Pages in Chip Multiprocessors,""A. Esteve"; A. Ros; M. E. Gómez; A. Robles;" J. Duato"",""Department of Computer Engineering, Universitat Politècnica de València, Valencia, Spain"; Departamento de Ingeniería y Tecnología de Computadores, Universidad de Murcia, Espinardo, Murcia, Spain; Department of Computer Engineering, Universitat Politècnica de València, Valencia, Spain; Department of Computer Engineering, Universitat Politècnica de València, Valencia, Spain;" Department of Computer Engineering, Universitat Politècnica de València, Valencia, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""748"",""761"",""Most of the data referenced by sequential and parallel applications running in current chip multiprocessors are referenced by a single thread, i.e., private. Recent proposals leverage this observation to improve many aspects of chip multiprocessors, such as reducing coherence overhead or the access latency to distributed caches. The effectiveness of those proposals depends to a large extent on the amount of detected private data. However, the mechanisms proposed so far do not consider neither thread migration nor the private use of data within different application phases. As a result, a considerable amount of private data is not detected. In order to increase the detection of private data, we propose a TLB-based mechanism that is able to account for both thread migration and application phases. Simulation results show that the average number of pages detected as private significantly increases from 43 percent in previous proposals up to 79 percent in ours while keeping a reasonable TLB miss rate. Furthermore, when our proposal is used to deactivate the coherence for private data in a directory protocol, it improves execution time by 13.5 percent, on average, with respect to previous techniques."",""1558-2183"","""",""10.1109/TPDS.2015.2412139"",""MINECO"; European Commission(grant numbers:TIN2012-38341-C04-01/03); Fundación Seneca-Agencia de Ciencia y Tecnología de la Región de Murcia; Jóvenes Líderes en Investigación(grant numbers:18956/JLI/13);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7058428"",""Multiprocessor";cache coherence;directory cache;coherence deactivation;TLB decay;Multiprocessor;cache coherence;directory cache;coherence deactivation;"TLB decay"",""Coherence";Protocols;Proposals;Message systems;Organizations;Scalability;"System performance"","""",""16"",""1"",""43"",""IEEE"",""11 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;
"Elastic-RAID: A New Architecture for Improved Availability of Parity-Based RAIDs by Elastic Mirroring,""J. Yao"; H. Jiang; Q. Cao; L. Tian;" C. Xie"",""School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, P. R. China"; Department of Computer Science and Engineering, University of Nebraska-Lincoln, Lincoln, NE; Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, P. R. China; Department of Computer Science and Engineering, University of Nebraska-Lincoln, Lincoln, NE;" Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, P. R. China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1044"",""1056"",""In this paper, we propose Elastic-RAID, a new RAID architecture to achieve high performance and high reliability for large-scale distributed and parallel storage systems. The key idea behind Elastic-RAID is to smartly utilize the free space existing in parity-based disk arrays to store additional mirroring data. This additional mirroring data redundancy, when strategically and judiciously activated and exploited in a RAID system, enables improved system I/O performance, fault tolerance and recovery. Depending on the amount of free space available and whether the emphasis is on performance or reliability, the elasticity in Elastic-RAID is manifested in how each design objective is achieved. For the performance objective, Elastic-RAID improves small-write performance by writing original and mirroring data synchronously and leaving the costly parity update in the background at a later idle/lightly-loaded time. For the reliability objective, at least two concurrent disk failures can be tolerated when Elastic-RAID is employed in a RAID5 system that has 50 percent or more free space. Higher reliability is provided for important data when free space is less than 50 percent. To achieve the design goal of elasticity, we introduce a novel data layout and addressing scheme. Our extensive trace-driven evaluations on an Elastic-RAID prototype in the typical configurations of RAID5 show that Elastic-RAID boosts the small-write performance in the normal operational state by at least 40 percent, improves the user I/O performance in the reconstruction state by at least 30 percent and shortens the recovery time by at least 40 percent."",""1558-2183"","""",""10.1109/TPDS.2015.2432808"",""National Basic Research Program of China(grant numbers:2011CB302303)"; Key Laboratory of Data Storage System; Ministry of Education of China;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106529"",""RAID";Performance and Reliability;Parallel I/O;RAID;performance and reliability;"parallel I/O"",""Redundancy";Layout;Reliability engineering;Standards;Elasticity;"Upper bound"","""",""3"","""",""42"",""IEEE"",""13 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Enabling Data-Centric Distribution Technology for Partitioned Embedded Systems,""H. Pérez";" J. J. Gutiérrez"",""Software Engineering and Real-Time Group, University of Cantabria, Spain";" Software Engineering and Real-Time Group, University of Cantabria, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3186"",""3198"",""Modern complex embedded systems are evolving into mixed-criticality systems in order to satisfy a wide set of non-functional requirements such as security, cost, weight, timing or power consumption. Partitioning is an enabling technology for this purpose, as it provides an environment with strong temporal and spatial isolation which allows the integration of applications with different requirements into a common hardware platform. At the same time, embedded systems are increasingly networked (e.g., cyber-physical systems) and they even might require global connectivity in open environments so enhanced communication mechanisms are needed to develop distributed partitioned systems. To this end, this work proposes an architecture to enable the use of data-centric real-time distribution middleware in partitioned embedded systems based on a hypervisor. This architecture relies on distribution middleware and a set of virtual devices to provide mixed-criticality partitions with a homogeneous and interoperable communication subsystem. The results obtained show that this approach provides low overhead and a reasonable trade-off between temporal isolation and performance."",""1558-2183"","""",""10.1109/TPDS.2016.2531695"",""Spanish Government"; FEDER(grant numbers:TIN2011-28567-C03-02,TIN2014-56158-C4-2-P);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412779"",""Real-time distributed";real-time systems and embedded systems;middleware;"application virtualization"",""Real-time systems";Standards;Middleware;Embedded systems;Virtual machine monitors;"Hardware"","""",""8"","""",""48"",""IEEE"",""18 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Enabling Personalized Search over Encrypted Outsourced Data with Efficiency Improvement,""Z. Fu"; K. Ren; J. Shu; X. Sun;" F. Huang"",""School of Computer and Software, Jiangsu Engineering Centre of Network Monitoring, Nanjing University of Information Science and Technology, Nanjing, China"; Department of Computer Science and Engineering, The State University of New York at Buffalo, Buffalo, NY; School of Computer and Software, Jiangsu Engineering Centre of Network Monitoring, Nanjing University of Information Science and Technology, Nanjing, China; School of Computer and Software, Jiangsu Engineering Centre of Network Monitoring, Nanjing University of Information Science and Technology, Nanjing, China;" School of Computer and Software, Jiangsu Engineering Centre of Network Monitoring, Nanjing University of Information Science and Technology, Nanjing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2546"",""2559"",""In cloud computing, searchable encryption scheme over outsourced data is a hot research field. However, most existing works on encrypted search over outsourced cloud data follow the model of “one size fits all” and ignore personalized search intention. Moreover, most of them support only exact keyword search, which greatly affects data usability and user experience. So how to design a searchable encryption scheme that supports personalized search and improves user search experience remains a very challenging task. In this paper, for the first time, we study and solve the problem of personalized multi-keyword ranked search over encrypted data (PRSE) while preserving privacy in cloud computing. With the help of semantic ontology WordNet, we build a user interest model for individual user by analyzing the user's search history, and adopt a scoring mechanism to express user interest smartly. To address the limitations of the model of “one size fit all” and keyword exact search, we propose two PRSE schemes for different search intentions. Extensive experiments on real-world dataset validate our analysis and show that our proposed solution is very efficient and effective."",""1558-2183"","""",""10.1109/TPDS.2015.2506573"",""National Science Foundation of China(grant numbers:61373133,U1536206,61232016,U1405254,61502242,BK20150925)"; PAPD fund; Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology; Prospective Research Project; Future Networks of Jiangsu Future Networks Innovation Institute(grant numbers:BY2013095-4-10); US National Science Foundation(grant numbers:CNS-1262277);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7349214"",""Cloud security";outsourcing security;personalized search;"user interest model"",""Cloud computing";Indexes;Servers;Encryption;Computational modeling;"Search problems"","""",""554"","""",""35"",""IEEE"",""8 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Energy and Makespan Tradeoffs in Heterogeneous Computing Systems using Efficient Linear Programming Techniques,""K. M. Tarplee"; R. Friese; A. A. Maciejewski; H. J. Siegel;" E. K. P. Chong"",""Department of Electrical and Computer Engineering, Colorado State University, Fort Collins, CO"; Department of Electrical and Computer Engineering, Colorado State University, Fort Collins, CO; Department of Electrical and Computer Engineering, Colorado State University, Fort Collins, CO; Department of Electrical and Computer Engineering, Colorado State University, Fort Collins, CO;" Department of Electrical and Computer Engineering, Department of Mathematics Colorado State University Fort Collins, CO"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1633"",""1646"",""Resource management for large-scale high performance computing systems pose difficult challenges to system administrators. The extreme scale of these modern systems require task scheduling algorithms that are capable of handling at least millions of tasks and thousands of machines. These large computing systems consume vast amounts of electricity leading to high operating costs. System administrators try to simultaneously reduce operating costs and offer state-of-the-art performance";" however, these are often conflicting objectives. Highly scalable algorithms are necessary to schedule tasks efficiently and to help system administrators gain insight into energy/performance trade-offs of the system. System administrators can examine this trade-off space to quantify how much a difference in the performance level will cost in electricity, or analyze how much performance can be expected within an energy budget. In this study, we design a novel linear programming based resource allocation algorithm for a heterogeneous computing system to efficiently compute high quality solutions for simultaneously minimizing energy and makespan. These solutions are used to bound the Pareto front to easily trade-off energy and performance. The new algorithms are highly scalable in both solution quality and computation time compared to existing algorithms, especially as the problem size increases."",""1558-2183"","""",""10.1109/TPDS.2015.2456020"",""Sjostrom Family Scholarship"; Numerica Corporation; US National Science Foundation(grant numbers:CNS-0905399,CCF-1302693); NSF Graduate Research Fellowship; Colorado State University;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155583"",""High performance computing";scheduling;resource management;bag-of-tasks;energy-aware;heterogeneous computing;vector optimization;linear programming;High performance computing;scheduling;resource management;bag-of-tasks;energy-aware;heterogeneous computing;vector optimization;"linear programming"",""Approximation methods";Optimization;Linear programming;Power demand;Processor scheduling;Scheduling;"Multicore processing"","""",""35"","""",""39"",""IEEE"",""13 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;
"Engineering Parallel Algorithms for Community Detection in Massive Networks,""C. L. Staudt";" H. Meyerhenke"",""Faculty of Informatics, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany";" Faculty of Informatics, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""171"",""184"",""The amount of graph-structured data has recently experienced an enormous growth in many applications. To transform such data into useful information, fast analytics algorithms and software tools are necessary. One common graph analytics kernel is disjoint community detection (or graph clustering). Despite extensive research on heuristic solvers for this task, only few parallel codes exist, although parallelism will be necessary to scale to the data volume of real-world applications. We address the deficit in computing capability by a flexible and extensible community detection framework with shared-memory parallelism. Within this framework we design and implement efficient parallel community detection heuristics: A parallel label propagation scheme"; the first large-scale parallelization of the well-known Louvain method, as well as an extension of the method adding refinement;" and an ensemble scheme combining the above. In extensive experiments driven by the algorithm engineering paradigm, we identify the most successful parameters and combinations of these algorithms. We also compare our implementations with state-of-the-art competitors. The processing rate of our fastest algorithm often reaches 50 M edges/second. We recommend the parallel Louvain method and our variant with refinement as both qualitatively strong and fast. Our methods are suitable for massive data sets with billions of edges. (A preliminary version of this paper appeared in Proceedings of the 42nd International Conference on Parallel Processing (ICPP 2013) [35].)"",""1558-2183"","""",""10.1109/TPDS.2015.2390633"",""Parallel Analysis of Dynamic Networks"; Ministry of Science, Research and the Arts;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006796"",""Disjoint community detection";graph clustering;parallel Louvain method;parallel algorithm engineering;network analysis;Disjoint community detection;graph clustering;parallel Louvain method;parallel algorithm engineering;"network analysis"",""Communities";Clustering algorithms;Parallel processing;Algorithm design and analysis;Image edge detection;Instruction sets;"Software algorithms"","""",""101"","""",""37"",""IEEE"",""12 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Enhancing Collusion Resilience in Reputation Systems,""H. Shen"; Y. Lin; K. Sapra;" Z. Li"",""Department of Electrical and Computer Engineering, Clemson University, Clemson, SC"; Department of Electrical and Computer Engineering, Clemson University, Clemson, SC; Department of Electrical and Computer Engineering, Clemson University, Clemson, SC;" Department of Electrical and Computer Engineering, Clemson University, Clemson, SC"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2274"",""2287"",""Real-world applications, such as peer-to-peer (P2P) networks, e-commerce and social networks, usually employ reputation systems to provide guidance in selecting trustworthy node for high system reliability and security. A reputation system computes and publishes reputation score for each node based on a collection of opinions from others about the node. However, collusion behaviors impair the effectiveness of reputation systems in trustworthy node selection. Though many reputation calculation methods have been proposed to mitigate collusion's influence, little effort has been devoted to specifically tackling collusion. Based on the important collusion behavior characteristics in reputation evaluation and influence on reputation values, we propose a basic collusion detection method to specifically detect suspicious collusion behaviors in pairs. We further optimize the method by reducing the computing overhead. We also propose two pre-processing methods to firstly identify partial reputation raters of a node that are more likely to be colluders before applying the collusion detection method on them, thus reducing the collusion detection overhead. Extensive experimental results show that our proposed methods can significantly enhance the capability of existing reputation systems to detect collusion with low overhead. Also, the pre-processing methods are effective in reducing the collusion detection overhead without affecting the collusion detection accuracy."",""1558-2183"","""",""10.1109/TPDS.2015.2489198"",""US National Science Foundation(grant numbers:NSF-1404981,IIS-1354123,CNS-1254006,CNS-1249603)"; Microsoft Research Faculty Fellowship(grant numbers:8300751);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7295625"",""Reputation systems";trust systems;peer-to-peer networks;"collusion detection"",""Peer-to-peer computing";Nickel;Social network services;Complexity theory;Resilience;History;"Clustering algorithms"","""",""12"","""",""39"",""IEEE"",""9 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Evaluating Replication for Parallel Jobs: An Efficient Approach,""Z. Qiu";" J. F. Pérez"",""Department of Computing, United Kingdom";" School of Mathematics and Statistics, University of Melbourne, Australia"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2288"",""2302"",""Many modern software applications rely on parallel job processing to exploit large resource pools available in cloud and grid infrastructures. The response time of a parallel job, made of many subtasks, is determined by the last subtask that finishes. Thus, a single laggard subtask or a failure, requiring re-processing, may increase the response time substantially. To overcome these issues, we explore concurrent replication with canceling. This mechanism executes two job replicas concurrently, and retrieves the result of the first replica that completes, immediately canceling the other one. To analyze this mechanism we propose a stochastic model that considers replication at both job-level and task-level. We find that task-level replication achieves a much higher reliability and shorter response times than job-level replication. We also observe that the impact of replication depends on the system utilization, the subtask reliability, and the correlation among replica failures. Based on the model, we propose a resource-provisioning strategy that determines the minimum number of computing nodes needed to achieve a service-level objective (SLO) defined as a response-time percentile. This strategy is evaluated by considering realistic traffic patterns from a parallel cluster, where task-level replication shows the potential to reduce the resource requirements for tight response-time SLOs."",""1558-2183"","""",""10.1109/TPDS.2015.2496593"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7313012"",""Parallel-job processing";performance analysis;"quality of service"",""Time factors";Reliability;Correlation;Program processors;Computational modeling;Absorption;"Servers"","""",""12"","""",""32"",""IEEE"",""30 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Evaluation Criteria for Sparse Matrix Storage Formats,""D. Langr";" P. Tvrdík"",""Department of Computer Systems, Faculty of Information Technology, Czech Technical University in Prague, Praha, Czech Republic";" Department of Computer Systems, Faculty of Information Technology, Czech Technical University in Prague, Praha, Czech Republic"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""428"",""440"",""When authors present new storage formats for sparse matrices, they usually focus mainly on a single evaluation criterion, which is the performance of sparse matrix-vector multiplication (SpMV) in FLOPS. Though such an evaluation is essential, it does not allow to directly compare the presented format with its competitors. Moreover, in case that matrices are within an HPC application constructed in different formats, this criterion alone is not sufficient for the key decision whether or not to convert them into the presented format for the SpMV-based application phase. We establish ten evaluation criteria for sparse matrix storage formats, discuss their advantages and disadvantages, and provide general suggestions for format authors/evaluators to make their work more valuable for the HPC community."",""1558-2183"","""",""10.1109/TPDS.2015.2401575"",""Czech Science Foundation(grant numbers:P202/12/2011)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7036061"",""Evaluation criterion";matrix-vector multiplication;memory footprint;nonzero matrix structure;sparse matrix;storage format;test matrices;Evaluation criterion;matrix-vector multiplication;memory footprint;nonzero matrix structure;sparse matrix;storage format;"test matrices"",""Sparse matrices";Matrix converters;Indexes;Standards;Runtime;"Memory management"","""",""76"","""",""80"",""IEEE"",""9 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Evaluation of HPC Applications’ Memory Resource Consumption via Active Measurement,""M. Casas";" G. Bronevetsky"",""Barcelona Supercomputing Center, Technical University of Catalonia, Barcelona";" Google, Mountain View, CA"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2560"",""2573"",""As the number of compute cores per chip continues to rise faster than the total amount of available memory, applications will become increasingly starved for memory storage capacity and bandwidth, making the problem of performance optimization even more critical. Also, understanding and optimizing the usage of an increasing number of hierarchical memory levels and complex cache management policies is becoming a very hard task. We propose a methodology for measuring and modeling the performance of hierarchical memories in terms of the application's utilization of the key memory resources: capacity of a given memory level and bandwidth between two levels. This is done by actively interfering with the application's use of these resources. The application's sensitivity to reduced resource availability is measured by observing the effect of interference on application performance. The resulting resource-oriented model of performance both greatly simplifies application performance analysis and makes it possible to predict an application's performance when running with various resource constraints. This is useful to predict performance for future memory-constrained architectures. This paper applies the proposed methodology to six important and well known High Performance Computing (HPC) codes to show the strength and the potential of analysis based on resource-oriented measurements."",""1558-2183"","""",""10.1109/TPDS.2015.2506563"",""European Research Council"; European Union’s 7th FP(grant numbers:FP/2007-2013); ERC(grant numbers:321253); Secretary for Universities; Research of the Ministry of Economy; Knowledge of the Government of Catalonia; Marie Curie Actions of the 7th R&D Framework Programme; European Union(grant numbers:2013 BP_B 00243);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7349236"",""Multi-core architectures";memory hierarchy;"performance analysis"",""Interference";Memory management;Bandwidth;Instruction sets;Hardware;Optimization;"Performance analysis"","""",""3"","""",""36"",""IEEE"",""8 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Evolutionary Multi-Objective Workflow Scheduling in Cloud,""Z. Zhu"; G. Zhang; M. Li;" X. Liu"",""Department of Computer Science, Brunel University London, Uxbridge, United Kingdom"; School of Computer and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu, China; Department of Computer Science, Brunel University London, Uxbridge, United Kingdom;" Department of Computer Science, Brunel University London, Uxbridge, United Kingdom"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1344"",""1357"",""Cloud computing provides promising platforms for executing large applications with enormous computational resources to offer on demand. In a Cloud model, users are charged based on their usage of resources and the required quality of service (QoS) specifications. Although there are many existing workflow scheduling algorithms in traditional distributed or heterogeneous computing environments, they have difficulties in being directly applied to the Cloud environments since Cloud differs from traditional heterogeneous environments by its service-based resource managing method and pay-per-use pricing strategies. In this paper, we highlight such difficulties, and model the workflow scheduling problem which optimizes both makespan and cost as a Multi-objective Optimization Problem (MOP) for the Cloud environments. We propose an evolutionary multi-objective optimization (EMO)-based algorithm to solve this workflow scheduling problem on an infrastructure as a service (IaaS) platform. Novel schemes for problem-specific encoding and population initialization, fitness evaluation and genetic operators are proposed in this algorithm. Extensive experiments on real world workflows and randomly generated workflows show that the schedules produced by our evolutionary algorithm present more stability on most of the workflows with the instance-based IaaS computing and pricing models. The results also show that our algorithm can achieve significantly better solutions than existing state-of-the-art QoS optimization scheduling algorithms in most cases. The conducted experiments are based on the on-demand instance types of Amazon EC2";" however, the proposed algorithm are easy to be extended to the resources and pricing models of other IaaS services."",""1558-2183"","""",""10.1109/TPDS.2015.2446459"",""National Science Foundation of China(grant numbers:61272420)"; Provincial Science Foundation of Jiangsu(grant numbers:BK2011022);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7127017"",""Cloud computing";Infrastructure as a Service;multi-objective optimization;evolutionary algorithm;workflow scheduling;Cloud computing;infrastructure as a service;multi-objective optimization;evolutionary algorithm;"workflow scheduling"",""Pricing";Schedules;Scheduling;Processor scheduling;Encoding;Quality of service;"Computational modeling"","""",""281"","""",""43"",""IEEE"",""17 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;
"Exploiting Analytics Shipping with Virtualized MapReduce on HPC Backend Storage Servers,""C. Xu"; R. Goldstone; Z. Liu; H. Chen; B. Neitzel;" W. Yu"",""Auburn University, Auburn, AL, USA"; Lawrence Livermore National Lab, Livermore, CA, USA; Auburn University, Auburn, AL, USA; Auburn University, Auburn, AL, USA; Intel, Santa Clara, CA, USA;" Auburn University, Auburn, AL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""185"",""196"",""Large-scale scientific applications on High-Performance Computing (HPC) systems are generating a colossal amount of data that need to be analyzed in a timely manner for new knowledge, but are too costly to transfer due to their sheer size. Many HPC systems have catered to in situ analytics solutions that can analyze temporary datasets as they are generated, i.e., without storing to long-term storage media. However, there is still an open question on how to conduct efficient analytics of permanent datasets that have been stored to the backend persistent storage because of their long-term value. To fill the void, we exploit the analytics shipping model for fast analysis of large-scale scientific datasets on HPC backend storage servers. Through an efficient integration of MapReduce and the popular Lustre storage system, we have developed a Virtualized Analytics Shipping (VAS) framework that can ship MapReduce programs to Lustre storage servers. The VAS framework includes three component techniques: (a) virtualized analytics shipping with fast network and disk I/O";" (b) stripe-aligned data distribution and task scheduling and (c) pipelined intermediate data merging and reducing. The first technique provides necessary isolation between MapReduce analytics and Lustre I/O services. The second and third techniques optimize MapReduce on Lustre and avoid explicit shuffling. Our performance evaluation demonstrates that VAS offers an exemplary implementation of analytics shipping and delivers fast and virtualized MapReduce programs on backend Lustre storage servers."",""1558-2183"","""",""10.1109/TPDS.2015.2389262"",""Intel and Lawrence Livermore National Laboratory"; NSF(grant numbers:1059376,1320016,1340947,1432892);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004064"",""Analytics Shipping";Hadoop;MapReduce;HPC;Lustre;Analytics shipping;hadoop;mapreduce;HPC;"lustre"",""Servers";Yarn;Bandwidth;Interference;Analytical models;Merging;"Computational modeling"","""",""7"",""1"",""31"",""IEEE"",""7 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;
"Exploiting Parallelism of Imperfect Nested Loops on Coarse-Grained Reconfigurable Architectures,""S. Yin"; X. Lin; L. Liu;" S. Wei"",""Institute of Microelectronics, Tsinghua University, Beijing, China"; Institute of Microelectronics, Tsinghua University, Beijing, China; National laboratory for Information, Science and Technology, Institute of Microelectronics, Tsinghua University, Beijing, China;" Institute of Microelectronics, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3199"",""3213"",""Coarse-grained reconfigurable architecture (CGRA) is a promising parallel computing platform that provides high performance, high power efficiency and flexibility. However, for imperfect nested loops, the existing loop mapping methods often result in low execution performance and poor hardware utilization. To tackle this problem, this paper makes three contributions: 1) a highly effective and general approach to map imperfect loops on CGRA"; 2) a global optimization strategy to search the optimal initiation intervals (IIs);" 3) a powerful kernel compression method to reduce the oversized kernel. Experiment results show that our approach can reduce the total computing latency by 20.5, 58.5 and 73.2 percent compared to the state-of-the-art approaches on $2 \times 2$ ,  $4 \times 4$  and  $8 \times 8$  CGRA respectively. Moreover, the compilation time and configuration context size is acceptable in practice."",""1558-2183"","""",""10.1109/TPDS.2016.2531678"",""NNSF(grant numbers:61274131)"; China National High Technologies Research Program(grant numbers:2015AA016601,2012AA012701,2012AA010904); China S&T Major Project(grant numbers:2013ZX01033001-001-003); Importation and Development of High-Caliber Talents Project(grant numbers:YETP0163);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412757"",""CGRA";software pipelining;imperfect nested loop;sibling inner loops;outer-level pipelining;"kernel compression"",""Pipeline processing";Kernel;Context;Computer architecture;"Field programmable gate arrays"","""",""11"","""",""34"",""IEEE"",""18 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Exploiting Redundancy and Application Scalability for Cost-Effective, Time-Constrained Execution of HPC Applications on Amazon EC2,""A. Marathe"; R. Harris; D. K. Lowenthal; B. R. de Supinski; B. Rountree;" M. Schulz"",""Lawrence Livermore National Laboratory, Livermore, CA"; Google Corporation, Mountain View, CA; Department of Computer Science, The University of Arizona, Tucson, AZ; Lawrence Livermore National Laboratory, Livermore, CA; Lawrence Livermore National Laboratory, Livermore, CA;" Lawrence Livermore National Laboratory, Livermore, CA"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2574"",""2588"",""The use of clouds to execute high-performance computing (HPC) applications has greatly increased recently. Clouds provide several potential advantages over traditional supercomputers and in-house clusters. The most popular cloud is currently Amazon EC2, which provides fixed-cost and variable-cost, auction-based options. The auction market trades lower cost for potential interruptions that necessitate checkpointing";" if the market price exceeds the bid price, a node is taken away from the user without warning. We explore techniques to maximize performance per dollar given a time constraint within which an application must complete. Specifically, we design and implement multiple techniques to reduce expected cost by exploiting redundancy in the EC2 auction market. We then design an adaptive algorithm that selects a scheduling algorithm and determines the bid price. We show that our adaptive algorithm executes programs up to seven times cheaper than using the on-demand market and up to 44 percent cheaper than the best non-redundant, auction-market algorithm. We extend our adaptive algorithm to incorporate application scalability characteristics for further cost savings. We show that the adaptive algorithm informed with scalability characteristics of applications achieves up to 56 percent cost savings compared to the expected cost for the base adaptive algorithm run at a fixed, user-defined scale."",""1558-2183"","""",""10.1109/TPDS.2015.2508457"",""U.S. Department of Energy"; Lawrence Livermore National Laboratory(grant numbers:DE-AC52-07NA27344,LLNL-JRNL-676899); National Science Foundation(grant numbers:1216829);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7355374"",""Fault tolerance";reliability;cloud computing;resource provisioning;"cost optimization"",""Adaptive algorithms";Redundancy;Scalability;Laboratories;Computational modeling;Checkpointing;"Resource management"","""",""12"","""",""29"",""IEEE"",""17 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;
"Exploiting Workload Characteristics and Service Diversity to Improve the Availability of Cloud Storage Systems,""B. Mao"; S. Wu;" H. Jiang"",""Software School of Xiamen University, Xiamen, Fujian, China"; Computer Science Department of Xiamen University, Xiamen, Fujian, China;" Department of Computer Science & Engineering at the University of Texas at Arlington, Department of Computer Science & Engineering at the University of Nebraska-Lincoln"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""2010"",""2021"",""With the increasing utilization and popularity of the cloud infrastructure, more and more data are moved to the cloud storage systems. This makes the availability of cloud storage services critically important, particularly given the fact that outages of cloud storage services have indeed happened from time to time. Thus, solely depending on a single cloud storage provider for storage services can risk violating the service-level agreement (SLA) due to the weakening of service availability. This has led to the notion of Cloud-of-Clouds, where data redundancy is introduced to distribute data among multiple independent cloud storage providers, to address the problem. The key in the effectiveness of the Cloud-of-Clouds approaches lies in how the data redundancy is incorporated and distributed among the clouds. However, the existing Cloud-of-Clouds approaches utilize either replication or erasure codes to redundantly distribute data across multiple clouds, thus incurring either high space or high performance overheads. In this paper, we propose a hybrid redundant data distribution approach, called HyRD, to improve the cloud storage availability in Cloud-of-Clouds by exploiting the workload characteristics and the diversity of cloud providers. In HyRD, large files are distributed in multiple cost-efficient cloud storage providers with erasure-coded data redundancy while small files and file system metadata are replicated on multiple high-performance cloud storage providers. The experiments conducted on our lightweight prototype implementation of HyRD show that HyRD improves the cost efficiency by 33.4 and 20.4 percent, and reduces the access latency by 58.7 and 34.8 percent than the DuraCloud and RACS schemes, respectively."",""1558-2183"","""",""10.1109/TPDS.2015.2475273"",""National Natural Science Foundation of China(grant numbers:61100033,61472336,61402385)"; US National Science Foundation(grant numbers:NSF-CNS-1116606,NSF-CNS-1016609); National Key Technology R&D Program Foundation of China(grant numbers:2015BAH16F02); Fundamental Research Funds for the Central Universities(grant numbers:20720140515);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7234928"",""Cloud-of-Clouds";Replication;Erasure Codes;Dependability;Cost Efficiency;Cloud-of-clouds;replication;erasure codes;availability;"cost efficiency"",""Cloud computing";Redundancy;Switches;Bandwidth;Distributed databases;"Performance evaluation"","""",""16"","""",""45"",""IEEE"",""1 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Exploring Heterogeneity within a Core for Improved Power Efficiency,""S. Srinivasan"; N. Kurella; I. Koren;" S. Kundu"",""Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA"; Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA; Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA;" Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1057"",""1069"",""Asymmetric multi-core processors (AMPs) comprise cores with different sizes of micro-architectural resources yielding very different performance and energy characteristics. Since the computational demands of workloads vary from one task to the other, AMPs can often provide a higher power efficiency than symmetric multi-cores. Furthermore, as the computational demands of a task change during its course of execution, reassigning the task from one core to another, where it can run more efficiently, can further improve the overall power efficiency. However, too frequent re-assignments of tasks to cores may result in high overhead. To greatly reduce this overhead, we propose a morphable core architecture that can dynamically adapt its resource sizes, operating frequency and voltage to assume one of four possible core configurations. Such a morphable architecture allows more frequent task to core configuration re-assignments for a better match between the current needs of the task and the available resources. To make the online morphing decisions we have developed a runtime analysis scheme that uses hardware performance counters. Our results indicate that the proposed morphable architecture controlled by the runtime management scheme, can improve the throughput/Watt of applications by 31 percent over executing on a static out-of-order core while the previously proposed big/little morphable architecture achieves only a 17 percent improvement."",""1558-2183"","""",""10.1109/TPDS.2015.2430861"",""National Science Foundation(grant numbers:0903191,1201834)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7103357"",""Asymmetric multi-core processors";Hardware Performance Counters;Morphable core;Design space exploration;Online morphing;Asymmetric multi-core processors;hardware performance counters;morphable core;design space exploration;"online morphing"",""Multicore processing";Out of order;Switches;Benchmark testing;Space exploration;"Runtime"","""",""8"","""",""34"",""IEEE"",""7 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Exploring the Design Tradeoffs for Extreme-Scale High-Performance Computing System Software,""K. Wang"; A. Kulkarni; M. Lang; D. Arnold;" I. Raicu"",""Department of Computer Science, Illinois Institute of Technology, Chicago, IL"; Department of Computer Science, Indiana University, Bloomington, IN; Los Alamos National Laboratory, Los Alamos, NM; Department of Computer Science, University of New Mexico, Albuquerque, NM;" Department of Computer Science, Illinois Institute of Technology, Chicago, IL"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1070"",""1084"",""Owing to the extreme parallelism and the high component failure rates of tomorrow's exascale, high-performance computing (HPC) system software will need to be scalable, failure-resistant, and adaptive for sustained system operation and full system utilizations. Many of the existing HPC system software are still designed around a centralized server paradigm and hence are susceptible to scaling issues and single points of failure. In this article, we explore the design tradeoffs for scalable system software at extreme scales. We propose a general system software taxonomy by deconstructing common HPC system software into their basic components. The taxonomy helps us reason about system software as follows: (1) it gives us a systematic way to architect scalable system software by decomposing them into their basic components";" (2) it allows us to categorize system software based on the features of these components, and finally (3) it suggests the configuration space to consider for design evaluation via simulations or real implementations. Further, we evaluate different design choices of a representative system software, i.e. key-value store, through simulations up to millions of nodes. Finally, we show evaluation results of two distributed system software, Slurm++ (a distributed HPC resource manager) and MATRIX (a distributed task execution framework), both developed based on insights from this work. We envision that the results in this article help to lay the foundations of developing next-generation HPC system software for extreme scales."",""1558-2183"","""",""10.1109/TPDS.2015.2430852"",""U.S. Department of Energy(grant numbers:DE-FC02-06ER25750)"; US National Science Foundation(grant numbers:CNS-1042543); National Science Foundation(grant numbers:NSF-1054974); Office of Science; U.S. Department of Energy(grant numbers:DEAC02-06CH11357);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7103354"",""Distributed systems";high-performance computing;key-value stores;simulation;systems and software;Distributed systems;high-performance computing;key-value stores;simulation;"systems and software"",""Servers";System software;Data models;Distributed databases;Taxonomy;"Memory management"","""",""10"","""",""59"",""IEEE"",""7 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;
"F2C: Enabling Fair and Fine-Grained Resource Sharing in Multi-Tenant IaaS Clouds,""H. Liu";" B. He"",""Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China";" Nanyang Technological University, Singapore"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2589"",""2602"",""This paper presents F2C, a cooperative resource management system for Infrastructure-as-a-Service (IaaS) clouds. Inspired by group-buying mechanisms in real product and service markets, F2C advocates a group of cloud tenants (called tenant coalition) to buy resource capacity in bulk and share the resource pool in the form of virtual machines (VMs). Tenant coalitions leads to vast opportunities for fine-grained resource sharing among multiple tenants. However, resource sharing, especially for multiple resource types, poses several challenging problems in pay-as-you-use cloud environments, such as sharing incentive, free-riding, lying and economic fairness. To address those problems, we propose Reciprocal Resource Fairness (RRF) , a novel resource allocation mechanism to enable fair sharing on multiple resource types within a tenant coalition. RRF is implemented in two complementary and hierarchical mechanisms: inter-tenant resource trading and intra-tenant weight adjustment. RRF satisfies several highly desirable properties to ensure fairness. We implement F2C in Xen platform. The experimental results show F2C is promising for both cloud providers and tenants. For cloud providers, F2C improves VM density and cloud providers' revenue by 2.2X compared to the current IaaS cloud models. For tenants, F2C improves application performance by 45 percent and guarantees 95 percent economic fairness among multiple tenants."",""1558-2183"","""",""10.1109/TPDS.2015.2499769"",""NSFC(grant numbers:61300040)"; Singapore National Research Foundation(grant numbers:1002-IRIS-09); Environmental & Water Technologies Strategic Research Programme; Environment & Water Industry Programme Office (EWI); PUB;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7327230"",""Cloud computing";fairness;IaaS;resource sharing;"virtual machine"",""Resource management";Cloud computing;Indexes;Biological system modeling;Random access memory;Economics;"Memory management"","""",""20"","""",""46"",""IEEE"",""11 Nov 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Fast Compression of Large Semantic Web Data Using X10,""L. Cheng"; A. Malik; S. Kotoulas; T. E. Ward;" G. Theodoropoulos"",""Faculty of Computer Science, TU Dresden, Germany"; Department of Electrical & Computer Engineering, University of Auckland, New Zealand; IBM Research, Dublin, Ireland; Department of Electronic Engineering, National University of Ireland Maynooth, Ireland;" Institute of Advanced Research Computing, Durham University, UK"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2603"",""2617"",""The Semantic Web comprises enormous volumes of semi-structured data elements. For interoperability, these elements are represented by long strings. Such representations are not efficient for the purposes of applications that perform computations over large volumes of such information. A common approach to alleviate this problem is through the use of compression methods that produce more compact representations of the data. The use of dictionary encoding is particularly prevalent in Semantic Web database systems for this purpose. However, centralized implementations present performance bottlenecks, giving rise to the need for scalable, efficient distributed encoding schemes. In this paper, we propose an efficient algorithm for fast encoding large Semantic Web data. Specially, we present the detailed implementation of our approach based on the state-of-art asynchronous partitioned global address space (APGAS) parallel programming model. We evaluate performance on a cluster of up to 384 cores and datasets of up to 11 billion triples (1.9 TB). Compared to the state-of-art approach, we demonstrate a speed-up of  $2.6 - 7.4\times$  and excellent scalability. In the meantime, these results also illustrate the significant potential of the APGAS model for efficient implementation of dictionary encoding and contributes to the engineering of more efficient, larger scale Semantic Web applications."",""1558-2183"","""",""10.1109/TPDS.2015.2496579"",""DFG"; DIAMOND(grant numbers:KR 4381/1-1); HAEC(grant numbers:CRC 912);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7313002"",""RDF";parallel compression;dictionary encoding;X10;"HPC"",""Encoding";Resource description framework;Dictionaries;Distributed databases;Electronic mail;"Algorithm design and analysis"","""",""9"","""",""44"",""IEEE"",""30 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Fast Consensus Using Bounded Staleness for Scalable Read-Mostly Synchronization,""H. Chen"; H. Zhang; R. Liu; B. Zang;" H. Guan"",""Shanghai Key Laboratory for Scalable Computing and Systems, Shanghai Jiao Tong University, Shanghai, China"; Shanghai Key Laboratory for Scalable Computing and Systems, Shanghai Jiao Tong University, Shanghai, China; Shanghai Key Laboratory for Scalable Computing and Systems, Shanghai Jiao Tong University, Shanghai, China; Shanghai Key Laboratory for Scalable Computing and Systems, Shanghai Jiao Tong University, Shanghai, China;" Shanghai Key Laboratory for Scalable Computing and Systems, Shanghai Jiao Tong University, Shanghai, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3485"",""3500"",""Reader-mostly synchronization schemes, such as rwlocks and RCU, aim to maximize parallelism among readers, but many existing designs either cause readers to contend, or significantly extend writer latency, or both. This paper attributes such a problem to the lack of a fast consensus protocol between readers and writers, by which the two parts cooperate to obey the semantics of a synchronization construct. This paper describes FCP, a fast consensus protocol among readers and writers that provides scalable read-side performance as well as small writer latency for TSO architectures. The heart of FCP is a version-based consensus protocol between multiple non-communicating readers and a pending writer. FCP leverages bounded staleness of memory consistency to avoid atomic instructions and memory barriers in readers' common paths, and uses message-passing (e.g., IPI) for straggling readers so that the writer latency can be bounded. To demonstrate the effectiveness of FCP, this paper applies FCP to construct a scalable reader-writers lock (rwlock) and a scalable RCU implementation. Evaluation on a 64-core machine shows that FCP significantly boosts the performance of the Linux virtual memory subsystem, a concurrent hashtable and an in-memory database. Micro-benchmarks show that FCP achieves smaller reader-side latency and lower writer-side latency when compared to state-of-the-art rwlocks and RCU implementation."",""1558-2183"","""",""10.1109/TPDS.2016.2539953"",""China National Natural Science Foundation(grant numbers:61572314)"; National Youth Top-notch Talent Support Program of China;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429771"",""Consensus";reader-mostly synchronization;reader-writer lock;"RCU"",""Access control";Synchronization;Semantics;Scalability;"Protocols"","""",""2"","""",""35"",""IEEE"",""9 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Fast Online Set Intersection for Network Processing on FPGA,""Y. R. Qu";" V. K. Prasanna"",""Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA";" Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3214"",""3225"",""Online set intersection operations have been widely used in network processing tasks, such as Quality of Service differentiation, firewall processing, and packet/traffic classification. The major challenge for online set intersection is to sustain line-rate processing speed"; accelerating set intersection using state-of-the-art hardware devices is of great interest to the research community. In this paper, we present a novel high-performance set intersection approach on FPGA. In our approach, each element in any set is represented by a combination of Group ID (GID) and Bit Stride (BS); all the sets are intersected using linear merge techniques and bitwise AND operations. We map our online set intersection algorithm onto hardware;" this is done by constructing modular Processing Element (PE) and concatenating multiple PEs into a tree-based parallel architecture. In order to improve the throughput on a state-of-the-art FPGA, we feed all the inputs to FPGA in a streaming fashion with the help of the synchronization GIDs. Post place-and-route results show that, for a typical set intersection problem in network processing, our design can intersect $\text{eight}$  sets, each of up to  $32$ K elements, at a throughput of  $47.4$  Thousand Intersections Per Second (KIPS) and a latency of  $94.8\,\mu$ s per batch of inputs. Compared to the classic linear merge or bitwise AND techniques on state-of-the-art multi-core processors, our designs on FPGA achieves up to  $66\times$  throughput improvement and $80\times$  latency reduction."",""1558-2183"","""",""10.1109/TPDS.2016.2537818"",""U.S. National Science Foundation(grant numbers:CCF-1116781,CCF-1320211)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425232"",""Set intersection";network processing;"field-programmable gate array (FPGA)"",""Field programmable gate arrays";Memory management;Hardware;Engines;Throughput;Indexes;"Data structures"","""",""3"","""",""22"",""IEEE"",""3 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Fault-Tolerant Scheduling for Real-Time Scientific Workflows with Elastic Resource Provisioning in Virtualized Clouds,""X. Zhu"; J. Wang; H. Guo; D. Zhu; L. T. Yang;" L. Liu"",""Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, Hunan, P. R. China"; Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, Hunan, P. R. China; School of Computer Science and Engineering, University of New South Wales, NSW, Australia; Department of Computer Science, The University of Texas at San Antonio, San Antonio, TX; Department of Computer Science, St. Francis Xavier University, Antigonish, NS, Canada;" College of Computing, Georgia Institute of Technology, 266 Ferst Drive, Atlanta, GA"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3501"",""3517"",""Clouds are becoming an important platform for scientific workflow applications. However, with many nodes being deployed in clouds, managing reliability of resources becomes a critical issue, especially for the real-time scientific workflow execution where deadlines should be satisfied. Therefore, fault tolerance in clouds is extremely essential. The PB (primary backup) based scheduling is a popular technique for fault tolerance and has effectively been used in the cluster and grid computing. However, applying this technique for real-time workflows in a virtualized cloud is much more complicated and has rarely been studied. In this paper, we address this problem. We first establish a real-time workflow fault-tolerant model that extends the traditional PB model by incorporating the cloud characteristics. Based on this model, we develop approaches for task allocation and message transmission to ensure faults can be tolerated during the workflow execution. Finally, we propose a dynamic fault-tolerant scheduling algorithm, FASTER, for realtime workflows in the virtualized cloud. FASTER has three key features: 1) it employs a backward shifting method to make full use of the idle resources and incorporates task overlapping and VM migration for high resource utilization, 2) it applies the vertical/horizontal scaling-up technique to quickly provision resources for a burst of workflows, and 3) it uses the vertical scaling-down scheme to avoid unnecessary and ineffective resource changes due to fluctuated workflow requests. We evaluate our FASTER algorithm with synthetic workflows and workflows collected from the real scientific and business applications and compare it with six baseline algorithms. The experimental results demonstrate that FASTER can effectively improve the resource utilization and schedulability even in the presence of node failures in virtualized clouds."",""1558-2183"","""",""10.1109/TPDS.2016.2543731"",""National Natural Science Foundation of China(grant numbers:61572511,61403402,11428101)"; Hunan Provincial Natural Science Foundation of China(grant numbers:2015JJ3023); Southwest Electron & Telecom Technology Institute(grant numbers:2015014); NSF; CISE(grant numbers:1564097,1230740,1115375,0905493);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435325"",""Virtualized clouds";fault-tolerant scheduling;primary-backup model;overlapping;"VM migration"",""Fault tolerant systems";Cloud computing;Real-time systems;Processor scheduling;Dynamic scheduling;"Resource management"","""",""102"","""",""29"",""IEEE"",""17 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;
"FPGA Hardware Acceleration of Monte Carlo Simulations for the Ising Model,""F. Ortega-Zamorano"; M. A. Montemurro; S. A. Cannas; J. M. Jerez;" L. Franco"",""Departamento de Lenguajes y Ciencias de la Computación, Universidad de Málaga, Campus de Teatinos S/N, Málaga, Spain"; Department of Life Sciences, University of Manchester, Manchester, U.K; Facultad de Matemática, Astronomía y Física (IFEG-CONICET), Universidad Nacional de Córdoba, Córdoba, Argentina; Departamento de Lenguajes y Ciencias de la Computación, Universidad de Málaga, Campus de Teatinos S/N, Málaga, Spain;" Departamento de Lenguajes y Ciencias de la Computación, Universidad de Málaga, Campus de Teatinos S/N, Málaga, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2618"",""2627"",""A two-dimensional Ising model with nearest-neighbors ferromagnetic interactions is implemented in a Field Programmable Gate Array (FPGA) board. Extensive Monte Carlo simulations were carried out using an efficient hardware representation of individual spins and a combined global-local LFSR random number generator. Consistent results regarding the descriptive properties of magnetic systems, like energy, magnetization and susceptibility are obtained while a speed-up factor of approximately six times is achieved in comparison to previous FPGA-based published works and almost $10^4$  times in comparison to a standard CPU simulation. A detailed description of the logic design used is given together with a careful analysis of the quality of the random number generator used. The obtained results confirm the potential of FPGAs for analyzing the statistical mechanics of magnetic systems."",""1558-2183"","""",""10.1109/TPDS.2015.2505725"",""Junta de Andalucia(grant numbers:P10-TIC-5770)"; MICIIN(grant numbers:TIN2010-16556,TIN2014-58516-c2-1-R); CONICET(grant numbers:PIP11220110100213);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7347434"",""Hardware implementation";LFSR random number generator;Monte Carlo simulations;"Ising model"",""Field programmable gate arrays";Lattices;Hardware;Monte Carlo methods;Magnetic susceptibility;Computational modeling;"Analytical models"","""",""11"","""",""42"",""IEEE"",""4 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Freeweb: P2P-Assisted Collaborative Censorship-Resistant Web Browsing,""H. Shen"; A. X. Liu; G. Liu;" L. Zhao"",""Department of Electrical and Computer Engineering, Clemson University, Clemson, SC"; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI; Department of Electrical and Computer Engineering, Clemson University, Clemson, SC;" Department of Electrical and Computer Engineering, Clemson University, Clemson, SC"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3226"",""3241"",""In many countries, the Internet is under stringent censorship for political or religious reasons which severely undermines the free flow of information. A censorship-resistant web browsing system must be scalable, blocking resistant, and tracing resistant. However, current censorship-resistant web browsing systems, which use a group of dedicated proxies to bypass censorship, fail to meet these requirements. To tackle these challenges, we propose Freeweb, which relies on widely-distributed peer-to-peer (P2P) nodes in a decentralized manner rather than specified proxies in a centralized manner. We also proposed enhancement methods to reduce file access delay and avoid node overloads in Freeweb. Freeweb is built on top of a Distributed Hash Table (DHT)-based P2P network, where nodes not under censorship help nodes under censorship to access blocked webpages. Freeweb has a web browser front-end whose user interface resembles existing web browsers. The underlying complex process of retrieving blocked webpages is therefore hidden from users. We implemented an open-sourced Freeweb and conducted extensive real-world experiments on PlanetLab. The experimental results show that Freeweb has a high success rate and reasonable browsing latency, and its enhancement reduces much network load and file access latency, and avoids node overloads."",""1558-2183"","""",""10.1109/TPDS.2015.2468227"",""US National Science Foundation(grant numbers:CNS-1254006,CNS-1249603,CNS-1049947,CNS-0917056,CNS-1025652,CNS-0845513,CNS-1017598,CNS-1017588)"; Microsoft Research Faculty Fellowship(grant numbers:8300751); National Natural Science Foundation of China(grant numbers:61472184,61321491,61272546); Jiangsu Future Internet Program(grant numbers:BY2013095-4-08); Future Network Futuristic Research Program; Jiangsu Future Networks Innovation Institute; Jiangsu High-level Innovation & Entrepreneurship;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194820"",""Censorship-resistance";web browsing;peer-to-peer network;"distributed hash table"",""Peer-to-peer computing";Servers;Uniform resource locators;IP networks;Censorship;Resistance;"Cryptography"","""",""2"","""",""57"",""IEEE"",""13 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"GBC3: A Versatile Cube-Based Server-Centric Network for Data Centers,""Z. Li";" Y. Yang"",""Department of Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY";" Department of Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2895"",""2910"",""A new network structure called BCube Connected Crossbars (BCCC) was recently proposed. Its short diameter, good expandability and low cost make it a very promising topology for data center networks. However, it can utilize only two NIC ports of each server, which is suitable for nowadays technology, even though more NIC ports are available. Due to technology advances, servers with more NIC ports are emerging and they will become low-cost commodities some time later. In this paper, we propose a more general server-centric data center network structure, called GBC3, which can utilize inexpensive commodity off-the-shelf switches and servers with any fixed number of NIC ports and provide good network properties. Like BCCC, GBC3 has good expandability. When doing expansion, there is no need to alter the existing system but only to add new components into it. Thus the expansion cost that BCube suffers from can be significantly reduced in GBC3. We also introduce an addressing scheme and several efficient routing algorithms for one-to-one, one-to-all and one-to-many communications in GBC3 respectively. We make comprehensive comparisons between GBC3 and some popular existing structures in terms of several critical metrics, such as diameter, network size, bisection bandwidth and capital expenditure. We also conduct extensive experiments to evaluate GBC3, which show that GBC3 achieves the best flexibility to make tradeoff among all these critical metrics and it can suit for many different applications by fine tuning its parameters."",""1558-2183"","""",""10.1109/TPDS.2015.2511725"",""U.S. National Science Foundation(grant numbers:CCF-1526162)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364277"",""Data center networks";server-centric;network diameter;topology;"expandability"",""Servers";Ports (Computers);Routing;Network topology;Hypercubes;Topology;"Hardware"","""",""24"","""",""28"",""IEEE"",""23 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"GCA:Global Congestion Awareness for Load Balance in Networks-on-Chip,""M. Ramakrishna"; V. K. Kodati; P. V. Gratz;" A. Sprintson"",""Department of Electrical and Computer Engineering, Texas A&M University, College Station, Texas"; Department of Electrical and Computer Engineering, Texas A&M University, College Station, Texas; Department of Electrical and Computer Engineering, Texas A&M University, College Station, Texas;" Department of Electrical and Computer Engineering, Texas A&M University, College Station, Texas"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""2022"",""2035"",""As modern CMPs scale to ever increasing core counts, Networks-on-Chip (NoCs) are emerging as an interconnection fabric, enabling communication between components. While NoCs provide high and scalable bandwidth, current routing algorithms, such as dimension-ordered routing, suffer from poor load balance, leading to reduced throughput and high latencies. Improving load balance, hence, is critical in future CMP designs where increased latency leads to wasted power and energy waiting for outstanding requests to resolve. Adaptive routing is a known technique to improve load balance, however, prior adaptive routing techniques either use local or regionally-aggregated information to form their routing decisions. This paper proposes a new, light-weight, adaptive routing algorithm for on-chip routers based on global link state and congestion information, Global Congestion Awareness (GCA). GCA uses a simple, low-complexity route calculation unit, to calculate paths to their destination without the myopia of local decisions, nor the aggregation of unrelated status information, found in prior designs. In particular GCA outperforms local adaptive routing by 26 percent, Regional Congestion Awareness (RCA) by 15 percent, and a recent competing adaptive routing algorithm, DAR, by 8 percent on average on realistic workloads."",""1558-2183"","""",""10.1109/TPDS.2015.2477840"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7254220"",""GCA";Congestion awareness;Adaptive routing;Network-on-Chip;Load balancing;GCA;congestion awareness;adaptive routing;network-on-chip;"load balancing"",""Routing";Ports (Computers);Adaptive systems;Algorithm design and analysis;Measurement;Silicon;"Complexity theory"","""",""32"","""",""21"",""IEEE"",""10 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Global Fixed Priority Scheduling with Preemption Threshold: Schedulability Analysis and Stack Size Minimization,""C. Wang"; Z. Gu;" H. Zeng"",""College of Computer Science, Zhejiang University, Hangzhou, China"; College of Computer Science, Zhejiang University, Hangzhou, China;" Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3242"",""3255"",""Memory is a limited resource in cost-sensitive, resource-constrained embedded applications. Preemption Threshold Scheduling (PTS) is a well-known technique for reducing the system stack size requirement. We consider Global Fixed Priority Scheduling with Preemption Threshold (gFPPT), as integration of PTS with global Fixed-Priority scheduling on a homogeneous multiprocessor platform, and formulate the optimization problem of minimizing the system stack size requirement while guaranteeing schedulability. We present schedulability analysis, optimization algorithms for priority and preemption threshold assignment, and an ILP formulation for computing system stack size requirement. Performance evaluation shows that the system stack size requirement can be reduced significantly with gFPPT compared to preemptive scheduling."",""1558-2183"","""",""10.1109/TPDS.2016.2528978"",""National Natural Science Foundation of China(grant numbers:61272127,61471165)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7405349"",""Real-time scheduling";real-time embedded systems;preemption threshold scheduling;"global multiprocessor scheduling"",""Processor scheduling";Job shop scheduling;Algorithm design and analysis;Runtime;Optimization;"Automotive engineering"","""",""21"","""",""20"",""IEEE"",""11 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"GMU: Genuine Multiversion Update-Serializable Partial Data Replication,""S. Peluso"; P. Ruivo; P. Romano; F. Quaglia;" L. Rodrigues"",""ECE Department, Virginia Tech, Blacksburg, Virginia, USA"; Red Hat Inc, Dublin, Ireland; INESC-ID, Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal; Dipartimento di Ingegneria Informatica, Automatica, e Gestionale, Sapienza University of Rome, Italy;" INESC-ID, Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2911"",""2925"",""In this article we introduce GMU, a genuine partial replication protocol for transactional systems, which exploits an innovative, highly scalable, distributed multiversioning scheme. Unlike existing multiversion-based solutions, GMU does not rely on any global logical clock, which may represent a contention point and a major impairment to system scalability. Also, GMU never aborts read-only transactions and spares them from undergoing distributed validation schemes. This makes GMU particularly efficient in presence of read-intensive workloads, as typical of a wide range of real-world applications. GMU guarantees the Extended Update Serializability (EUS) isolation level. This consistency criterion is particularly attractive as it is sufficiently strong to ensure correctness even for very demanding applications (such as TPC-C), but is also weak enough to allow efficient and scalable implementations, such as GMU. Further, unlike several relaxed consistency models proposed in literature, EUS shows simple and intuitive semantics, thus being an attractive consistency model for ordinary programmers. We integrated GMU in a popular open source in-memory transactional data grid, namely Infinispan. On the basis of a wide experimental study performed on heterogeneous platforms and using industry standard benchmarks (namely TPC-C and YCSB), we show that GMU achieves almost linear scalability and that it introduces reduced overhead, with respect to solutions ensuring non-serializable semantics, in a wide range of workloads."",""1558-2183"","""",""10.1109/TPDS.2015.2510998"",""Fundação para a Ciência e Tecnologia(grant numbers:UID/CEC/50021/2013)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7362215"",""Partial data replication";multiversioning;transactional systems;"fault tolerance"",""Protocols";Proposals;Scalability;Semantics;Clocks;History;"Benchmark testing"","""",""3"","""",""46"",""IEEE"",""22 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"GPU Robot Motion Planning Using Semi-Infinite Nonlinear Programming,""B. Chrétien"; A. Escande;" A. Kheddar"",""CNRS-AIST JRL, UMI3218/RL, Tsukuba, Japan"; CNRS-AIST JRL, UMI3218/RL, Tsukuba, Japan;" CNRS-AIST JRL, UMI3218/RL, Tsukuba, Japan"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2926"",""2939"",""We propose a many-core GPU implementation of robotic motion planning formulated as a semi-infinite optimization program. Our approach computes the constraints and their gradients in parallel, and feeds the result to a nonlinear optimization solver running on the CPU. To ensure the continuous satisfaction of our constraints, we use polynomial approximations over time intervals. Because each constraint and its gradient can be evaluated independently for each time interval, we end up with a highly parallelizable problem that can take advantage of many-core architectures. Classic robotic computations (geometry, kinematics, and dynamics) can also benefit from parallel processors, and we carefully study their implementation in our context. This results in having a full constraint evaluator running on the GPU. We present several optimization examples with a humanoid robot. They reveal substantial improvements in terms of computation performance compared to a parallel CPU version."",""1558-2183"","""",""10.1109/TPDS.2016.2521373"",""EU FP7"; Japan Society for Promotion of Science(grant numbers:P13786); Grant-in-Aid for Scientific Research(grant numbers:25280096);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7390287"",""GPGPU";CUDA;nonlinear optimization;motion planning;robotics;parallel computing;"HPC"",""Planning";Robot kinematics;Optimization;Service robots;Graphics processing units;"Kinematics"","""",""18"","""",""32"",""IEEE"",""25 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"GPU Strategies for Distance-Based Outlier Detection,""F. Angiulli"; S. Basta; S. Lodi;" C. Sartori"",""DIMES Department, University of Calabria, Via P. Bucci, 41C, Rende (CS), Italy"; Institute of High Performance Computing and Networking, Italian National Research Council, Via P. Bucci 41C, Rende (CS), Italy; Department of Computer Science and Engineering, University of Bologna, Viale Risorgimento 2, Bologna, Italy;" Department of Computer Science and Engineering, University of Bologna, Viale Risorgimento 2, Bologna, Italy"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3256"",""3268"",""The process of discovering interesting patterns in large, possibly huge, data sets is referred to as data mining, and can be performed in several flavours, known as “data mining functions.” Among these functions, outlier detection discovers observations which deviate substantially from the rest of the data, and has many important practical applications. Outlier detection in very large data sets is however computationally very demanding and currently requires high-performance computing facilities. We propose a family of parallel and distributed algorithms for graphic processing units (GPU) derived from two distance-based outlier detection algorithms: BruteForce and SolvingSet. The algorithms differ in the way they exploit the architecture and memory hierarchy of the GPU and guarantee significant improvements with respect to the CPU versions, both in terms of scalability and exploitation of parallelism. We provide a detailed discussion of their computational properties and measure performances with an extensive experimentation, comparing the several implementations and showing significant speedups."",""1558-2183"","""",""10.1109/TPDS.2016.2528984"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7405341"",""Distance-based outliers";outlier detection;"parallel and distributed algorithms"",""Graphics processing units";Data mining;Complexity theory;Algorithm design and analysis;Computer architecture;"Indexes"","""",""21"","""",""24"",""IEEE"",""11 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Graphine: Programming Graph-Parallel Computation of Large Natural Graphs for Multicore Clusters,""J. Yan"; G. Tan; Z. Mo;" N. Sun"",""State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences"; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences; Institute of Applied Physics and Computational Mathematics;" State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1647"",""1659"",""Graph-parallel computation has become a crucial component in emerging applications of web search, data analytics and machine learning. In practice, most graphs derived from real-world phenomena are very large and scale-free. Unfortunately, distributed graph-parallel computation of these natural graphs still suffers strong scalability issues on contemporary multicore clusters. To embrace the multicore architecture in distributed graph-parallel computation, we propose the framework Graphine, which features (i) A Scatter-Combine computation abstraction that is evolved from the traditional vertex-centric approach by fusing the paired scatter and gather operations, executed separately on two edge sides, into a one-sided scatter. Further coupled with active message mechanism, it potentially reduces intermediate message cost and enables fine-grained parallelism on multicore architecture. (ii) An Agent-Graph data model, which leverages an idea similar to vertex-cut but conceptually splits the remote replica into two agent types of scatter and combiner, resulting in less communication. We implement the Graphine framework and evaluate it using several representative algorithms on six large real-world graphs and a series of synthetic graphs with power-law degree distributions. We show that Graphine achieves sublinear scalability with the number of cores per node, number of nodes, and graph sizes (up to one billion vertices), and is 2~15 times faster than the state-of-the-art PowerGraph on a cluster of 16 multicore nodes."",""1558-2183"","""",""10.1109/TPDS.2015.2453978"",""National Natural Science Foundation of China(grant numbers:61272134,31327901,91430218,60921002,60925009,61472395)"; National 863 Program(grant numbers:2009AA01A129); 973 Program(grant numbers:2012CB316502,2011CB302502);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152922"",""Parallel Framework";Graph-Parallel;Computational Model;Graph-parallel;parallel framework;"computational model"",""Multicore processing";Mirrors;Runtime;Scalability;Data models;"Computational modeling"","""",""6"","""",""49"",""IEEE"",""8 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Hadoop Performance Modeling for Job Estimation and Resource Provisioning,""M. Khan"; Y. Jin; M. Li; Y. Xiang;" C. Jiang"",""Department of Electronic and Computer Engineering, Brunel University London, Uxbridge, United Kingdom"; National Key Lab for Electronic Measurement Technology, Department of Electronic and Computer Engineering, Brunel University London, Uxbridge, United Kingdom; Department of Electronic and Computer Engineering, Key Laboratory of Embedded Systems and Service Computing, Ministry of Education, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Siping Road, Shanghai, China;" Department of Computer Science and Technology, Tongji University, Siping Road, Shanghai, China"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""441"",""454"",""MapReduce has become a major computing model for data intensive applications. Hadoop, an open source implementation of MapReduce, has been adopted by an increasingly growing user community. Cloud computing service providers such as Amazon EC2 Cloud offer the opportunities for Hadoop users to lease a certain amount of resources and pay for their use. However, a key challenge is that cloud service providers do not have a resource provisioning mechanism to satisfy user jobs with deadline requirements. Currently, it is solely the user's responsibility to estimate the required amount of resources for running a job in the cloud. This paper presents a Hadoop job performance model that accurately estimates job completion time and further provisions the required amount of resources for a job to be completed within a deadline. The proposed model builds on historical job execution records and employs Locally Weighted Linear Regression (LWLR) technique to estimate the execution time of a job. Furthermore, it employs Lagrange Multipliers technique for resource provisioning to satisfy jobs with deadline requirements. The proposed model is initially evaluated on an in-house Hadoop cluster and subsequently evaluated in the Amazon EC2 Cloud. Experimental results show that the accuracy of the proposed model in job execution estimation is in the range of 94.97 and 95.51 percent, and jobs are completed within the required deadlines following on the resource provisioning scheme of the proposed model."",""1558-2183"","""",""10.1109/TPDS.2015.2405552"",""UK EPSRC(grant numbers:EP/K006487/1)"; National Basic Research Program (973) of China(grant numbers:2014CB340404);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7045505"",""Cloud computing";Hadoop MapReduce;job estimation;Cloud computing;Hadoop MapReduce;performance modeling;job estimation;"resource provisioning"",""Mathematical model";Computational modeling;Estimation;Upper bound;Cloud computing;Data models;"Educational institutions"","""",""78"",""1"",""32"",""IEEE"",""19 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"HadoopCL2: Motivating the Design of a Distributed, Heterogeneous Programming System With Machine-Learning Applications,""M. Grossman"; M. Breternitz;" V. Sarkar"",""Department of Computer Science, 6100 Main St., Rice University, Houston, TX"; AMD Research, 7171 Southwest Parkway, Austin, TX;" Department of Computer Science, 6100 Main St., Rice University, Houston, TX"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""762"",""775"",""Machine learning (ML) algorithms have garnered increased interest as they demonstrate improved ability to extract meaningful trends from large, diverse, and noisy data sets. While research is advancing the state-of-the-art in ML algorithms, it is difficult to drastically improve the real-world performance of these algorithms. Porting new and existing algorithms from single-node systems to multi-node clusters, or from architecturally homogeneous systems to heterogeneous systems, is a promising optimization technique. However, performing optimized ports is challenging for domain experts who may lack experience in distributed and heterogeneous software development. This work explores how challenges in ML application development on heterogeneous, distributed systems shaped the development of the HadoopCL2 (HCL2) programming system. ML applications guide this work because they exhibit features that make application development difficult: large & diverse datasets, complex algorithms, and the need for domain-specific knowledge. The goal of this work is a general, MapReduce programming system that outperforms existing programming systems. This work evaluates the performance and portability of HCL2 against five ML applications from the Mahout ML framework on two hardware platforms. HCL2 demonstrates speedups of greater than 20x relative to Mahout for three computationally heavy algorithms and maintains minor performance improvements for two I/O bound algorithms."",""1558-2183"","""",""10.1109/TPDS.2015.2414943"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064791"",""MapReduce";heterogeneous;distributed;programming model;GPU;"auto-scheduling"",""Programming";Performance evaluation;Vectors;Java;Kernel;Object oriented modeling;"Computational modeling"","""",""10"","""",""16"",""IEEE"",""20 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Hardware Implementation on FPGA for Task-Level Parallel Dataflow Execution Engine,""C. Wang"; J. Zhang; X. Li; A. Wang;" X. Zhou"",""University of Science and Technology of China, China"; University of Science and Technology of China, China; University of Science and Technology of China, China; University of Science and Technology of China, China;" University of Science and Technology of China, China"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2303"",""2315"",""Heterogeneous multicore platform has been widely used in various areas to achieve both power efficiency and high performance. However, it poses significant challenges to researchers to uncover more coarse-grained task level parallelization. In order to support automatic task parallel execution, this paper proposes a FPGA implementation of a hardware out-of-order scheduler on heterogeneous multicore platform. The scheduler is capable of exploring potential inter-task dependency, leading to a significant acceleration of dependence-aware applications. With the help of renaming scheme, the task dependencies are detected automatically during execution, and then task-level Write-After-Write (WAW) and Write-After-Read (WAR) dependencies can be eliminated dynamically. We extended the instruction level renaming techniques to perform task-level out-of-order execution, and implemented a prototype on a state-of-art Xilinx Virtex-5 FPGA device. Given the reconfigurable characteristic of FPGA, our scheduler supports changing accelerators at runtime to improve the flexibility. Experimental results demonstrate that our scheduler is efficient at both performance and resources usage."",""1558-2183"","""",""10.1109/TPDS.2015.2487346"",""National Science Foundation of China(grant numbers:61379040,61272131,61202053,61222204,61221062)"; Jiangsu Provincial Natural Science Foundation(grant numbers:SBK201240198); State Key Laboratory of Computer Architecture, ICT, CAS; CCF-Tencent Open Research Fund;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7289452"",""FPGA";dataflow;dependency analysis;out-of-order;"parallel architecture"",""Hardware";Programming;Field programmable gate arrays;Parallel processing;Out of order;"Computer architecture"","""",""16"","""",""45"",""IEEE"",""5 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Hardware-Acceleration of Short-Read Alignment Based on the Burrows-Wheeler Transform,""H. M. Waidyasooriya";" M. Hariyama"",""Graduate School of Information Sciences, Tohoku University, Aoba 6-6-05, Aramaki, Aoba, Sendai, Miyagi, Japan";" Graduate School of Information Sciences, Tohoku University, Aoba 6-6-05, Aramaki, Aoba, Sendai, Miyagi, Japan"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1358"",""1372"",""The alignment of millions of short DNA fragments to a large genome is a very important aspect of the modern computational biology. However, software-based DNA sequence alignment takes many hours to complete. This paper proposes an FPGA-based hardware accelerator to reduce the alignment time. We apply a data encoding scheme that reduces the data size by 96 percent, and propose a pipelined hardware decoder to decode the data. We also design customized data paths to efficiently use the limited bandwidth of the DDR3 memories. The proposed accelerator can align a few hundred million short DNA fragments in an hour by using 80 processing elements in parallel. The proposed accelerator has the same mapping quality compared to the software-based methods."",""1558-2183"","""",""10.1109/TPDS.2015.2444376"",""MEXT"; KAKENHI(grant numbers:15K15958,24300013);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7122348"",""Short-read alignment";genome mapping;Burrows-Wheeler alignment;FPGA accelerator;Short-read alignment;genome mapping;Burrows-Wheeler alignment;"FPGA accelerator"",""Arrays";Bioinformatics;Genomics;Decoding;Field programmable gate arrays;Hardware;"Encoding"","""",""17"",""1"",""26"",""IEEE"",""11 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Heads-Join: Efficient Earth Mover's Distance Similarity Joins on Hadoop,""J. Huang"; R. Zhang; R. Buyya; J. Chen;" Y. Wu"",""Department of Information and Computing Systems, University of Melbourne, Melbourne, VIC, Australia"; Department of Information and Computing Systems, University of Melbourne, Melbourne, VIC, Australia; Department of Information and Computing Systems, University of Melbourne, Melbourne, VIC, Australia; School of Software Engineering, South China University of Technology, Guangzhou, China;" Department of Computer Science and Technology, Tsinghua National Laboratory for Information Science and Technology (TNLIST), Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1660"",""1673"",""The Earth Mover's Distance (EMD) similarity join has a number of important applications such as near duplicate image retrieval and distributed based pattern analysis. However, the computational cost of EMD is super cubic and consequently the EMD similarity join operation is prohibitive for datasets of even medium size. We propose to employ the Hadoop platform to speed up the operation. Simply porting the state-of-the-art metric distance similarity join algorithms to Hadoop results in inefficiency because they involve excessive distance computations and are vulnerable to skewed data distributions. We propose a novel framework, named HEADS-JOIN, which transforms data into the space of EMD lower bounds and performs pruning and partitioning at a low cost because computing these EMD lower bounds has constant or linear complexity. We investigate both range and top-k joins, and design efficient algorithms on three popular Hadoop computation paradigms, i.e., MapReduce, Bulk Synchronous Parallel, and Spark. We conduct extensive experiments on both real and synthetic datasets. The results show that HEADS-JOIN outperforms the state-of-the-art metric similarity join technique, i.e., Quickjoin, by up to an order of magnitude and scales out well."",""1558-2183"","""",""10.1109/TPDS.2015.2462354"",""Australian Research Council(grant numbers:DP130104587)"; National High-Tech R&D (863) Program of China(grant numbers:2013AA01A213); Natural Science Foundation of China(grant numbers:61433008,61373145,61170210,U1435216); Chinese Special Project of Science and Technology(grant numbers:2013zx01039-002-002); ARC Future Fellowships Projects(grant numbers:FT120100832,FT120100545); Fundamental Research Funds for the Central Universities(grant numbers:2015ZZ029);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7172540"",""Earth Mover’s Distance";Similarity Join;MapReduce;Bulk Synchronous Parallel;Earth Mover's distance;similarity join;MapReduce;"bulk synchronous parallel"",""Histograms";Sparks;Upper bound;Transforms;Algorithm design and analysis;Earth;"Approximation error"","""",""14"","""",""30"",""IEEE"",""29 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;
"High-Performance and Dynamically Updatable Packet Classification Engine on FPGA,""Y. R. Qu";" V. K. Prasanna"",""Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA";" Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""197"",""209"",""High-performance and dynamically updatable hardware architectures for multi-field packet classification have regained much interest in the research community. For example, software defined networking requires 15 fields of the packets to be checked against a predefined rule set. Many algorithmic solutions for packet classification have been studied over the past decade. FPGA-based packet classification engines can achieve very high throughput"; however, supporting dynamic updates is yet challenging. In this paper, we present a two-dimensional pipelined architecture for packet classification on FPGA; this architecture achieves high throughput while supporting dynamic updates. In this architecture, modular Processing Elements (PEs) are arranged in a two-dimensional array. Each PE accesses its designated memory locally, and supports prefix match and exact match efficiently. The entire array is both horizontally and vertically pipelined. We exploit striding, clustering, dual-port memory, and power gating techniques to further improve the performance of our architecture. The total memory is proportional to the rule set size. Our architecture sustains high clock rate even if we scale up (1) the length of each packet header, or/and (2) the number of rules in the rule set. The performance of the entire architecture does not depend on rule set features such as the number of unique values in each field. The PEs are also self-reconfigurable;" they support dynamic updates of the rule set during run-time with very little throughput degradation. Experimental results show that, for a 1 K 15-tuple rule set, a state-of-the-art FPGA can sustain a throughput of 650 Million Packets Per Second (MPPS) with 1 million updates/second. Compared to TCAM, our architecture demonstrates at least four-fold energy efficiency while achieving two-fold throughput."",""1558-2183"","""",""10.1109/TPDS.2015.2389239"",""US National Science Foundation(grant numbers:CCF-1320211)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004892"",""Packet classification";Field-Programmable Gate Array (FPGA);2-dimensional pipeline;dynamic updates;Packet classification;field-programmable gate array (FPGA);two-dimensional pipeline;"dynamic updates"",""Field programmable gate arrays";Pipelines;Throughput;Arrays;Vectors;"Registers"","""",""57"",""2"",""24"",""IEEE"",""8 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"High-Performance and Endurable Cache Management for Flash-Based Read Caching,""Q. Xia";" W. Xiao"",""Department of Electrical and Computer Engineering, Virginia Commonwealth University, 601 West Main Street, Richmond, VA";" Department of Electrical and Computer Engineering, Virginia Commonwealth University, 601 West Main Street, Richmond, VA"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3518"",""3531"",""Flash-based SSDs are widely used as storage caches, which can benefit from both the higher performance of SSDs and lower price of disks. Unfortunately, issues of reliability and lifetime limit the use of flash-based cache. One way to solve this problem is to use the flash memory as read cache and use other devices like nonvolatile memory for write buffering. In this paper, we propose a new flash-aware read cache design, which leverages out-of-place update property of SSDs to improve both cache hit ratio and lifetime. Due to the out-of-place update property, when a cache entry is evicted from the flash cache, the eviction only removes the metadata, while the real data is still accessible and resides in the physical flash page until the whole flash block being erased. The main idea of our flash-aware cache is to reuse these evicted but still available data, when a request for the previously evicted data page arrives, instead of accessing underlying storage to fetch the data and rewriting it into fash cache, our design just needs to revive the evicted data. To evaluate the benefits of flash-aware cache design, we implemented the normal LRU, normal ARC, flash-aware LRU (FLRU), and flashaware ARC (FARC) cache algorithms on the Disksim simulator with SSD extension. Our simulation results demonstrate that our flashaware cache can improve the cache hit ratio by up to 28 percent, reduce the average response time by up to 40 percent with higher performance stability, and alleviate the lifetime limitation of flash cache by reducing the erase count by up to more than 70 percent. Besides of the flash-aware design, we also propose a new zero-migration garbage collection scheme to further extend the lifetime of flash cache. Our experiments show that the combination of our flash-aware cache design and the zero-migration garbage collection scheme reduces the erase count by up to nearly 90 percent."",""1558-2183"","""",""10.1109/TPDS.2016.2537822"",""US National Science Foundation(grant numbers:CCF-1547804,CSR-1526190)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425233"",""Flash memory";out-of-place update;read cache;LRU;ARC;zero-migration;"garbage collection"",""Random access memory";Performance evaluation;Error correction codes;Aerospace electronics;Flash memories;Cache storage;"Metadata"","""",""7"","""",""58"",""IEEE"",""3 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"High-Speed Medical Imaging in 3D Ultrasound Computer Tomography,""M. Birk"; E. Kretzek; P. Figuli; M. Weber; J. Becker;" N. V. Ruiter"",""Karlsruhe Institute of Technology, Karlsruhe, Germany"; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany;" Karlsruhe Institute of Technology, Karlsruhe, Germany"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""455"",""467"",""A promising candidate for sensitive imaging of breast cancer is 3D Ultrasound Computer Tomography (3D USCT). So far its clinical applicability for diagnosis has been limited by the duration of the demanding image reconstruction. In this paper we investigate how signal processing and image reconstruction can be accelerated for diagnosis by using heterogeneous hardware. Additionally, the time and costs for real-time system for a future diagnosis and therapy device is estimated. Reusing the device's built-in FPGA-based data acquisition system (DAQ) through reconfiguration results in a speed-up by a factor of 7 for signal processing and by a factor of 2 for image reconstruction. Applying cutting-edge single FPGAs and GPUs, speed-ups by a factor of 10 (FPGA) and 6 (GPU) for signal processing and 15 (FPGA) and 37 (GPU) for image reconstruction were achieved compared to a recent quad-core Intel Core-i7 CPU. Using quad-core CPUs and a cluster of eight GPUs allowed us for the first time to calculate volumes in less than 30 min with an overall speed-up by a factor of 47, enabling a first clinical study. Based on these results we extrapolated that real-time reconstruction for a therapeutic 3D USCT will be possible in the year 2020 if the trend in density follows the ITRS roadmap."",""1558-2183"","""",""10.1109/TPDS.2015.2405508"",""German Research Foundation(grant numbers:WE 2899/2-1,BE 2134/11-1)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7045577"",""medical imaging";computer tomography;FPGA;Medical imaging;computer tomography;ultrasound;high performance;FPGA;"GPU"",""Field programmable gate arrays";Data acquisition;Image reconstruction;Three-dimensional displays;Random access memory;Hardware;"Receivers"","""",""14"","""",""29"",""IEEE"",""19 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;
"High-Throughput Multi-Core LDPC Decoders Based on x86 Processor,""B. Le Gal";" C. Jego"",""IMS Lab., Univ. Bordeaux, Bordeaux INP, CNRS UMR 5218, 351 cours de la libération, Talence, France";" IMS Lab., Univ. Bordeaux, Bordeaux INP, CNRS UMR 5218, 351 cours de la libération, Talence, France"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1373"",""1386"",""Low-Density Parity-Check (LDPC) codes are an efficient way to correct transmission errors in digital communication systems. Although initially targeting strictly to ASICs due to computation complexity, LDPC decoders have been recently ported to multicore and many-core systems. Most works focused on taking advantage of GPU devices. In this paper, we propose an alternative solution based on a layered OMS/NMS LDPC decoding algorithm that can be efficiently implemented on a multi-core device using Single Instruction Multiple Data (SIMD) and Single Program Multiple Data (SPMD) programming models. Several experimentations were performed on a x86 processor target. Throughputs up to 170 Mbps were achieved on a single core of an INTEL Core i7 processor when executing 20 layered-based decoding iterations. Throughputs reaches up to 560 Mbps on four INTEL Core-i7 cores. Experimentation results show that the proposed implementations achieved similar BER correction performance than previous works. Moreover, much higher throughputs have been achieved by comparison with all previous GPU and CPU works. They range from x1.4 to x8 by comparison with recent GPU works."",""1558-2183"","""",""10.1109/TPDS.2015.2435787"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7110620"",""LDPC decoding";software decoders;SIMD architecture;x86 processor;GPU;throughput;Software Define Radio (SDR);LDPC decoding;software decoders;SIMD architecture;x86 processor;GPU;throughput;"software define radio (SDR)"",""Decoding";Graphics processing units;Iterative decoding;Throughput;"Processor scheduling"","""",""40"","""",""40"",""IEEE"",""20 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Higher Dimensional Gaussian Networks,""B. Bose"; A. Shamaei;" M. Flahive"",""School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR"; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR;" Department of Mathematics, Oregon State University, Corvallis, OR"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2628"",""2638"",""Gaussian interconnection networks have been introduced as a useful alternative to the classical toroidal networks, and in this paper this concept is generalized to higher dimensions. We also explore many important properties of this new topology, including distance distribution and the decomposition of higher dimensional Gaussian networks into edge-disjoint tori and Hamiltonian cycles. In addition, an optimal shortest path routing algorithm and a one-to-all broadcast algorithm for higher dimensional Gaussian networks are given. Simulation results show that the routing algorithm proposed for higher dimensional Gaussian networks outperforms the routing algorithm of the corresponding torus network of the same node-degree and the same number of nodes."",""1558-2183"","""",""10.1109/TPDS.2015.2504936"",""National Science Foundation(grant numbers:CCF-1015804,CCF-1423656)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7345602"",""Interconnection network";Gaussian integers;routing;Hamiltonian decomposition;"Gray codes"",""Routing";Artificial neural networks;Network topology;Topology;Multiprocessor interconnection;Computers;"Message passing"","""",""3"","""",""23"",""IEEE"",""3 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"HIPAcc: A Domain-Specific Language and Compiler for Image Processing,""R. Membarth"; O. Reiche; F. Hannig; J. Teich; M. Körner;" W. Eckert"",""German Research Center for Artificial Intelligence, Saarland University, Saarbrücken, Germany"; Department of Computer Science, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Department of Computer Science, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Department of Computer Science, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Siemens Healthcare Sector, Forchheim, Germany;" Siemens Corporate Technology, Erlangen, Germany"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""210"",""224"",""Domain-specific languages (DSLs) provide high-level and domain-specific abstractions that allow expressive and concise algorithm descriptions. Since the description in a DSL hides also the properties of the target hardware, DSLs are a promising path to target different parallel and heterogeneous hardware from the same algorithm description. In theory, the DSL description can capture all characteristics of the algorithm that are required to generate highly efficient parallel implementations. However, most frameworks do not make use of this knowledge and the performance cannot reach that of optimized library implementations. In this article, we present the HIPAcc framework, a DSL and source-to-source compiler for image processing. We show that domain knowledge can be captured in the language and that this knowledge enables us to generate tailored implementations for a given target architecture. Back ends for CUDA, OpenCL, and Renderscript allow us to target discrete graphics processing units (GPUs) as well as mobile, embedded GPUs. Exploiting the captured domain knowledge, we can generate specialized algorithm variants that reach the maximal achievable performance due to the peak memory bandwidth. These implementations outperform state-of-the-art domain-specific languages and libraries significantly."",""1558-2183"","""",""10.1109/TPDS.2015.2394802"",""German Research Foundation"; Research Training Group;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7017495"",""domain-specific language";image processing;code generation;source-to-source translation;GPU;CUDA;OpenCL;Renderscript;Domain-specific language;image processing;code generation;source-to-source translation;GPU;CUDA;OpenCL;"Renderscript"",""DSL";Graphics processing units;Kernel;Image processing;Hardware;Indexes;"Optimization"","""",""77"","""",""37"",""IEEE"",""21 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;
"HV Code: An All-Around MDS Code for RAID-6 Storage Systems,""Z. Shen"; J. Shu;" Y. Fu"",""Department of Computer Science and Technology, Tsinghua University, Beijing, China"; Department of Computer Science and Technology, Tsinghua University, Beijing, China;" Department of Computer Science and Technology, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1674"",""1686"",""The increasing expansion of data scale leads to the widespread deployment of storage systems with larger capacity and further induces the climbing probability of data loss or damage. The Maximum Distance Separable (MDS) code in RAID-6, which tolerates the concurrent failures of any two disks with minimal storage requirement, is one of the best candidates to enhance the data reliability. However, most of the existing works in this literature are more inclined to be specialized and cannot provide a satisfied performance under an all-round evaluation. Aiming at this problem, we propose an all-round MDS code named Horizontal-Vertical Code (HV Code) by taking advantage of horizontal parity and vertical parity. HV Code achieves the perfect I/O balancing and optimizes the operation of partial stripe writes, while preserving the optimal encoding/decoding/update efficiency. Moreover, it owns a shorter parity chain which grants it a more efficient recovery for single disk failure. HV Code also behaves well on degraded read operation and accelerates the reconstruction of double disk failures by executing four recovery chains in parallel. The performance evaluation demonstrates that HV Code well balances the I/O distribution. HV Code also eliminates up to 32.2 percent I/O operations for partial stripe writes in read-modify-write mode, and reduces up to 28.9 percent I/O operations for partial stripe writes in reconstruct-write mode. Moreover, HV Code reduces 5.4~39.8 percent I/O operations per element for the single disk reconstruction, decreases 8.3~39.0 percent I/O operations for degraded read operations, and shortens 47.4~59.7 percent recovery time for double disk recovery."",""1558-2183"","""",""10.1109/TPDS.2015.2464800"",""National Natural Science Foundation of China(grant numbers:61232003,61433008)"; National High Technology Research and Development Program of China(grant numbers:2013AA013201); State Key Laboratory of High-end Server and Storage Technology(grant numbers:2014HSSA02);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7180372"",""erasure codes";RAID-6;degraded read;load balancing;single failure recovery;Erasure codes;RAID-6;degraded read;load balancing;"single failure recovery"",""Complexity theory";Reliability;Measurement;Maintenance engineering;Load management;Layout;"Reed-Solomon codes"","""",""4"","""",""39"",""IEEE"",""5 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Hybrid Job-Driven Scheduling for Virtual MapReduce Clusters,""M. -C. Lee"; J. -C. Lin;" R. Yahyapour"",""Department of Computer Science, National Chiao Tung University, Taiwan"; Department of Informatics, University of Oslo, Norway;" GWDG—Gesellschaft für wissenschaftliche Datenverarbeitung mbH Göttingen, Lower Saxony, Germany"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1687"",""1699"",""It is cost-efficient for a tenant with a limited budget to establish a virtual MapReduce cluster by renting multiple virtual private servers (VPSs) from a VPS provider. To provide an appropriate scheduling scheme for this type of computing environment, we propose in this paper a hybrid job-driven scheduling scheme (JoSS for short) from a tenant's perspective. JoSS provides not only job-level scheduling, but also map-task level scheduling and reduce-task level scheduling. JoSS classifies MapReduce jobs based on job scale and job type and designs an appropriate scheduling policy to schedule each class of jobs. The goal is to improve data locality for both map tasks and reduce tasks, avoid job starvation, and improve job execution performance. Two variations of JoSS are further introduced to separately achieve a better map-data locality and a faster task assignment. We conduct extensive experiments to evaluate and compare the two variations with current scheduling algorithms supported by Hadoop. The results show that the two variations outperform the other tested algorithms in terms of map-data locality, reduce-data locality, and network overhead without incurring significant overhead. In addition, the two variations are separately suitable for different MapReduce-workload scenarios and provide the best job performance among all tested algorithms."",""1558-2183"","""",""10.1109/TPDS.2015.2463817"",""Ministry of Science and Technology"; Deutscher Akademischer Austausch Dienst(grant numbers:NSC 102-2911-I-100-524,NSC 101-2911-I-009-020-2);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7175043"",""MapReduce";Hadoop;virtual MapReduce cluster;MapReduce;Hadoop;virtual MapReduce cluster;map-task scheduling;"reduce-task scheduling"",""Benchmark testing";Scheduling algorithms;Schedules;Clustering algorithms;Scheduling;"Information filtering"","""",""24"","""",""36"",""IEEE"",""3 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"I/O-Efficient Scaling Schemes for Distributed Storage Systems with CRS Codes,""S. Wu"; Y. Xu; Y. Li;" Z. Yang"",""School of Computer Science and Technology, University of Science and Technology of China and the AnHui Province Key Laboratory of High Performance Computing, University of Science and Technology of China"; School of Computer Science and Technology, University of Science and Technology of China and the Collaborative Innovation Center of High Performance Computing, National University of Defense Technology, China, Changsha, China; School of Computer Science and Technology, University of Science and Technology of China and the AnHui Province Key Laboratory of High Performance Computing, University of Science and Technology of China;" School of Computer Science and Technology, University of Science and Technology of China"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2639"",""2652"",""System scaling becomes essential and indispensable for distributed storage systems due to the explosive growth of data volume. Considering that fault-protection is a necessity in large-scale distributed storage systems, and Cauchy Reed-Solomon (CRS) codes are widely deployed to tolerate multiple simultaneous node failures, this paper studies the scaling problem of distributed storage systems with CRS codes. In particular, we formulate the scaling problem with an optimization model in which both the post-scaling encoding matrix and the data migration policy are assumed to be unknown in advance. To minimize the I/O overhead, we propose a three-phase optimization scaling scheme for CRS codes. Specifically, we first derive the optimal post-scaling encoding matrix under a given data migration policy, then optimize the data migration process using the selected post-scaling encoding matrix, and finally exploit the Maximum Distance Separable (MDS) property to further optimize the designed data migration process. Our scaling scheme requires minimal data movement while achieving uniform data distribution. Moreover, it requires to read fewer data blocks than conventional minimum data migration schemes, but still guarantees the minimum amount of migrated data. To validate the efficiency of our scheme, we implement it atop a networked file system. Extensive experiments show that our scaling scheme uses less scaling time than the basic scheme."",""1558-2183"","""",""10.1109/TPDS.2015.2505722"",""National Nature Science Foundation of China(grant numbers:61379038)"; Huawei Innovation Research Program; National Nature Science Foundation of China(grant numbers:61303048); Anhui Provincial Natural Science Foundation(grant numbers:1508085SQF214);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7347422"",""Scaling";cauchy reed-solomon codes;distributed storage systems;encoding matrix;"data migration"",""Encoding";Optimization;Data models;Algorithm design and analysis;Distributed databases;Reed-Solomon codes;"Layout"","""",""23"","""",""16"",""IEEE"",""4 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Implementation and Tuning of Batched Cholesky Factorization and Solve for NVIDIA GPUs,""J. Kurzak"; H. Anzt; M. Gates;" J. Dongarra"",""Electrical Engineering and Computer Science, University of Tennessee, 1122 Volunteer Blvd, Ste 413 Claxton, Knoxville, Tennessee"; Electrical Engineering and Computer Science, University of Tennessee, Knoxville, Tennessee; Electrical Engineering and Computer Science, University of Tennessee, Knoxville, Tennessee;" Electrical Engineering and Computer Science, University of Tennessee, Knoxville, Tennessee"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""2036"",""2048"",""Many problems in engineering and scientific computing require the solution of a large number of small systems of linear equations. Due to their high processing power, Graphics Processing Units became an attractive target for this class of problems, and routines based on the LU and the QR factorization have been provided by NVIDIA in the cuBLAS library. This work addresses the situation where the systems of equations are symmetric positive definite. The paper describes the implementation and tuning of the kernels for the Cholesky factorization and the forward and backward substitution. Targeted workloads involve the solution of thousands of linear systems of the same size, where the focus is on matrix dimensions from 5 by 5 to 100 by 100. Due to the lack of a cuBLAS Cholesky factorization, execution rates of cuBLAS LU and cuBLAS QR are used for comparison against the proposed Cholesky factorization in this work. Execution rates of forward and backward substitution routines are compared to equivalent cuBLAS routines. Comparisons against optimized multicore implementations are also presented. Superior performance is reached in all cases."",""1558-2183"","""",""10.1109/TPDS.2015.2481890"",""Bench-testing Environment for Automated Software Tuning (BEAST)(grant numbers:#SHF-1320603)"; National Science Foundation; Department of Energy(grant numbers:#DE-SC0010042); NVIDIA Corporation;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275187"",""Cholesky factorization";batched;kernel;GPU;CUDA;SIMT;Cholesky factorization;batched;kernel;GPU;CUDA;"SIMT"",""Instruction sets";Random access memory;Registers;Graphics processing units;Niobium;Kernel;"Linear systems"","""",""27"","""",""21"",""IEEE"",""24 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;
"Improving Batch Scheduling on Blue Gene/Q by Relaxing Network Allocation Constraints,""Z. Zhou"; X. Yang; Z. Lan; P. Rich; W. Tang; V. Morozov;" N. Desai"",""Department of Computer Science, Illinois Institute of Technology, Chicago, IL"; Department of Computer Science, Illinois Institute of Technology, Chicago, IL; Department of Computer Science, Illinois Institute of Technology, Chicago, IL; Argonne Leadership Computing Facility, Argonne National Laboratory, Lemont, IL; Google Inc, New York, NY; Argonne Leadership Computing Facility, Argonne National Laboratory, Lemont, IL;" Ericsson Inc, San Jose, CA"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3269"",""3282"",""As systems scale toward exascale, many resources will become increasingly constrained. While some of these resources have historically been explicitly allocated, many-such as network bandwidth, I/O bandwidth, or power-have not. As systems continue to evolve, we expect many such resources to become explicitly managed. This change will pose critical challenges to resource management and job scheduling. In this paper, we explore the potential of relaxing network allocation constraints for Blue Gene systems. Our objective is to improve the batch scheduling performance, where the partition-based interconnect architecture provides a unique opportunity to explicitly allocate network resources to jobs. This paper makes three major contributions. The first is substantial benchmarking of parallel applications, focusing on assessing application sensitivity to communication bandwidth at large scale. The second is three new scheduling schemes using relaxed network allocation and targeted at balancing individual job performance with overall system performance. The third is a comparative study of our scheduling schemes versus the existing scheduler on Mira, a 48-rack Blue Gene/Q system at Argonne National Laboratory. Specifically, we use job traces collected from this production system."",""1558-2183"","""",""10.1109/TPDS.2016.2528247"",""US National Science Foundation(grant numbers:CNS-1320125,CCF-1422009)"; US Department of Energy; Office of Science(grant numbers:DE-AC02-06CH11357);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404249"",""Job scheduling";resource management;network partition;"torus/mesh topology"",""Resource management";Wiring;Scheduling;Bandwidth;Processor scheduling;Network topology;"Benchmark testing"","""",""3"","""",""54"",""IEEE"",""11 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;
"Improving Performance of Parallel I/O Systems through Selective and Layout-Aware SSD Cache,""S. He"; Y. Wang;" X. -H. Sun"",""State Key Laboratory of Software Engineering, Computer School, Wuhan University, Hubei, Wuhan, China"; Shenzhen Institute of Advanced Technology, Chinese Academy of Science, Xueyuan Avenue 1068, Shenzhen University Town, Shenzhen, China;" Department of Computer Science, Illinois Institute of Technology, Chicago, IL"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2940"",""2952"",""Parallel file systems (PFS) are widely-used to ease the I/O bottleneck of modern high-performance computing systems. However, PFSs do not work well for small requests, especially small random requests. Newer Solid State Drives (SSD) have excellent performance on small random data accesses, but also incur a high monetary cost. In this study, we propose SLA-Cache, a Selective and Layout-Aware Cache system that employs a small set of SSD-based file servers as a cache of conventional HDD-based file servers. SLA-Cache uses a novel scheme to identify performance-critical data, and conducts a selective cache admission (SCA) policy to fully utilize SSD-based file servers. Moreover, since data layout of the cache system can also largely influence its access performance, SLA-Cache applies a layout-aware cache placement scheme (LCP) to store data on SSD-based file servers. By storing data with an optimal layout requiring the lowest access cost among three typical layout candidates, LCP can further improve system performance. We have implemented SLA-Cache under the MPICH2 I/O library. Experimental results show that SLA-Cache can significantly improve I/O throughput, and is a promising approach for parallel applications."",""1558-2183"","""",""10.1109/TPDS.2016.2521363"",""National Basic Research 973 Program of China(grant numbers:2015CB352400)"; National Science Foundation of China(grant numbers:61572377); Natural Science Foundation of Hubei Province of China(grant numbers:2014CFB239); HPCL(grant numbers:201512-02); SKLSE(grant numbers:2015-A-06); US National Science Foundation(grant numbers:CNS-1162540);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7390309"",""Parallel I/O system";I/O middleware;solid state drive;"cache system"",""Servers";Layout;System performance;Throughput;Middleware;Performance evaluation;"Parallel processing"","""",""16"","""",""42"",""IEEE"",""25 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"IMR: High-Performance Low-Cost Multi-Ring NoCs,""S. Liu"; T. Chen; L. Li; X. Feng; Z. Xu; H. Chen; F. Chong;" Y. Chen"",""State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China"; CAS Center for Excellence in Brain Science and Intelligence Technology; Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Institute of Parallel and Distributed Systems, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science, University of California, Santa Barbara, CA;" CAS Center for Excellence in Brain Science and Intelligence Technology"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1700"",""1712"",""A ring topology is a common solution of network-on-chip (NoC) in industry, but is frequently criticized to have poor scalability. In this paper, we present a novel type of multi-ring NoC called isolated multi-ring (IMR), which can even support chip multiprocessors (CMPs) with 1,024 cores. In IMR, any pair of cores are connected via at least one isolated ring, so that each packet can reach the destination without transferring from one ring to another. Therefore, IMR no longer needs expensive routers as mesh, which not only enhances the network performance but also reduces hardware overheads. We utilize simulated evolution to design optimized IMR topologies. We compare these IMR topologies against nine representative NoCs (e.g., traditional mesh, multi mesh, low-cost mesh, Express-virtual-channels mesh (EVC), torus ring, and hierarchical ring). We observe from experiments that IMR significantly outperforms its competitors in both saturation throughput and latency across all scenarios considered. For example, in a 16 × 16 CMP, IMR improves the saturation throughput of a state-of-the-art mesh (EVC) by 265.29 percent on average, and reduces the average packet latency on SPLASH-2 application traces by 71.58 percent, while consuming 5.08 percent less area and 9.76 percent less power. In a 32 × 32 CMP, IMR averagely improves the saturation throughput of EVC by 191.58 percent, and averagely reduces the packet latency on SPLASH-2 application traces by 23.09 percent, while consuming 2.86 percent less area and 10.81 percent less power."",""1558-2183"","""",""10.1109/TPDS.2015.2465905"",""NSF(grant numbers:61133004,61222204,61221062,61303158,61432016,61472396,61473275)"; 973 Program of China(grant numbers:2015CB358800); Strategic Priority Research Program of the CAS(grant numbers:XDA06010403,XDB02040009); International Collaboration Key Program of the CAS(grant numbers:171111KYSB20130002); 10000 talent program;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7182353"",""Network on Chip";Topology;Multi-Ring;Network on Chip;Topology;"Multi-Ring"",""Routing";Evolutionary computation;Linear programming;Hardware;Sociology;Statistics;"Guidelines"","""",""17"",""2"",""44"",""IEEE"",""7 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;
"In-Place Matrix Transposition on GPUs,""J. Gómez-Luna"; I. -J. Sung; L. -W. Chang; J. M. González-Linares; N. Guil;" W. -M. W. Hwu"",""University of Córdoba, Spain"; Multicoreware, Inc.; University of Illinois at Urbana Champaign; University of Málaga, Spain; University of Málaga, Spain;" University of Illinois at Urbana Champaign"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""776"",""788"",""Matrix transposition is an important algorithmic building block for many numeric algorithms such as FFT. With more and more algebra libraries offloading to GPUs, a high performance in-place transposition becomes necessary. Intuitively, in-place transposition should be a good fit for GPU architectures due to limited available on-board memory capacity and high throughput. However, direct application of CPU in-place transposition algorithms lacks the amount of parallelism and locality required by GPU to achieve good performance. In this paper we present our in-place matrix transposition approach for GPUs that is performed using elementary tile-wise transpositions. We propose low-level optimizations for the elementary transpositions, and find the best performing configurations for them. Then, we compare all sequences of transpositions that achieve full transposition, and detect which is the most favorable for each matrix. We present an heuristic to guide the selection of tile sizes, and compare them to brute-force search. We diagnose the drawback of our approach, and propose a solution using minimal padding. With fast padding and unpadding kernels, the overall throughput is significantly increased. Finally, we compare our method to another recent implementation."",""1558-2183"","""",""10.1109/TPDS.2015.2412549"",""Starnet Center for Future Architecture Research"; Center of Excellence; NVIDIA; Ministry of Education of Spain(grant numbers:TIN2010-16144); Junta de Andalucía of Spain(grant numbers:TIC-1692);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7059219"",""GPU";Transposition;In-Place;GPU;transposition;"in-place"",""Arrays";Graphics processing units;Throughput;Parallel processing;Multicore processing;Libraries;"Layout"","""",""7"",""1"",""20"",""IEEE"",""12 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;
"Intrusion-Tolerant Broadcast and Agreement Abstractions in the Presence of Byzantine Processes,""A. Mostéfaoui";" M. Raynal"",""LINA, Université de Nantes, Nantes Cedex, France";" Institut Universitaire de France and IRISA, Université de Rennes, Rennes Cedex, France"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1085"",""1098"",""A process commits a Byzantine failure when its behavior does not comply with the algorithm it is assumed to execute. Considering asynchronous message-passing systems, this paper presents distributed abstractions, and associated algorithms, that allow non-faulty processes to correctly cooperate, despite the uncertainty created by the net effect of asynchrony and Byzantine failures. These abstractions are broadcast abstractions (namely, no-duplicity broadcast, reliable broadcast, and validated broadcast), and agreement abstraction (namely, consensus). While no-duplicity broadcast and reliable broadcast are well-known one-to-all communication abstractions, validated broadcast is a new all-to-all communication abstraction designed to address agreement problems. After having introduced these abstractions, the paper presents an algorithm implementing validated broadcast on top of reliable broadcast. Then the paper presents two consensus algorithms, which are reductions of multivalued consensus to binary consensus. The first one is a generic algorithm, that can be instantiated with unreliable broadcast or no-duplicity broadcast, while the second is a consensus algorithm based on validated broadcast. Finally, a third algorithm is presented that solves the binary consensus problem. This algorithm is a randomized algorithm based on validated broadcast and a common coin. The presentation of all the abstractions and their algorithms is done incrementally."",""1558-2183"","""",""10.1109/TPDS.2015.2427797"",""ANR"; DISPLEXITY; DISCMAT;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7097735"",""Abstraction level";Agreement;Asynchronous message-passing system;Broadcast abstraction;Byzantine process;Common coin;Consensus;Distributed algorithm;Faulttolerance;Intrusion-tolerance;Message validation;Reliable broadcast;Signature-free algorithm;Abstraction level;agreement;asynchronous message-passing system;broadcast abstraction;byzantine process;common coin;consensus;distributed algorithm;fault-tolerance;intrusion-tolerance;message validation;reliable broadcast;"signature-free algorithm"",""Reliability";Computer crashes;Computational modeling;Distributed computing;Algorithm design and analysis;Distributed algorithms;"Security"","""",""18"",""1"",""29"",""IEEE"",""29 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;
"Joint Optimization of Lifetime and Transport Delay under Reliability Constraint Wireless Sensor Networks,""M. Dong"; K. Ota; A. Liu;" M. Guo"",""Department of Information and Electronic Engineering, Muroran Insitute of Technology, Muroran, Hokkaido, Japan"; Department of Information and Electronic Engineering, Muroran Insitute of Technology, Muroran, Hokkaido, Japan; School of Information Science and Engineeing, Central South University, ChangSha, China;" Department of Computer Science, Shanghai Jiao Tong University, Shanghai, China"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""225"",""236"",""This paper first presents an analysis strategy to meet requirements of a sensing application through trade-offs between the energy consumption (lifetime) and source-to-sink transport delay under reliability constraint wireless sensor networks. A novel data gathering protocol named Broadcasting Combined with Multi-NACK/ACK (BCMN/A) protocol is proposed based on the analysis strategy. The BCMN/A protocol achieves energy and delay efficiency during the data gathering process both in intra-cluster and inter-cluster. In intra-cluster, after each round of TDMA collection, a cluster head broadcasts NACK to indicate nodes which fail to send data in order to prevent nodes that successfully send data from retransmission. The energy for data gathering in intra-cluster is conserved and transport delay is decreased with multi-NACK mechanism. Meanwhile in inter-clusters, multi-ACK is returned whenever a sensor node sends any data packet. Although the number of ACKs to be sent is increased, the number of data packets to be retransmitted is significantly decreased so that consequently it reduces the node energy consumption. The BCMN/A protocol is evaluated by theoretical analysis as well as extensive simulations and these results demonstrate that our proposed protocol jointly optimizes the network lifetime and transport delay under network reliability constraint."",""1558-2183"","""",""10.1109/TPDS.2015.2388482"",""JSPS KAKENHI(grant numbers:25880002,26730056)"; JSPS A3 Foresight Program; NSFC(grant numbers:61450110085,61379110,61073104,61272494,61309027); National Basic Research 973 Program of China(grant numbers:2015CB352403,2014CB046305); State Key Laboratory of Industrial Control Technology(grant numbers:ICT1407);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7018943"",""wireless sensor networks";network lifetime;transport delay;statistical reliability;cluster-radius;Wireless sensor networks;network lifetime;transport delay;statistical reliability;"cluster-radius"",""Delays";Protocols;Reliability;Energy consumption;Broadcasting;Wireless sensor networks;"Automatic repeat request"","""",""119"","""",""22"",""IEEE"",""23 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;
"Kernel-Based Thread and Data Mapping for Improved Memory Affinity,""M. Diener"; E. H. M. Cruz; M. A. Z. Alves; P. O. A. Navaux; A. Busse;" H. -U. Heiss"",""Informatics Institute of the Federal University of Rio Grande do Sul, Porto Alegre, Brazil"; Informatics Institute of the Federal University of Rio Grande do Sul, Porto Alegre, Brazil; Informatics Institute of the Federal University of Rio Grande do Sul, Porto Alegre, Brazil; Informatics Institute of the Federal University of Rio Grande do Sul, Porto Alegre, Brazil; Communication and Operating Systems Group of the Technische Universität Berlin, Germany;" Communication and Operating Systems Group of the Technische Universität Berlin, Germany"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2653"",""2666"",""Reducing the cost of memory accesses, both in terms of performance and energy consumption, is a major challenge in shared-memory architectures. Modern systems have deep and complex memory hierarchies with multiple cache levels and memory controllers, leading to a Non-Uniform Memory Access (NUMA) behavior. In such systems, there are two ways to improve the memory affinity: First, by mapping threads that share data to cores with a shared cache, cache usage and communication performance are optimized. Second, by mapping memory pages to memory controllers that perform the most accesses to them and are not overloaded, the average cost of accesses is reduced. We call these two techniques thread mapping and data mapping, respectively. Thread and data mapping should be performed in an integrated way to achieve a compounding effect that results in higher improvements overall. Previous work in this area requires expensive tracing operations to perform the mapping, or require changes to the hardware or to the parallel application. In this paper, we propose kMAF, a mechanism that performs integrated thread and data mapping in the kernel. kMAF uses the page faults of parallel applications to characterize their memory access behavior and performs the mapping during the execution of the application based on the detected behavior. In an evaluation with a large set of parallel benchmarks executing on three NUMA architectures, kMAF achieved substantial performance and energy efficiency improvements, close to an Oracle-based mechanism and significantly higher than previous proposals."",""1558-2183"","""",""10.1109/TPDS.2015.2504985"",""CNPq"; CAPES;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7345593"",""Cache memories";shared memory;virtual memory;NUMA;memory affinity;thread mapping;"data mapping"",""Instruction sets";Hardware;Message systems;Memory management;Operating systems;"Energy consumption"","""",""11"","""",""40"",""IEEE"",""3 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"Lazy-Merge: A Novel Implementation for Indexed Parallel  $K$ -Way In-Place Merging,""A. Salah"; K. Li;" K. Li"",""College of Information Science and Engineering, Hunan University, Changsha, Hunan, China"; College of Information Science and Engineering, Hunan University, Changsha, Hunan, China;" College of Information Science and Engineering, Hunan University, Changsha, Hunan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""2049"",""2061"",""Merging sorted segments is a core topic of fundamental computer science that has many different applications, such as n-body simulation. In this research, we propose Lazy-Merge, a novel implementation of sequential in-place k-way merging algorithms, that can be utilized in their parallel counterparts. The implementation divides the k-way merging problem into t ordered and independent smaller k-way merging tasks (partitions), but each merging task includes a set of scattered ranges to be merged by an existing merging algorithm. The final merged list includes ranges with ordered elements, but the ranges themselves are not ordered. Lazy-Merge utilizes a novel usage of indexes to access the entire set of merged elements in order. Its merging time complexity is O(k log (n/k) + merge(n/p)), where k, n, and pare the number of segments, the list size and the number of processors (partitions), respectively. Here, merge(n/p) represents the time needed to merge n/p elements by the used in-place merging algorithm. The time complexity of accessing an element in the merged list is O(log k), that time can be constant if k processors are used. The results of the proposed work are compared with those of bitonic merge and the best time-space optimal algorithms on number of moves and execution time. In comparison with the existing algorithms, significant speedup and reasonable reduction factor for number of moves have been achieved."",""1558-2183"","""",""10.1109/TPDS.2015.2475763"",""National Natural Science Foundation of China(grant numbers:61133005,61432005)"; International Science & Technology Cooperation Program of China(grant numbers:2015DFA11240); National Natural Science Foundation of China(grant numbers:61370095,61472124); Egyptian Ministry of Higher Education;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7236913"",""In-place merging";k-way merging;lazy-merge;parallel algorithm;"rosetta index"",""Merging";Electronic mail;Standards;Indexes;Partitioning algorithms;Computer science;"Time complexity"","""",""8"","""",""35"",""IEEE"",""2 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Lightweight Memory Management for High Performance Applications in Consolidated Environments,""B. Kocoloski";" J. Lange"",""Department of Computer Science, University of Pittsburgh, Pittsburgh, PA, 15260";" Department of Computer Science, University of Pittsburgh, Pittsburgh, PA, 15260"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""468"",""480"",""Linux-based operating systems and runtimes (OS/Rs) have emerged as the environments of choice for the majority of HPC systems. While Linux-based OS/Rs have advantages such as extensive feature sets and developer familiarity, these features come at the cost of additional system overhead. In contrast to Linux, there is a substantial history of work in the HPC community focused on lightweight OS/Rs that provide scalable and consistent performance for HPC applications, but lack many of the features offered by commodity OS/Rs. In this paper, we propose to bridge the gap between LWKs and commodity OS/Rs by selectively providing a lightweight memory subsystem for HPC applications in a commodity OS/R where concurrently executing a diverse range of workloads is commonplace. Our system HPMMAP provides lightweight memory performance transparently to HPC applications by bypassing Linux's memory management layer. Using HPMMAP, HPC applications achieve consistent performance while the same local compute nodes execute competing workloads likely to be found in HPC clusters and “in-situ” workload deployments. Our approach is dynamically configurable at runtime, and requires no resources when not in use. We show that HPMMAP can decrease variance and reduce application runtime by up to 50 percent when executing a co-located competing commodity workload."",""1558-2183"","""",""10.1109/TPDS.2015.2397452"",""Advanced Scientific Computing Research";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7029138"",""lightweight kernels";operating systems;high performance computing;cloud computing;Lightweight kernels;operating systems;high performance computing;"cloud computing"",""Linux";Memory management;Resource management;Kernel;Benchmark testing;Random access memory;"Runtime"","""",""4"","""",""31"",""IEEE"",""2 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Local Congestion Avoidance in Network-on-Chip,""M. Tang"; X. Lin;" M. Palesi"",""Department of Computer Science and Technology, GuangDong University of Finance, Guangzhou, China"; Key Laboratory of Digital Life (Sun Yat-sen University), Ministry of Education, Guangzhou, China;" Kore University, Kore, Italy"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""2062"",""2073"",""Network-on-Chip (NoC) has been made the communication infrastructure for many-core architecture. NoC are subject to congestion, which is claimed to be avoided by many researchers. However, there is no completely understanding of congestion in literature, which hinders its solution. Toward this direction, we firstly carry out study on congestion in this paper. We find that congestion usually occurs at a portion of nodes in a local network region. Moreover, local congestion will significantly decrease system performance and mostly impact some particular communication pairs. Then we attempt to solve local congestion by addressing different local region size, based on Divide-Conquer approach and routing pressure. It avoids congestion in every local region by keeping routing pressure of every local region minimum. Using different local region size will create different routings. Our study shows that the local region size is closely related with the routing performance. When local region size is 5 × 5 the optimal routing performance of large size network could be achieved."",""1558-2183"","""",""10.1109/TPDS.2015.2474375"",""National Natural Science Foundation of China(grant numbers:61472454)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7229336"",""Network-on-Chip";routing algorithm;Divide- Conquer;routing pressure;local congestion;Network-on-chip;routing algorithm;divide-conquer;routing pressure;"local congestion"",""Routing";Delays;Noise measurement;Topology;Algorithm design and analysis;Throughput;"Adaptation models"","""",""18"","""",""39"",""IEEE"",""28 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Locality-Aware Parallel Sparse Matrix-Vector and Matrix-Transpose-Vector Multiplication on Many-Core Processors,""M. O. Karsavuran"; K. Akbudak;" C. Aykanat"",""Department of Computer Engineering, Bilkent University, Ankara, Turkey"; Department of Computer Engineering, Bilkent University, Ankara, Turkey;" Department of Computer Engineering, Bilkent University, Ankara, Turkey"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1713"",""1726"",""Sparse matrix-vector and matrix-transpose-vector multiplication (SpMMTV) repeatedly performed as z←ATx and y← A z (or y A w) for the same sparse matrix A is a kernel operation widely used in various iterative solvers. One important optimization for serial SpMMTV is reusing A-matrix nonzeros, which halves the memory bandwidth requirement. However, thread-level parallelization of SpMMTV that reuses A-matrix nonzeros necessitates concurrent writes to the same output-vector entries. These concurrent writes can be handled in two ways: via atomic updates or thread-local temporary output vectors that will undergo a reduction operation, both of which are not efficient or scalable on processors with many cores and complicated cache-coherency protocols. In this work, we identify five quality criteria for efficient and scalable thread-level parallelization of SpMMTV that utilizes one-dimensional (1D) matrix partitioning. We also propose two locality-aware 1D partitioning methods, which achieve reusing A-matrix nonzeros and intermediate z-vector entries"; exploiting locality in accessing x-, y-, and z-vector entries;" and reducing the number of concurrent writes to the same output-vector entries. These two methods utilize rowwise and columnwise singly bordered block-diagonal (SB) forms of A. We evaluate the validity of our methods on a wide range of sparse matrices. Experiments on the 60-core cache-coherent Intel Xeon Phi processor show the validity of the identified quality criteria and the validity of the proposed methods in practice. The results also show that the performance improvement from reusing A-matrix nonzeros compensates for the overhead of concurrent writes through the proposed SB-based methods."",""1558-2183"","""",""10.1109/TPDS.2015.2453970"",""PRACE 4IP project"; EU Framework Programme for Research and Innovation(grant numbers:653838);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152923"",""cache locality";sparse matrix;sparse matrix-vector multiplication;Cache locality;sparse matrix;sparse matrix-vector multiplication;matrix reordering;singly bordered block-diagonal form;Intel Many Integrated Core Architecture (Intel MIC);"Intel Xeon Phi"",""Sparse matrices";Instruction sets;Partitioning algorithms;Couplings;Upper bound;"Computer architecture"","""",""18"","""",""33"",""IEEE"",""8 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Lock-Free and Wait-Free Slot Scheduling Algorithms,""P. Aggarwal";" S. R. Sarangi"",""Department of Computer Science & Engineering, Indian Institute of Technology, New Delhi, India";" Department of Computer Science & Engineering, Indian Institute of Technology, New Delhi, India"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1387"",""1400"",""In this paper, we consider the design space of parallel non-blocking slot scheduling algorithms. Slot schedulers divide time into discrete quanta called slots, and schedule resources at the granularity of slots. They are typically used in high throughput I/O systems, data centers, video servers, and network drivers. We propose a family of parallel slot scheduling problems of increasing complexity, and then propose parallel lock-free and wait-free algorithms to solve them. In specific, we propose problems that can reserve, as well as free a set of contiguous slots in a non-blocking manner. We show that in a system with 64 threads, it is possible to get speedups of 10X by using lock-free algorithms as compared to a baseline implementation that uses locks. We additionally propose wait-free algorithms, whose mean performance is roughly the same as the version with locks. However, they suffer from significantly lower jitter and ensure a high degree of fairness among threads."",""1558-2183"","""",""10.1109/TPDS.2015.2435786"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7110616"",""Wait free";lock free;scheduler;"slot scheduling"",""Schedules";Arrays;Instruction sets;Processor scheduling;"Scheduling"","""",""3"","""",""25"",""IEEE"",""20 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"MACS: A Highly Customizable Low-Latency Communication Architecture,""R. Kumar";" A. Gordon-Ross"",""NSF Center for High-Performance Reconfigurable Computing (CHREC), University of Florida, Gainesville, FL, 32611 USA";" NSF Center for High-Performance Reconfigurable Computing (CHREC), University of Florida, Gainesville, FL, 32611 USA"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""237"",""249"",""Networks-on-chips (NoCs) are an increasingly popular communication infrastructure in single chip VLSI design for enhancing parallelism and system scalability. Processing elements (PEs) connect to a communication topology via NoC switches, which are responsible for runtime establishment and management of inter-PE communication channels. Since NoC switch design directly affects overall system performance and exploited communication parallelism, much previous work focused on efficient NoC switch design. In this paper, we present MACS-a highly parametric NoC switch architecture that provides reduced data transfer latency, increased designer flexibility, and scalability as compared to previous architectures by combining and enhancing several NoC design strategies. MACS enhances inter-PE communication using a circuit switching technique with minimal adaptive routing and a simple and fair path resolution algorithm to maximize bandwidth utilization. We evaluate area and performance of an FPGA implementation of MACS, and, show that compared to previous work, MACS offers a 2× to 7× decrease in average channel setup latency, a 1.7× to 2× reduction in area requirements, similar average packet latency, up to a 6× increase in the network saturation point, and up to a 1.4× increase in bandwidth utilization. Additionally, we illustrate MACS's low average channel setup latency using six network traffic patterns and eight parallel JPEG decompression core trace simulations."",""1558-2183"","""",""10.1109/TPDS.2015.2390631"",""National Science Foundation(grant numbers:EEC-0642422,IIP-1161022)"; NSF;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006979"",""Network-on-chip";minimal adaptive;distributed round-robin;FPGA;Network-on-chip;minimal adaptive;distributed round-robin;"FPGA"",""Ports (Computers)";Bandwidth;Routing;Switching circuits;Communication channels;Switches;"Topology"","""",""7"","""",""37"",""USGov"",""12 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Many-Core Real-Time Task Scheduling with Scratchpad Memory,""S. -W. Cheng"; C. -W. Chang; J. -J. Chen; T. -W. Kuo;" P. -C. Hsiu"",""Department of Computer Science and Information Engineering, National Taiwan University, No. 1, Sec. 4, Roosevelt Rd., Taipei, Taiwan, R.O.C"; Department of Computer Science and Information Engineering, School of Electrical and Computer Engineering, College of Engineering, Chang Gung University, No. 259, Wenhua 1st Rd., Guishan Township, Taoyuan County 333, Taiwan, R.O.C; Department of Informatics, Karlsruhe Institute of Technology, P.O. Box 3640, Karlsruhe, Germany; Department of Computer Science and Information Engineering, National Taiwan University, No. 1, Sec. 4, Roosevelt Rd., Taipei, Taiwan, R.O.C;" Research Center for Information Technology Innovation, Institute of Information Science, Academia Sinica, No. 128, Sec. 2, Academia Rd., Nankang Dist., Taipei 115, Taiwan, R.O.C"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2953"",""2966"",""This work is motivated by the demand for scheduling tasks upon the increasingly popular island-based many-core architectures. On such an architecture, homogeneous cores are grouped into islands, each of which is equipped with a scratchpad memory module (referred to as local memory). We first show the NP-hardness and the inapproximability of the scheduling problem. Despite the inapproximability, positive results can still be found when different cases of the problem are investigated. A $(3-\frac{1}{F})$ - approximation algorithm is proposed for the minimization of the maximum system utilization, where  $F$  is the number of cores in the platform. When the technique of resource augmentation is considered, this paper further develops a $(\gamma +1)$ -memory $\frac{2\gamma -1}{\gamma -1}$ -approximation algorithm, where $\gamma$  represents the trade-off between CPU utilization and local memory space. On the other hand, a special case is also considered when the ratio of the worst-case execution time of a task without and with using the local memory is bounded by a constant. The capabilities of the proposed algorithms are then evaluated with benchmarks from MRTC, UTDSP, NetBench and DSPstone, where the maximum system utilization can be significantly reduced even when the local memory size is only 5 percent of the total footprint of all of the tasks."",""1558-2183"","""",""10.1109/TPDS.2016.2516519"",""Chang Gung University(grant numbers:BMRPD84)"; Ministry of Science and Technology(grant numbers:103-2218-E-182-004-MY2,103-2221-E-001-040-MY3,104-2628-E-001-003-MY3); DFG;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7378514"",""Many-core architecture";scratchpad memory;partitioned scheduling algorithms;real-time systems;multi-level memory;"resource augmentation"",""Real-time systems";Resource management;Processor scheduling;Scheduling;Memory management;"Hardware"","""",""7"","""",""42"",""IEEE"",""12 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Mapping Streaming Applications on Commodity Multi-CPU and GPU On-Chip Processors,""A. Vilches"; A. Navarro; R. Asenjo; F. Corbera; R. Gran;" M. J. Garzarán"",""Universidad de Málaga, Spain"; Universidad de Málaga, Spain; Universidad de Málaga, Spain; Universidad de Málaga, Spain; Universidad de Zaragoza, Spain;" Department of Computer Science, UIUC, Urbana-Champaign, IL"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1099"",""1115"",""In this paper, we consider the problem of efficiently executing streaming applications on commodity processors composed of several cores and an on-chip GPU. Streaming applications, such as those in vision and video analytic, consist of a pipeline of stages and are good candidates to take advantage of this type of platforms. We also consider that characteristics of the input may change while the application is running. Therefore, we propose a framework that adaptively finds the optimal mapping of the pipeline stages. The core of the framework is an analytical model coupled with information collected at runtime used to dynamically map each pipeline stage to the most efficient device, taking into consideration both performance and energy. Our experimental results show that for the evaluated applications running on two different architectures, our model always predicts the best configuration among the evaluated alternatives, and significantly reduces the amount of information that needs to be collected at runtime. This best configuration has, on the average, 20 percent higher throughput than the configuration recommended by a baseline state of the art approach, while the ratio throughput/energy is 43 percent higher. We have measured improvements in throughput and throughput/energy of up-to 81 and 204 percent, respectively, when the model is used to adapt to a video that changes from low to high definition."",""1558-2183"","""",""10.1109/TPDS.2015.2432809"",""Spanish projects(grant numbers:TIN2010-16144,TIN 2013-42253-P,TIN2013-46957-C2-1-P)"; NoE(grant numbers:TIN2014-52608-REDC,P08-TIC-03500,P11-TIC-08144); gaZ: T48 research group;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106505"",""Heterogeneous CPU-GPU chips";pipeline pattern;adaptive mapping;analytical model;energy aware;Heterogeneous CPU-GPU chips;pipeline pattern;adaptive mapping;analytical model;"energy aware"",""Pipelines";Graphics processing units;Instruction sets;Runtime;Throughput;Streaming media;"Parallel processing"","""",""11"","""",""32"",""IEEE"",""13 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;
"MATCH for the Prosumer Smart Grid The Algorithmics of Real-Time Power Balance,""R. Pal"; C. Chelmis; M. Frincu;" V. Prasanna"",""Departments of Computer Science and Electrical Engineering, University of Southern California, CA"; Department of Computer Science, University of Southern California, Los Angeles, CA; Department of Computer Science, West University of Timisoara, Timisoara, Romania;" Departments of Computer Science and Electrical Engineering, University of Southern California, CA"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3532"",""3546"",""Prosumers or proactive consumers are steadily on the rise in emerging Smart Grid systems. These consumers, apart from their traditonal role of using energy from the grid, also are actively involved in individually transferring stored energy from renewable sources such as wind and solar, to the grid. The large-scale integration of renewable generation in the emerging grid will re-define ways of meeting consumer energy demands, and more importantly drive greener and cost-effective utility operations. In this paper, we investigate the problem of matching consumer demand with the grid supply in real-time, and in the presence of renewables. We formulate this problem as a stochastic optimization problem and propose MATCH, a fast distributed real-time algorithm that accounts for the uncertainties in (i) renewable generation, (ii) the latter's transmission through the grid network, (iii) loads, and (iv) energy prices, and balances power in the Smart Grid at all times. MATCH is based on the Lyapunov stochastic optimization framework and scales to localities with a large number of networked renewable generation sources. We validate the efficacy of MATCH through experiments conducted using data modelled on proprietary data obtained from two public utilities. As part of the main results of this work, we show that (a) MATCH outputs unique approximate-optimal grid parameter configuration vectors in real-time that ensure perennial supplydemand balance in the grid at a minimum cost, and (b) mesh transmission network topologies lead to better MATCH outputs when compared to other existing transmission network topologies."",""1558-2183"","""",""10.1109/TPDS.2016.2544316"",""United States Department of Energy(grant numbers:DE-OE0000192)"; U.S. National Science Foundation(grant numbers:ACI-1339756); Department of Water and Power;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7437455"",""Prosumer";renewable energy;topology;power balance;optimization;"MATCH"",""Smart grids";Real-time systems;Algorithm design and analysis;Heuristic algorithms;Network topology;Optimization;"Energy storage"","""",""22"","""",""32"",""IEEE"",""21 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Measuring and Evaluating Live Content Consistency in a Large-Scale CDN,""G. Liu"; H. Shen; H. Chandler;" J. Li"",""Department of Electrical and Computer Engineering, Clemson University, Clemson, SC"; Department of Electrical and Computer Engineering, Clemson University, Clemson, SC; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI;" Microsoft Research, Redmond, WA"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""2074"",""2090"",""Content Delivery Networks (CDNs) play a central role in today's Internet infrastructure and have seen a sharp increase in scale. More and more internet sites are armed with live contents, such as live sports game statistics, e-commerce, and online auctions, and they rely on CDNs to deliver such contents freshly at scale. However, the problem of maintaining consistency for live (dynamic) contents while achieving high scalability is non-trivial in CDNs. The large number of widely scattered replicas guarantees the QoS of end-users while substantially increasing the complexity of consistency maintenance under frequent updates. Current consistency maintenance infrastructures and methods cannot simultaneously satisfy both scalability and consistency. In this paper, we first analyze our crawled trace data of cached sports game content on thousands of content servers of a major CDN. We analyze the content consistency from different perspectives, from which we break down the reasons for inconsistency among content servers. We verify that the CDN uses unicast instead of multicast trees as the update infrastructure, which may not scale effectively. Then, we further evaluate the performance in consistency, scalability and overhead for different infrastructures with different update methods. We itemize the advantages and disadvantages of different methods and infrastructures in different scenarios through the evaluation. Based on this evaluation, we propose our hybrid and self-adaptive update method to reduce network load and improve scalability under the conditions recorded in the trace and prove its effectiveness through trace-driven experiments. We aim to give guidance for appropriate selections of consistency maintenance infrastructures and methods for a CDN, and for choosing a CDN service with different considerations."",""1558-2183"","""",""10.1109/TPDS.2015.2479222"",""U.S. NSF(grant numbers:NSF-1404981,IIS-1354123,CNS-1254006,CNS-1249603)"; Microsoft Research Faculty Fellowship(grant numbers:8300751);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7270312"",""Content delivery network";consistency maintenance;scalability;Content delivery network;consistency maintenance;"scalability"",""Servers";Maintenance engineering;IP networks;Games;Scalability;Unicast;"Propagation delay"","""",""6"","""",""44"",""IEEE"",""16 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Melia: A MapReduce Framework on OpenCL-Based FPGAs,""Z. Wang"; S. Zhang; B. He;" W. Zhang"",""Nanyang Technological University, Singapore"; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore;" Hong Kong University of Science and Technology, Hong Kong"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3547"",""3560"",""MapReduce, originally developed by Google for search applications, has recently become a popular programming framework for parallel and distributed environments. This paper presents an energy-efficient architecture design for MapReduce on Field Programmable Gate Arrays (FPGAs). The major goal is to enable users to program FPGAs with simple MapReduce interfaces, and meanwhile to embrace automatic performance optimizations within the MapReduce framework. Compared to other processors like CPUs and GPUs, FPGAs are (re-)programmable hardware and have very low energy consumption. However, the design and implementation of MapReduce on FPGAs can be challenging: firstly, FPGAs are usually programmed with hardware description languages, which hurts the programmability of the MapReduce design to its users";" secondly, since MapReduce has irregular access patterns (especially in the reduce phase) and needs to support user-defined functions, careful designs and optimizations are required for efficiency. In this paper, we design, implement and evaluate Melia, a MapReduce framework on FPGAs. Melia takes advantage of the recent OpenCL programming framework developed for Altera FPGAs, and abstracts FPGAs behind the simple and familiar MapReduce interfaces in C. We further develop a series of FPGA-centric optimization techniques to improve the efficiency of Melia, and a costand resource-based approach to automate the parameter settings for those optimizations. We evaluate Melia on a recent Altera Stratix V GX FPGA with a number of commonly used MapReduce benchmarks. Our results demonstrate that 1) the efficiency and effectiveness of our optimizations and automated parameter setting approach, 2) Melia can achieve promising energy efficiency in comparison with its counterparts on CPUs/GPUs on both single-FPGA and cluster settings."",""1558-2183"","""",""10.1109/TPDS.2016.2537805"",""MoE AcRF(grant numbers:MOE2012-T2-1-126,MOE2012-T2-2-067)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425227"",""FPGA";MapReduce;programming frameworks;cost model;"OpenCL"",""Field programmable gate arrays";Optimization;Digital signal processing;Programming;"Data processing"","""",""38"","""",""49"",""IEEE"",""3 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Minimizing Inter-Server Communications by Exploiting Self-Similarity in Online Social Networks,""H. Chen"; H. Jin;" S. Wu"",""Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"; Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China;" Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1116"",""1130"",""Efficiently operating on relevant data for users in large-scale online social network (OSN) systems is a challenging problem. Storage systems used by popular OSNs often rely on key-value stores, where randomly partitioning the data of users among servers across the data centers is the defacto standard. Although by using DHTs, the random partition scheme is highly scalable for hosting a large number of users, it leads to costly inter-server communications across data centers due to the complexity of interconnection and interaction between OSN users. In this paper, we explore how to reduce the inter-server communications by retaining the simple and robust nature of OSNs. We propose a data placement solution atop OSN systems to divide users among servers according to the interaction-locality-based structure. Our approach exploits a simple, yet powerful principle of OSN interactions, self-similarity, which reveals that the inter-server communication cost is minimized under such intrinsic structure. Our algorithm avoids a significant amount of inter-server traffic as well as achieves load balance among servers across the data centers. We demonstrate the existence of self-similarity in large-scale Facebook traces including 10 million Facebook users and 24 million interaction events. We conduct comprehensive trace-driven simulations to evaluate this design. Results show that our scheme significantly reduces the traffic and latency of OSN systems comparing to existing schemes."",""1558-2183"","""",""10.1109/TPDS.2015.2427155"",""NSFC(grant numbers:61370233,61422202)"; Ministry of Education and China Mobile Communications Corporation Research Founding(grant numbers:MCM20130382); Foundation for the Author of National Excellent Doctoral Dissertation of PR China(grant numbers:201345);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7097076"",""Self-similarity";interaction graph;inter-server communications;data center;online social networks;Self-similarity;interaction graph;inter-server communications;data center;"online social networks"",""Facebook";Communities;Servers;Internet;Topology;"Mathematical model"","""",""45"","""",""47"",""IEEE"",""28 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Minimum Dependencies Energy-Efficient Scheduling in Data Centers,""M. Żotkiewicz"; M. Guzek; D. Kliazovich;" P. Bouvry"",""University of Luxembourg, Luxembourg"; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg;" University of Luxembourg, Luxembourg"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3561"",""3574"",""This work presents an on-line, energy- and communication-aware scheduling strategy for SaaS applications in data centers. The applications are composed of various services and represented as workflows. Each workflow consists of tasks related to each other by precedence constraints and represented by Directed Acyclic Graphs (DAGs). The proposed scheduling strategy combines advantages of state-of-the-art workflow scheduling strategies with energy-aware independent task scheduling approaches. The process of scheduling consists of two phases. In the first phase, virtual deadlines of individual tasks are set in the central scheduler. These deadlines are determined using a novel strategy that favors tasks which are less dependent on other tasks. During the second phase, tasks are dynamically assigned to computing servers based on the current load of network links and servers in a data center. The proposed approach, called Minimum Dependencies Energy-efficient DAG (MinD+ED) scheduling, has been implemented in the GreenCloud simulator. It outperforms other approaches in terms of energy efficiency, while keeping a satisfiable level of tardiness."",""1558-2183"","""",""10.1109/TPDS.2016.2542817"",""European Union in the framework of European Social Fund"; Supporting Educational Initiatives of the Warsaw University of Technology; National Research Fund; ECO-CLOUD(grant numbers:C12/IS/3977641); Green@Cloud(grant numbers:INTER/CNRS/11/03); IShOP(grant numbers:POL-LUX/13/IS/6466384);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7434655"",""Workflow scheduling";DAG scheduling;energy-efficient;"dynamic scheduling"",""Servers";Processor scheduling;Job shop scheduling;Logic gates;Dynamic scheduling;Energy consumption;"Energy efficiency"","""",""24"","""",""46"",""IEEE"",""16 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Mitigating the Impact of Hardware Variability for GPGPUs Register File,""J. Tan"; M. Chen; Y. Yi;" X. Fu"",""Department of Electrical and Computer Engineering, University of Houston, Houston, TX"; Software Engineering Institute at the East China Normal University, Shanghai, China; Department of Electrical Engineering and Computer Science at the University of Kansas, Lawrence, KS;" Department of Electrical and Computer Engineering, University of Houston, Houston, TX"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3283"",""3297"",""As technology keeps scaling down, hardware variability, such as process variations (PV) and negative bias temperature instability (NBTI), emerges as a growing challenge in the modern GPGPUs (general-purpose computing on graphics processing units). PV induces significant delay variations statically, while NBTI dynamically slows down the GPGPUs. Each computing core (i.e., streaming multiprocessor) in GPGPUs supports thousands of simultaneously active threads, and requires a large register file. Such a sizable register file is very sensitive to the hardware variability, and becomes one of the major units in determining the core frequency. In this study, we propose a set of techniques that mitigate both the PV and NBTI impacts on GPGPUs register file. In order to mitigate the susceptibility to PV, we first develop a novel mechanism that classifies registers into fast and slow categories in the highly-banked register architecture to maximize the frequency improvement. We then leverage the unique features in GPGPU applications to effectively tolerate the extra access delay to the slow registers. Moreover, we propose to dynamically balance the utilization across registers to further tolerate the NBTI degradation. Our experimental results show that our proposed techniques optimize GPGPUs performance by 22 percent on average under both PV and NBTI effects."",""1558-2183"","""",""10.1109/TPDS.2016.2531668"",""US National Science Foundation(grant numbers:CCF-1320730,CCF-1351054,EPS-0903806)"; NSF(grant numbers:91418203);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412772"",""Hardware variability";process variations (PV);negative bias temperature instability (NBTI);aging;GPGPUs;"register file"",""Registers";Radio frequency;Delays;Hardware;Instruction sets;Degradation;"Stress"","""",""5"","""",""40"",""IEEE"",""18 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Mobility Prediction Based Joint Stable Routing and Channel Assignment for Mobile Ad Hoc Cognitive Networks,""F. Tang"; M. Guo; S. Guo;" C. -Z. Xu"",""Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China"; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Computer Science, The University of Aizu, Fukushima, Japan;" Department of Electrical and Computer Engineering, Wayne State University, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""12 Feb 2016"",""2016"",""27"",""3"",""789"",""802"",""Link instability and channel interference cause significant performance degradation to mobile ad hoc cognitive networks (MACNets). Existing work designs routing and assigns channels separately or does not consider mobility prediction and channel vacation to primary nodes. In this paper, we investigate how to jointly optimize route setup and channel assignment. Firstly, we propose an integrated data transmission cost (IDTC) to quantitatively measure the communication quality of links. This novel routing metric IDTC integratively considers 1) node mobility, 2) co-channel interference among primary and cognitive nodes, 3) relay workload on a specified channel, and 4) distance between the relay and the destination node. We, then, design channel assignment algorithms that completely avoid the interference with primary nodes and minimize the conflict to cognitive nodes. Finally, we propose a joint stable routing and channel assignment (J-SRCA) protocol based on mobility prediction for the network throughput maximization. In our J-SRCA, each link selected hop by hop is simultaneously assigned an interference-avoiding channel during a route setup. NS2-based simulation results demonstrate that our J-SRCA significantly improves various network performance, and the higher interference degree cognitive networks experience, the more improvement our J-SRCA will bring to the networks."",""1558-2183"","""",""10.1109/TPDS.2013.216"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6587033"",""Cognitive network";stable routing;channel assignment;mobility model;"multi-hop ad hoc network"",""Interference";Routing;Stability analysis;Relays;Throughput;Joints;"Measurement"","""",""36"","""",""21"",""IEEE"",""26 Aug 2013"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Modeling QoE in Dependable Tele-Immersive Applications: A Case Study of World Opera,""N. R. Veeraragavan"; L. Montecchi; N. Nostro; R. Vitenberg; H. Meling;" A. Bondavalli"",""Department of Informatics, University of Oslo, Oslo, Norway"; Department of Mathematics and Informatics, University of Firenze, Firenze, Italy; Department of Mathematics and Informatics, University of Firenze, Firenze, Italy; Department of Informatics, University of Oslo, Oslo, Norway; Electrical Engineering and Computer Science, University of Stavanger, Stavanger, Norway;" Department of Mathematics and Informatics, University of Firenze, Firenze, Italy"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2667"",""2681"",""With the advent of recent technological advances, more demanding tele-immersive applications have started to emerge. In the World Opera application, artists from different opera houses across the globe can participate in a single united performance, and interact almost as if they were co-located. One of the main design challenges in this application domain is to assess to what extent the inevitable failures of some of the numerous and complex hardware, software, and network components affect the quality of experience for the user. This challenge cannot be addressed by traditional system-centric methods for dependability evaluation, which do not take personalized user perspective into account when considering meaningful and acceptable degradation of services. In this paper, we propose a novel method to assess the quality of experience in presence of failures, based on a new metric called perceived reliability. The method takes the human perspective into account and allows considering factors such as human perception of video and audio, characteristics of the audience, as well as performance elements and artistic content. This method can help system designers and engineers compare architectural variants and determine the dependability budget. We show the feasibility of our method by applying it to a World Opera performance. To this end, we construct a SAN-based model and run simulations in the Möbius framework. The obtained results provide useful guidelines for system engineers towards improving the quality of experience of World Opera performances despite the presence of failures."",""1558-2183"","""",""10.1109/TPDS.2015.2503291"",""Tidal News project(grant numbers:201406)"; Research Council of Norway; TENACE PRIN(grant numbers:20103P34XC); Italian Ministry of Education, University and Research; DEVASSES project; EU Seventh Framework Programme(grant numbers:PIRSES-GA-2013-612569);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336533"",""Reliability analysis";quality of experience;tele-immersive applications;"world opera"",""Streaming media";Workstations;Reliability;Measurement;Cameras;Microphones;"Mixers"","""",""9"","""",""39"",""IEEE"",""24 Nov 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;
"MPI-ACC: Accelerator-Aware MPI for Scientific Applications,""A. M. Aji"; L. S. Panwar; F. Ji; K. Murthy; M. Chabbi; P. Balaji; K. R. Bisset; J. Dinan; W. -c. Feng; J. Mellor-Crummey; X. Ma;" R. Thakur"",""Department of Computer Science, Virginia Tech, Blacksburg, VA"; Department of Computer Science, Virginia Tech, Blacksburg, VA; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science, Rice University, Houston, TX; Department of Computer Science, Rice University, Houston, TX; Mathematical and Computer Science, Argonne National Laboratory; Virginia Bioinformatics Inst., Virginia Tech, Blacksburg, VA; Mathematical and Computer Science, Argonne National Laboratory; Department of Computer Science, Virginia Tech, Blacksburg, VA; Department of Computer Science, Rice University, Houston, TX; Department of Computer Science, North Carolina State University, Raleigh, NC;" Mathematical and Computer Science, Argonne National Laboratory"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1401"",""1414"",""Data movement in high-performance computing systems accelerated by graphics processing units (GPUs) remains a challenging problem. Data communication in popular parallel programming models, such as the Message Passing Interface (MPI), is currently limited to the data stored in the CPU memory space. Auxiliary memory systems, such as GPU memory, are not integrated into such data movement standards, thus providing applications with no direct mechanism to perform end-to-end data movement. We introduce MPI-ACC, an integrated and extensible framework that allows end-to-end data movement in accelerator-based systems. MPI-ACC provides productivity and performance benefits by integrating support for auxiliary memory spaces into MPI. MPI-ACC supports data transfer among CUDA, OpenCL and CPU memory spaces and is extensible to other offload models as well. MPI-ACC's runtime system enables several key optimizations, including pipelining of data transfers, scalable memory management techniques, and balancing of communication based on accelerator and node architecture. MPI-ACC is designed to work concurrently with other GPU workloads with minimum contention. We describe how MPI-ACC can be used to design new communication-computation patterns in scientific applications from domains such as epidemiology simulation and seismology modeling, and we discuss the lessons learned. We present experimental results on a state-of-the-art cluster with hundreds of GPUs";" and we compare the performance and productivity of MPI-ACC with MVAPICH, a popular CUDA-aware MPI solution. MPI-ACC encourages programmers to explore novel application-specific optimizations for improved overall cluster utilization."",""1558-2183"","""",""10.1109/TPDS.2015.2446479"",""US Department of Energy(grant numbers:DE-SC0001770,DE-AC02-06CH11357,DE-AC05-00OR22725,DE-ACO6-76RL01830)"; DOE Office of Science(grant numbers:DE-FC02-07ER25800); DOE GTO(grant numbers:EE0002758); DTRA CNIMS(grant numbers:HDTRA1-11-D-0016-0001); NSF(grant numbers:OCI-0904844); NSF Blue Waters(grant numbers:OCI-0832603); NSF(grant numbers:CNS-0960081,CNS-054630,CNS-0958311); NVIDIA Graduate Fellowship; NVIDIA Professor Partnership; CUDA Research Center; National Science Foundation(grant numbers:CNS-0960081);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7127020"",""Heterogeneous (hybrid) systems";parallel systems;distributed architectures;concurrent programming;Heterogeneous (hybrid) systems;parallel systems;distributed architectures;"concurrent programming"",""Graphics processing units";Computational modeling;Optimization;Pipeline processing;Programming;Bandwidth;"Productivity"","""",""12"","""",""30"",""IEEE"",""17 Jun 2015"","""","""",""IEEE"",""IEEE Journals"""
"Multi-Jagged: A Scalable Parallel Spatial Partitioning Algorithm,""M. Deveci"; S. Rajamanickam; K. D. Devine;" Ü. V. Çatalyürek"",""Departments of Biomedical Informatics, and Computer Science & Engineering, The Ohio State University, Columbus, OH"; Computer Science Research Institute in the Center for Computing Research at Sandia National Laboratories, Albuquerque, NM; Computer Science Research Institute in the Center for Computing Research at Sandia National Laboratories, Albuquerque, NM;" Departments of Biomedical Informatics, Electrical & Computer Engineering and Computer Science & Engineering, The Ohio State University, Columbus, OH"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""803"",""817"",""Geometric partitioning is fast and effective for load-balancing dynamic applications, particularly those requiring geometric locality of data (particle methods, crash simulations). We present, to our knowledge, the first parallel implementation of a multidimensional-jagged geometric partitioner. In contrast to the traditional recursive coordinate bisection algorithm (RCB), which recursively bisects subdomains perpendicular to their longest dimension until the desired number of parts is obtained, our algorithm does recursive multi-section with a given number of parts in each dimension. By computing multiple cut lines concurrently and intelligently deciding when to migrate data while computing the partition, we minimize data movement compared to efficient implementations of recursive bisection. We demonstrate the algorithm’s scalability and quality relative to the RCB implementation in Zoltan on both real and synthetic datasets. Our experiments show that the proposed algorithm performs and scales better than RCB in terms of run-time without degrading the load balance. Our implementation partitions 24 billion points into 65,536 parts within a few seconds and exhibits near perfect weak scaling up to 6K cores."",""1558-2183"","""",""10.1109/TPDS.2015.2412545"",""U.S. Department of Energy"; Office of Science; Office of Advanced Scientific Computing Research; Advanced Computing (SciDAC) program; National Science Foundation(grant numbers:OCI-0904809); Office of Science; U.S. Department of Energy(grant numbers:DE-AC02-05CH11231);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7061994"",""Geometric partitioning";spatial partitioning;recursive bisection;jagged partitioning;load balancing;Geometric partitioning;spatial partitioning;recursive bisection;jagged partitioning;"load balancing"",""Partitioning algorithms";Program processors;Scalability;Distributed databases;Software algorithms;Heuristic algorithms;"Indexes"","""",""23"","""",""36"",""IEEE"",""18 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;
"New Bandwidth Sharing and Pricing Policies to Achieve a Win-Win Situation for Cloud Provider and Tenants,""H. Shen";" Z. Li"",""Department of Electrical and Computer Engineering, Clemson University, Clemson, SC";" Department of Electrical and Computer Engineering, Clemson University, Clemson, SC"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2682"",""2697"",""For predictable application performance or fairness in network sharing in clouds, many bandwidth allocation policies have been proposed. However, with these policies, tenants are not incentivized to use idle bandwidth or prevent link congestion, and may even take advantage of the policies to gain unfair bandwidth allocation. Increasing network utilization while avoiding congestion not only benefits cloud provider but also the tenants by improving application performance. In this paper, we propose a new pricing model that sets different unit prices for reserved bandwidth, the bandwidth on congested links and on uncongested links, and makes the unit price for congested links proportional to their congestion degrees. We use game theory model to analyze tenants' behaviors in our model and the current pricing models, which shows the effectiveness of our model in providing the incentives. With the pricing model, we propose a network sharing policy to achieve both min-guarantee and proportionality, while prevent tenants from earning unfair bandwidth. We further propose methods for each virtual machine to arrange its traffic to reduce its unsatisfied demand and maximize its utility, while increase network utilization. As a result, our solution creates a win-win situation, where tenants strive to increase their benefits in bandwidth sharing, which also concurrently increases the utilities of cloud provider and other tenants. Our simulation and trace-driven experimental results show the effectiveness of our solutions in creating the win-win situation."",""1558-2183"","""",""10.1109/TPDS.2015.2497701"",""US National Science Foundaton(grant numbers:NSF-1404981,IIS-1354123,CNS-1254006)"; Microsoft Research Faculty Fellowship(grant numbers:8300751);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7317795"",""Bandwidth allocation";pricing policies;network proportionality;"min-guarantee"",""Bandwidth";Pricing;Channel allocation;Barium;Analytical models;Resource management;"Cloud computing"","""",""17"","""",""26"",""IEEE"",""4 Nov 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Offloading Interrupt Load Balancing from SMP Virtual Machines to the Hypervisor,""L. Cheng";" F. C. M. Lau"",""Data Infrastructure, Facebook, Menlo Park, CA";" Department of Computer Science, University of Hong Kong (HKU)"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3298"",""3310"",""Cloud computing increasingly leverages SMP virtual machines (VMs) to host multi-threaded applications. Interrupt balancing as a problem becomes more challenging because VMs are subject to the hypervisor's scheduling. Since the scheduling delays are typically tens of milliseconds, when they are added to one VM's interrupt delivery, they can seriously degrade the VM's I/O performance. Traditional balancing techniques are designed for dedicated environments, which cannot work well in virtualized environments because VMs are disallowed to directly control the hardware in many cases. In this paper, we present hBalance, a very simple approach to offload interrupt load balancing from SMP-VMs to the hypervisor. To accelerate the interrupt processing, our approach does not require shortening the hypervisor's scheduling time slice, but dynamically redirects interrupts from preempted virtual CPUs to running ones in a balanced manner. hBalance supports both Fully Virtualiized (FV) guests and Para-Virtualized (PV) guests, and exhibits high portability among various hypervisors. With our prototype implementation in Xen, the experimental results with both micro-level and application-level benchmarks show that hBalance significantly improves SMP-VMs' I/O performance while introduces moderate overhead."",""1558-2183"","""",""10.1109/TPDS.2016.2537804"",""RGC"; CRF(grant numbers:C7036-15G); HKU;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425234"",""SMP virtual machines";interrupt load balancing;"I/O performance"",""Virtual machine monitors";Hardware;Load management;Virtual machining;Delays;Prototypes;"Kernel"","""",""9"","""",""45"",""IEEE"",""3 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"On Acceleration and Scalability of Number Theoretic Private Information Retrieval,""E. Ünal";" E. Savaş"",""Faculty of Engineering and Natural Sciences, Sabancı University, İstanbul, Turkey";" Faculty of Engineering and Natural Sciences, Sabancı University, İstanbul, Turkey"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1727"",""1741"",""We present scalable and parallel versions of Lipmaa's computationally-private information retrieval (CPIR) scheme [20], which provides log-squared communication complexity. In the proposed schemes, instead of binary decision diagrams utilized in the original CPIR, we employ an octal tree based approach, in which non-sink nodes have eight child nodes. Using octal trees offers two advantages: i) a serial implementation of the proposed scheme in software is faster than the original scheme and ii) its bandwidth usage becomes less than the original scheme when the number of items in the data set is moderately high (e.g., 4,096 for 80-bit security level using Damgard-Jurik cryptosystem). In addition, we present a highly-optimized parallel algorithm for shared-memory multi-core/processor architectures, which minimizes the number of synchronization points between the cores. We show that the parallel implementation is about 50 times faster than the serial implementation for a data set with 4,096 items on an eight-core machine. Finally, we propose a hybrid algorithm that scales the CPIR scheme to larger data sets with small overhead in bandwidth complexity. We demonstrate that the hybrid scheme based on octal trees can lead to more than two orders of magnitude faster parallel implementations than serial implementations based on binary trees. Comparison with the original as well as the other schemes in the literature reveals that our scheme is the best in terms of bandwidth requirement."",""1558-2183"","""",""10.1109/TPDS.2015.2456021"",""Turk Telekom(grant numbers:3014-07)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155582"",""Number Theoretic Private Information Retrieval";Security;Privacy;Parallel Algorithms;Number theoretic private information retrieval;security;privacy;"parallel algorithms"",""Databases";Complexity theory;Encryption;Servers;Bandwidth;"Protocols"","""",""3"","""",""30"",""IEEE"",""13 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"On Binary Decomposition Based Privacy-Preserving Aggregation Schemes in Real-Time Monitoring Systems,""X. Yang"; X. Ren; J. Lin;" W. Yu"",""Xi'an Jiaotong University, Xi'an, China"; Xi'an Jiaotong University, Xi'an, China; Xi'an Jiaotong University, Xi'an, China;" Towson University, Towson, MD"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Sep 2016"",""2016"",""27"",""10"",""2967"",""2983"",""In real-time monitoring systems, fine-grained measurements would pose great privacy threats to the participants as real-time measurements could disclose accurate people-centric activities. Differential privacy has been proposed to formalize and guide the design of privacy-preserving schemes. Nonetheless, due to the correlations and high fluctuations in time-series data, it is hard to achieve an effective privacy and utility tradeoff by differential privacy mechanisms. To address this issue, in this paper, we first proposed novel multi-dimensional decomposition based schemes to compress the noise and enhance the utility in differential privacy. The key idea is to decompose the measurements into multi-dimensional records and to achieve differential privacy in bounded dimensions so that the error caused by unbounded measurements can be significantly reduced. We then extended our developed scheme and developed a binary decomposition scheme for privacy-preserving time-series aggregation in real-time monitoring systems. Through a combination of extensive theoretical analysis and experiments, our data shows that our proposed schemes can effectively improve usability while achieving the same level of differential privacy than existing schemes."",""1558-2183"","""",""10.1109/TPDS.2016.2516983"",""Natural Science Foundation of China(grant numbers:61373115,61402356,61572398)"; China Post doctoral Science Foundation(grant numbers:2015M572565); US National Science Foundation(grant numbers:1117175,1350145);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379007"",""Real-time monitoring systems";real-time aggregation;multi-dimensional decomposition;"differential privacy"",""Privacy";Real-time systems;Data privacy;Sensitivity;Atmospheric measurements;Particle measurements;"Sensors"","""",""18"","""",""63"",""IEEE"",""12 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"On Traffic-Aware Partition and Aggregation in MapReduce for Big Data Applications,""H. Ke"; P. Li; S. Guo;" M. Guo"",""School of Computer Science and Engineering, the University of Aizu, Aizu, Japan"; School of Computer Science and Engineering, the University of Aizu, Aizu, Japan; School of Computer Science and Engineering, the University of Aizu, Aizu, Japan;" Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""818"",""828"",""The MapReduce programming model simplifies large-scale data processing on commodity cluster by exploiting parallel map tasks and reduce tasks. Although many efforts have been made to improve the performance of MapReduce jobs, they ignore the network traffic generated in the shuffle phase, which plays a critical role in performance enhancement. Traditionally, a hash function is used to partition intermediate data among reduce tasks, which, however, is not traffic-efficient because network topology and data size associated with each key are not taken into consideration. In this paper, we study to reduce network traffic cost for a MapReduce job by designing a novel intermediate data partition scheme. Furthermore, we jointly consider the aggregator placement problem, where each aggregator can reduce merged traffic from multiple map tasks. A decomposition-based distributed algorithm is proposed to deal with the large-scale optimization problem for big data application and an online algorithm is also designed to adjust data partition and aggregation in a dynamic manner. Finally, extensive simulation results demonstrate that our proposals can significantly reduce network traffic cost under both offline and online cases."",""1558-2183"","""",""10.1109/TPDS.2015.2419671"",""JST"; NSF; National Natural Science Foundation of China(grant numbers:61261160502,61272099); Program for Changjiang Scholars and Innovative Research Team in University(grant numbers:IRT1158); Shanghai Innovative Action Plan(grant numbers:13511504200);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079380"",""MapReduce, partition, aggregation, big data, lagrangian decomposition"",""Big data";Programming;Data models;Distributed algorithms;Heuristic algorithms;Algorithm design and analysis;"Network topology"","""",""34"","""",""25"",""IEEE"",""3 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Online Resource Scheduling Under Concave Pricing for Cloud Computing,""R. Zhang"; K. Wu; M. Li;" J. Wang"",""Department of Computer Science, City University of Hong Kong, Hong Kong"; Department of Computer Science, University of Victoria, Victoria, BC, Canada; Department of Computer Science, City University of Hong Kong, Hong Kong;" Department of Computer Science, City University of Hong Kong, Hong Kong"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1131"",""1145"",""With the booming cloud computing industry, computational resources are readily and elastically available to the customers. In order to attract customers with various demands, most Infrastructure-as-a-service (IaaS) cloud service providers offer several pricing strategies such as pay as you go, pay less per unit when you use more (so called volume discount), and pay even less when you reserve. The diverse pricing schemes among different IaaS service providers or even in the same provider form a complex economic landscape that nurtures the market of cloud brokers. By strategically scheduling multiple customers' resource requests, a cloud broker can fully take advantage of the discounts offered by cloud service providers. In this paper, we focus on how a broker can help a group of customers to fully utilize the volume discount pricing strategy offered by cloud service providers through cost-efficient online resource scheduling. We present a randomized online stack-centric scheduling algorithm (ROSA) and theoretically prove the lower bound of its competitive ratio. Three special cases of the offline concave cost scheduling problem and the corresponding optimal algorithms are introduced. Our simulation shows that ROSA achieves a competitive ratio close to the theoretical lower bound under the special cases. Trace-driven simulation using Google cluster data demonstrates that ROSA is superior to the conventional online scheduling algorithms in terms of cost saving."",""1558-2183"","""",""10.1109/TPDS.2015.2432799"",""Hong Kong Research Grants Council"; GRF(grant numbers:11213114); CityU(grant numbers:117913); Natural Sciences and Engineering Research Council of Canada(grant numbers:195819339);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106504"",""Cloud computing";Bulk purchasing;Concave pricing;Cloud computing;bulk purchasing;"concave pricing"",""Optimal scheduling";Cost function;Schedules;Cloud computing;Pricing;Scheduling;"Scheduling algorithms"","""",""35"","""",""28"",""IEEE"",""13 May 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Optimal Edge Congestion of Exchanged Hypercubes,""T. -H. Tsai"; Y. -C. Chen;" J. J. M. Tan"",""Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan, R.O.C"; Department of Information Management, Minghsin University of Science and Technology, Xinfeng Hsinchu, Taiwan, R.O.C;" Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan, R.O.C"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""250"",""262"",""Topological properties have become a popular and important area of focus for studies that analyze interconnections between networks. The hypercube is one of the most widely discussed topological structures for interconnections between networks and is usually covered in introductions to the basic principles and methods for network design. The exchanged hypercube EH(s, t) is a new variant of the hypercube that has slightly more than half as many edges and retains several valuable and desirable properties of the hypercube. In this paper, we propose an approach for shortest path routing algorithms from the source vertex to the destination vertex in EH(s, t) with time complexity O(n), where n = s + t + 1 and 1 ≤ s ≤ t. We focus on edge congestion, which is an important indicator for cost analyses and performance measurements in interconnection networks. Based on our shortest path routing algorithm, we show that the edge congestion of EH(s, t) is 3 · 2s+t+1 - 2s+1 - 2t+1. In addition, we prove that our shortest path routing algorithm is an optimal routing strategy with respect to the edge congestion of EH(s, t)."",""1558-2183"","""",""10.1109/TPDS.2014.2387284"",""National Science Council of the Republic of China(grant numbers:103-2221-E-159-007,103-2221-E-009-112)"; Elite Research Center Development Plan;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7001085"",""Hypercube";exchanged hypercube;interconnection network;shortest path routing;edge congestion;Hypercube;exchanged hypercube;interconnection network;shortest path routing;"edge congestion"",""Routing";Hypercubes;Algorithm design and analysis;Time complexity;Bipartite graph;"Hamming distance"","""",""8"","""",""25"",""IEEE"",""1 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Optimal Reconfiguration of High-Performance VLSI Subarrays with Network Flow,""J. Qian"; Z. Zhou; T. Gu; L. Zhao;" L. Chang"",""Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, China"; Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, China; Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, China; Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, China;" Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3575"",""3587"",""A two-dimensional mesh-connected processor array is an extensively investigated architecture used in parallel processing. Massive studies have addressed the use of reconfiguration algorithms for the processor arrays with faults. However, the subarray generated by previous algorithms contains a large number of long interconnects, which in turn leads to more communication costs, capacitance and dynamic power dissipation. In this paper, we propose novel techniques, making use of the idea of network flow, to construct the high-performance subarray, which has the minimum number of long interconnects. First, we construct a network flow model according to the host array under a specific constraint. Second, we show that the reconfiguration problem of high-performance subarray can be optimally solved in polynomial time by using efficient minimum-cost flow algorithms. Finally, we prove that the geometric properties of the resulted subarray meet the system requirements. Simulations based on several random and clustered fault scenarios clearly reveal the advantage of the proposed technique for reducing the number of long interconnects. It is shown that, for a host array of size 512 × 512, the number of long interconnects in the subarray can be reduced by up to 70.05 percent for clustered faults and by up to 55.28 percent for random faults with density of 1 percent as compared to the-state-of-the-art."",""1558-2183"","""",""10.1109/TPDS.2016.2539958"",""National Natural Science Foundation of China(grant numbers:61262008,61363030,61562015,61572146,U1501252)"; High Level Innovation Team of Guangxi Colleges and Universities; Outstanding Scholars Fund; Guangxi Natural Science Foundation of China(grant numbers:2012GXNSFAA053220,2015GXNSFDA139038); Guilin University of Electronic Technology; Guangxi Key Laboratory of Trusted Software Focus Fund;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429772"",""Reconfiguration";processor array;high-performance;network flow;"minimum-cost flow algorithm"",""Switches";Fault tolerance;Fault tolerant systems;Circuit faults;Very large scale integration;Parallel processing;"Heuristic algorithms"","""",""19"","""",""38"",""IEEE"",""9 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;
"Optimization of the Processing of Data Streams on Roughly Characterized Distributed Resources,""D. Millot";" C. Parrot"",""Institut Mines-Telecom, Telecom SudParis, Évry, France";" Institut Mines-Telecom, Telecom SudParis, Évry, France"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1415"",""1429"",""The AS4DR (Adaptive Scheduling for Distributed Resources) scheduling method presented in this paper aims at maximizing throughput, when processing several data streams by divisible load applications on star-shaped distributed memory platforms, with available speeds for communicating and computing which may be poorly estimated, or varying over time. The total workload is supposed to be unknown. According to the computation cost model, AS4DR can either maximize throughput, or CPU utilization by avoiding data-starvation of the computing units. An experimental assessment of the adaptation of the workload distribution to the variation of the communicating and computing speeds has been performed that shows that the use of AS4DR can significantly improve the throughput. This paper also experimentally assesses a resource selection method to set up star-shaped clusters of distributed resources, so as to process efficiently a set of data streams with AS4DR."",""1558-2183"","""",""10.1109/TPDS.2015.2447515"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7128739"",""parallel application";distributed memory;divisible load scheduling;adaptive scheduling;data-intensive application;Parallel application;distributed memory;divisible load scheduling;adaptive scheduling;"data-intensive application"",""Computational modeling";Throughput;Adaptation models;Processor scheduling;Context;Schedules;"Distributed databases"","""",""3"","""",""33"",""IEEE"",""19 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Ordering Traces Logically to Identify Lateness in Message Passing Programs,""K. E. Isaacs"; T. Gamblin; A. Bhatele; M. Schulz; B. Hamann;" P. -T. Bremer"",""Department of Computer Science, University of California, Davis, CA"; Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, Livermore, CA; Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, Livermore, CA; Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, Livermore, CA; Department of Computer Science, University of California, Davis, CA;" Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, Livermore, CA"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""829"",""840"",""Event traces are valuable for understanding the behavior of parallel programs. However, automatically analyzing a large parallel trace is difficult, especially without a specific objective. We aid this endeavor by extracting a trace’s logical structure, an ordering of trace events derived from happened-before relationships, while taking into account developer intent. Using this structure, we can calculate an operation’s delay relative to its peers on other processes. The logical structure also serves as a platform for comparing and clustering processes as well as highlighting communication patterns in a trace visualization. We present an algorithm for determining this idealized logical structure from traces of message passing programs, and we develop metrics to quantify delays and differences among processes. We implement our techniques in Ravel, a parallel trace visualization tool that displays both logical and physical timelines. Rather than showing the duration of each operation, we display where delays begin and end, and how they propagate. We apply our approach to the traces of several message passing applications, demonstrating the accuracy of our extracted structure and its utility in analyzing these codes."",""1558-2183"","""",""10.1109/TPDS.2015.2417531"",""U.S. Department of Energy"; Lawrence Livermore National Laboratory(grant numbers:DE-AC52-07NA27344); Office of Science; Office of Advanced Scientific Computing Research; Advanced Simulation and Computing(grant numbers:LLNL-JRNL-668754);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7072533"",""Trace analysis";performance;Trace analysis;"performance"",""Visualization";Partitioning algorithms;Merging;Message passing;"Delays"","""",""11"","""",""39"",""IEEE"",""30 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"PacketCloud: A Cloudlet-Based Open Platform for In-Network Services,""Y. Chen"; Y. Chen; Q. Cao;" X. Yang"",""School of Computer Science, Fudan University, China"; Department of Computer Science, Duke University; Department of Computer Science, Duke University;" Department of Computer Science, Duke University"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1146"",""1159"",""The Internet was designed with the end-to-end principle where the network layer provided merely the best-effort forwarding service. This design makes it challenging to add new services into the Internet infrastructure. However, as the Internet connectivity becomes a commodity, users and applications increasingly demand new in-network services. This paper proposes PacketCloud, a cloudlet-based open platform to host in-network services. Different from standalone, specialized middleboxes, cloudlets can efficiently share a set of commodity servers among different services, and serve the network traffic in an elastic way. PacketCloud can help both Internet Service Providers (ISPs) and emerging application/content providers deploy their services at strategic network locations. We have implemented a proof-of-concept prototype of PacketCloud. PacketCloud introduces a small additional delay, and can scale well to handle high-throughput data traffic. We have evaluated PacketCloud in both a fully functional emulated environment, and the real Internet."",""1558-2183"","""",""10.1109/TPDS.2015.2424222"",""National Science Foundation(grant numbers:1040043)"; AWS;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7088634"",""Cloud computing";in-network services;open platform;elasticity;Cloud computing;in-network services;open platform;"elasticity"",""Cloud computing";Servers;Middleboxes;Aggregates;Clouds;"Resource management"","""",""16"","""",""36"",""IEEE"",""17 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Parallel and Streaming Truth Discovery in Large-Scale Quantitative Crowdsourcing,""R. W. Ouyang"; L. M. Kaplan; A. Toniolo; M. Srivastava;" T. J. Norman"",""CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China"; Networked Sensing & Fusion Branch, US Army Research Laboratory, Adelphi, MD; Department of Computing Science, University of Aberdeen, Aberdeen, United Kingdom; Department of Electrical Engineering and the Department of Computer Science, University of California, CA, Los Angeles;" Department of Computing Science, University of Aberdeen, Aberdeen, United Kingdom"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2984"",""2997"",""To enable reliable crowdsourcing applications, it is of great importance to develop algorithms that can automatically discover the truths from possibly noisy and conflicting claims provided by various information sources. In order to handle crowdsourcing applications involving big or streaming data, a desirable truth discovery algorithm should not only be effective, but also be scalable. However, with respect to quantitative crowdsourcing applications such as object counting and percentage annotation, existing truth discovery algorithms are not simultaneously effective and scalable. They either address truth discovery in categorical crowdsourcing or perform batch processing that does not scale. In this paper, we propose new parallel and streaming truth discovery algorithms for quantitative crowdsourcing applications. Through extensive experiments on real-world and synthetic datasets, we demonstrate that 1) both of them are quite effective, 2) the parallel algorithm can efficiently perform truth discovery on large datasets, and 3) the streaming algorithm processes data incrementally, and it can efficiently perform truth discovery both on large datasets and in data streams."",""1558-2183"","""",""10.1109/TPDS.2016.2515092"",""U.S. ARL"; U.K. Ministry of Defense(grant numbers:W911NF-06-3-0001); NSF(grant numbers:CNS-1213140);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7373643"",""Crowdsourcing";truth discovery;quantitative task;big data;parallel algorithm;"streaming algorithm"",""Crowdsourcing";Algorithm design and analysis;Inference algorithms;Parallel algorithms;Estimation;Encoding;"Electronic mail"","""",""22"","""",""33"",""IEEE"",""6 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Parallel Distributed Breadth First Search on the Kepler Architecture,""M. Bisson"; M. Bernaschi;" E. Mastrostefano"",""“Istituto per le Applicazioni del Calcolo” (IAC), National Research Council of Italy, Rome, Italy"; “Istituto per le Applicazioni del Calcolo” (IAC), National Research Council of Italy, Rome, Italy;" “Sapienza” University of Rome, Roma, Italy"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""2091"",""2102"",""We present the results obtained by using an evolution of our CUDA-based solution for the exploration, via a breadth first search, of large graphs. This latest version exploits at its best the features of the Kepler architecture and relies on a combination of techniques to reduce both the number of communications among the GPUs and the amount of exchanged data. The final result is a code that can visit more than 800 billion edges in a second by using a cluster equipped with 4,096 Tesla K20X GPUs."",""1558-2183"","""",""10.1109/TPDS.2015.2475270"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7234934"",""Large graphs";Breadth First Search;Parallel computing;GPU;CUDA;Large graphs;breadth first search;parallel computing;GPU;"CUDA"",""Arrays";Indexes;Instruction sets;Graphics processing units;Message systems;"Parallel processing"","""",""18"","""",""28"",""IEEE"",""1 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Parallel Multiview Video Coding Exploiting Group of Pictures Level Parallelism,""C. Jiang";" S. Nooshabadi"",""Department of Electrical and Computer Engineering, Michigan Tech, Houghton, MI";" Department of Electrical and Computer Engineering, Michigan Tech, Houghton, MI"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2316"",""2328"",""This paper presents the use of a computer cluster with heterogeneous computing components to provide concurrency and multi-level parallelism at coarse grain and massive fine-grain for multiview video coding (MVC) applications. MVC involves coding of multiple video sequences that are taken from the same scene but different perspective. In addition to motion estimation (ME) used in conventional video coding for single view video for exploiting inter-frame temporal similarities, MVC adopts disparity estimation (DE) to further increase compression. To overcome the huge computational cost associated with ME and by extension with DE, attention has been mainly focused on developing fast ME/DE algorithms. Although fast ME/DE algorithms bring substantial speedup, to achieve realtime MVC encoding, it requires further acceleration of the coding process at higher levels. Towards this end, this paper proposes a multiple-view-parallel, multiple-interleaved group of pictures (multiple-IGOP) scheduling scheme for MVC. When evaluated over eight views, with no loss in rate distortion (RD) performance, the proposed scheme outperforms view-sequential coding by a factor of up to 12.4 and 12.3, respectively, for two popular prediction structures, IBP and IPP."",""1558-2183"","""",""10.1109/TPDS.2015.2485993"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7287762"",""Multiview video";group of pictures;cluster computing;"parallel computing"",""Parallel processing";Encoding;Video coding;Streaming media;Graphics processing units;Central Processing Unit;"Standards"","""",""3"","""",""43"",""IEEE"",""2 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Parallel Pairwise Epistasis Detection on Heterogeneous Computing Architectures,""J. González-Domínguez"; S. Ramos; J. Touriño;" B. Schmidt"",""Parallel and Distributed Architectures Group, Institute of Computer Science, Johannes Gutenberg University Mainz, Germany"; Computer Architecture Group, Department of Electronics and Systems, University of A Coruña, Spain; Computer Architecture Group, Department of Electronics and Systems, University of A Coruña, Spain;" Parallel and Distributed Architectures Group, Institute of Computer Science, Johannes Gutenberg University Mainz, Germany"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2329"",""2340"",""Development of new methods to detect pairwise epistasis, such as SNP-SNP interactions, in Genome-Wide Association Studies is an important task in bioinformatics as they can help to explain genetic influences on diseases. As these studies are time consuming operations, some tools exploit the characteristics of different hardware accelerators (such as GPUs and Xeon Phi coprocessors) to reduce the runtime. Nevertheless, all these approaches are not able to efficiently exploit the whole computational capacity of modern clusters that contain both GPUs and Xeon Phi coprocessors. In this paper we investigate approaches to map pairwise epistasic detection on heterogeneous clusters using both types of accelerators. The runtimes to analyze the well-known WTCCC dataset consisting of about 500 K SNPs and 5 K samples on one and two NVIDIA K20m are reduced by 27 percent thanks to the use of a hybrid approach with one additional single Xeon Phi coprocessor."",""1558-2183"","""",""10.1109/TPDS.2015.2460247"",""Ministry of Economy and Competitiveness"; FEDER(grant numbers:TIN2013-42148-P);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7165657"",""High performance computing";epistasis;pairwise gene-gene interaction;Xeon Phi;"GPU"",""Coprocessors";Graphics processing units;Computational modeling;Computer architecture;Data models;Genetics;"Acceleration"","""",""15"","""",""43"",""IEEE"",""23 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Pareto Optimal Operation of Distributed Battery Energy Storage Systems for Energy Arbitrage under Dynamic Pricing,""X. Tan"; Y. Wu;" D. H. K. Tsang"",""Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong"; College of Information Engineering, Zhejiang University of Technology, Hangzhou, China;" Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""2103"",""2115"",""The optimal operation of a distributed battery energy storage system (BESS) for energy arbitrage under dynamic pricing is studied in this paper, and the Pareto optimal arbitrage policy that balances the economic value and lifetime tradeoff of the BESS is obtained. Specifically, the lifetime performance of the BESS is represented by its average lifetime, i.e., the average operational duration within which its capacity stays above a certain threshold, and the value performance of the BESS is defined as the total average arbitrage value within its entire lifetime. We propose a constrained stochastic shortest path (CSSP) model to characterize the optimal value-lifetime performance pair. By exploiting the hidden structure of this CSSP problem, an efficient parallel algorithm is proposed to compute the optimal policy. We further prove the condition under which the optimal policy is Pareto optimal. This implies that the achievable optimal value-lifetime performance pair is globally optimal as long as the system-wide utility is monotonically increasing in both the value performance and the lifetime performance. We validate our proposed model and algorithm via real battery specifications and electricity market data, and the results show promising insights for both infrastructure planning and operational management of BESSs in practice."",""1558-2183"","""",""10.1109/TPDS.2015.2478785"",""Hong Kong Research Grants Councils General Research Fund(grant numbers:16209814,16210215)"; National Natural Science Foundation of China(grant numbers:61303235); Zhejiang Natural Science Foundation(grant numbers:LQ13F010006); Doctoral Program of Higher Education(grant numbers:20133317120002); Ministry of Education of China;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7265089"",""Battery energy storage system";energy arbitrage;value and lifetime performances;"pareto optimal operation"",""Batteries";Pareto optimization;Economics;Discharges (electric);"Markov processes"","""",""25"",""1"",""33"",""IEEE"",""14 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Parity-Switched Data Placement: Optimizing Partial Stripe Writes in XOR-Coded Storage Systems,""Z. Shen"; J. Shu;" Y. Fu"",""Department of Computer Science and Technology, Tsinghua University, Beijing, China"; Department of Computer Science and Technology, Tsinghua University, Beijing, China;" Department of Computer Science and Technology, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3311"",""3322"",""Erasure codes tolerate disk failures by pre-storing a low degree of data redundancy, and have been commonly adopted in current storage systems. However, the attached requirement on data consistency exaggerates partial stripe write operations and thus seriously downgrades system performance. Previous works to optimize partial stripe writes are relatively limited, and a general mechanism is still absent. In this paper, we propose a Parity-Switched Data Placement (PDP) to optimize partial stripe writes for any XOR-coded storage system. PDP first reduces the write operations by arranging continuous data elements to join a common parity element's generation. To achieve a deeper optimization, PDP further explores the generation orders of parity elements and makes any two continuous data elements associate with a common parity element. Intensive evaluations show that for tested erasure codes, PDP reduces up to 31.9 percent of write operations and further increases the write speed by up to 59.8 percent when compared with two state-of-the-art data placement methods."",""1558-2183"","""",""10.1109/TPDS.2016.2525770"",""National Natural Science Foundation of China(grant numbers:61232003,61327902)"; Key Laboratory of High-end Server and Storage Technology(grant numbers:2014HSSA02);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399425"",""Partial stripe writes";XOR-coded storage systems;data placement;"parity generation"",""Distributed databases";Optimization;Layout;Redundancy;System performance;"Fault tolerant systems"","""",""7"","""",""41"",""IEEE"",""4 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Particle Routing in Distributed Particle Filters for Large-Scale Spatial Temporal Systems,""F. Bai"; F. Gu; X. Hu;" S. Guo"",""Department of Computer Science, Georgia State University, Atlanta, GA"; Department of Computer Science, The City University of New York, Staten Island, NY; Department of Computer Science, Georgia State University, Atlanta, GA;" Department of Computer Science, Georgia State University, Atlanta, GA"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""481"",""493"",""Particle filters are important techniques to support data assimilation for large-scale spatial temporal simulation systems. Distributed particle filters improve the performance of particle filtering by distributing particles to multiple processing units (PUs). While different resampling algorithms have been developed for distributed particle filters, less research has been conducted to investigate how to route particles among the PUs after resampling in effective and efficient manners. This paper develops particle routing policies in distributed particle filters with both the centralized resampling and the distributed resampling. The developed routing policies are evaluated from the aspects of the communication cost and the data assimilation accuracy based on an application of data assimilation for large-scale wildfire spread simulations."",""1558-2183"","""",""10.1109/TPDS.2015.2405912"",""US Natural Science Foundation(grant numbers:CNS-0841170,CNS-0941432,1356977)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7046371"",""Distributed applications";Monte Carlo;routing and layout;simulation;Distributed applications;Monte Carlo;routing and layout;"simulation"",""Routing";Particle filters;Data assimilation;Data models;Fires;Indexes;"RNA"","""",""13"","""",""39"",""IEEE"",""20 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"PathGraph: A Path Centric Graph Processing System,""P. Yuan"; C. Xie; L. Liu;" H. Jin"",""Services Computing Technology and System Lab., Cluster and Grid Computing Lab., Big Data Technology and System Lab., School of Computer Science & Technology, Huazhong University of Science & Technology, Wuhan, China"; Services Computing Technology and System Lab., Cluster and Grid Computing Lab., Big Data Technology and System Lab., School of Computer Science & Technology, Huazhong University of Science & Technology, Wuhan, China; College of Computing, Georgia Institute of Technology, Atlanta, GA;" Services Computing Technology and System Lab., Cluster and Grid Computing Lab., Big Data Technology and System Lab., School of Computer Science & Technology, Huazhong University of Science & Technology, Wuhan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""2998"",""3012"",""Large scale iterative graph computation presents an interesting systems challenge due to two well known problems: (1) the lack of access locality and (2) the lack of storage efficiency. This paper presents PathGraph, a system for improving iterative graph computation on graphs with billions of edges. First, we improve the memory and disk access locality for iterative computation algorithms on large graphs by modeling a large graph using a collection of tree-based partitions. This enables us to use path-centric computation rather than vertex-centric or edge-centric computation. For each tree partition, we re-label vertices using DFS in order to preserve consistency between the order of vertex ids and vertex order in the paths. Second, a compact storage that is optimized for iterative graph parallel computation is developed in the PathGraph system. Concretely, we employ delta-compression and store tree-based partitions in a DFS order. By clustering highly correlated paths together as tree based partitions, we maximize sequential access and minimize random access on storage media. Third but not the least, our path-centric computation model is implemented using a scatter/gather programming model. We parallel the iterative computation at partition tree level and perform sequential local updates for vertices in each tree partition to improve the convergence speed. To provide well balanced workloads among parallel threads at tree partition level, we introduce the concept of multiple stealing points based task queue to allow work stealings from multiple points in the task queue. We evaluate the effectiveness of PathGraph by comparing with recent representative graph processing systems such as GraphChi and X-Stream etc. Our experimental results show that our approach outperforms the two systems on a number of graph algorithms for both in-memory and out-of-core graphs. While our approach achieves better data balance and load balance, it also shows better speedup than the two systems with the growth of threads."",""1558-2183"","""",""10.1109/TPDS.2016.2518664"",""NSFC(grant numbers:61433019)"; NSF; CISE; Intel ISTC; IBM Faculty;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7384525"",""Graphs and networks";concurrent programming;graph algorithms;"data storage representations"",""Graphics processing units";Concurrent programming;Data storage;Storage automation;Large-scale systems;"Iterative methods"","""",""23"","""",""29"",""IEEE"",""18 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"PerfCompass: Online Performance Anomaly Fault Localization and Inference in Infrastructure-as-a-Service Clouds,""D. J. Dean"; H. Nguyen; P. Wang; X. Gu; A. Sailer;" A. Kochut"",""Department of Computer Science, North Carolina State University, Raleigh, NC"; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science, North Carolina State University, Raleigh, NC; IBM T.J. Watson Research Center, Yorktown Heights, NY;" IBM T.J. Watson Research Center, Yorktown Heights, NY"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1742"",""1755"",""Infrastructure-as-a-service clouds are becoming widely adopted. However, resource sharing and multi-tenancy have made performance anomalies a top concern for users. Timely debugging those anomalies is paramount for minimizing the performance penalty for users. Unfortunately, this debugging often takes a long time due to the inherent complexity and sharing nature of cloud infrastructures. When an application experiences a performance anomaly, it is important to distinguish between faults with a global impact and faults with a local impact as the diagnosis and recovery steps forfaults with a global impact or local impact are quite different. In this paper, we present PerfCompass, an online performance anomaly fault debugging tool that can quantify whether a production-run performance anomaly has a global impact or local impact. PerfCompass can use this information to suggest the root cause as either an external fault (e.g., environment-based) or an internal fault (e.g., software bugs). Furthermore, PerfCompass can identify top affected system calls to provide useful diagnostic hints for detailed performance debugging. PerfCompass does not require source code or runtime application instrumentation, which makes it practical for production systems. We have tested PerfCompass by running five common open source systems (e.g., Apache, MySQL, Tomcat, Hadoop, Cassandra) inside a virtualized cloud testbed. Our experiments use a range of common infrastructure sharing issues and real software bugs. The results show that PerfCompass accurately classifies 23 out of the 24 tested cases without calibration and achieves 100 percent accuracy with calibration. PerfCompass provides useful diagnosis hints within several minutes and imposes negligible runtime overhead to the production system during normal execution time."",""1558-2183"","""",""10.1109/TPDS.2015.2444392"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7127024"",""Reliability";availability and serviceability;Debugging aids;Distributed debugging;Performance;Reliability;availability;and serviceability;debugging aids;distributed debugging;"performance"",""Instruction sets";Debugging;Message systems;Fault diagnosis;Servers;"Dispersion"","""",""24"",""1"",""54"",""IEEE"",""17 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;
"Performance Analysis of Multimedia Retrieval Workloads Running on Multicores,""Y. Lu"; X. Wang; W. Zhang; H. Chen; L. Peng;" W. Zhao"",""Parallel Processing Institute, Fudan University, Shanghai, China"; Parallel Processing Institute, Fudan University, Shanghai, China; Parallel Processing Institute, Fudan University, Shanghai, China; Institute of Parallel and Distributed Systems, Shanghai Jiaotong University, Shanghai, China; Division of Electrical and Computer Engineering, Louisiana State University, Baton Rouge, LA;" Parallel Processing Institute, Fudan University, Shanghai, China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3323"",""3337"",""Multimedia data has become a major data type in the Big Data era. The explosive volume of such data and the increasing real-time requirement to retrieve useful information from it have put significant pressure in processing such data in a timely fashion. However, while prior efforts have done in-depth analysis on architectural characteristics of traditional multimedia processing and text-based retrieval algorithms, there has been no systematic study towards the emerging multimedia retrieval applications. This may impede the architecture design and system evaluation of these applications. In this paper, we make the first attempt to construct a multimedia retrieval benchmark suite (MMRBench for short) that can be used to evaluate architectures and system designs for multimedia retrieval applications. MMRBench covers modern multimedia retrieval algorithms with different versions (sequential, parallel and distributed). MMRBench also provides a series of flexible interfaces as well as certain automation tools. With such a flexible design, the algorithms in MMRBench can be used both in individual kernel-level evaluation and in integration to form a complete multimedia data retrieval infrastructure for full system evaluation. Furthermore, we use performance counters to analyze a set of architecture characteristics of multimedia retrieval algorithms in MMRBench, including the characteristics of core level, chip level and inter-chip level. The study shows that micro-architecture design in current processor is inefficient (both in performance and power) for these multimedia retrieval workloads, especially in core resources and memory systems. We then derive some insights into the architecture design and system evaluation for such multimedia retrieval algorithms."",""1558-2183"","""",""10.1109/TPDS.2016.2533606"",""National High Technology Research and Development Program of China(grant numbers:2015AA015303)"; National Natural Science Foundation of China(grant numbers:61370081);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416213"",""Multimedia retrieval";benchmarks;"architectural characteristics"",""Multimedia communication";Algorithm design and analysis;Benchmark testing;Feature extraction;Computer architecture;"Streaming media"","""",""6"","""",""46"",""IEEE"",""23 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Performance and Energy Aware Inhomogeneous 3D Networks-on-Chip Architecture Generation,""M. O. Agyeman"; A. Ahmadinia;" N. Bagherzadeh"",""Intel Embedded System Research group, Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong"; School of Engineering and Built Environment, Glasgow Caledonian University, Glasgow, Unites Kingdom;" Department of Electrical Engineering and Computer Science, University of California, Irvine, Irvine, CA"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1756"",""1769"",""Recently, Through-Silicon-Via (TSV) has been more popular to provide faster inter-layer communication in three-dimensional Networks-on-Chip (3D NoCs). However, the area overhead of TSVs reduces wafer utilization and yield which impact design of 3D architectures using a large number of TSVs such as homogeneous 3D NoCs topologies. Also, 3D routers require more memory and thus they are more power hungry than conventional 2D routers. Alternatively, hybrid 3D NoCs combine both the area and performance benefits of 2D and 3D router architectures by using a limited number of TSVs. Existing hybrid architectures suffer from higher packet delays as they do not consider the dynamic communication patterns of different application and their NoC resource usage. We propose a novel algorithm to systematically generate hybrid 3D NoC topologies for a given application such that the vertical connections are minimized while the NoC performance is not sacrificed. The proposed algorithm analyses the target application and generates hybrid architectures by efficiently redistributing the vertical links and buffer spaces based on their utilizations. Furthermore, the algorithm has been evaluated with synthetic and various real-world traffic patterns. Experimental results show that the proposed algorithm generates optimized architectures with lower energy consumption and a significant reduction in packet delay compared to the existing solutions."",""1558-2183"","""",""10.1109/TPDS.2015.2457444"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7161378"",""Network-on-Chip";Multi-Processor System;3D Integration;Performance Evaluation;Network-on-chip;multi-processor system;3d integration;"performance evaluation"",""Three-dimensional displays";Routing;Through-silicon vias;Computer architecture;Algorithm design and analysis;Topology;"Heuristic algorithms"","""",""26"","""",""37"",""Crown"",""17 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Performance Evaluation of Cloud Computing Centers with General Arrivals and Service,""T. Atmaca"; T. Begin; A. Brandwajn;" H. Castel-Taleb"",""SAMOVAR, Télécom SudParis, CNRS, Université Paris-Saclay, 9 rue Charles Fourier, Évry, France"; Université Lyon 1 / LIP (UMR Inria, ENS Lyon CNRS, UCBL), France; Baskin School of Engineering, University of California Santa Cruz;" SAMOVAR, Télécom SudParis, CNRS, Université Paris-Saclay, 9 rue Charles Fourier, Évry, France"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2341"",""2348"",""Cloud providers need to size their systems to determine the right amount of resources to allocate as a function of customer's needs so as to meet their SLAs (Service Level Agreement), while at the same time minimizing their costs and energy use. Queueing theory based tools are a natural choice when dealing with performance aspects of the QoS (Quality of Service) part of the SLA and forecasting resource utilization. The characteristics of a cloud center lead to a queueing system with multiple servers (nodes) in which there is potentially a very large number of servers and both the arrival and service process can exhibit high variability. We propose to use a G/G/c-like model to represent a cloud system and assess expected performance indices. Given the potentially high number of servers in a cloud system, we present an efficient, fast and easy-to-implement approximate solution. We have extensively validated our approximation against discrete-event simulation for several QoS performance metrics such as task response time and blocking probability with excellent results. We apply our approach to examples of system sizing and our examples clearly demonstrate the importance of taking into account the variability of the tasks arrivals and thus expose the risk of under- or over-provisioning if one relies on a model with Poisson assumptions."",""1558-2183"","""",""10.1109/TPDS.2015.2499749"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7327216"",""Cloud computing";performance evaluation;quality of service;blocking probability;response time;approximation;queueing model;"general distribution"",""Servers";Cloud computing;Approximation methods;Computational modeling;Time factors;Quality of service;"Measurement"","""",""47"","""",""29"",""IEEE"",""11 Nov 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Performance-Aware Architectures for Parallel 4D Color fMRI Filtering Algorithm: A Complete Performance Indices Package,""S. Hasan"",""Department of Systems Engineering, College of Information Engineering, Al-Nahrain University, Al-jadria, Baghdad, Iraq"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""2116"",""2129"",""A parallel 4D fMRI filtering algorithm is proposed to overcome the bottlenecks of large 4D volumetric fMRI data and its overlapping segments by input decimation, multidimensional intensive computation by parallel processing and the boundary conditions by output interpolation. Three spatial convolution architectures implement this parallel multidimensional filtering algorithm in Virtex-6 FPGA board, as automated 4D fMRI filtering systems. These three automated filtering systems are devised as “plug and develop” processors to filter any 4D volumetric data. Then, two sets of generic Edge and noise smoothing filtering operators are prototypically plugged and developed to be improved for filtering a dementia case study of color 256 × 256 × 4 × 3 volumetric fMRI. Accordingly, performance indices of the three architectures are evaluated as a complete package of area, speed, dynamic power, and throughput. Significant improvements have been achieved in keeping a stable speed, decreasing power consumption and increasing throughput in color fMRI filtering applications. All three architectures have an operating (225 MHz) maximum frequency. The power consumption improved more than two-fold using architecture 2 compared to 3. The highest throughput is achieved by architectures 2 and 3 almost (2.5) times than that of architecture 1. Evidently, all three architectures are performance-aware processors, and architecture 2 is optimal."",""1558-2183"","""",""10.1109/TPDS.2015.2475267"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7234938"",""Computational neuroscience";Parallel algorithms;Parallel Architectures;Performance of Systems;Computational neuroscience;parallel algorithms;parallel architectures;performance of systems;"fMRI, FPGA, speed, logic area, power, throughput, digital signal processing, biomedical image filtering, 3D, 4D, 4D throughput, performance indices, dementia case study"",""Finite impulse response filters";Convolvers;Engines;Image color analysis;"Filtering algorithms"","""",""5"","""",""31"",""IEEE"",""1 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Performance-Aware Cloud Resource Allocation via Fitness-Enabled Auction,""H. Wang"; Z. Kang;" L. Wang"",""School of Computer Science and Engineering and Key Laboratory of Computer Network and Information Integration, Southeast University, SIPAILOU 2, NanJing, China"; School of Computer Science and Engineering and Key Laboratory of Computer Network and Information Integration, Southeast University, SIPAILOU 2, NanJing, China;" School of Computer Science and Engineering and Key Laboratory of Computer Network and Information Integration, Southeast University, SIPAILOU 2, NanJing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1160"",""1173"",""Cloud computing is a new computing paradigm which features renting the computation devices instead of buying them. In a typical cloud computing environment, there will always be different kinds of cloud resources and a number of cloud services making use of cloud resources to run on. As we can see, these cloud services usually have different performance traits. Some may be I/O-intensive, like those data querying services, while others might demand more CPU cycles, like 3D image processing services. Meanwhile, cloud resources also have different kinds of capabilities such as data processing, I/O throughput, 3D image rendering, etc. A simple fact is that allocating a suitable resource will greatly improve the performance of the cloud service, and make the cloud resource itself more efficient as well. In this paper, a new cloud resource allocating algorithm via fitness-enabled auction is proposed to guarantee the fitness of performance traits between cloud resources (sellers) and cloud services (buyers). We study the allocating algorithm in terms of economic efficiency and system performance, and experiments show that the allocation is far more efficient in comparison with the continuous double auction in which the idea of fitness is not introduced."",""1558-2183"","""",""10.1109/TPDS.2015.2426188"",""NSFC(grant numbers:61232007)"; Doctoral Fund of Ministry of Education of China(grant numbers:20120092110028);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7094282"",""Performance-Aware";Cloud Resource Allocation;Fitness-enabled Auction;Cloud Computing;Auction Theory;Performance-aware;cloud resource allocation;fitness-enabled auction;cloud computing;"auction theory"",""Resource management";Standards;Yarn;Quality of service;Cloud computing;Acceleration;"Supply and demand"","""",""20"","""",""33"",""IEEE"",""24 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Picking Pesky Parameters: Optimizing Regular Expression Matching in Practice,""X. Chen"; B. Jones; M. Becchi;" T. Wolf"",""Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA"; Department of Electrical and Computer Engineering, University of Missouri, Columbia, MO; Department of Electrical and Computer Engineering, University of Missouri, Columbia, MO;" Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1430"",""1442"",""Network security systems inspect packet payloads for signatures of attacks. These systems use regular expression matching at their core. Many techniques for implementing regular expression matching at line rate have been proposed. Solutions differ in the type of automaton used (i.e., deterministic versus non-deterministic) and in the configuration of implementation-specific parameters. While each solution has been shown to perform well on specific rule sets and traffic patterns, there has been no systematic comparison across a large set of solutions, rule sets and traffic patterns. Thus, it is extremely challenging for a practitioner to make an informed decision within the plethora of existing algorithmic and architectural proposals. Moreover, as multi-core processors are becoming popular, many parameters need to be tuned to maximize the multi-core potential. To address this problem, we present a comprehensive evaluation of a broad set of regular expression matching techniques. We consider both algorithmic and architectural aspects. Specifically, we explore the performance, area requirements, and power consumption of implementations targeting multi-core processors and FPGAs using rule sets of practical size and complexity. We present detailed performance results and specific guidelines for determining optimal configurations based on a simple evaluation of the rule set. These guidelines can help significantly when implementing regular expression matching systems in practice."",""1558-2183"","""",""10.1109/TPDS.2015.2453986"",""US National Science Foundation(grant numbers:1115999)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152954"",""Network security";deep packet inspection;deterministic finite automaton;Network security;deep packet inspection;deterministic finite automaton;non-deterministic finite automaton;regular expressions;"design space exploration"",""Automata";Encoding;Layout;Program processors;Memory management;Hardware;"Field programmable gate arrays"","""",""13"","""",""26"",""IEEE"",""8 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Placement and Performance Analysis of Virtual Multicast Networks in Fat-Tree Data Center Networks,""J. Duan";" Y. Yang"",""Department of Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY";" Department of Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""3013"",""3028"",""Virtualization of servers and networks is a key technique to resolve the conflict between the increasing demands on computing power and the high cost of hardware in data centers. In order to map virtual networks to physical infrastructure efficiently, designers have to make careful decisions on the allocation of limited resources, which makes placement of virtual networks in data centers a critical issue. In this paper, we study the placement of virtual networks in fat-tree data center networks. In order to meet the requirements of instant parallel data transfer between multiple computing units, we propose a model of multicast-capable virtual networks (MVNs). We then design four virtual machine (VM) placement schemes to embed MVNs into fat-tree data center networks, named Most-Vacant-Fit (MVF), Most-Compact-First (MCF), Mixed-Bidirectional-Fill (MBF), and Malleable-Shallow-Fill (MSF). All these VM placement schemes guarantee the nonblocking multicast capability of each MVN while simultaneously achieving significant saving in the cost of network hardware. In addition, each VM placement scheme has its unique features. The MVF scheme has zero interference to existing computing tasks in data centers"; the MCF scheme leads to the greatest cost saving; the MBF scheme simultaneously possesses the merits of MVF and MCF, and it provides an adjustable parameter allowing cloud providers to achieve preferred balance between the cost and the overhead;" the MSF scheme performs at least as well as MBF, and possesses some additional predictable features. Finally, we compare the performance and overhead of these VM placement schemes, and present simulation results to validate the theoretical results."",""1558-2183"","""",""10.1109/TPDS.2015.2514285"",""U.S. National Science Foundation(grant numbers:CCF-1320044)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7370928"",""Data center networks";fat-tree;virtualization;network embedding;multicast;nonblocking;"virtual machine placement"",""Servers";Unicast;Cloud computing;Virtual machining;Virtualization;Bandwidth;"Hardware"","""",""14"","""",""39"",""IEEE"",""4 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Poris: A Scheduler for Parallel Soft Real-Time Applications in Virtualized Environments,""S. Wu"; L. Zhou; H. Sun; H. Jin;" X. Shi"",""Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"; VMware, Inc; Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China;" Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""841"",""854"",""With the prevalence of cloud computing and virtualization, more and more cloud services including parallel soft real-time applications (PSRT applications) are running in virtualized data centers. However, current hypervisors do not provide adequate support for them because of soft real-time constraints and synchronization problems, which result in frequent deadline misses and serious performance degradation. CPU schedulers in underlying hypervisors are central to these issues. In this paper, we identify and analyze CPU scheduling problems in hypervisors. Then, we design and implement a parallel soft real-time scheduler according to the analysis, named Poris, based on Xen. It addresses both soft real-time constraints and synchronization problems simultaneously. In our proposed method, priority promotion and dynamic time slice mechanisms are introduced to determine when to schedule virtual CPUs (VCPUs) according to the characteristics of soft real-time applications. Besides, considering that PSRT applications may run in a virtual machine (VM) or multiple VMs, we present parallel scheduling, group scheduling and communication-driven group scheduling to accelerate synchronizations of these applications and make sure that tasks are finished before their deadlines under different scenarios. Our evaluation shows Poris can significantly improve the performance of PSRT applications no matter how they run in a VM or multiple VMs. For example, compared to the Credit scheduler, Poris decreases the response time of web search benchmark by up to 91.6 percent."",""1558-2183"","""",""10.1109/TPDS.2015.2410280"",""National Science Foundation of China(grant numbers:61232008,61472151)"; National 863 Hi-Tech Research and Development Program(grant numbers:2015AA011402); MOE(grant numbers:20110142130005);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7055368"",""virtualization";soft real-time;parallel;Virtualization;soft real-time;parallel;"scheduling"",""Real-time systems";Synchronization;Schedules;Virtual machine monitors;Dynamic scheduling;Time factors;"Processor scheduling"","""",""7"","""",""33"",""IEEE"",""5 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"Post-Deployment Anomaly Detection and Diagnosis in Networked Embedded Systems by Program Profiling and Symptom Mining,""W. Dong"; L. Luo; C. Chen; J. Bu; X. Liu;" Y. Liu"",""College of Computer Science, Zhejiang University, Zhejiang, 310027, China"; College of Computer Science, Zhejiang University, Zhejiang, 310027, China; College of Computer Science, Zhejiang University, Zhejiang, 310027, China; College of Computer Science, Zhejiang University, Zhejiang, 310027, China; School of Computer Science, McGill University, Canada;" MOE Key Lab for Information System Security, School of Software, TNLIST, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3588"",""3601"",""Detecting and diagnosing anomalies in networked embedded systems like sensor networks is a very difficult task, due to the variable workloads and severe resource constraints. In this paper, we focus on how to aid bug diagnosis after the system has been deployed. We notice that most node-level debugging tools can provide detailed program information inside the node but fail to detect when and where a problem occurs in the network. On the other hand, most network-level diagnosis tools can effectively detect a problem from the network but fail to narrow down the problem within the node because they lack detailed program information. To close the gap, we propose D2, a new method for post-deployment anomaly detection and diagnosis in networked embedded systems by combining program profiling and symptom mining. D2 employs binary instrumentation to perform lightweight function count profiling. Based on the statistics, D2 uses PCA (Principal Component Analysis) based approach for automatically detecting network anomalies. Compared with previous methods, D2 is able to point programmers closer to the most likely causes by a novel approach combining statistical tests and program call graph analysis. We implement our method based on TinyOS 2.1.1 and evaluate its effectiveness by case studies in the development of a working sensor network. Results show that our method can aid programmers to diagnose problems quickly in real-world sensor network systems, and at the same time, incurs an acceptable overhead to the running system."",""1558-2183"","""",""10.1109/TPDS.2016.2542815"",""National Natural Science Foundation of China(grant numbers:61472360)"; National Key Technology R&D Program(grant numbers:2014BAK15B02); Fundamental Research Funds for the Central Universities; China Ministry of Education—China Mobile Joint Project(grant numbers:MCM20150401);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7434644"",""Networked embedded systems";sensor networks;diagnosis;program profiling;"symptom mining"",""Debugging";Embedded systems;Instruments;Runtime;Computer bugs;"Principal component analysis"","""",""6"","""",""41"",""IEEE"",""16 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"POST: Exploiting Dynamic Sociality for Mobile Advertising in Vehicular Networks,""J. Qin"; H. Zhu; Y. Zhu; L. Lu; G. Xue;" M. Li"",""Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, P. R. China"; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, P. R. China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, P. R. China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, P. R. China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, P. R. China;" Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, P. R. China"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1770"",""1782"",""Mobile advertising in vehicular networks is of great interest with which timely information can be fast spread into the network. Given a limited budget for hiring seed vehicles, how to achieve the maximum advertising coverage within a given period of time is NP-hard. In this paper, we propose an innovative scheme, POST, for mobile advertising in vehicular networks. The POST design is based on two key observations we have found by analyzing three large-scale vehicular traces. First, vehicles demonstrate dynamic sociality in the network";" second, such vehicular sociality has strong temporal correlations. With the knowledge, POST uses Markov chains to infer future vehicular sociality and adopts two greedy heuristics to select the most “centric” vehicles as seeds for mobile advertising. Extensive simulations based on three real data sets of taxi and bus traces have been carried out. The results show that POSTcan greatly improve the coverage and the intensity of advertising. For all the three involved data sets, it achieves an average gain of 64 percent comparing with the state-of-art schemes."",""1558-2183"","""",""10.1109/TPDS.2015.2467392"",""National Natural Science Foundation of China(grant numbers:61202375,61373157,61173171,61170237,61170238,60903190,61472255,61420106010)"; National High Technology Research and Development Program(grant numbers:2013AA01A601); Fundamental Research Funds for the Central Universities(grant numbers:ZYGX2012J072); Program for Changjiang Scholars and Innovative Research Team in Universities of China(grant numbers:IRT1158);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192632"",""vehicular networks";mobile advertising;dynamic sociality,;social network analysis.;Vehicular networks;mobile advertising;dynamic sociality;"social network analysis"",""Vehicles";Advertising;Mobile communication;Public transportation;Mobile computing;Social network services;"Correlation"","""",""49"","""",""31"",""IEEE"",""12 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;
"Predicting Cross-Core Performance Interference on Multicore Processors with Regression Analysis,""J. Zhao"; H. Cui; J. Xue;" X. Feng"",""School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, China"; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; School of Computer Science and Engineering, University of New South Wales, Sydney, New South Wales, Australia;" State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1443"",""1456"",""Despite their widespread adoption in cloud computing, multicore processors are heavily under-utilized in terms of computing resources. To avoid the potential for negative and unpredictable interference, co-location of a latency-sensitive application with others on the same multicore processor is disallowed, leaving many cores idle and causing low machine utilization. To enable co-location while providing QoS guarantees, it is challenging but important to predict performance interference between co-located applications. We observed that the performance degradation of an application can be represented as a piecewise predictor function of the aggregate pressures on shared resources from all cores. Based on this observation, we propose to adopt regression analysis to build a predictor function for an application. Furthermore, the prediction model thus obtained for an application is able to characterize its contentiousness and sensitivity. Validation using a large number of single-threaded and multi-threaded benchmarks and nine real-world datacenter applications on two different platforms shows that our approach is also precise, with an average error not exceeding 0.4 percent."",""1558-2183"","""",""10.1109/TPDS.2015.2442983"",""National High Technology Research and Development Program of China(grant numbers:2012AA010902,2015AA011505)"; National Natural Science Foundation of China(grant numbers:61202055,61221062,61303053,61432016,61402445); National Basic Research Program of China(grant numbers:2011CB302504); Australian Research Council(grant numbers:DP110104628,DP130101970);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120141"",""cross-core performance interference";memory subsystems;multicore processors;performance analysis;prediction model;Cross-core performance interference;memory subsystems;multicore processors;performance analysis;"prediction model"",""Training";Degradation;Interference;Bandwidth;Aggregates;Program processors;"Predictive models"","""",""16"","""",""56"",""IEEE"",""9 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;
"Prefetching on Storage Servers through Mining Access Patterns on Blocks,""J. Liao"; F. Trahay; B. Gerofi;" Y. Ishikawa"",""State Key Laboratory for Novel Software Technology Nanjing University, Jiangsu, China"; Telecom SudParis, France; RIKEN Advanced Institute for Computational Science, Japan;" University of Tokyo, Japan"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2698"",""2710"",""Distributed file systems have been widely deployed as back-end storage systems to offer I/O services for parallel/distributed applications that process large amounts of data. Data prefetching in distributed file systems is a well-known optimization technique which can mask both network and disk latency and consequently boost I/O performance. Traditionally, data prefetching is initiated by the client file systems, however, conventional prefetching schemes are not well suited for client machines that have limited memory and computing capacity. To offer an efficient prefetching approach for resource-limited client machines, this paper proposes a novel server-side prefetching mechanism. Specifically, we propose to piggyback client identification to I/O requests so that server side block access history can be put into context. On the server side, we utilize the horizontal visibility graph technique to transform per-client time series of block access sequences into a connected graph for which we employ Tarjan's algorithm to disclose cut points in the connected graph. We express these patterns with feature tuples and we propose the X-step pattern matching algorithm to find a matching access pattern (i.e., a feature tuple) for a given block access history. Experimental results indicate that our newly proposed prefetching mechanism can ease client machines and their applications from the process of data prefetching, boosting client performance accordingly, and that it yields an attractive increase in data throughput as well."",""1558-2183"","""",""10.1109/TPDS.2015.2496595"",""National Natural Science Foundation of China(grant numbers:61303038,61303227)"; Natural Science Foundation; CSTC(grant numbers:CSTC2013JCYJA40050); Scientific Research Foundation; Returned Overseas Chinese Scholars; State Education Ministry; State Key Laboratory for Novel Software Technology(grant numbers:KFKT2014B17);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7313010"",""Storage servers";distributed file systems;data prefetching;block access patterns;"horizontal visibility graph"",""Prefetching";Servers;History;Pattern matching;Time series analysis;Distributed databases;"Optimization"","""",""19"","""",""38"",""IEEE"",""30 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;
"Proactive Cache Placement on Cooperative Client Caches for Online Social Networks,""S. Nikolaou"; R. Van Renesse;" N. Schiper"",""Computer Sciences, Cornell University, Ithaca, New York, NY"; Computer Sciences, Cornell University, Ithaca, New York, NY;" Computer Sciences, Cornell University, Ithaca, New York, NY"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1174"",""1186"",""This paper investigates cache placement on a cooperative cache built from individual client caches in an online social network or web service. We use a service that maintains a mapping between content and the clients that cache it, and propose cache placement schemes that leverage relationships between clients (for example, social links) and workload statistics, proactively placing content on clients that are likely to access it. We evaluate efficacy through simulation, comparing our schemes against commonly used cache placement algorithms as well as optimal placement. We synthesize a workload to match characteristics of online social networks. Simulation results of our proposed caching schemes impose moderate network overhead and show considerable improvement to the client's cache hit ratio, even under churn."",""1558-2183"","""",""10.1109/TPDS.2015.2425398"",""US Defense Advanced Research Projects Agency"; US National Science Foundation; Facebook; Microsoft Corporation;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091936"",""Cooperative caching";cache placement;social networks;Cooperative caching;cache placement;"social networks"",""Social network services";Cooperative caching;Bandwidth;Subscriptions;Privacy;Algorithm design and analysis;"Complexity theory"","""",""21"",""1"",""26"",""IEEE"",""22 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Protecting Your Right: Verifiable Attribute-Based Keyword Search with Fine-Grained Owner-Enforced Search Authorization in the Cloud,""W. Sun"; S. Yu; W. Lou; Y. T. Hou;" H. Li"",""Virginia Polytechnic Institute and State University, Blacksburg, VA"; University of Arkansas at Little Rock, Little Rock, AR; Virginia Polytechnic Institute and State University, Blacksburg, VA; Virginia Polytechnic Institute and State University, Blacksburg, VA;" State Key Laboratory of Integrated Services Networks, Xidian University, Xi'an, Shaanxi, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1187"",""1198"",""Search over encrypted data is a critically important enabling technique in cloud computing, where encryption-before-outsourcing is a fundamental solution to protecting user data privacy in the untrusted cloud server environment. Many secure search schemes have been focusing on the single-contributor scenario, where the outsourced dataset or the secure searchable index of the dataset are encrypted and managed by a single owner, typically based on symmetric cryptography. In this paper, we focus on a different yet more challenging scenario where the outsourced dataset can be contributed from multiple owners and are searchable by multiple users, i.e., multi-user multi-contributor case. Inspired by attribute-based encryption (ABE), we present the first attribute-based keyword search scheme with efficient user revocation (ABKS-UR) that enables scalable fine-grained (i.e., file-level) search authorization. Our scheme allows multiple owners to encrypt and outsource their data to the cloud server independently. Users can generate their own search capabilities without relying on an always online trusted authority. Fine-grained search authorization is also implemented by the owner-enforced access policy on the index of each file. Further, by incorporating proxy re-encryption and lazy re-encryption techniques, we are able to delegate heavy system update workload during user revocation to the resourceful semi-trusted cloud server. We formalize the security definition and prove the proposed ABKS-UR scheme selectively secure against chosen-keyword attack. To build confidence of data user in the proposed secure search system, we also design a search result verification scheme. Finally, performance evaluation shows the efficiency of our scheme."",""1558-2183"","""",""10.1109/TPDS.2014.2355202"",""NSFC(grant numbers:61272457)"; National Project(grant numbers:2012ZX03002003-002); 863 Project(grant numbers:2012AA013102); 111 Project(grant numbers:B08038); IRT1078; FRF(grant numbers:K50511010001); NSFC(grant numbers:61170251); US National Science Foundation(grant numbers:CNS-1217889,CNS-1338102);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6893023"",""Cloud computing";attribute-based keyword search;fine-grained owner-enforced search authorization;multi-user search;"verifiable search"",""Indexes";Keyword search;Authorization;Encryption;"Servers"","""",""222"","""",""36"",""IEEE"",""5 Sep 2014"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;
"PURE: Blind Regression Modeling for Low Quality Data with Participatory Sensing,""S. Chang"; H. Zhu; W. Zhang; L. Lu;" Y. Zhu"",""School of Computer Science & Technology, Donghua University, Shanghai, P.R. China"; Department of Computer Science and Technology, Shanghai Jiao Tong University, Shanghai, P.R. China; Department of Computer Science and Technology, Shanghai Jiao Tong University, Shanghai, P.R. China; School of Computer Science and Engineering, University of Electronic Science and Technology, Chengdu, P.R. China;" Department of Computer Science and Technology, Shanghai Jiao Tong University, Shanghai, P.R. China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1199"",""1211"",""Participatory regression modeling is a cost-efficient mechanism to establish the relationships among multiple dimensions of sensory data collected from volunteers. Getting an accurate model estimate is challenging for two main reasons. First, with the concern of confidentiality of individual private data, the original data are nearly unavailable";" second, low quality data with outliers are inherently embedded in the collected data. In this paper, we propose an innovative scheme, PURE, which can accurately estimate the global regression model without the need for knowing local private data (referred to as blind regression modeling) even when there is a large portion of outliers embedded. The wisdom of PURE is to let individual participants peer judge and further improve the global estimate via negotiations. Meanwhile, during the whole process, all information is exchanged in an aggregated way. By design, PURE is secure and can well protect individual privacy. Furthermore, PURE is a lightweight protocol suitable for mobile devices. Extensive trace-driven simulation results show that PURE can achieve an outstanding accuracy gain of two orders of magnitude even with random outliers near a ratio of 50 percent compared with the state-of-the-art least square estimator."",""1558-2183"","""",""10.1109/TPDS.2015.2427805"",""National Natural Science Foundation of China(grant numbers:61300199,61173171,61472068,61370205,61472254,61170238,61202375,61472255,61420106010)"; 973 Program(grant numbers:2014CB340303); Fundamental Research Funds for the Central Universities(grant numbers:2232014D3-21); China Postdoctoral Science Foundation(grant numbers:2014M550466); STCSM(grant numbers:12ZR1414900); CCF-Tencent Open Fund;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7097702"",""participatory sensing";blind regression modeling;data confidentiality;low quality data;Participatory sensing;blind regression modeling;data confidentiality;"low quality data"",""Servers";Data models;Sensors;Nickel;Mathematical model;Mobile handsets;"Distributed databases"","""",""13"","""",""37"",""IEEE"",""29 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;
"qcAffin: A Hardware Topology Aware Interrupt Affinitizing and Balancing Scheme for Multi-Core and Multi-Queue Packet Processing Systems,""N. -F. Huang";" W. -Y. Tsai"",""Institute of Communications Engineering, and the Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan";" Institute of Communications Engineering, National Tsing Hua University, Hsinchu, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1783"",""1795"",""Interrupt affinitization of multi-queue network interface cards is a fundamental composition that defines how packets from individual queue are processed by which CPU-cores on multi-core platforms. In this paper, we propose qcAffin to attain an optimal queue-to-core affinitization for packet processing systems based on a numerical cost model derived from hardware topology and runtime system workloads. Static architectural characteristics comprising the memory hierarchy and topology of hardware components are first analyzed to calculate static interrupt affinitization costs. Then we attempt dynamic interrupt affinitization to balance workloads on CPU-cores and improve overall performance. Classical networking applications ranging from bridging, routing, access control list (ACL) matching to deep packet inspection (DPI) with different frame sizes are extensively experimented to compare the performance of the proposed scheme and other existing approaches. As demonstrated in the comparison result, qcAffin achieves the similar performance of the best affinitization approach and outperforms the Linux default affinitizer by averages of 102, 278, 248 and 131 percent on 1G NICs for the four applications. On 10G NICs, dramatic boosts of 1,424 and 1,343 percent are measured for the bridging and routing applications, respectively. Moreover, the effectiveness of dynamic interrupt balancing is justified by a maximum of 150 percent higher system utilization and 1.2 Mpps more throughput compared to the fixed affinitization approach in a simulated setup of unbalanced traffic load."",""1558-2183"","""",""10.1109/TPDS.2015.2453960"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152926"",""interrupts affinitization";multi-core computing;interrupts balancing;Interrupts affinitization;multi-core computing;"interrupts balancing"",""Hardware";Topology;Instruction sets;Linux;Sockets;Runtime;"Measurement"","""",""3"","""",""20"",""IEEE"",""8 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Quantum-Inspired Hyper-Heuristics for Energy-Aware Scheduling on Heterogeneous Computing Systems,""S. Chen"; Z. Li; B. Yang;" G. Rudolph"",""College of Computer Science and Electronic Engineering of Hunan University, National Supercomputing Center in Changsha, Changsha, China"; College of Computer Science and Electronic Engineering of Hunan University, National Supercomputing Center in Changsha, Changsha, China; College of Computer Science and Electronic Engineering of Hunan University, National Supercomputing Center in Changsha, Changsha, China;" Department of Computer Science, TU Dortmund University, Dortmund, Germany"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1796"",""1810"",""Power and performance tradeoff optimization is one of the most significant issues on heterogeneous multiprocessor or multicomputer systems (HMCSs) with dynamically variable voltage. In this paper, the problem is defined as energy-constrained performance optimization and performance-constrained energy optimization. Task scheduling for precedence-constrained parallel applications represented by a directed acyclic graph (DAG) in HMCSs is an NP-HARD problem. Over the last three decades, several task scheduling techniques have been developed for energy-aware scheduling. However, it is impossible for a single task scheduling technique to outperform all other techniques for all types of applications and situations. Motivated by these observations, hyperheuristic framework is introduced. Moreover, a quantum-inspired high-level learning strategy is proposed to improve the performance of this framework. Meanwhile, a fast solution evaluation technique is designed to reduce the computational burden for each iteration step. Experimental results show that the fast solution evaluation technique can improve average algorithm search speed by 38 percent and that the proposed algorithm generally exhibits outstanding convergence performance."",""1558-2183"","""",""10.1109/TPDS.2015.2462835"",""National Natural Science Foundation of China(grant numbers:61173107)"; National High Technology Research and Development Program of China(grant numbers:2012AA01A301-01); Special Project on the Integration of Industry, Education and Research of Guangdong Province(grant numbers:2012A090300003); Science and Technology Planning Project of Guangdong Province(grant numbers:2013B090700003);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7173041"",""power and performance tradeoff optimization";precedence-constrained parallel application;energy-aware scheduling;heterogeneous multiprocessor or multicomputer systems;hyper-heuristics;quantum;Power and performance tradeoff optimization;precedence-constrained parallel application;energy-aware scheduling;heterogeneous multiprocessor or multicomputer systems;hyper-heuristics;"quantum computing"",""Program processors";Processor scheduling;Energy consumption;Optimization;Scheduling;Heuristic algorithms;"Schedules"","""",""36"","""",""51"",""IEEE"",""30 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;
"RAMPS: A Reconfigurable Architecture for Minimal Perfect Sequencing,""C. Nelson"; K. R. Townsend; O. G. Attia; P. H. Jones;" J. Zambreno"",""Department of Electrical and Computer Engineering, Iowa State University, Ames, IA"; Department of Electrical and Computer Engineering, Iowa State University, Ames, IA; Department of Electrical and Computer Engineering, Iowa State University, Ames, IA; Department of Electrical and Computer Engineering, Iowa State University, Ames, IA;" Department of Electrical and Computer Engineering, Iowa State University, Ames, IA"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""3029"",""3043"",""The alignment of many short sequences of DNA, called reads, to a long reference genome is a common task in molecular biology. When the problem is expanded to handle typical workloads of billions of reads, execution time becomes critical. In this paper we present a novel reconfigurable architecture for minimal perfect sequencing (RAMPS). While existing solutions attempt to align a high percentage of the reads using a small memory footprint, RAMPS focuses on performing fast exact matching. Using the human genome as a reference, RAMPS aligns short reads hundreds of thousands of times faster than current software implementations such as SOAP2 or Bowtie, and about a thousand times faster than GPU implementations such as SOAP3. Whereas other aligners require hours to preprocess reference genomes, RAMPS can preprocess the reference human genome in a few minutes, opening the possibility of using new reference sources that are more genetically similar to the newly sequenced data."",""1558-2183"","""",""10.1109/TPDS.2015.2513053"",""National Science Foundation(grant numbers:CNS-1116810,CCF-1149539)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368199"",""Hardware algorithms";FPGAs;bioinformatics;short-read aligner;convey HC-2;"reconfigurable hardware"",""Bioinformatics";Genomics;Sequential analysis;Hardware;DNA;Algorithm design and analysis;"Software"","""",""2"","""",""45"",""IEEE"",""29 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Real-Time Semantic Search Using Approximate Methodology for Large-Scale Storage Systems,""Y. Hua"; H. Jiang;" D. Feng"",""Wuhan National Laboratory for Optoelectronics, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"; Department of Computer Science and Engineering, University of Nebraska-Lincoln, Lincoln, NE;" Wuhan National Laboratory for Optoelectronics, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Mar 2016"",""2016"",""27"",""4"",""1212"",""1225"",""The challenges of handling the explosive growth in data volume and complexity cause the increasing needs for semantic queries. The semantic queries can be interpreted as the correlation-aware retrieval, while containing approximate results. Existing cloud storage systems mainly fail to offer an adequate capability for the semantic queries. Since the true value or worth of data heavily depends on how efficiently semantic search can be carried out on the data in (near-) real-time, large fractions of data end up with their values being lost or significantly reduced due to the data staleness. To address this problem, we propose a near-real-time and cost-effective semantic queries based methodology, called FAST. The idea behind FAST is to explore and exploit the semantic correlation within and among datasets via correlation-aware hashing and manageable flat-structured addressing to significantly reduce the processing latency, while incurring acceptably small loss of data-search accuracy. The near-real-time property of FAST enables rapid identification of correlated files and the significant narrowing of the scope of data to be processed. FAST supports several types of data analytics, which can be implemented in existing searchable storage systems. We conduct a real-world use case in which children reported missing in an extremely crowded environment (e.g., a highly popular scenic spot on a peak tourist day) are identified in a timely fashion by analyzing 60 million images using FAST. FAST is further improved by using semantic-aware namespace to provide dynamic and adaptive namespace management for ultra-large storage systems. Extensive experimental results demonstrate the efficiency and efficacy of FAST in the performance improvements."",""1558-2183"","""",""10.1109/TPDS.2015.2425399"",""National Natural Science Foundation of China(grant numbers:61173043)"; National Basic Research 973 Program of China(grant numbers:2011CB302301); US National Science Foundation(grant numbers:NSF-CNS-1016609,NSF-CNS-1116606);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091938"",""Cloud storage";data analytics;real-time performance;semantic correlation;Cloud storage;data analytics;real-time performance;"semantic correlation"",""Data analysis";Semantics;Real-time systems;Correlation;Accuracy;Cloud computing;"Smart phones"","""",""4"","""",""65"",""IEEE"",""22 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Reconsidering Single Disk Failure Recovery for Erasure Coded Storage Systems: Optimizing Load Balancing in Stack-Level,""Y. Fu"; J. Shu; Z. Shen;" G. Zhang"",""Department of Computer Science and Technology, Tsinghua University, Beijing, China"; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China;" Department of Computer Science and Technology, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1457"",""1469"",""The fast growing of data scale encourages the wide employment of data disks with large storage capacity. However, a mass of data disks' equipment will in turn increase the probability of data loss or damage, because of the appearance of various kinds of disk failures. To ensure the intactness of the hosted data, modern storage systems usually adopt erasure codes, which can recover the lost data by pre-storing a small amount of redundant information. As the most common case among all the recovery mechanisms, the single disk failure recovery has been receiving intensive attentions for the past few years. However, most of existing works still take the stripe-level recovery as their only consideration, and a considerable performance improvement on single failure disk reconstruction in the stack-level (i.e., a group of rotated stripes) is missed. To seize this potential improvement, in this paper we systematically study the problem of single failure recovery in the stack-level. We first propose two recovery mechanism based on greedy algorithm to seek for the near-optimal solution (BP-Scheme and STP-Scheme) for any erasure array code in stack level, and further design a rotated recovery algorithm (RR-Algorithm) to eliminate the size of required memory. Through a rigorous statistic analysis and intensive evaluation on a real system, the results show that BP-Scheme gains 3.4 to 38.9 percent (the average is 21.2 percent) higher recovery speed than Khan's Scheme and 3.4 to 34.8 percent (the average is 19.1 percent) higher recovery speed than Luo's U-Scheme, while STP-Scheme owns 3.4 to 46.9 percent (the average is 25.15 percent) and 3.4 to 41.1 percent (the average is 22.3 percent) higher recovery speed than Khan's Scheme and Luo's U-Scheme, respectively."",""1558-2183"","""",""10.1109/TPDS.2015.2442979"",""National Natural Science Foundation of China(grant numbers:61232003,61327902)"; National High Technology Research and Development Program of China(grant numbers:2013AA013201); State Key Laboratory of High-end Server and Storage Technology(grant numbers:2014HSSA02);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120164"",""Single Failure Recovery";Erasure Code;Stack;Storage System;Single failure recovery;erasure code;stack;"storage system"",""Algorithm design and analysis";Arrays;Approximation algorithms;Simulated annealing;Generators;Memory management;"Polynomials"","""",""10"",""1"",""27"",""IEEE"",""9 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Reducing Fragmentation for In-line Deduplication Backup Storage via Exploiting Backup History and Cache Knowledge,""M. Fu"; D. Feng; Y. Hua; X. He; Z. Chen; J. Liu; W. Xia; F. Huang;" Q. Liu"",""Wuhan National Laboratory for Optoelectronics, School of Computer Science and Technology, Huazhong University of Science and Technology, Division of Data Storage System, Wuhan, China"; Wuhan National Laboratory for Optoelectronics, School of Computer Science and Technology, Huazhong University of Science and Technology, Division of Data Storage System, Wuhan, China; Wuhan National Laboratory for Optoelectronics, School of Computer Science and Technology, Huazhong University of Science and Technology, Division of Data Storage System, Wuhan, China; Department of Electrical and Computer Engineering, Virginia Commonwealth University, Richmond, VA, USA; National Engineering Research Center for Parallel Computer, Beijing, China; Wuhan National Laboratory for Optoelectronics, School of Computer Science and Technology, Huazhong University of Science and Technology, Division of Data Storage System, Wuhan, China; Wuhan National Laboratory for Optoelectronics, School of Computer Science and Technology, Huazhong University of Science and Technology, Division of Data Storage System, Wuhan, China; Wuhan National Laboratory for Optoelectronics, School of Computer Science and Technology, Huazhong University of Science and Technology, Division of Data Storage System, Wuhan, China;" Wuhan National Laboratory for Optoelectronics, School of Computer Science and Technology, Huazhong University of Science and Technology, Division of Data Storage System, Wuhan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""855"",""868"",""In backup systems, the chunks of each backup are physically scattered after deduplication, which causes a challenging fragmentation problem. We observe that the fragmentation comes into sparse and out-of-order containers. The sparse container decreases restore performance and garbage collection efficiency, while the out-of-order container decreases restore performance if the restore cache is small. In order to reduce the fragmentation, we propose History-Aware Rewriting algorithm (HAR) and Cache-Aware Filter (CAF). HAR exploits historical information in backup systems to accurately identify and reduce sparse containers, and CAF exploits restore cache knowledge to identify the out-of-order containers that hurt restore performance. CAF efficiently complements HAR in datasets where out-of-order containers are dominant. To reduce the metadata overhead of the garbage collection, we further propose a Container-Marker Algorithm (CMA) to identify valid containers instead of valid chunks. Our extensive experimental results from real-world datasets show HAR significantly improves the restore performance by 2.84-175.36 $\times$  at a cost of only rewriting 0.5-2.03 percent data."",""1558-2183"","""",""10.1109/TPDS.2015.2410781"",""National Basic Research 973 Program of China(grant numbers:2011CB302301)"; NSFC(grant numbers:61025008,61173043,61232004); 863 Project(grant numbers:2013AA013203); Fundamental Research Funds for the Central Universities; HUST(grant numbers:2014QNRC019); US National Science Foundation(grant numbers:CNS-1320349,CNS-1218960); Key Laboratory of Information Storage System; Ministry of Education;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7055358"",""Data deduplication";storage system;chunk fragmentation;performance evaluation;Data deduplication;storage system;chunk fragmentation;"performance evaluation"",""Containers";Out of order;Image restoration;Merging;Distributed databases;Indexes;"Prefetching"","""",""23"","""",""29"",""IEEE"",""5 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;
"Redundant Network Traffic Elimination with GPU Accelerated Rabin Fingerprinting,""J. Sun"; H. Chen; L. He;" H. Tan"",""College of Computer Science and Electronic Engineering, Hunan University, ChangSha, China"; College of Computer Science and Electronic Engineering, Hunan University, ChangSha, China; College of Computer Science and Electronic Engineering, Hunan University, ChangSha, China;" College of Computer Science and Electronic Engineering, Hunan University, ChangSha, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""2130"",""2142"",""Recently, redundant network traffic elimination has attracted a lot of attention from both the academia and the industry. A core challenge and enabling technique in implementing redundancy elimination is to perform content-based chunking, which typically involves the computationally heavy Rabin fingerprinting algorithm. In this paper, we propose a GPU-based implementation of Rabin fingerprinting to address this issue. To maximize performance gains, a diverse set of optimization strategies, such as efficient buffer management, GPU memory hierarchy optimization, and balanced load distribution, is proposed by either exploiting the intrinsic hardware features or addressing domain-specific challenges. Extensive evaluations on both the overall and microscopic performance reveal the effectiveness of the GPU-accelerated Rabin fingerprinting algorithm, and we can achieve up to 40 Gpbs throughput on a GTX 780 card. The throughput shows 1.87× speedup against the state-of-the-art using comparable hardware. In addition, although some optimization designs are specific for the problem, techniques proposed in this work including the indexed compact buffer scheme and approximate sorting would also be beneficial and applicable to other network applications leveraging GPU acceleration."",""1558-2183"","""",""10.1109/TPDS.2015.2473166"",""National Science Foundation of China(grant numbers:61272190,61572179,61173166)"; Program for New Century Excellent Talents in University; Fundamental Research Funds for the Central Universities of China;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7225160"",""Rabin Fingerprinting";GPU;Redundancy Elimination;Rabin fingerprinting;GPU;redundancy elimination;data deduplication;"approximate sorting"",""Graphics processing units";Instruction sets;Optimization;Indexes;Arrays;Sorting;"Bandwidth"","""",""12"","""",""25"",""IEEE"",""26 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"REFRESH: REDEFINE for Face Recognition Using SURE Homogeneous Cores,""G. Mahale"; H. Mahale; S. K. Nandy;" R. Narayan"",""Computer Aided Design Laboratory, Indian Institute of Science, Bangalore, India"; Computer Aided Design Laboratory, Indian Institute of Science, Bangalore, India; Computer Aided Design Laboratory, Indian Institute of Science, Bangalore, India;" Morphing Machines Pvt. Ltd., Bangalore, India"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3602"",""3616"",""In this paper we present design and analysis of a scalable real-time Face Recognition (FR) module to perform 450 recognitions per second. We introduce an algorithm for FR, which is a combination of Weighted Modular Principle Component Analysis and Radial Basis Function Neural Networks. This algorithm offers better recognition accuracy in various practical conditions than algorithms used in existing architectures for real-time FR. To meet real-time requirements, a Scalable Parallel Pipelined Architecture (SPPA) is developed by realizing the above FR algorithm as independent parallel streams and sub-streams of computations. SPPA is capable of supporting large databases maintained in external (DDR) memory. By casting the computations in a stream into hardware, we present the design of a Scalable Unit for Region Evaluation (SURE) core. Using SURE cores as computer elements in a massively parallel CGRA, like REDFINE, we provide a FR system on REDEFINE called REFRESH. We report FPGA and ASIC synthesis results for SPPA and REFRESH. Through analysis using these results, we show that excellent scalability and added programmability in REFRESH makes it a flexible and favorable solution for real-time FR."",""1558-2183"","""",""10.1109/TPDS.2016.2539164"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426839"",""Face and gesture recognition";real-time systems;parallel architectures;reconfigurable hardware;"multi-core/single-chip multiprocessors"",""Real-time systems";Algorithm design and analysis;Face recognition;Feature extraction;Principal component analysis;Databases;Gesture recognition;"Parallel processing"","""",""5"","""",""40"",""IEEE"",""7 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Reliability and Energy-Aware Mapping and Scheduling of Multimedia Applications on Multiprocessor Systems,""A. Das"; A. Kumar;" B. Veeravalli"",""School of Electronics and Computer Science, University of Southampton, United Kingdom"; Department of Electrical and Computer Engineering, National University of Singapore, Singapore;" Department of Electrical and Computer Engineering, National University of Singapore, Singapore"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""869"",""884"",""Lifetime reliability is an emerging concern in multiprocessor systems as escalating power density and hence temperature variation continues to accelerate wear-out leading to a growing prominence of device defects. In this paper, we propose a system-level approach that involves performance-aware mapping of multimedia applications on a multiprocessor system to jointly minimize energy consumption and temperature related wear-out. Fundamental to this approach is a simplified temperature model that incorporates not only the transient and the steady-state behavior (temporal effect), but also the temperature dependency on the surrounding cores (spatial effect). This model is validated against the temperature obtained using theHotSpot tool with transient and steady-state simulations, and is shown to be accurate within 5.5°C, leading to an MTTF estimation accuracy of an average 21 percent with respect to the state-of-the-art approaches. The proposed temperature model is integrated in a gradient-based fast heuristic that controls the voltage and frequency of the cores to limit the average and peak temperature leading to a longer lifetime, simultaneously minimizing the energy consumption. Lifetime computation considers task remapping, which is a common feature available in modern multiprocessor systems. A linear programming approach is then proposed to distribute the cores of a multiprocessor system among concurrent applications to maximize the lifetime. Experiments conducted with a set of synthetic and real-life applications represented as synchronous data flow graphs demonstrate that the proposed approach minimizes energy consumption by an average 24 percent with 47 percent increase in lifetime. For concurrent applications, the proposed lifetime-aware core distribution results in an average 10 percent improvement in lifetime as compared to performance-based core distribution."",""1558-2183"","""",""10.1109/TPDS.2015.2412137"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7059234"",""Lifetime reliability";mean time to failure (MTTF);platform-based design;synchronous data flow graphs;Lifetime reliability;mean time to failure (MTTF);platform-based design;"synchronous data flow graphs"",""Reliability";Steady-state;Multiprocessing systems;Temperature dependence;Transient analysis;Mathematical model;"Computational modeling"","""",""41"","""",""33"",""IEEE"",""12 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Replication-Based Load Balancing,""A. Nahir"; A. Orda;" D. Raz"",""Department of Computer Science, Technion, Israel Institue of Technology, Haifa, Israel"; Department of Electrical Engineering, Technion,, Israel Institue of Technology, Haifa, Israel;" Department of Computer Science, Technion, Israel Institue of Technology, Haifa, Israel"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""494"",""507"",""Load balancing of large distributed server systems is a complex optimization problem of critical importance in cloud systems and data centers. Existing schedulers often incur a high communication overhead when collecting the data required to make scheduling decisions, hence delaying job requests on their way to the executing servers. We propose a novel scheme that incurs no communication overhead between the users and the servers upon job arrival, thus removing any scheduling overhead from the job's critical path. Our approach is based on creating several replicas of each job and sending each replica to a different server. Upon the arrival of a replica to the head of the queue at its server, the latter signals the servers holding replicas of that job, so as to remove them from their queues. We show, through analysis and simulations, that this scheme significantly improves the expected queuing overhead over traditional schemes under various load conditions and different job length distributions. In addition, we show that our scheme remains efficient even when the inter-server signal propagation delay is significant (relative to the job's execution time). We provide a heuristic solution to the performance degradation that occurs in such cases and show, by simulations, that it efficiently mitigates the detrimental effect of propagation delays."",""1558-2183"","""",""10.1109/TPDS.2015.2400456"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7031965"",""Load balancing";queuing;distributed systems;Load balancing;queuing;"distributed systems"",""Servers";Load modeling;Delays;Load management;Propagation delay;Mathematical model;"Vectors"","""",""24"","""",""22"",""IEEE"",""5 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Reproducible MPI Benchmarking is Still Not as Easy as You Think,""S. Hunold";" A. Carpen-Amarie"",""Vienna University of Technology, Faculty of Informatics, Research Group for Parallel Computing, Vienna, Austria";" Vienna University of Technology, Faculty of Informatics, Research Group for Parallel Computing, Vienna, Austria"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3617"",""3630"",""The Message Passing Interface (MPI) is the prevalent programming model used on today's supercomputers. Therefore, MPI library developers are looking for the best possible performance (shortest run-time) of individual MPI functions across many different supercomputer architectures. Several MPI benchmark suites have been developed to assess the performance of MPI implementations. Unfortunately, the outcome of these benchmarks is often neither reproducible nor statistically sound. To overcome these issues, we show which experimental factors have an impact on the run-time of blocking collective MPI operations and how to measure their effect. Finally, we present a new experimental method that allows us to obtain reproducible and statistically sound measurements of MPI functions."",""1558-2183"","""",""10.1109/TPDS.2016.2539167"",""Austrian Science Fund(grant numbers:P26124,P25530)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426807"",""MPI";benchmarking;reproducibility;"statistical analysis"",""Benchmark testing";Time measurement;Statistical analysis;"Supercomputers"","""",""28"","""",""31"",""IEEE"",""7 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Resource Allocation Policies for Loosely Coupled Applications in Heterogeneous Computing Systems,""E. Hwang"; S. Kim; T. -k. Yoo; J. -S. Kim; S. Hwang;" Y. -r. Choi"",""School of Electrical and Computer Engineering, UNIST, Ulsan, Republic of Korea"; School of Electrical and Computer Engineering, UNIST, Ulsan, Republic of Korea; School of Electrical and Computer Engineering, UNIST, Ulsan, Republic of Korea; National Institute of Supercomputing and Networking, Korea Institute of Science and Technology Information, Daejeon, Republic of Korea; National Institute of Supercomputing and Networking, Korea Institute of Science and Technology Information, Daejeon, Republic of Korea;" School of Electrical and Computer Engineering, UNIST, Ulsan, Republic of Korea"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2349"",""2362"",""High-Throughput Computing (HTC) and Many-Task Computing (MTC) paradigms employ loosely coupled applications which consist of a large number, from tens of thousands to even billions, of independent tasks. To support such large-scale applications, a heterogeneous computing system composed of multiple computing platforms with different types such as supercomputers, grids, and clouds can be used. On allocating heterogeneous resources of the system to multiple users, there are three important aspects to consider: fairness among users, efficiency for maximizing the system throughput, and user satisfaction for reducing the average user response time. In this paper, we present three resource allocation policies for multi-user and multi-application workloads in a heterogeneous computing system. These three policies are a fairness policy, a greedy efficiency policy, and a fair efficiency policy. We evaluate and compare the performance of the three resource allocation policies over various settings of a heterogeneous computing system and loosely coupled applications, using simulation based on the trace from real experiments. Our simulation results show that the fair efficiency policy can provide competitive efficiency, with a balanced level of fairness and user satisfaction, compared to the other two resource allocation policies."",""1558-2183"","""",""10.1109/TPDS.2015.2461154"",""KISTI"; National Research Foundation of Korea; Ministry of Science, ICT and Future Planning(grant numbers:NRF-2012R1A1A1043329); UNIST;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7167692"",""Resource allocation policies";heterogeneous computing systems;loosely coupled applications;high-throughput computing;many-task computing;fairness;efficiency;"user satisfaction"",""Resource management";Throughput;Runtime;Computational modeling;Measurement;Time factors;"Hardware"","""",""15"","""",""38"",""IEEE"",""27 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;
"Resource and Instance Hour Minimization for Deadline Constrained DAG Applications Using Computer Clouds,""H. Wu"; X. Hua; Z. Li;" S. Ren"",""Illinois Institute of Technology, Chicago, IL, USA"; Illinois Institute of Technology, Chicago, IL, USA; Illinois Institute of Technology, Chicago, IL, USA;" Illinois Institute of Technology, Chicago, IL, USA"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""885"",""899"",""In this paper, we address the resource and virtual machine instance hour minimization problem for directed-acyclic-graph based deadline constrained applications deployed on computer clouds. The allocated resources and instance hours on computer clouds must: (1) guarantee the satisfaction of a deadline constrained application's end-to-end deadline"; (2) ensure that the number of virtual machine (VM) instances allocated to the application is minimized; (3) under the allocated number of VM instances, determine application execution schedule that minimizes the application's makespan;" and (4) under the decided application execution schedule, determine a VM operation schedule, i.e., when a VM should be turned on or off, that minimizes total VM instance hours needed to execute the application. We first give lower and upper bounds for the number of VM instances needed to guarantee the satisfaction of a deadline constrained application's end-to-end deadline. Based on the bounds, we develop a heuristic algorithm called minimal slack time and minimal distance (MSMD) algorithm that finds the minimum number of VM instances needed to guarantee the application's deadline and schedules tasks on the allocated VM instances so that the application's makespan is minimized. Once the application execution schedule and the number of VM instances needed are determined, the proposed VM instance hour minimization (IHM) algorithm is applied to further reduce the instance hours needed by VMs to complete the application's execution. Our experimental results show that the MSMD algorithm can guarantee applications' end-to-end deadlines with less resources than the HEFT [32], MOHEFT [16], DBUS [9], QoS-base [40] and Auto-Scaling [25] heuristic scheduling algorithms in the literature. Furthermore, under allocated resources, the MSMD algorithm can, on average, reduce an application's makespan by 3.4 percent of its deadline. In addition, with the IHM algorithm we can effectively reduce the application's execution instance hours compared with when IHM is not applied."",""1558-2183"","""",""10.1109/TPDS.2015.2411257"",""NSF(grant numbers:0746643,1018731,1035894)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7056525"",""Cloud";scheduling;cost minimization;makespan minimization;resource minimization;real-time,MSMD;instance hour minimization;Cloud;scheduling;cost minimization;makespan minimization;resource minimization;real-time,MSMD;"instance hour minimization"",""Cloud computing";Computers;Virtual machining;Schedules;Minimization;Heuristic algorithms;"Processor scheduling"","""",""27"","""",""40"",""IEEE"",""9 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;
"RFHOC: A Random-Forest Approach to Auto-Tuning Hadoop's Configuration,""Z. Bei"; Z. Yu; H. Zhang; W. Xiong; C. Xu; L. Eeckhout;" S. Feng"",""Center for Cloud Computing, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China"; Center for Cloud Computing, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Center for Cloud Computing, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Center for Cloud Computing, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Center for Cloud Computing, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Ghent University, Belgium;" Center for Cloud Computing, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1470"",""1483"",""Hadoop is a widely-used implementation framework of the MapReduce programming model for large-scale data processing. Hadoop performance however is significantly affected by the settings of the Hadoop configuration parameters. Unfortunately, manually tuning these parameters is very time-consuming, if at all practical. This paper proposes an approach, called RFHOC, to automatically tune the Hadoop configuration parameters for optimized performance for a given application running on a given cluster. RFHOC constructs two ensembles of performance models using a random-forest approach for the map and reduce stage respectively. Leveraging these models, RFHOC employs a genetic algorithm to automatically search the Hadoop configuration space. The evaluation of RFHOC using five typical Hadoop programs, each with five different input data sets, shows that it achieves a performance speedup by a factor of 2.11 $\times$  on average and up to 7.4 $\times$  over the recently proposed cost-based optimization (CBO) approach. In addition, RFHOC's performance benefit increases with input data set size."",""1558-2183"","""",""10.1109/TPDS.2015.2449299"",""China National Basic Research Program(grant numbers:2015CB352400)"; NICT(grant numbers:XDA06000000); Shenzhen Peacock Innovation Project(grant numbers:KQCX20140521115045448); NSFC(grant numbers:U1401258); European Research Council; European Community's Seventh Framework Programme(grant numbers:FP7/2007-2013); ERC(grant numbers:259295); Chinese Academy of Sciences;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7132754"",""performance tuning";MapReduce/Hadoop;system configuration;random forest;genetic algorithm;Performance tuning;MapReduce/Hadoop;system configuration;random forest;"genetic algorithm"",""Training";Predictive models;Genetic algorithms;Analytical models;Support vector machines;Data models;"Prediction algorithms"","""",""60"","""",""29"",""IEEE"",""24 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;
"Robinhood: Towards Efficient Work-Stealing in Virtualized Environments,""Y. Peng"; S. Wu;" H. Jin"",""Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"; Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China;" Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2363"",""2376"",""Work-stealing, as a common user-level task scheduler for managing and scheduling tasks of multithreaded applications, suffers from inefficiency in virtualized environments, because the steal attempts of thief threads may waste CPU cycles that could be otherwise used by busy threads. This paper contributes a novel scheduling framework named Robinhood. The basic idea of Robinhood is to use the time slices of thieves to accelerate busy threads with no available tasks (referred to as poor workers) at both the guest Operating System (OS) level and Virtual Machine Monitor (VMM) level. In this way, Robinhood can reduce the cost of steal attempts and accelerate the threads doing useful work, so as to put the CPU cycles to better use. We implement Robinhood based on BWS, Linux and Xen. Our evaluation with various benchmarks demonstrates that Robinhood paves a way to efficiently run work-stealing applications in virtualized environments. Compared to Cilk++ and BWS, Robinhood can reduce up to 90 and 72 percent execution time of work-stealing applications, respectively."",""1558-2183"","""",""10.1109/TPDS.2015.2492563"",""National Science Foundation of China(grant numbers:61472151,61232008)"; National 863 Hi-Tech Research and Development Program(grant numbers:2014AA01A302,2015AA01A203); Fundamental Research Funds for the Central Universities(grant numbers:2015TS067);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300465"",""Virtualization";work-stealing;multicore;"parallel program optimization"",""Acceleration";Message systems;Instruction sets;Multicore processing;Virtual machine monitors;Linux;"Face"","""","""","""",""32"",""IEEE"",""19 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Rollup: Non-Disruptive Rolling Upgrade with Fast Consensus-Based Dynamic Reconfigurations,""V. Gramoli"; L. Bass; A. Fekete;" D. W. Sun"",""NICTA and University of Sydney, Sydney, N.S.W., Australia"; NICTA, Australia; NICTA and University of Sydney, Sydney, N.S.W., Australia;" NICTA, Australia"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2711"",""2724"",""Rolling upgrade consists of upgrading progressively the servers of a distributed system to reduce service downtime.Upgrading a subset of servers requires a well-engineered cluster membership protocol to maintain, in the meantime, the availability of the system state. Existing cluster membership reconfigurations, like CoreOS etcd, rely on a primary not only for reconfiguration but also for storing information. At any moment, there can be at most one primary, whose replacement induces disruption. We propose Rollup, a non-disruptive rolling upgrade protocol with a fast consensus-based reconfiguration. Rollup relies on a candidate leader only for the reconfiguration and scalable biquorums for service requests. While Rollup implements a non-disruptive cluster membership protocol, it does not offer a full-fledged coordination service. We analyzed Rollup theoretically and experimentally on an isolated network of 26 physical machines and an Amazon EC2 cluster of 59 virtual machines. Our results show an 8-fold speedup compared to a rolling upgrade based on a primary for reconfiguration."",""1558-2183"","""",""10.1109/TPDS.2015.2499772"",""Australian Government"; Department of Communications; Australian Research Council; ICT Centre of Excellence Program;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7327226"",""Quorum";Paxos;online upgrade;cluster management;membership change;"active replication"",""Servers";Protocols;Fault tolerance;Fault tolerant systems;Optimization;Australia;"Radiation detectors"","""",""20"","""",""55"",""IEEE"",""11 Nov 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Scalability of Broadcast Performance in Wireless Network-on-Chip,""S. Abadal"; A. Mestres; M. Nemirovsky; H. Lee; A. González; E. Alarcón;" A. Cabellos-Aparicio"",""NaNoNetworking Center in Catalonia, Universitat Politècnica de Catalunya, Barcelona, Spain"; NaNoNetworking Center in Catalonia, Universitat Politècnica de Catalunya, Barcelona, Spain; ICREA Senior Research Professor at the Barcelona Supercomputing Center, Barcelona, Spain; Samsung Advanced Institute of Technology, Suwon, South Korea; Department of Computer Architecture at Universitat Politècnica de Catalunya, Barcelona, Spain; NaNoNetworking Center in Catalonia, Universitat Politècnica de Catalunya, Barcelona, Spain;" NaNoNetworking Center in Catalonia, Universitat Politècnica de Catalunya, Barcelona, Spain"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3631"",""3645"",""Networks-on-Chip (NoCs) are currently the paradigm of choice to interconnect the cores of a chip multiprocessor. However, conventional NoCs may not suffice to fulfill the on-chip communication requirements of processors with hundreds or thousands of cores. The main reason is that the performance of such networks drops as the number of cores grows, especially in the presence of multicast and broadcast traffic. This not only limits the scalability of current multiprocessor architectures, but also sets a performance wall that prevents the development of architectures that generate moderate-to-high levels of multicast. In this paper, a Wireless Network-on-Chip (WNoC) where all cores share a single broadband channel is presented. Such design is conceived to provide low latency and ordered delivery for multicast/broadcast traffic, in an attempt to complement a wireline NoC that will transport the rest of communication flows. To assess the feasibility of this approach, the network performance of WNoC is analyzed as a function of the system size and the channel capacity, and then compared to that of wireline NoCs with embedded multicast support. Based on this evaluation, preliminary results on the potential performance of the proposed hybrid scheme are provided, together with guidelines for the design of MAC protocols for WNoC."",""1558-2183"","""",""10.1109/TPDS.2016.2537332"",""Catalan Government"; Ministry of Economy and Competitiveness(grant numbers:PCIN-2015-012);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423812"",""Network-on-chip";wireless on-chip communication;design space exploration;multicast;broadcast;latency;throughput;MAC protocols;manycore processors;"hybrid NoC"",""Wireless communication";Scalability;Computer architecture;System-on-chip;Program processors;"Throughput"","""",""36"","""",""69"",""IEEE"",""2 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;
"Scaling Multi-Core Network Processors without the Reordering Bottleneck,""A. Shpiner"; I. Keslassy;" R. Cohen"",""Department of Electrical Engineering, Technion-Israel Institute of Technology, Haifa, Israel"; Department of Electrical Engineering, Technion-Israel Institute of Technology, Haifa, Israel;" IBM Research, Haifa, Israel"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""900"",""912"",""Today, designers of network processors strive to keep the packet reception and transmission orders identical, and therefore avoid any possible out-of-order transmission. However, the development of new features in advanced network processors has resulted in increasingly parallel architectures and increasingly heterogeneous packet processing times, leading to large reordering delays. In this paper, we introduce novel scalable scheduling algorithms for preserving flow order in parallel multi-core network processors. We show how these algorithms can reduce reordering delay while adapting to any load-balancing algorithm and keeping a low implementation complexity overhead. To do so, we use the observation that all packets in a given flow have similar processing requirements and can be described with a constant number of logical processing phases. We further define three possible knowledge frameworks of the time when a network processor learns about these logical phases, and deduce appropriate algorithms for each of these frameworks. Finally, we model our proposed algorithms and simulate them under both synthetic traffic and real-life traces, and show that they significantly outperform past approaches."",""1558-2183"","""",""10.1109/TPDS.2015.2421449"",""Hasso Plattner Institute Research School"; European Research Council Starting(grant numbers:210389); Intel ICRI-CI Center; Israel Ministry of Science and Technology; Neptune Magnet Consortium; Gordon Fund for Systems Engineering; Technion Funds for Security Research; Shillman, Erteschik and Greenberg Research Funds; NSF; US Department of Homeland Security; CAIDA;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7084139"",""Network processors, packet reordering, sequence control"",""Delays";Tin;Algorithm design and analysis;Generators;Throughput;"Out of order"","""",""1"","""",""41"",""IEEE"",""10 Apr 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Security-Aware Mapping and Scheduling with Hardware Co-Processors for FlexRay-Based Distributed Embedded Systems,""Z. Gu"; G. Han; H. Zeng;" Q. Zhao"",""College of of Computer Science, Zhejiang University, Hangzhou, China"; College of Computer Science, National University of Defense Technology, Changsha, China; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA;" School of Computer Science and Technology, Nanjing University of Posts and Telecommunications, Nanjing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""3044"",""3057"",""Automotive in-vehicle systems are distributed systems consisting of multiple ECUs (Electronic Control Units) interconnected with a broadcast network such as FlexRay. Message authentication is an effective mechanism to prevent attackers from injecting malicious messages into the network. In order to reduce timing interference of message authentication operations on application tasks, hardware coprocessors in the form of either FPGA or ASIC are adopted to offload computation-intensive cryptographic algorithms from the ECU. However, it may not be feasible or desirable to equip every ECU with a hardware coprocessor, as modern vehicles can contain more than one hundred ECUs, and the automotive industry is cost-sensitive. In this paper, we consider the problem of mapping an application task graph onto a FlexRay-based distributed hardware platform, to meet security and deadline requirements while minimizing the number of hardware coprocessors needed in the system. We present a Mixed Integer Linear Programming (MILP) formulation, a divide-and-conquer heuristic algorithm, and a Simulated Annealing algorithm. We evaluate the algorithms with industrial case studies."",""1558-2183"","""",""10.1109/TPDS.2016.2520949"",""National Natural Science Foundation of China(grant numbers:61272127,61471165)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7390091"",""FlexRay";security;message authentication;optimization;"automotive embedded systems"",""Receivers";Message authentication;Encryption;Authentication;Hardware;Public key;"Automotive engineering"","""",""59"","""",""32"",""IEEE"",""22 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Selective Data Replication for Online Social Networks with Distributed Datacenters,""G. Liu"; H. Shen;" H. Chandler"",""Department of Electrical and Computer Engineering, Clemson University, Clemson, SC"; Department of Electrical and Computer Engineering, Clemson University, Clemson, SC;" Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2377"",""2393"",""Though the new OSN model, which deploys datacenters globally, helps reduce service latency, it causes higher inter-datacenter communication load. In Facebook, each datacenter has a full copy of all data, and the master datacenter updates all other datacenters, generating tremendous load in this new model. Distributed data storage, which only stores a user's data to his/her geographically closest datacenters mitigates the problem. However, frequent interactions between distant users lead to frequent inter-datacenter communication and hence long service latencies. In this paper, we aim to reduce inter-datacenter communications while still achieving low service latency. We first verify the benefits of the new model and present OSN typical properties that underlie the basis of our design. We then propose Selective Data replication mechanism in Distributed Datacenters ( $SD^3$ ). Since replicas need inter-datacenter data updates, datacenters in  $SD^3$  jointly consider update rates and visit rates to select user data for replication";" furthermore, $SD^3$  atomizes users’ different types of data (e.g., status update, friend post, music) for replication, ensuring that a replica always reduces inter-datacenter communication. $SD^3$  also incorporates three strategies to further enhance its performance: locality-aware multicast update tree, replica deactivation, and datacenter congestion control. The results of trace-driven experiments on the real-world PlanetLab testbed demonstrate the higher efficiency and effectiveness of $SD^3$  in comparison to other replication methods and the effectiveness of its three schemes."",""1558-2183"","""",""10.1109/TPDS.2015.2485266"",""US National Science Foundation(grant numbers:CNS-1254006,CNS-1249603,CNS-1049947,CNS-0917056,CNS-1025652)"; Microsoft Research Faculty Fellowship(grant numbers:8300751);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7286841"",""Social networks";datacenter;scalability;data replication;"locality"",""Facebook";Videos;Distributed databases;Data models;Standards;"Load modeling"","""",""29"","""",""53"",""IEEE"",""1 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Shadow/Puppet Synthesis: A Stepwise Method for the Design of Self-Stabilization,""A. Klinkhamer";" A. Ebnenasir"",""Department of Computer Science, Michigan Technological University, Houghton, MI";" Department of Computer Science, Michigan Technological University, Houghton, MI"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3338"",""3350"",""This paper presents a novel two-step method for automated design of self-stabilization. The first step enables the specification of legitimate states and an intuitive (but imprecise) specification of the desired functional behaviors in the set of legitimate states (hence the term “shadow”). After creating the shadow specifications, we systematically introduce the main variables and the topology of the desired self-stabilizing system. Subsequently, we devise a parallel and complete backtracking search towards finding a self-stabilizing solution that implements a precise version of the shadow behaviors, and guarantees recovery to legitimate states from any state. To the best of our knowledge, the shadow/puppet synthesis is the first sound and complete method that exploits parallelism and randomization along with the expansion of the state space towards generating self-stabilizing systems that cannot be synthesized with existing methods. We have validated the proposed method by creating both a sequential and a parallel implementation in the context of a software tool, called Protocon. Moreover, we have used Protocon to automatically design three new self-stabilizing protocols that we conjecture to require the minimal number of states per process to achieve stabilization (when processes are deterministic): 2-state maximal matching on bidirectional rings, 5-state token passing on unidirectional rings, and 3-state token passing on bidirectional chains."",""1558-2183"","""",""10.1109/TPDS.2016.2536023"",""NSF(grant numbers:CCF-1116546)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422153"",""Self-stabilization";distributed computing;"program synthesis"",""Protocols";Convergence;Algorithm design and analysis;Design methodology;Instruction sets;Topology;"Parallel processing"","""",""6"","""",""35"",""IEEE"",""29 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Shield: A Reliable Network-on-Chip Router Architecture for Chip Multiprocessors,""P. Poluri";" A. Louri"",""Department of Electrical and Computer Engineering, University of Arizona, Tucson, AZ";" Department of Electrical and Computer Engineering, University of Arizona, Tucson, AZ"",""IEEE Transactions on Parallel and Distributed Systems"",""8 Sep 2016"",""2016"",""27"",""10"",""3058"",""3070"",""The increasing number of cores on a chip has made the network on chip (NoC) concept the standard communication paradigm for chip multiprocessors. A fault in an NoC leads to undesirable ramifications that can severely impact the performance of a chip. Therefore, it is vital to design fault tolerant NoCs. In this paper, we present Shield , a reliable NoC router architecture that has the unique ability to tolerate both hard and soft errors in the routing pipeline using techniques such as spatial redundancy, exploitation of idle cycles, bypassing of faulty resources and selective hardening. Using Mean Time to Failure and Silicon Protection Factor metrics, we show that Shield is six times more reliable than the baseline-unprotected router and is at least 1.5 times more reliable than existing fault tolerant router architectures. We introduce a new metric called Soft Error Improvement Factor and show that the soft error tolerance of Shield has improved by three times in comparison to the baseline-unprotected router. This reliability improvement is accomplished by incurring an area and power overhead of 34 and 31 percent respectively. Latency analysis using SPLASH-2 and PARSEC reveals that in the presence of faults, latency increases by a modest 13 and 10 percent respectively."",""1558-2183"","""",""10.1109/TPDS.2016.2521641"",""NSF(grant numbers:1547034,1547035,1547036,1600820)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7390298"",""Network-on-chip";router architecture;hard faults;soft errors;"mean time to failure"",""Ports (Computers)";Pipelines;Computer architecture;Routing;Fault tolerance;Fault tolerant systems;"Circuit faults"","""",""25"","""",""61"",""IEEE"",""25 Jan 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"SPA: A Secure and Private Auction Framework for Decentralized Online Social Networks,""A. Thapa"; W. Liao; M. Li; P. Li;" J. Sun"",""Department of Electrical Engineering, Tuskegee University, Tuskegee, AL"; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH; Department of Computer Science and Engineering, University of Nevada, Reno, NV; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH;" Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, TN"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2394"",""2407"",""The security and privacy threats on e-commerce have attracted intensive attention recently. The explosive growth of online social networks (OSNs) has made them potential new great marketplaces for e-commerce, which, however, raise serious security and privacyconcerns. This is mainly due to the centralized system architecture where the service provider knows all users’ private data and becomes the single point of failure. To this end, we propose a secure and private auction framework, called SPA, for decentralized online social networks (DOSNs). SPA consists of three phases: identity initiation, buyer-seller matching, and private auction. It requires no trust among the participants but can provide security, privacy, authenticity, non-repudiation, and correctness for the auctions. We analyze the computation and communication complexities of the proposed private auction scheme, which are  $O(n+K)$  for each node where $n$  is the number of bidders and $K$  is the number of pricing points. In contrast, those of previous auction schemes are $O(nK)$  at best. The storage complexity is significantly lower than before as well. Security and privacy of SPA are also analyzed. Extensive experiments are conducted to validate the efficiency of SPA."",""1558-2183"","""",""10.1109/TPDS.2015.2494009"",""U.S. National Science Foundation(grant numbers:CNS-1343220,CNS-1149786,ECCS-1128768)"; Pacific Northwest National Laboratory; U. S. Department of Energy(grant numbers:DE-AC05-76RL01830);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7303967"",""Distributed online social networks";auction;security;"privacy"",""Peer-to-peer computing";Privacy;Protocols;Cryptography;Social network services;"Bridges"","""",""11"","""",""43"",""IEEE"",""26 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Space Shuffle: A Scalable, Flexible, and High-Performance Data Center Network,""Y. Yu";" C. Qian"",""Department of Computer Science, University of Kentucky, Lexington, KY";" Department of Computer Science, University of Kentucky, Lexington, KY"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Oct 2016"",""2016"",""27"",""11"",""3351"",""3365"",""The increasing need of cloud and big data applications requires data center networks to be scalable and bandwidth-rich. Current data center network architectures often use rigid topologies to increase network bandwidth. A major limitation is that they can hardly support incremental network growth. Recent work has been investigating new network architecture and protocols to achieve three important design goals of large data centers, namely, high throughput, routing and forwarding scalability, and flexibility for incremental growth. Unfortunately, existing data center network architectures focus on one or two of the above properties and pay little attention to the others. In this paper, we design a novel flexible data center network architecture, Space Shuffle (S2), which applies greedy routing on multiple ring spaces to achieve high-throughput, scalability, and flexibility. The proposed greedy routing protocol of S2 effectively exploits the path diversity of densely connected topologies and enables key-based routing. Extensive experimental studies show that S2 provides high bisectional bandwidth and throughput, near-optimal routing path lengths, extremely small forwarding state, fairness among concurrent data flows, and resiliency to network failures."",""1558-2183"","""",""10.1109/TPDS.2016.2533618"",""National Science Foundation(grant numbers:CNS-1464335)"; University of Kentucky College of Engineering Startup;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416229"",""Data center networks";routing protocols;"cloud computing"",""Routing";Topology;Routing protocols;Bandwidth;"Throughput"","""",""21"","""",""39"",""IEEE"",""23 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Specification-Based Design of Self-Stabilization,""M. Demirbas";" A. Arora"",""Department of Computer Science and Engineering, University at Buffalo, SUNY, Buffalo, NY";" Department of Computer Science and Engineering, The Ohio State University, Columbus, OH"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""263"",""270"",""Research in system stabilization has traditionally relied on the availability of a complete system implementation. As such, it would appear that the scalability and reusability of stabilization is limited in practice. To redress this perception, in this paper, we show for the first time that system stabilization may be designed knowing only the system specification but not the system implementation. We refer to stabilization designed thus as specification-based design of stabilization and identify “local everywhere specifications” and “convergence refinements” as being amenable to the specification-based design of stabilization. Using our approach, we present the design of Dijkstra's four-state stabilizing token-ring system starting from an abstract fault-intolerant token-ring system. We also present an illustration of automated design of specification-based stabilization on a three-state token-ring system."",""1558-2183"","""",""10.1109/TPDS.2015.2388480"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004085"",""Self-stabilization";Fault-tolerance preserving refinements;Distributed systems;Self-stabilization;fault-tolerance preserving refinements;"distributed systems"",""Convergence";Abstracts;Fault tolerance;Fault tolerant systems;Concrete;Servers;"Transient analysis"","""",""3"","""",""19"",""IEEE"",""7 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Stackelberg Game Approach for Energy-Aware Resource Allocation in Data Centers,""B. Yang"; Z. Li; S. Chen; T. Wang;" K. Li"",""College of Computer Science and Electronic Engineering, Hunan University, National Supercomputing Center in Changsha, Key Laboratory for Embedded and Network Computing of Hunan Province, Changsha, China"; College of Computer Science and Electronic Engineering of Hunan University, National Supercomputing Center in Changsha, Key Laboratory for Embedded and Network Computing of Hunan Province, Changsha, China; College of Computer Science and Electronic Engineering of Hunan University, National Supercomputing Center in Changsha, Key Laboratory for Embedded and Network Computing of Hunan Province, Changsha, China; College of Computer Science and Electronic Engineering of Hunan University, National Supercomputing Center in Changsha, Key Laboratory for Embedded and Network Computing of Hunan Province, Changsha, China;" College of Computer Science and Electronic Engineering, State University of New York, New Paltz, NY"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3646"",""3658"",""Data centers hosting distributed computing systems consume huge amounts of electrical energy, contributing to high operational costs, whereas the utilization of data centers continues to be very low. Moreover, a data center generally consists of heterogeneous servers with different performance and energy. Failure to fully consider the heterogeneity of servers will lead to both sub-optimal energy saving and performance. In this study, we employ game theoretic approaches to model the problem of minimizing energy consumption as a Stackelberg game. In our model, the system monitor, who plays the role of the leader, can maximize profit by adjusting resource provisioning, whereas scheduler agents, who act as followers, can select resources to obtain optimal performance. In addition, we model the problem of minimizing average response time of tasks as a noncooperative game among decentralized scheduler agents as they compete with one another in the sharing resources. Several algorithms are presented to implement the game models. Simulation results demonstrate that the proposed technique has immense potential to improve energy efficiency under dynamic work scenarios without compromising service level agreements."",""1558-2183"","""",""10.1109/TPDS.2016.2537809"",""National Natural Science Foundation of China(grant numbers:61173107)"; National High Technology Research and Development Program of China(grant numbers:2012AA01A301-01); Special Project on the Integration of Industry, Education and Research(grant numbers:2012A090300003); Science and Technology Planning Project of Guangdong Province(grant numbers:2013B090700003);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425237"",""Data centers";dynamic capacity provisioning;energy efficiency;"game theory"",""Servers";Data centers;Energy consumption;Resource management;Time factors;Game theory;Power demand;"Energy efficiency"","""",""59"","""",""46"",""IEEE"",""3 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"STI-BT: A Scalable Transactional Index,""N. Diegues";" P. Romano"",""INESC-ID and Instituto Superior Técnico, Universidade de Lisboa";" INESC-ID and Instituto Superior Técnico, Universidade de Lisboa"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2408"",""2421"",""Distributed Key-Value (DKV) stores have been intensively used to manage online transaction processing on large data-sets. DKV stores provide simplistic primitives to access data based on the primary key of the stored objects. To help programmers to efficiently retrieve data, some DKV stores provide distributed indexes. Besides that, and also to simplify programming such applications, several proposals have provided strong consistency abstractions via distributed transactions. In this paper we present STI-BT, a highly scalable, transactional index for Distributed Key-Value stores. STI-BT is organized as a distributed B$^+$ Tree and adopts an innovative design that allows to achieve high efficiency in large-scale, elastic DKV stores. As such, it provides both the desirable properties identified above, and does so in a far more efficient and scalable way than the few existing state of the art proposals that also enable programmers to have strongly consistent distributed transactional indexes. We have implemented STI-BT on top of an open-source DKV store and deployed it on a public cloud infrastructure. Our extensive study demonstrates scalability in a cluster of $100$  machines, and speed ups with respect to state of the art up to $5.4\times$ ."",""1558-2183"","""",""10.1109/TPDS.2015.2485267"",""Fundação para a Ciência e Tecnologia(grant numbers:UID/CEC/50021/2013)"; GreenTM project(grant numbers:EXPL/EEI-ESS/0361/2013); European project(grant numbers:257784);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7287754"",""Secondary index";distributed transactions;key-value data-store;data locality;B+ tree;"strong consistency"",""Scalability";Clocks;Context;Distributed databases;Load management;"Indexing"","""",""1"","""",""41"",""IEEE"",""2 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Storage SLA Guarantee with Novel SSD I/O Scheduler in Virtualized Data Centers,""H. Park"; S. Yoo; C. -H. Hong;" C. Yoo"",""College of Informatics, Korea University, Seoul, NA, Korea"; Mobile Systems Engineering, Dankook University, Yongin shi, Kyunggi do, Korea; College of Informatics, Korea University, Seoul, NA, Korea;" College of Informatics, Korea University, Seoul, NA, Korea"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2422"",""2434"",""Service level agreements (SLAs) for storage performance in virtualized systems are difficult to guarantee, because different consolidated virtual machines have their own performance requirements. Moreover, hard disk drives (HDDs) in virtualized systems are being replaced by solid-state drives (SSDs). SSDs have higher throughput and lower latency than HDDs";" however, they pose new challenges in terms of SLAs. In this paper, we determine that existing I/O schedulers working with SSDs fail to guarantee SLAs among virtualmachines, and do not effectively utilize the high performance of SSDs. To address this issue, we propose the opportunistic I/O scheduler (OIOS), a novel I/O scheduler for SSDs. OIOS guarantees SLAs and fully utilizes the high performance of SSDs. To support realistic SLAs, OIOS provides diverse SLA support functions, including reservations, limitations, and proportional sharing. In addition, OIOS accepts SLAs that are specified in four measurement types: bandwidth, I/Os per second (IOPS), latency, and utilization. Experimental results show that OIOS increases the aggregated bandwidth of VMs by 80 percent compared to mClock, while achieving a similar level of fairness. In addition, we evaluate the proposed scheduler with realistic benchmarks, such as Filebench and the Yahoo CloudServing Benchmark. OIOS successfully guarantees the requirements of diverse SLAs with different metrics."",""1558-2183"","""",""10.1109/TPDS.2015.2493524"",""Institute for Information & communications Technology Promotion(IITP)"; Korea government(grant numbers:R0126-15-1066); Korea University; National Research Foundation of Korea; Korean government(grant numbers:2010-0029180); KREONET;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7303970"",""I/O scheduler";solid-state drives;storage system;virtualized environment;"cloud computing"",""Bandwidth";Performance evaluation;Servers;Ash;Virtual machine monitors;"Benchmark testing"","""",""9"","""",""33"",""IEEE"",""26 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Strategy Configurations of Multiple Users Competition for Cloud Service Reservation,""C. Liu"; K. Li; C. Xu;" K. Li"",""College of Information Science and Engineering, Hunan University, and National Supercomputing Center in Changsha, Hunan, China"; College of Information Science and Engineering, Hunan University, and National Supercomputing Center in Changsha, Hunan, China; Department of Electrical and Computer Engineering, Wayne State University, Detroit, MI;" College of Information Science and Engineering, Hunan University, and National Supercomputing Center in Changsha, China"",""IEEE Transactions on Parallel and Distributed Systems"",""18 Jan 2016"",""2016"",""27"",""2"",""508"",""520"",""In this paper, we focus on strategy configurations of multiple users to make cloud service reservation. We consider the problem from a game theoretic perspective and formulate it into a non-cooperative game among the multiple cloud users, in which each user is informed with incomplete information of other users. For each user, we design a utility function which combines the net profit with time efficiency and try to maximize its value. We solve the problem by employing variational inequality (VI) theory and prove that there exists a Nash equilibrium solution set for the formulated game. Then, we propose an iterative proximal algorithm (IPA), which is designed to compute a Nash equilibrium solution. The convergence of the IPA algorithm is also analyzed and we find that it converges to a Nash equilibrium if several conditions are satisfied. Finally, we conduct some numerical calculations to verify our theoretical analysis. The experimental results show that our proposed IPA algorithm converges to a stable state very quickly and improves the utilities of all users to certain extent by configuring a proper request strategy."",""1558-2183"","""",""10.1109/TPDS.2015.2398435"",""National Natural Science Foundation of China(grant numbers:61133005,61432005)"; National Natural Science Foundation of China(grant numbers:61370095,61472124,61202109,61472126,61402400); US National Science Foundation(grant numbers:CCF-1016966);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7027853"",""Cloud service reservation";Nash equilibrium;Non-cooperative game theory;Cloud service reservation;nash equilibrium;non-cooperative game theory;"variational inequality theory"",""Games";Servers;Nash equilibrium;Pricing;Algorithm design and analysis;"Time factors"","""",""74"","""",""31"",""IEEE"",""30 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Suitability Analysis of FPGAs for Heterogeneous Platforms in HPC,""F. A. Escobar"; X. Chang;" C. Valderrama"",""Department of Electronic and Microelectronics, Universite de Mons, Mons, Belgium"; Department of Electronic and Microelectronics, Universite de Mons, Mons, Belgium;" Department of Electronic and Microelectronics, Universite de Mons, Mons, Belgium"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""600"",""612"",""High performance computing (HPC) systems currently integrate several resources such as multi-cores (CPUs), graphic processing units (GPUs) and reconfigurable logic devices, like field programmable gate arrays (FPGAs). The role of the latter two has traditionally being confined to act as secondary accelerators rather than as main execution units. We perform a deep survey around state of the art research and implementation of HPC algorithms";" we extract features relevant to each family and list them as key factors to obtain higher performance. Due to the broad spectra of the survey we only include the most complete references found. We provide a general classification of the 13 HPC families with respect to their needs and suitability for hardware implementation. In addition, we present an analysis based on current and future technology availability as well as in particular aspects identified in the survey. Finally we list general guidelines and opportunities to be accounted for in future heterogeneous designs that employ FPGAs for HPC."",""1558-2183"","""",""10.1109/TPDS.2015.2407896"",""FEDER project";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051218"",""High Performance Computing";FPGA;Heterogeneous Architectures;Design Approach;Suitability;High performance computing;FPGA;heterogeneous architectures;design approach;"suitability"",""Field programmable gate arrays";Graphics processing units;Hardware;Parallel processing;Memory management;"Algorithm design and analysis"","""",""29"","""",""124"",""IEEE"",""27 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Support for Provisioning and Configuration Decisions for Data Intensive Workflows,""L. B. Costa"; S. Al-Kiswany; M. Ripeanu;" H. Yang"",ECE Department—The University of British Columbia"; ECE Department—The University of British Columbia; ECE Department—The University of British Columbia;" ECE Department—The University of British Columbia,""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2725"",""2739"",""System provisioning, resource allocation, and configuration decisions for I/O-intensive workflow applications are complex even for expert users. Users face choices at multiple levels: allocating resources to individual sub-systems (e.g., the application layer, the storage layer) as well as configuring each of these optimally (e.g., replication level, chunk size, caching policies in case of storage) all having a large impact on the overall application performance. This paper presents a solution to address the problem of supporting these provisioning, allocation and configuration decisions for workflow applications. To enable selecting a good choice in a reasonable time, we propose an approach that accelerates the exploration of the configuration space based on a low-cost performance predictor that estimates total execution time of a workflow application in a given setup. We evaluate the predictor in a number of different scenarios including the Montage application: a workflow composed of over 7,500 tasks structured in 10 different stages with varying characteristics. Our evaluation shows that: (i) the predictor is effective in identifying the desired system configuration, (ii) it can scale to model a complex workflow application run on a 100-node cluster, while (iii) using orders of magnitude less resources than running the actual application. Additionally, we extend the predictor to estimate the energy usage of the system, and we present our experience with incorporating it in the development process of a distributed storage system."",""1558-2183"","""",""10.1109/TPDS.2015.2497693"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7317779"",""Storage systems";workflow applications;data-intensive;performance prediction;"storage provisioning"",""Accuracy";Resource management;Predictive models;Benchmark testing;Data models;Space exploration;"Complexity theory"","""",""1"","""",""41"",""IEEE"",""4 Nov 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Supporting Soft Real-Time Sporadic Task Systems on Uniform Heterogeneous Multiprocessors with No Utilization Loss,""G. Tong";" C. Liu"",""Department of Computer Science, Erik Jonsson School of Engineering and Computer Science, The University of Texas at Dallas 800 W. Campbell Road"; MS EC31 Richardson, TX; Department of Computer Science, Erik Jonsson School of Engineering and Computer Science, The University of Texas at Dallas 800 W. Campbell Road;" MS EC31 Richardson, TX"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2740"",""2752"",""Uniform heterogeneous multicore architectures are becoming increasingly popular due to their potential of achieving high performance and energy efficiency compared to the homogeneous multicore architectures. In such systems, the real-time scheduling problem becomes more challenging because processors have different speeds. Prior research on uniform heterogeneous multiprocessor real-time scheduling has focused on hard real-time systems, where, significant processing capacity may have to be sacrificed in the worst-case to ensure that all deadlines are met. As meeting hard deadlines is overkill for many soft real-time systems in practice, this paper shows that on soft real-time uniform heterogeneous multiprocessors, bounded response times can be ensured for globally-scheduled sporadic task systems with no utilization loss. A GEDF-based scheduling algorithm, named as GEDF-H, is presented and response time bounds are established under both preemptive and non-preemptive GEDF-H scheduling. Extensive experiments show that the magnitude of the derived response time bound is reasonable, often smaller than four task relative deadlines. To the best of our knowledge, this paper is the first to show that soft real-time sporadic task systems can be supported on uniform heterogeneous multiprocessors without utilization loss under global scheduling, and with reasonable predicted response times."",""1558-2183"","""",""10.1109/TPDS.2015.2503278"",""University of Texas at Dallas";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336563"",""Scheduling";multiprocessor;real-time;"modeling and prediction"",""Program processors";Processor scheduling;Time factors;Real-time systems;Job shop scheduling;"Multicore processing"","""",""15"","""",""17"",""IEEE"",""24 Nov 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Task Scheduling for Maximizing Performance and Reliability Considering Fault Recovery in Heterogeneous Distributed Systems,""C. -Y. Chen"",""Department of Computer Science and Information Engineering, National Cheng Kung University, No. 1, Ta-Hsueh Road, Tainan, Taiwan, ROC"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""521"",""532"",""Machine and network failures worsen the results of executing applications on system. Therefore, the reliability of applications on system is an important issue. The recovery of failed machines may increase processing time. This work studies the expected makespan to schedule tasks in heterogeneous distributed systems. A task may be replicated many times to reduce the expected execution time. A two-phase algorithm is proposed. The first phase uses a linear program formulation and a rounding procedure to obtain a favorable allotment to minimize the expected makespan. The second phase applies a scheduling method that is based on the expected executed time and the communication time. During execution, two strategies are considered. In the first strategy, no replication of a task on a set of processors can be stopped. In the second strategy, once a replication of a task has been completed, the other replications of the task are immediately aborted. A comparison reveals that the proposed algorithm significantly outperformed previously proposed algorithms in terms of schedule length ratio, reliability and speedup."",""1558-2183"","""",""10.1109/TPDS.2015.2403861"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7042339"",""Scheduling algorithm";heterogeneous systems;reliability;precedence constraints;Scheduling algorithm;heterogeneous systems;reliability;"precedence constraints"",""Program processors";Reliability;Schedules;Scheduling algorithms;Clustering algorithms;"Computer network reliability"","""",""37"","""",""31"",""IEEE"",""13 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"The Edge Weight Computation with MapReduce for Extracting Weighted Graphs,""Y. Feng"; J. Wang; Z. Zhang; H. Zhong; Z. Ming; X. Yang;" R. Mao"",""College of Computer Science and Software Engineering and the Guangdong Province Key Laboratory of Popular High Performance Computers, Shenzhen University, Shenzhen, China"; College of Computer Science and Software Engineering and the Guangdong Province Key Laboratory of Popular High Performance Computers, Shenzhen University, Shenzhen, China; Department of Research and Development, Beansmile, Guangzhou, China; Big Data Center, WeBank, Shenzhen, China; College of Computer Science and Software Engineering and the Guangdong Province Key Laboratory of Popular High Performance Computers, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering and the Guangdong Province Key Laboratory of Popular High Performance Computers, Shenzhen University, Shenzhen, China;" College of Computer Science and Software Engineering and the Guangdong Province Key Laboratory of Popular High Performance Computers, Shenzhen University, Shenzhen, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3659"",""3672"",""Automated weighted graph construction from massive data is essential to weighted graph theory based data mining processes, where the edge weight computation is time consuming or even fails to complete on a single machine when necessary resources are exhausted. In addition, existing work lacks of the measurement on the accuracy of the edge weights, which represents the graph accuracy and affects the following data mining results. This paper describes the classification, implementation and evaluation of edge weight computation algorithms with MapReduce Framework, which is a powerful parallel and distributed processing model. First, a classification of the edge weight computation algorithms is developed and how they can be applied on MapReduce is also discussed. Then we propose comprehensive measurements on the edge weight accuracy in terms of the number of edges, strength distribution, community structure, Hop-plot and effective diameters. Finally, a performance study has been conducted to evaluate these algorithms in terms of memory and disk usage, execution time and accuracy using a real massive social network application dataset. The results are presented and discussed. Our comparison results can help find out the most effective parallel and distributed edge weight computation algorithm for constructing a weighted graph for a given massive dataset."",""1558-2183"","""",""10.1109/TPDS.2016.2536024"",""Shenzhen Science and Technology Foundation(grant numbers:JCYJ20150324140036842,JCYJ2015,0529164656096JCYJ201418193546117,JCYJ2014050917,2609174)"; National Natural Science Foundation of China(grant numbers:61103001,61170077,61202377); National Key Technology Research and Development Program; Ministry of Science and Technology of China(grant numbers:2014BAH28F05); Guangdong Province Key Laboratory Project(grant numbers:2012A061400024); Guangdong Natural Science Foundation(grant numbers:2014A030313553); National High Technology Joint Research Program of China(grant numbers:2015AA015305); Science and Technology Planning Project of Guangdong Province(grant numbers:2013B090500055); National High Technology Joint Research Program of China(grant numbers:2015AA015305); NSF; Guangdong Province Joint Project(grant numbers:U1301252);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422158"",""Weighted graph extraction";edge weight computation;similarity measurement;MapReduce;"massive data analysis"",""Data mining";Feature extraction;Weight measurement;Distributed databases;Data analysis;"Graph theory"","""",""3"","""",""31"",""IEEE"",""29 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;
"The Extra, Restricted Connectivity and Conditional Diagnosability of Split-Star Networks,""L. Lin"; L. Xu; S. Zhou;" S. -Y. Hsieh"",""School of Mathematics and Computer Science and are also with the Key Laboratory of Network Security and Cryptology, Fujian Normal University, Fuzhou, Fujian, P. R. China"; School of Mathematics and Computer Science and are also with the Key Laboratory of Network Security and Cryptology, Fujian Normal University, Fuzhou, Fujian, P. R. China; School of Mathematics and Computer Science and are also with the Key Laboratory of Network Security and Cryptology, Fujian Normal University, Fuzhou, Fujian, P. R. China;" Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""533"",""545"",""Connectivity is a classic measure for fault tolerance of a network in the case of vertices failures. Extra connectivity and restricted connectivity are two important indicators of the robustness of a multi-processor system in presence of failing processors. An interconnection network's diagnosability is an important measure of its self-diagnostic capability. The conditional diagnosability is widely accepted as a new measure of diagnosability by assuming that any fault-set cannot contain all neighbors of any node in a multiprocessor system. In this paper, we analyze the combinatorial properties and fault tolerance ability for the Split-Star Network, denoted by Sn2, a well-known interconnection network proposed for multiprocessor systems, establish the g-extra connectivity, where 1 ≤ g ≤ 3. We also determine the h-restricted connectivity (h = 1";" 2), and prove that the conditional diagnosability of Sn2 (n ≥ 4) is 6n - 16 under the comparison model, which is about three times of the Sn2's traditional diagnosability. As a product, the strong diagnosability of Sn2 is also obtained."",""1558-2183"","""",""10.1109/TPDS.2015.2400459"",""National Natural Science Foundation of China(grant numbers:61072080,U1405255)"; Natural Science Foundation of Fujian Province(grant numbers:2013J01221,2013J01222); Fujian Normal University Innovative Research Team(grant numbers:IRTL1207); Fujian Normal University;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7031970"",""Fault tolerance";System-level diagnosis;Extra connectivity;Restricted connectivity;Conditional diagnosability;Split-Star Networks;Comparison model;Fault tolerance;system-level diagnosis;extra connectivity;restricted connectivity;conditional diagnosability;split-star networks;"comparison model"",""Program processors";Fault tolerance;Fault tolerant systems;Multiprocessing systems;Artificial neural networks;Multiprocessor interconnection;"Network topology"","""",""64"","""",""65"",""IEEE"",""5 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;
"The Server Provisioning Problem for Continuous Distributed Interactive Applications,""H. Zheng";" X. Tang"",""School of Computer Engineering, Nanyang Technological University, Singapore";" School of Computer Engineering, Nanyang Technological University, Singapore"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""271"",""285"",""In this paper, we study the server provisioning problem for continuous Distributed Interactive Applications (DIAs) whose application states not only change because of the operations performed by participants, but also evolve along with the passing of time. We focus on finding the locations of servers for hosting continuous DIAs, with the goals of optimizing the interactivity performance while fulfilling the consistency and fairness requirements. We show that the server provisioning problem is challenging by presenting its NP-hardness and non-approximability results under several conditions. We propose two efficient server placement algorithms and analyze their approximation ratios. The approximation ratio of the proposed M-BETTER algorithm is quite close to a lower bound for any polynomial-time algorithm. We also conduct experimental evaluations to compare the proposed algorithms with several baseline server placements."",""1558-2183"","""",""10.1109/TPDS.2015.2388473"",""Singapore Ministry of Education Academic Research(grant numbers:MOE2013-T2-2-067)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7001654"",""Distributed interactive application";server placement;interactivity;approximation algorithm;Distributed interactive application;server placement;interactivity;"approximation algorithm"",""Servers";Approximation algorithms;Approximation methods;Algorithm design and analysis;Synchronization;Delays;"Games"","""",""12"","""",""30"",""IEEE"",""6 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Throughput Assurance for Multiple Body Sensor Networks,""Z. Ren"; X. Qi; G. Zhou; H. Wang;" D. T. Nguyen"",""Synopsys, Inc., Durham, NC"; Department of Computer Science, College of William and Mary, Williamsburg, VA; Department of Computer Science, College of William and Mary, Williamsburg, VA; Department of Electrical and Computer Engineering;" Department of Computer Science, College of William and Mary, Williamsburg, VA"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""546"",""557"",""Existing research has demonstrated that inter-body sensor network (inter-BSN) information sharing among coexisting BSNs can enhance applications' performance and save energy. However, how to achieve effective inter-BSN information sharing through wireless communication is a challenging task. On one hand, a BSN should be able to discover neighboring BSNs and establish inter-BSN links with quality of service (QoS) assurances. On the other hand, a BSN should be able to prevent the QoS of intraand inter-BSN links from being degraded by multiple BSNs' mutual interference. In this paper, we propose BuddyQoS, a framework that provides network throughput assurances for coexisting and shared buddy BSNs. In particular, BuddyQoS accurately estimates and adaptively schedules wireless resources to meet the throughput requirements of all interand intra-BSN links. Our trace-driven experiment results demonstrate that BuddyQoS outperforms the default CSMA solution in the standard TinyOS-2.x releases in terms of providing throughput assurances."",""1558-2183"","""",""10.1109/TPDS.2015.2408611"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7054555"",""Body Sensor Network";Protocol Design;Quality of Service;Resource Management;Body sensor network;protocol design;quality of service;"resource management"",""Throughput";Receivers;Quality of service;Transmitters;Wireless communication;Wireless sensor networks;"Sensors"","""",""7"","""",""46"",""IEEE"",""4 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Throughput-Driven Partitioning of Stream Programs on Heterogeneous Distributed Systems,""V. T. N. Nguyen";" R. Kirner"",""University of Hertfordshire, United Kingdom";" University of Hertfordshire, United Kingdom"",""IEEE Transactions on Parallel and Distributed Systems"",""11 Feb 2016"",""2016"",""27"",""3"",""913"",""926"",""Graph partitioning is an important problem in computer science and is of NP-hard complexity. In practice it is usually solved using heuristics. In this article we introduce the use of graph partitioning to partition the workload of stream programs to optimise the throughput on heterogeneous distributed platforms. Existing graph partitioning heuristics are not adequate for this problem domain. In this article we present two new heuristics to capture the problem space of graph partitioning for stream programs to optimise throughput. The first algorithm is an adaptation of the well-known Kernighan-Lin algorithm, called KL-Adapted (KLA), which is relatively slow. As a second algorithm we have developed the Congestion Avoidance (CA) partitioning algorithm, which performs reconfiguration moves optimised to our problem type. We compare both KLA and CA with the generic meta-heuristic Simulated Annealing (SA). All three methods achieve similar throughput results for most cases, but with significant differences in calculation time. For small graphs KLA is faster than SA, but KLA is slower for larger graphs. CA on the other hand is always orders of magnitudes faster than both KLA and SA, even for large graphs. This makes CA potentially useful for re-partitioning of systems during runtime."",""1558-2183"","""",""10.1109/TPDS.2015.2416726"",""Asynchronous and Dynamic Virtualization through performance ANalysis to support Concurrency Engineering(grant numbers:IST-2010-248828)"; ConstRaint and Application driven Framework for Tailoring Embedded Real-time Systems(grant numbers:295371);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7069261"",""Stream programs, throughput optimisation, graph partitioning, simulated annealing"",""Throughput";Partitioning algorithms;Streaming media;Programming;Schedules;"Cost function"","""",""5"","""",""47"",""OAPA"",""26 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"TIGER: Thermal-Aware File Assignment in Storage Clusters,""A. Chavan"; M. I. Alghamdi; X. Jiang; X. Qin; M. Qiu; M. Jiang;" J. Zhang"",""Department of Computer Science and Software Engineering, Auburn University, Auburn, AL"; Department of Computer Science, Al-Baha University, Al-Baha City, Kingdom of Saudi Arabia; Department of Computer Science and Software Engineering, Auburn University, Auburn, AL; Department of Computer Science and Software Engineering, Auburn University, Auburn, AL; Department of Computer Science, Pace University, NY, New York; College of Mathematics and Computer Science, Wuhan Textile University, Wuhan, China;" School of Computer Science and Technology, Taiyuan University of Science and Technology, Taiyuan, China"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""558"",""573"",""In this paper, we present a thermal-aware file assignment technique called TIGER for reducing the cooling cost of storage clusters in data centers. We show that peak inlet temperatures of storage nodes depend on not only CPU utilization but also I/O activities, which rely on file assignments in a cluster. The TIGER scheme aims to lower peak inlet temperatures of storage clusters by dynamic thermal management through file placements. TIGER makes use of cross-interference coefficients to estimate the re-circulation of hot air from the outlets to the inlets of data nodes. TIGER first calculates the thresholds of disks in each data node based on its contribution to heat re-circulation in a data center. TIGER undertakes two steps to achieve high I/O performance while reducing cooling cost. First, TIGER assigns groups of files with similar service times to shorten I/O response times. Second, TIGER ensures that load imbalance does not exceed a specified threshold. We evaluate performance of TIGER in terms of both cooling energy conservation and response time of a storage cluster. Our results confirm that TIGER reduces cooling-power requirements for clusters by offering about 10 to 15 percent cooling-energy savings without significantly degrading I/O performance."",""1558-2183"","""",""10.1109/TPDS.2015.2409872"",""US National Science Foundation"; CAREER(grant numbers:CCF-0845257); CSR(grant numbers:CNS-0917137); CSR(grant numbers:CNS-0757778); CPA(grant numbers:CCF-0742187); CyberTrust(grant numbers:CNS-0831502); CRI(grant numbers:CNS-0855251); CI-TEAM(grant numbers:OCI-0753305); CCLI(grant numbers:DUE-0837341); SFS(grant numbers:DUE-0830831); Al-Baha University; NSF(grant numbers:CNS-1457506,CNS-1359557);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7054504"",""Clustered Storage";Heat Re-circulation.;Clustered storage system;"heat re-circulation"",""Heating";Cooling;Temperature distribution;Power demand;Thermal management;Temperature measurement;"Servers"","""",""11"","""",""37"",""IEEE"",""4 Mar 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;
"TLIA: Efficient Reconfigurable Architecture for Control-Intensive Kernels with Triggered-Long-Instructions,""L. Liu"; J. Wang; J. Zhu; C. Deng; S. Yin;" S. Wei"",""Institute of Microelectronics, Tsinghua University, Beijing, China"; Institute of Microelectronics, Tsinghua University, Beijing, China; Institute of Microelectronics, Tsinghua University, Beijing, China; Institute of Microelectronics, Tsinghua University, Beijing, China; Institute of Microelectronics, Tsinghua University, Beijing, China;" Institute of Microelectronics, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""2143"",""2154"",""Coarse-Grained Reconfigurable Architectures (CGRAs), which provide high performance, low power and flexibility, is viewed as a promising trend for computing. CGRAs are mostly employed to process compute-intensive kernels because of their inefficiency for control flows. Various methods have been proposed to alleviate this problem, and triggered instruction is one of the state-of-the-art techniques. In this paper, a reconfigurable architecture called Triggered-Long-Instruction Architecture (TLIA) is proposed to enhance the triggered instructions with parallel condition method. In the proposed architecture, triggered instruction set is employed on processing elements (PEs). In this way, over-serialized execution and branch instructions are both eliminated. In the meanwhile, each PE has an improved data-path with three ALUs which is inspired by the parallel condition method. In this way, the amount of parallelism inside each control flow is increased by paralleling predicate computations and predicated operations. Moreover, multiple triggered instructions, which may have internal control dependence, can be executed on PEs in parallel. The strategy of issuing instructions is implemented in hardware, and verified by FPGA. Experimental results show that the performance is improved by 20.9 to 140.0 percent, the area is reduced by 24.5 percent, and the power is reduced by 32.5 percent over the equivalent Triggered Instruction Architecture (TIA)."",""1558-2183"","""",""10.1109/TPDS.2015.2477841"",""China National High Technologies Research Program(grant numbers:2012AA012701)"; State Grid Cooperation of China(grant numbers:SGRI-WD-71-13-014/008/010/011);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7254223"",""Reconfigurable architecture";triggered instruction;predicate execution;control flow;Reconfigurable architecture;triggered instruction;predicate execution;"control flow"",""Hardware";Registers;Reconfigurable architectures;Kernel;Radiation detectors;"Parallel processing"","""",""9"","""",""23"",""OAPA"",""10 Sep 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;
"TMACS: A Robust and Verifiable Threshold Multi-Authority Access Control System in Public Cloud Storage,""W. Li"; K. Xue; Y. Xue;" J. Hong"",""Department of Electrical Engineering and Computer Science, University of Science and Technology of China, Hefei, China"; Department of Electrical Engineering and Computer Science, University of Science and Technology of China, Hefei, China; Department of Electrical Engineering and Computer Science, University of Science and Technology of China, Hefei, China;" Department of Electrical Engineering and Computer Science, University of Science and Technology of China, Hefei, China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1484"",""1496"",""Attribute-based Encryption (ABE) is regarded as a promising cryptographic conducting tool to guarantee data owners’ direct control over their data in public cloud storage. The earlier ABE schemes involve only one authority to maintain the whole attribute set, which can bring a single-point bottleneck on both security and performance. Subsequently, some multi-authority schemes are proposed, in which multiple authorities separately maintain disjoint attribute subsets. However, the single-point bottleneck problem remains unsolved. In this paper, from another perspective, we conduct a threshold multi-authority CP-ABE access control scheme for public cloud storage, named TMACS, in which multiple authorities jointly manage a uniform attribute set. In TMACS, taking advantage of ($t,n$ ) threshold secret sharing, the master key can be shared among multiple authorities, and a legal user can generate his/her secret key by interacting with any $t$  authorities. Security and performance analysis results show that TMACS is not only verifiable secure when less than  $t$  authorities are compromised, but also robust when no less than  $t$  authorities are alive in the system. Furthermore, by efficiently combining the traditional multi-authority scheme with TMACS, we construct a hybrid one, which satisfies the scenario of attributes coming from different authorities as well as achieving security and system-level robustness."",""1558-2183"","""",""10.1109/TPDS.2015.2448095"",""National Natural Science Foundation of China(grant numbers:61379129,61170231)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130642"",""CP-ABE";(t; n) threshold secret sharing;multi-authority;public cloud storage;access control;CP-ABE;(t,n) threshold secret sharing;multi-authority;public cloud storage;"access control"",""Cloud computing";Access control;Servers;Public key;"Robustness"","""",""101"","""",""36"",""IEEE"",""22 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Token-Based Function Computation with Memory,""S. Salehkaleybar";" S. J. Golestani"",""Department of Electrical Engineering, Sharif University of Technology, Tehran, Iran";" Department of Electrical Engineering, Sharif University of Technology, Tehran, Iran"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1811"",""1823"",""In distributed function computation, each node has an initial value and the goal is to compute a function of these values in a distributed manner. In this paper, we propose a novel token-based approach to compute a wide class of target functions to which we refer as “token-based function computation with memory” (TCM) algorithm. In this approach, node values are attached to tokens and travel across the network. Each pair of travelling tokens would coalesce when they meet, forming a token with a new value as a function of the original token values. In contrast to the coalescing random walk (CRW) algorithm, where token movement is governed by random walk, meeting of tokens in our scheme is accelerated by adopting a novel chasing mechanism. We proved that, compared to the CRW algorithm, the TCM algorithm results in a reduction of time complexity by a factor of at least √(n/log(n) in Erdos-Renyi and complete graphs, and by a factor of log (n)/log(log(n)) in torus networks. Simulation results show that there is at least a constant factor improvement in the message complexity of TCM algorithm in all considered topologies. Robustness of the CRW and TCM algorithms in the presence of node failure is analyzed. We show that their robustness can be improved by running multiple instances of the algorithms in parallel."",""1558-2183"","""",""10.1109/TPDS.2015.2458311"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163357"",""Distributed computation";distributed algorithms;gossip protocols;sensor networks;Distributed computation;distributed algorithms;gossip protocols;"sensor networks"",""Robustness";Network topology;Time complexity;Simulation;Topology;"Computational modeling"","""","""","""",""31"",""IEEE"",""20 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Towards Distributed Optimal Movement Strategy for Data Gathering in Wireless Sensor Networks,""C. -H. Lee"; J. Kwak;" D. Y. Eun"",""Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC"; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC;" Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC"",""IEEE Transactions on Parallel and Distributed Systems"",""14 Jan 2016"",""2016"",""27"",""2"",""574"",""584"",""In this paper, we address how to design a distributed movement strategy for mobile collectors, which can be either physical mobile agents or query/collector packets periodically launched by the sink, to achieve successful data gathering in wireless sensor networks. Formulating the problem as general random walks on a graph composed of sensor nodes, we analyze how much data can be successfully gathered in time under any Markovian random-walk movement strategies for mobile collectors moving over a graph (or network), while each sensor node is equipped with limited buffer space and data arrival rates are heterogeneous over different sensor nodes. In particular, from the analysis, we obtain the optimal movement strategy among a class of Markovian strategies so as to minimize the data loss rate over all sensor nodes, and explain how such an optimal movement strategy can be made to work in a distributed fashion. We demonstrate that our distributed optimal movement strategy can lead to about two times smaller loss rate than a standard random walk strategy under diverse scenarios. In particular, our strategy results in up to 70 percent cost savings for the deployment of multiple collectors to achieve the target data loss rate than the standard random walk strategy."",""1558-2183"","""",""10.1109/TPDS.2015.2407893"",""National Science Foundation(grant numbers:CNS-1217341)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051231"",""Wireless sensor networks";mobile collectors;data gathering;Markovian random-walk movement strategies;distributed optimal movement strategy;network loss probability;Wireless sensor networks;mobile collectors;data gathering;Markovian random-walk movement strategies;distributed optimal movement strategy;"network loss probability"",""Mobile communication";Mobile computing;Mobile agents;Distributed databases;Markov processes;Standards;"Measurement"","""",""15"","""",""34"",""IEEE"",""27 Feb 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Towards Exploring Data-Intensive Scientific Applications at Extreme Scales through Systems and Simulations,""D. Zhao"; N. Liu; D. Kimpe; R. Ross; X. -H. Sun;" I. Raicu"",""Department of Computer Science, Illinois Institute of Technology, Chicago, IL"; Department of Computer Science, Illinois Institute of Technology, Chicago, IL; Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL; Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL; Department of Computer Science, Illinois Institute of Technology, Chicago, IL;" Department of Computer Science, Illinois Institute of Technology, Chicago, IL"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1824"",""1837"",""The state-of-the-art storage architecture of high-performance computing systems was designed decades ago, and with today's scale and level of concurrency, it is showing significant limitations. Our recent work proposed a new architecture to address the I/O bottleneck of the conventional wisdom, and the system prototype (FusionFS) demonstrated its effectiveness on up to 16 K nodes-the scale on par with today's largest supercomputers. The main objective of this paper is to investigate FusionFS's scalability towards exascale. Exascale computers are predicted to emerge by 2018, comprising millions of cores and billions of threads. We built an event-driven simulator (FusionSim) according to the FusionFS architecture, and validated it with FusionFS's traces. FusionSim introduced less than 4 percent error between its simulation results and FusionFS traces. With FusionSim we simulated workloads on up to two million nodes and find out almost linear scalability of I/O performance";" results justified FusionFS's viability for exascale systems. In addition to the simulation work, this paper extends the FusionFS system prototype in the following perspectives: (1) the fault tolerance of file metadata is supported, (2) the limitations of the current system design is discussed, and (3) a more thorough performance evaluation is conducted, such as N-to-1 metadata write, system efficiency, and more platforms such as Amazon Cloud."",""1558-2183"","""",""10.1109/TPDS.2015.2456896"",""US National Science Foundation(grant numbers:OCI-1054974)"; Department of Energy; Office of Advanced Scientific Computer Research(grant numbers:DE-AC02-06CH11357);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7159078"",""Data storage systems";file systems;high performance computing;supercomputers;Data storage systems;file systems;high performance computing;"supercomputers"",""Computer architecture";Fuses;Computational modeling;File systems;Fault tolerance;"Fault tolerant systems"","""",""19"","""",""76"",""IEEE"",""15 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;
"Towards Multistep Electricity Prices in Smart Grid Electricity Markets,""J. Lin"; W. Yu;" X. Yang"",""Department of Comptuer Science and Technology, Xi’an Jiaotong University, Xi’an, Shaanxi, China"; Department of Computer and Information Science, Towson University, 8000 York Road, Towson, MD;" Department of Comptuer Science and Technology, Xi’an Jiaotong University, Xi’an, Shaanxi, China"",""IEEE Transactions on Parallel and Distributed Systems"",""9 Dec 2015"",""2016"",""27"",""1"",""286"",""302"",""The multistep electricity price (MEP) policy has been introduced by many countries to promote energy saving, load balancing, and fairness in electricity consumption. Nonetheless, with the development of the smart grid, how to determine the quantity of electricity and at what price in a step-like fashion has not been fully investigated in the past. To address this issue, in this paper, we introduce two types of MEP models: a one-dimensional MEP model and a two-dimensional MEP model, which can be used to formally analyze and determine the desirable quantities of electricity and pricing in multiple steps. Particularly, in the one-dimensional MEP model, the steps are scaled only by the quantity of electricity whereas in the two-dimensional MEP model, the steps are scaled by both the quantity of electricity and the time when the electricity is used. Based on the proposed MEP models, we further investigate the vulnerability of the electricity market operation and investigate false data injection attacks against electricity prices and charges to consumers. Through an extensive simulation study, our data shows that the proposed MEP models can achieve fairness in electricity consumption, balance loads between peak and non-peak times, and improve electricity resource utilization. Our data also indicates that false data injection attacks can only partially compromise prices in our MEP models, leading to a limited impact on users' charges."",""1558-2183"","""",""10.1109/TPDS.2015.2388479"",""Natural Science Foundation of China(grant numbers:61373115,61402356)"; US National Science Foundation(grant numbers:1117175,1350145);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004067"",""Electricity market";Multistep electricity price;Fairness of electricity consumption;Load balance;False data injection attacks;Electricity market;multistep electricity price;fairness of electricity consumption;load balance;"false data injection attacks"",""Electricity";Load modeling;Smart grids;Energy conservation;Electricity supply industry;Load management;"Data models"","""",""65"","""",""59"",""IEEE"",""7 Jan 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"Towards Practical and Near-Optimal Coflow Scheduling for Data Center Networks,""S. Luo"; H. Yu; Y. Zhao; S. Wang; S. Yu;" L. Li"",""Key Laboratory of Optical Fiber Sensing and Communications, Ministry of Education, University of Electronic Science and Technology of China, Chengdu, P.R.China"; Key Laboratory of Optical Fiber Sensing and Communications, Ministry of Education, University of Electronic Science and Technology of China, Chengdu, P.R.China; Key Laboratory of Optical Fiber Sensing and Communications, Ministry of Education, University of Electronic Science and Technology of China, Chengdu, P.R.China; Key Laboratory of Optical Fiber Sensing and Communications, Ministry of Education, University of Electronic Science and Technology of China, Chengdu, P.R.China; School of IT, Deakin University, Burwood, Vic., Australia;" Key Laboratory of Optical Fiber Sensing and Communications, Ministry of Education, University of Electronic Science and Technology of China, Chengdu, P.R.China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3366"",""3380"",""In current data centers, an application (e.g., MapReduce, Dryad, search platform, etc.) usually generates a group of parallel flows to complete a job. These flows compose a coflow and only completing them all is meaningful to the application. Accordingly, minimizing the average Coflow Completion Time (CCT) becomes a critical objective of flow scheduling. However, achieving this goal in today's Data Center Networks (DCNs) is quite challenging, not only because the schedule problem is theoretically NP-hard, but also because it is tough to perform practical flow scheduling in large-scale DCNs. In this paper, we find that minimizing the average CCT of a set of coflows is equivalent to the well-known problem of minimizing the sum of completion times in a concurrent open shop. As there are abundant existing solutions for concurrent open shop, we open up a variety of techniques for coflow scheduling. Inspired by the best known result, we derive a 2-approximation algorithm for coflow scheduling, and further develop a decentralized coflow scheduling system, D-CAS, which avoids the system problems associated with current centralized proposals while addressing the performance challenges of decentralized suggestions. Trace-driven simulations indicate that D-CAS achieves a performance close to Varys, the state-of-the-art centralized method, and outperforms Baraat, the only existing decentralized method, significantly."",""1558-2183"","""",""10.1109/TPDS.2016.2525767"",""973 Program(grant numbers:2013CB329103)"; 863 Program(grant numbers:2015AA015702,2015AA016102); National Natural Science Foundation of China(grant numbers:61271171,61271165,61571098); Ministry of Education—China Mobile Research Fund(grant numbers:MCM20130131);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399419"",""Coflow";datacenter networks;decentralized;"scheduling"",""Schedules";Job shop scheduling;Bandwidth;Processor scheduling;Scalability;"Real-time systems"","""",""50"","""",""37"",""IEEE"",""4 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Transparent and Optimized Distributed Processing on GPUs,""A. L. R. Tupinambá";" A. Sztajnberg"",""Petrobras, a Brazilian oil and gas company, Rio de Janeiro, Brazil";" Programa de Pós-Graduação em Engenharia Eletrônica – PEL, Maracanã, Rio de Janeiro, RJ,, Brazil"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3673"",""3686"",""DistributedCL is a middleware which enables transparent parallel processing on distributed GPUs. With the support of the DistributedCL middleware an application designed to use the OpenCL API can run in a distributed manner and transparently use remote GPUs without having to change or rebuild the code. The proposed architecture for the DistributedCL middleware is modular, with well-defined layers. A prototype was built according to the architecture, which considered various optimization points, including sending data in batches, network asynchronous communication and asynchronous request to the OpenCL API. The prototype was evaluated using available benchmarks and a specific benchmark, the CLBench, was developed to facilitate the evaluations according to the amount of processed data. The prototype presented good performance, higher when compared to similar proposals, which also consider transparent use of remote GPUs. The data size to be transmitted over the network was the major limiting factor."",""1558-2183"","""",""10.1109/TPDS.2016.2550445"",""FAPERJ"; CNPq;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7447815"",""OpenCL";GPGPU;GPU;middleware;"distributed systems"",""Graphics processing units";Middleware;Performance evaluation;Computer architecture;Programming;Data models;"Distributed processing"","""",""3"","""",""22"",""IEEE"",""5 Apr 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Tuning Heterogeneous Computing Platforms for Large-Scale Hydrology Data Management,""L. Leonard"; K. Madduri;" C. J. Duffy"",""Department of Civil and Environmental Engineering, The Pennsylvania State University, 406 Sackett Building, University Park, PA"; Department of Computer Science and Engineering, The Pennsylvania State University, 343E IST Building, University Park, PA;" Department of Civil and Environmental Engineering, The Pennsylvania State University, 212 Sackett Building, University Park, PA"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2753"",""2765"",""HydroTerre is a research prototype platform developed at Penn State for the hydrology community. It provides access to aggregated scientific data sets that are useful for hydrological modeling and research. HydroTerre's frontend is a web service, and a user query can request creation of a data bundle whose size can vary from a few megabytes to 100's of gigabytes. In this article, we present software tuning and optimization strategies for various hardware configurations of the HydroTerre platform. Our goal is to minimize access time to a wide range of data bundle creation queries from users. We use automated schemes to estimate the computational work required for various queries, and identify the best-performing hardware/software configuration. We hope this study is instructive for researchers developing similar data management cyberinfrastructure in other science and engineering fields."",""1558-2183"","""",""10.1109/TPDS.2015.2499741"",""National Science Foundation"; XSEDE Science Gateways program(grant numbers:TG-EAR120019); NSF(grant numbers:GEO-44417482); NSF(grant numbers:IIS-1344272); EPA(grant numbers:96305901); NOAA(grant numbers:NA10OAR4310166); US National Science Foundation(grant numbers:ACI-1253881);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7327220"",""H.5.2.b benchmarking";H.3.5.b data sharing;H.3.4.b distributed systems;H.2.8.o spatial databases and GIS;H.3.5.e web-based services;"H.4.1.g workflow management"",""Servers";Databases;Software;Hardware;Meteorology;Data models;"Atmospheric modeling"","""",""2"","""",""36"",""IEEE"",""11 Nov 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;
"Two-Phase Low-Energy N-Modular Redundancy for Hard Real-Time Multi-Core Systems,""M. Salehi"; A. Ejlali;" B. M. Al-Hashimi"",""Department of Computer Engineering, Sharif University of Technology, Tehran"; Department of Computer Engineering, Sharif University of Technology, Tehran;" School of Electronics and Computer Science, University of Southampton, Southampton, U.K"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1497"",""1510"",""This paper proposes an N-modular redundancy (NMR) technique with low energy-overhead for hard real-time multi-core systems. NMR is well-suited for multi-core platforms as they provide multiple processing units and low-overhead communication for voting. However, it can impose considerable energy overhead and hence its energy overhead must be controlled, which is the primary consideration of this paper. For this purpose the system operation can be divided into two phases: indispensable phase and on-demand phase. In the indispensable phase only half-plus-one copies for each task are executed. When no fault occurs during this phase, the results must be identical and hence the remaining copies are not required. Otherwise, the remaining copies must be executed in the on-demand phase to perform a complete majority voting. In this paper, for such a two-phase NMR, an energy-management technique is developed where two new concepts have been considered: i) Block-partitioned scheduling that enables parallel task execution during on-demand phase, thereby leaving more slack for energy saving, ii) Pseudo-dynamic slack, that results when a task has no faulty execution during the indispensable phase and hence the time which is reserved for its copies in the on-demand phase is reclaimed for energy saving. The energy-management technique has an off-line part that manages static and pseudo-dynamic slacks at design time and an online part that mainly manages dynamic slacks at run-time. Experimental results show that the proposed NMR technique provides up to 29 percent energy saving and is 6 orders of magnitude higher reliable as compared to a recent previous work."",""1558-2183"","""",""10.1109/TPDS.2015.2444402"",""Sharif University of Technology(grant numbers:G930827)"; EPSRC(grant numbers:EP/K034448/1);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7122343"",""Energy minimization";multi-core systems;real-time and embedded systems;reliability;scheduling;Energy minimization;multi-core systems;real-time and embedded systems;reliability;"scheduling"",""Schedules";Nuclear magnetic resonance;Energy consumption;Real-time systems;Redundancy;"Multicore processing"","""",""35"","""",""39"",""EU"",""11 Jun 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Using Formal Grammars to Predict I/O Behaviors in HPC: The Omnisc'IO Approach,""M. Dorier"; S. Ibrahim; G. Antoniu;" R. Ross"",""ENS Rennes, IRISA, Rennes, France"; Inria, Centre de Rennes Bretagne-Atlanique, France; Inria, Centre de Rennes Bretagne-Atlanique, France;" Argonne National Laboratory, Lemont, IL"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2435"",""2449"",""The increasing gap between the computation performance of post-petascale machines and the performance of their I/O subsystem has motivated many I/O optimizations including prefetching, caching, and scheduling. In order to further improve these techniques, modeling and predicting spatial and temporal I/O patterns of HPC applications as they run has become crucial. In this paper we present Omnisc'IO, an approach that builds a grammar-based model of the I/O behavior of HPC applications and uses it to predict when future I/O operations will occur, and where and how much data will be accessed. To infer grammars, Omnisc'IO is based on StarSequitur, a novel algorithm extending Nevill-Manning's Sequitur algorithm. Omnisc'IO is transparently integrated into the POSIX and MPI I/O stacks and does not require any modification in applications or higher-level I/O libraries. It works without any prior knowledge of the application and converges to accurate predictions of any N future I/O operations within a couple of iterations. Its implementation is efficient in both computation time and memory footprint."",""1558-2183"","""",""10.1109/TPDS.2015.2485980"",""US Department of Energy"; Office of Science; Office of Advanced Scientific Computing Research(grant numbers:DE-AC02-06CH11357);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7289462"",""HPC";storage;I/O;prediction;grammar;"Omnisc'IO"",""Grammar";Context;Predictive models;Prediction algorithms;Hidden Markov models;Libraries;"Prefetching"","""",""15"","""",""36"",""IEEE"",""5 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;
"Verifying Pipelined-RAM Consistency over Read/Write Traces of Data Replicas,""H. Wei"; M. De Biasi; Y. Huang; J. Cao;" J. Lu"",""State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China"; Computational Complexity, Puzzles and Machines organization, Italy; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Hong Kong Polytechnic University;" State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Apr 2016"",""2016"",""27"",""5"",""1511"",""1523"",""Data replication technologies in distributed storage systems introduce the problem of data consistency. For high performance, data replication systems often settle for weak consistency models, such as Pipelined-RAM consistency. To determine whether a data replication system provides Pipelined-RAM consistency, we study the problem of  verifying Pipelined-RAM consistency over read/write traces (VPC, for short). Four variants of VPC (labeled VPC-SU, VPC-MU, VPC-SD, and VPC-MD) are identified according to whether there are Multiple shared variables (or one Single variable) and whether write operations can assign Duplicate values (or only Unique values) to each shared variable. We prove that VPC-SD is $\sf {NP}$ -complete (so is VPC-MD) by reducing the strongly $\sf {NP}$ -complete problem 3-Partition  to it. For VPC-MU, we present the Read-Centric algorithm with time complexity  $O(n^4)$ , where $n$  is the number of operations. The algorithm constructs an operation graph by iteratively applying a rule which guarantees that no overwritten values can be read later. It incrementally processes all the read operations one by one, and exploits the total order between the dictating writes on the same variable to avoid redundant applications of the rule. The experiments have demonstrated its practical efficiency and scalability."",""1558-2183"","""",""10.1109/TPDS.2015.2453985"",""National 973 Program of China(grant numbers:2015CB352202)"; National Science Foundation of China(grant numbers:61272047,91318301,61321491);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152941"",""Pipelined-RAM";consistency model;verification;Pipelined-RAM;consistency model;verification;"replication"",""Schedules";Polynomials;Law;NP-complete problem;Time complexity;"Electronic mail"","""",""3"","""",""25"",""IEEE"",""8 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;
"VINEA: An Architecture for Virtual Network Embedding Policy Programmability,""F. Esposito"; I. Matta;" Y. Wang"",""Advanced Technology Group at Exegy, Inc., St. Louis, MO"; Computer Science Department at Boston University, Boston, MA;" Computer Science Department at Boston University, Boston, MA"",""IEEE Transactions on Parallel and Distributed Systems"",""7 Oct 2016"",""2016"",""27"",""11"",""3381"",""3396"",""Network virtualization has enabled new business models by allowing infrastructure providers to lease or share their physical network. A fundamental management problem that cloud providers face to support customized virtual network (VN) services is the virtual network embedding. This requires solving the (NP-hard) problem of matching constrained virtual networks onto the physical network. In this paper we present VINEA, a policy-based virtual network embedding architecture, and its system implementation. VINEA leverages our previous results on VN embedding optimality and convergence guarantees, and it is based on a network utility maximization approach that separates policies (i.e., high-level goals) from underlying embedding mechanisms: resource discovery, virtual network mapping, and allocation on the physical infrastructure. We show how VINEA can subsume existing embedding approaches, and how it can be used to design novel solutions that adapt to different scenarios, by merely instantiating different policies. We describe the VINEA architecture, as well as our object model: our VINO protocol and the API to program the embedding policies";" we then analyze key representative tradeoffs among novel and existing VN embedding policy configurations, via event-driven simulations, and with our prototype implementation. Among our findings, our evaluation shows how, in contrast to existing solutions, simultaneously embedding nodes and links may lead to lower providers' revenue. We release our implementation on a testbed that uses a Linux system architecture to reserve virtual node and link capacities. Our prototype can be also used to augment existing open-source “Networking as a Service” architectures such as OpenStack Neutron, that currently lacks a VN embedding protocol, and as a policy-programmable solution to the “slice stitching” problem within wide-area virtual network testbeds."",""1558-2183"","""",""10.1109/TPDS.2016.2526999"",""National Science Foundation(grant numbers:CNS-0963974)";" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7401050"",""Network virtualization";virtual network embedding;network management;"cloud computing"",""Prototypes";Protocols;Indium phosphide;III-V semiconductor materials;Cloud computing;Computer architecture;"Resource management"","""",""8"","""",""49"",""IEEE"",""8 Feb 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Virtual Snooping Coherence for Multi-Core Virtualized Systems,""D. Kim"; C. H. Park; H. Kim;" J. Huh"",""Department of Electrical Computer Engineering, University of Wisconsin Madison, Madison, WI"; Department of Computer Science, KAIST, Daejeon, Korea; EMC, USA;" Department of Computer Science, KAIST, Daejeon, Korea"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Jun 2016"",""2016"",""27"",""7"",""2155"",""2167"",""Proliferation of virtualized systems opens a new opportunity to improve the scalability of multi-core architectures. Among the scalability bottlenecks in multi-cores, cache coherence has been one of the most critical problems. Although snoop-based protocols have been dominating commercial multi-core designs, it has been difficult to scale them for more cores, as snooping protocols require high network bandwidth and power consumption for snooping all the caches.In this paper, we propose a novel snoop-based cache coherence protocol, called virtual snooping, for virtualized multi-core architectures. Virtual snooping exploits memory isolation across virtual machines and prevents unnecessary snoop requests from crossing the virtual machine boundaries. Each virtual machine becomes a virtual snoop domain, consisting of a subset of the cores in a system. Although the majority of virtual machine memory is isolated, sharing of cachelines across VMs still occur. To address such data sharing, this paper investigates three factors, data sharing through the hypervisor, virtual machine relocation, and content-based sharing. In this paper, we explore the design space of virtual snooping with experiments on emulated and real virtualized systems including the mechanisms and overheads of the hypervisor. In addition, the paper discusses the scheduling impact on the effectiveness of virtual snooping."",""1558-2183"","""",""10.1109/TPDS.2015.2473173"",""National Research Foundation of Korea"; Korea government(grant numbers:NRF-2010-0025511,NRF-2013R1A2A2A01015514);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7225169"",""Cache coherence";Virtualization;Snoop filtering;Cache coherence;virtualization;"snoop filtering"",""Virtual machine monitors";Coherence;Hardware;Virtualization;Multicore processing;Virtual machining;"Protocols"","""",""1"","""",""24"",""IEEE"",""26 Aug 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Wait Analysis of Distributed Systems Using Kernel Tracing,""F. Giraldeau";" M. Dagenais"",""Department of Computer Engineering, Polytechnique Montreal, Montreal, Québec, Canada";" Department of Computer Engineering, Polytechnique Montreal, Montreal, Québec, Canada"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2450"",""2461"",""We propose a new class of profiler for distributed and heterogeneous systems. In these systems, a task may wait for the result of another task, either locally or remotely. Such wait dependencies are invisible to instruction profilers. We propose a host-based, precise method to recover recursively wait causes across machines, using blocking as the fundamental mechanism to detect changes in the control flow. It relies solely on operating system events, namely scheduling, interrupts and network events. It is therefore capable of observing kernel threads interactions and achieves user-space runtime independence. Given a task, the algorithm computes its active path from the trace, which is presented in an interactive viewer for inspection. We validated our new method with workloads representing major architecture and operating conditions found in distributed programs. We then used our method to analyze the execution behavior of five different distributed systems. We found that the worst case tracing overhead for a distributed application is 18 percent and that the typical average overhead is about 5 percent. The analysis implementation has linear runtime according to the trace size."",""1558-2183"","""",""10.1109/TPDS.2015.2488629"",""Ericsson"; EfficiOS; NSERC;" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7294678"",""Performance measurement";operating systems;tracing;"reverse engineering"",""Synchronization";Kernel;Transforms;Servers;Instruments;Instruction sets;"Clocks"","""",""21"","""",""26"",""OAPA"",""8 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Weighted-Tuple: Fast and Accurate Synchronization for Parallel Architecture Simulators,""M. Moeng"; A. K. Jones;" R. G. Melhem"",""Department of Computer Science, University of Pittsburgh, Pittsburgh, PA"; Department of Computer Science, University of Pittsburgh, Pittsburgh, PA;" Department of Computer Science, University of Pittsburgh, Pittsburgh, PA"",""IEEE Transactions on Parallel and Distributed Systems"",""13 Jul 2016"",""2016"",""27"",""8"",""2462"",""2474"",""Computer architecture research relies on software simulation to evaluate processor performance. Single-threaded simulators have unacceptable simulation times when modeling complex architectures with hundreds of cores. While parallelizing a simulator can improve performance, parallel simulators face the issue of synchronizing threads, which forces them to trade performance for accuracy. We study relaxed synchronization policies for parallel architecture simulators and introduce the weighted-tuple synchronization policy. Weighted-tuple is a distributed synchronization scheme which improves upon existing policies. We evaluate weighted-tuple for two parallel simulator settings: multicore simulation and network-on-chip simulation. For the multicore setting using weighted-tuple synchronization, average simulation time is reduced by $8$  percent over barrier synchronization";" error is also reduced by $28$  percent. For network-on-chip simulation, weighted-tuple synchronization improves simulation speed by  $42$ percent with an $0.3$  percent error increase compared to the barrier baseline."",""1558-2183"","""",""10.1109/TPDS.2015.2494589"",""Division of Computing and Communication Foundations(grant numbers:1064976)"; Division of Emerging Frontiers in Research and Innovation(grant numbers:1038139); Division of Computer and Network Systems(grant numbers:1012070);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7308077"",""Computational modeling, synchronization, hardware, parallel architectures, performance evaluation"",""Synchronization";Instruction sets;Accuracy;Multicore processing;Message systems;"Clocks"","""",""3"","""",""19"",""IEEE"",""27 Oct 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Workload Partitioning for Accelerating Applications on Heterogeneous Platforms,""J. Shen"; A. L. Varbanescu; Y. Lu; P. Zou;" H. Sips"",""Parallel and Distributed Systems Group, Delft University of Technology, the Netherlands"; Informatics Institute, University of Amsterdam, the Netherlands; School of Computer, National University of Defense Technology, China; School of Computer, National University of Defense Technology, China;" Parallel and Distributed Systems Group, Delft University of Technology, the Netherlands"",""IEEE Transactions on Parallel and Distributed Systems"",""5 Aug 2016"",""2016"",""27"",""9"",""2766"",""2780"",""Heterogeneous platforms composed of multi-core CPUs and different types of accelerators, like GPUs and Xeon Phi, are becoming popular for data parallel applications. The heterogeneity of the hardware mix and the diversity of the applications pose significant challenges to exploiting such platforms. In this situation, an effective workload partitioning between processing units is critically important for improving application performance. This partitioning is a function of the hardware capabilities as well as the application and the dataset to be used. In this work, we present a systematic approach to solve the partitioning problem. Specifically, we use modeling, profiling, and prediction techniques to quickly and correctly predict the optimal workload partitioning and the right hardware configuration to use. Our approach effectively characterizes the platform heterogeneity, efficiently determines the accurate partitioning, and easily adapts to new platforms, different application types, and different datasets. Experimental evaluation on 13 applications shows that our approach delivers excellent performance improvement of 1.2 $\times$ –14.6 $\times$  over a single-processor execution, and accurate partitioning with in most cases below 10 percent performance gap versus an oracle-based partitioning."",""1558-2183"","""",""10.1109/TPDS.2015.2509972"","""",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7360199"",""Heterogeneous platforms";workload partitioning;hardware configuration;multi-core CPUs;GPUs;"accelerators"",""Graphics processing units";Hardware;Data transfer;Throughput;Systematics;"Mathematical model"","""",""30"","""",""47"",""IEEE"",""17 Dec 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;
"Workload-Aware Optimal Power Allocation on Single-Chip Heterogeneous Processors,""J. Y. Jang"; H. Wang; E. Kwon; J. W. Lee;" N. S. Kim"",""College of Information and Communication Engineering, Sungkyunkwan University (SKKU), Suwon, Korea"; Department of Electrical and Computer Engineering, University of Wisconsin, Madison, WI; System LSI Buisness, Samsung Electronics, Yongin, Korea; College of Information and Communication Engineering, Sungkyunkwan University (SKKU), Suwon, Korea;" Department of Electrical and Computer Engineering, University of Wisconsin, Madison, WI"",""IEEE Transactions on Parallel and Distributed Systems"",""12 May 2016"",""2016"",""27"",""6"",""1838"",""1851"",""As technology scales below 32 nm, manufacturers began to integrate both CPU and GPU cores in a single chip, i.e., single-chip heterogeneous processor (SCHP), to improve the throughput of emerging applications. In SCHPs, the CPU and the GPU share the total chip power budget while satisfying their own power constraints, respectively. Consequently, to maximize the overall throughput and/or power efficiency, both power budget and workload should be judiciously allocated to the CPU and the GPU. In this paper, we first demonstrate that optimal allocation of power budget and workload to the CPU and the GPU can provide 13 percent higher throughput than the optimal allocation of workload alone for a single-program workload scenario. Second, we also demonstrate that asymmetric power allocation considering per-program characteristics for a multi-programmed workload scenario can provide 9 percent higher throughput or 24 percent higher power efficiency than the even power allocation per program depending on the optimization objective. Last, we propose effective runtime algorithms that can determine near-optimal or optimal combinations of workload and power budget partitioning for both single- and multi-programmed workload scenarios";" the runtime algorithms can achieve 96 and 99 percent of the maximum achievable throughput within 5-8 and 3-5 kernel invocations for single- and multi-programmed workload cases, respectively."",""1558-2183"","""",""10.1109/TPDS.2015.2453965"",""Ministry of Science, ICT & Future Planning"; IT R&D program; MSIP/KEIT(grant numbers:KI001810041244); Research Project on High Performance and Scalable Manycore Operating System(grant numbers:14-824-09-011); Basic Science Research Program(grant numbers:NRF-2014R1A1A1005894); US National Science Foundation(grant numbers:CNS-1217102);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152947"",""Single-chip heterogeneous processor";GPU;dynamic voltage and frequency scaling;Single-chip heterogeneous processor;GPU;dynamic voltage and frequency scaling;runtime system;"multicores"",""Graphics processing units";Throughput;Runtime;Benchmark testing;Resource management;"Kernel"","""",""6"","""",""31"",""IEEE"",""8 Jul 2015"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;
"Xscale: Online X-Code RAID-6 Scaling Using Lightweight Data Reorganization,""G. Zhang"; G. Wu; Y. Lu; J. Wu;" W. Zheng"",""Department of Computer Science and Technology, Tsinghua University, Beijing, China"; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer and Information Sciences, Temple University, Philadelphia, PA;" Department of Computer Science and Technology, Tsinghua University, Beijing, China"",""IEEE Transactions on Parallel and Distributed Systems"",""10 Nov 2016"",""2016"",""27"",""12"",""3687"",""3700"",""Disk additions to a RAID-6 storage system can simultaneously increase the I/O parallelism and expand the storage capacity. To regain a balanced load among both old and new disks, RAID-6 scaling requires moving certain data blocks onto newly added disks. Existing approaches to RAID-6 scaling are restricted by preserving a round-robin data distribution, and require migrating all the data, resulting in an expensive cost for RAID-6 scaling. In this paper, we propose Xscale, a new approach to accelerating X-code RAID-6 scaling by using lightweight data reorganization. Xscale minimizes the number of data blocks that require being moved, while maintaining a uniform data distribution across all disks. Furthermore, Xscale eliminates metadata updates while guaranteeing data consistency and data reliability. Compared with the round-robin approach, Xscale reduces the number of blocks to be moved by 63.689.5 percent, decreases the reorganization time by 35.62-37.26 percent, and reduces the I/O latency by 23.29-37.74 percent while the scaling programs are running in the background. In addition, there is no penalty in the performance of the data layout after scaling using Xscale, compared with the layouts maintained by other existing scaling approaches."",""1558-2183"","""",""10.1109/TPDS.2016.2542806"",""National Grand Fundamental Research 973 Program of China(grant numbers:2014CB340402)"; National Natural Science Foundation of China(grant numbers:61170008,61272055); National High Technology Research and Development Program of China(grant numbers:2013AA01A210);" "",""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7434645"",""RAID-6 scaling";load balance;data migration;data reorganization;"metadata update"",""Data migration";Metadata;Data processing;"Computer crashes"","""",""9"","""",""43"",""IEEE"",""16 Mar 2016"","""","""",""IEEE"",""IEEE Journals""";;;;;;;;;;;;;;;;;;;;;;;;;;;;;